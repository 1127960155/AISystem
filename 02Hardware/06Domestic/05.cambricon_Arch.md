前置声明，本文档不讨论寒武纪公司尚未公布的信息，一切以寒武纪公司官方公布为准，详细文档请参考[寒武纪官方文档](https://developer.cambricon.com/index/document/index/classid/3.html)。

# 寒武纪MLU芯片架构

寒武纪产品架构官方公布的名称分为MLU00 MLU01 MLU02 MLU03，分别对应于1A、1H、1M、以及官方尚未公布型号的MLU370的处理器内核。

![MLU02产品的架构](images/cambricon18.png)

以MLU02的产品为例，不同产品线采用的核心相同，但DRAM、PCIe等都有不同。

## MLU03

以官网所公布的目前（2024.4）为止最新的板卡MLU370为例，下图显示了它的产品形态，板卡之间借助主板的的MLU Link bridge互联，内存采用低功耗的LPDDR5，PCIe采用Gen4.0来与CPU互联。

![产品形态1](images/cambricon07.png)

![产品形态2](images/cambricon08.png)

MLU370-X8智能加速卡是全面升级的数据中心训推一体AI加速卡，基于寒武纪全新一代思元370芯片，接口为PCIe 4.0 X16，是全高全长双宽（FHFL-Dual-Slot）的标准PCIe加速卡，适用于业内最新的CPU平台，可轻松搭载于最先进的人工智能服务器，快速实现 AI算力的部署。MLU370-X8加速卡功耗为250W，可为计算机视觉、自然语言处理、语音等多样化的人工智能应用提供强大算力支持。

MLU370-X8通过MLU-Link™高速网络，组建大规模训练集群，并实现芯片间互联。新一代MLU-Link™，不仅支持板卡上2个思元370芯片间通过MLU-Link™进行通讯，同时也可以通过MLU-Link™桥接卡对外互联，板卡间MLU-Link互联双向总带宽为200GB/s，满足大型AI模型训练的需要。

关于芯粒技术，芯粒英文是Chiplet，是指预先制造好、具有特定功能、可组合集成的晶片（Die），Chiplet也有翻译为“小芯片”，中科院计算所韩银和等2020年时建议将Chiplet翻译为“芯粒”。在集成电路领域，我们的发展水平和国外存在差距，“卡脖子”成了很突出的问题。按摩尔定律去发展、去追赶是一条路，但也可以另辟蹊径。
芯粒集成就是这样的前沿技术。芯粒是指按特定功能进行分解的小芯片，芯粒集成技术则是把制程代际和功能不同的芯粒像搭积木一样组合形成一个芯片去使用。


## MLU03核心架构

寒武纪的 MLU 硬件是面向人工智能应用的领域专用处理器，针对人工智能算法的计算特性和访存特性，设计了高效的指令集、流水线、运算部件和访存部件。与通用处理器相比，MLU 硬件在处理人工智能任务时有更高的性能、灵活性和能效比。MLU 硬件针对人工智能中不同特征的访存数据流设计专用的数据通路和运算部件，实现了不同的数据流之间的隔离；同时向软件暴露了灵活的片上存储空间访问功能，提高了处理效率。

寒武纪硬件的基本组成单元是MLU Core（就是视频中所述的IPU）。每个 MLU Core 是具备完整计算、IO和控制功能的处理器核心，可以独立完成一个计算任务，也可以与其他 MLU Core 协作完成一个计算任务。每4个 MLU Core 核心构成一个 Cluster，在 MLUv02 以及后续架构中，每个 Cluster 内还会包含一个额外的 Memory Core 和一块被 Memory Core 和 4 个 MLU Core 共享的 SRAM（Shared RAM，共享存储单元）。Memory Core 不能执行向量和张量计算指令，只能用于 SRAM 与 DDR （Double Data Rate Synchronous Dynamic Random Access Memory，双倍速率同步动态随机存储器，DDR SDRAM通常简称为DDR） 和 MLU Core 之间的数据传输。

下图中展示了MLU03的核心架构，MLU03采用4个IPU和一个MPU组成一个Cluster（实际上MLU02也是），IPU上有大量的计算单元以及本地scratchpad memory（NeuronRAM WeightRAM），MPU上有SharedRAM，相当于GPU的shared memory。不同Cluster数量可以组成不同的产品形态（云端、边缘端、IP）

![MLU03 Cluster](images/cambricon11.png)

关于MLU03核心架构我们将在下一节中进行更详细的介绍，下面补充一些视频中没有提到的MLU概念

## 软件栈

寒武纪有自己的一套对标nvidia的软件栈，对标CUDA C的编程语言BANG C，对标CuDNN CuBLAS的算子库CNNL，对标NCCL的通信库CNCL，对标TensorRT的推理引擎MagicMind，对标cuda-gdb的调试器cngdb等等。






## 本节视频

<html>
<iframe src="https://player.bilibili.com/player.html?aid=956498914&bvid=BV1op4y157Qf&cid=1209962179&page=1&as_wide=1&high_quality=1&danmaku=0&t=30&autoplay=0" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</html>
