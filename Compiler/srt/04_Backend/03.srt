1
00:00:00,000 --> 00:00:08,320
Hello,大家好,我是宗米

2
00:00:08,320 --> 00:00:11,920
今天我们还是在AI编译器的后端优化

3
00:00:11,920 --> 00:00:14,760
今天我们主要去分享的内容是

4
00:00:14,760 --> 00:00:16,360
算子的调度优化

5
00:00:17,680 --> 00:00:19,520
现在我们来回顾一下

6
00:00:19,520 --> 00:00:21,080
在整个AI编译器里面

7
00:00:21,080 --> 00:00:24,760
现在算子的调度优化其实还在这个位置

8
00:00:24,760 --> 00:00:27,520
而今天或者接下来我要给大家汇报的内容

9
00:00:27,800 --> 00:00:29,920
更多的是集中在不同的parts

10
00:00:29,920 --> 00:00:32,720
不同的一些优化的方式方法

11
00:00:32,720 --> 00:00:35,120
那这一节里面我们更多的是聚焦于

12
00:00:35,120 --> 00:00:36,640
我们的算子的优化

13
00:00:36,640 --> 00:00:38,000
OPS的优化

14
00:00:38,000 --> 00:00:40,160
所以我们可能会更加硬核一点

15
00:00:40,160 --> 00:00:41,440
更加贴近底层一点

16
00:00:41,440 --> 00:00:42,440
不会吧

17
00:00:44,040 --> 00:00:45,400
现在我们回顾一下

18
00:00:45,400 --> 00:00:47,880
AI编译器的后端最主要的组成方式

19
00:00:47,880 --> 00:00:49,920
或者几个优化的一个大的模块

20
00:00:50,520 --> 00:00:52,320
首先我们会把graph IR

21
00:00:52,320 --> 00:00:54,480
就是我们的图的IR图的模式

22
00:00:54,480 --> 00:00:56,440
变成我们的tensor的IR

23
00:00:56,600 --> 00:00:57,840
生成低级的IR

24
00:00:57,840 --> 00:01:00,280
然后给我们的后端的优化去做

25
00:01:00,280 --> 00:01:01,360
那这个后端的优化

26
00:01:01,360 --> 00:01:03,760
就是我们接下来要给大家汇报的内容

27
00:01:03,760 --> 00:01:05,440
接着变成一个lower IR

28
00:01:05,440 --> 00:01:07,560
就是比较低级的机器语言码的IR

29
00:01:07,560 --> 00:01:08,800
然后给我们的后端

30
00:01:08,800 --> 00:01:13,200
后端对应的生成我们不同硬件的一些执行指令

31
00:01:14,880 --> 00:01:16,200
在上一节的内容里面

32
00:01:16,360 --> 00:01:17,640
其实我们去讲了

33
00:01:17,640 --> 00:01:19,640
或者给大家分享了一个调度数

34
00:01:19,640 --> 00:01:22,000
那调度数就是把我们的一些算子

35
00:01:22,360 --> 00:01:24,880
把算子的计算和调度分开

36
00:01:24,880 --> 00:01:28,560
那右边的这个就是对应的算子的一个执行的方式

37
00:01:28,560 --> 00:01:31,600
左边这个就是我们的低级的IR

38
00:01:31,600 --> 00:01:33,280
OPS IR或者tensor IR

39
00:01:33,280 --> 00:01:36,320
当然了每个IR的方式可能不尽相同

40
00:01:36,320 --> 00:01:38,200
所以我们统一叫做调度数

41
00:01:38,200 --> 00:01:41,080
Schedule Trace来代表我们的lower IR

42
00:01:41,080 --> 00:01:42,160
有了这个lower IR

43
00:01:42,320 --> 00:01:43,720
我们就可以对这个IR

44
00:01:43,720 --> 00:01:46,440
或者这个数进行一个编译的优化

45
00:01:46,720 --> 00:01:47,640
编译优化完之后

46
00:01:47,760 --> 00:01:49,480
我们就生成每一个算子

47
00:01:49,480 --> 00:01:52,320
所对应的调度的策略和调度的代码

48
00:01:52,320 --> 00:01:54,360
有了上两节课的基础之后

49
00:01:54,480 --> 00:01:56,120
我们今天主要聚焦的内容

50
00:01:56,120 --> 00:01:58,000
就是算子的调度优化

51
00:01:58,640 --> 00:02:00,360
可以看到其实我们的算子

52
00:02:00,360 --> 00:02:03,000
假设左边这个我们输一个马东梅

53
00:02:03,000 --> 00:02:04,440
那预测的是马东梅

54
00:02:05,280 --> 00:02:07,960
神经网络里面卷积这个算子的实现

55
00:02:08,120 --> 00:02:09,240
就像右边所示

56
00:02:09,240 --> 00:02:10,120
非常复杂

57
00:02:10,120 --> 00:02:12,120
特别是有非常多的fall

58
00:02:12,120 --> 00:02:13,480
非常多的循环

59
00:02:13,480 --> 00:02:16,240
所以我们最重要的特点就是多重循环嵌套

60
00:02:16,240 --> 00:02:18,720
第二个就是没有复杂的控制流

61
00:02:18,720 --> 00:02:20,680
一般都是一些简单的控制流

62
00:02:20,680 --> 00:02:22,360
或者根本就没有控制流

63
00:02:22,680 --> 00:02:25,840
第三个就是神经网络里面传输的时候

64
00:02:26,000 --> 00:02:28,440
是以张量作为一个主要的数据结构

65
00:02:28,440 --> 00:02:30,960
所以它的数据方式或者数据的排布

66
00:02:30,960 --> 00:02:32,120
会非常复杂

67
00:02:33,520 --> 00:02:35,360
而在HiLiD或者TVM里面

68
00:02:35,480 --> 00:02:37,920
有非常多不同的优化的方式

69
00:02:37,920 --> 00:02:40,160
提供给我们去做一个实现

70
00:02:40,160 --> 00:02:42,000
或者做一个初步的拼接的

71
00:02:42,440 --> 00:02:44,600
在正式的去展开这里面的

72
00:02:44,600 --> 00:02:46,200
各种的优化的方式

73
00:02:46,200 --> 00:02:48,760
或者编辑给我们提供的基本的方法之前

74
00:02:49,440 --> 00:02:51,680
我们来看一个基于原码

75
00:02:51,680 --> 00:02:54,040
进行一个修改的一些简单的内容

76
00:02:55,120 --> 00:02:57,920
首先第一个内容就是循环的交换

77
00:02:58,200 --> 00:02:59,480
在多重循环里面

78
00:02:59,480 --> 00:03:01,440
或者在我们的图像叠代里面

79
00:03:01,600 --> 00:03:03,920
我们可以看到假设先便利一个1000

80
00:03:03,920 --> 00:03:05,000
然后再便利200

81
00:03:05,000 --> 00:03:05,560
这个时候

82
00:03:06,040 --> 00:03:08,760
我们内层的循环便利的次数比较少

83
00:03:08,760 --> 00:03:11,720
但是我们外层循环便利的次数非常多

84
00:03:12,040 --> 00:03:15,320
这种方式可能会导致我们内存的消耗比较大

85
00:03:15,360 --> 00:03:17,480
我们可能需要把1万这里面的数据

86
00:03:17,600 --> 00:03:18,720
扔到我们的内存里面

87
00:03:18,720 --> 00:03:21,040
所以我们可以把它进行一个兑换

88
00:03:21,440 --> 00:03:23,160
这种就叫做循环交换

89
00:03:23,160 --> 00:03:24,320
我们先便利200

90
00:03:24,320 --> 00:03:25,440
再便利我们1万

91
00:03:25,960 --> 00:03:27,200
每次我们的编辑器

92
00:03:27,320 --> 00:03:28,520
就把这1万的数据

93
00:03:28,520 --> 00:03:30,000
丢给我们的硬件再去执行

94
00:03:30,000 --> 00:03:31,120
然后从我们的编译站

95
00:03:31,120 --> 00:03:32,240
或者我们堆在里面

96
00:03:32,440 --> 00:03:34,720
再迭代下一个i的数据出来

97
00:03:35,040 --> 00:03:36,560
这种方式可以很好的利用

98
00:03:36,560 --> 00:03:38,320
我们内存或者显存的空间

99
00:03:39,880 --> 00:03:42,520
第二个就是循环变量的实际化

100
00:03:42,520 --> 00:03:44,320
可以看到其实我们在for里面

101
00:03:44,520 --> 00:03:45,880
我们实际化了一个i

102
00:03:45,880 --> 00:03:47,160
再实际化了一个j

103
00:03:47,160 --> 00:03:50,680
但很多时候我们可以把i和j实际化出来

104
00:03:50,960 --> 00:03:52,200
避免每一次迭代

105
00:03:52,360 --> 00:03:54,040
都对它进行一个实际化

106
00:03:54,040 --> 00:03:57,760
接着我们还可能会有一个表达式的外放

107
00:03:59,200 --> 00:04:01,760
表达式的外放可能还是比较简单的

108
00:04:01,760 --> 00:04:04,040
假设我现在有x除以y-1

109
00:04:04,320 --> 00:04:07,080
这个数据其实跟我们的迭代i和j

110
00:04:07,080 --> 00:04:08,480
没有半毛钱关系

111
00:04:08,480 --> 00:04:10,840
所以我们会把这一个表达式

112
00:04:11,080 --> 00:04:13,280
直接外提到循环外面

113
00:04:13,280 --> 00:04:15,680
time等于x除以y-1

114
00:04:15,880 --> 00:04:18,000
这个时候我在迭代循环里面

115
00:04:18,320 --> 00:04:19,400
直接从内存空间

116
00:04:19,400 --> 00:04:20,680
或者在我们的cache里面

117
00:04:20,840 --> 00:04:22,200
读到我们的time里面

118
00:04:22,560 --> 00:04:24,360
以空间换时间的方法

119
00:04:24,360 --> 00:04:26,080
不用每次都进行一个计算

120
00:04:27,760 --> 00:04:30,040
另外我们还有一个循环宗旨

121
00:04:30,320 --> 00:04:32,320
循环宗旨主要是指消除

122
00:04:32,320 --> 00:04:34,720
循环宗旨时候的一个调用方式

123
00:04:35,000 --> 00:04:37,640
这个其实跟刚才的循环变量实际化

124
00:04:37,640 --> 00:04:38,320
比较相像

125
00:04:38,320 --> 00:04:39,320
我这里面int i

126
00:04:39,320 --> 00:04:41,240
那后面i它其实有一个

127
00:04:41,880 --> 00:04:43,000
循环宗旨的方式

128
00:04:43,000 --> 00:04:44,120
循环宗旨一开始

129
00:04:44,120 --> 00:04:46,080
可能直接点size去获取的

130
00:04:46,320 --> 00:04:48,000
这里面我们直接把点size

131
00:04:48,240 --> 00:04:50,120
实际化到我们的循环外面

132
00:04:50,120 --> 00:04:51,080
通过这种方式

133
00:04:51,240 --> 00:04:53,880
去消除我们循环宗旨时候的一个调用

134
00:04:55,480 --> 00:04:56,280
刚才所讲的

135
00:04:56,280 --> 00:04:58,080
只是我们在写算子的时候

136
00:04:58,080 --> 00:05:00,320
可能需要注意的一些触及的功能

137
00:05:00,920 --> 00:05:02,960
有了对刚才一些概念的了解

138
00:05:02,960 --> 00:05:05,720
其实我更建议大家去了解一下CUDA

139
00:05:06,080 --> 00:05:07,960
看看CUDA是怎么写代码的

140
00:05:07,960 --> 00:05:09,680
可能我们在写代码的时候

141
00:05:09,840 --> 00:05:10,880
不一定会用CUDA

142
00:05:10,880 --> 00:05:13,200
因为CUDA主要是针对GPU去使用的

143
00:05:13,560 --> 00:05:15,120
像华为生腾就推出了

144
00:05:15,120 --> 00:05:18,240
自己的DSL Domain Specific Language TBE

145
00:05:18,680 --> 00:05:20,200
成天琪推出的TBM

146
00:05:20,200 --> 00:05:23,800
像这种的Domain Specific Language的方式

147
00:05:24,440 --> 00:05:26,040
通过这些领域专用的语言

148
00:05:26,200 --> 00:05:28,080
我们可以写一些自己的算子

149
00:05:28,080 --> 00:05:30,640
而自己写算子就是我们AI框架

150
00:05:31,000 --> 00:05:31,800
变成了一个图档

151
00:05:32,080 --> 00:05:32,920
或者变成一个

152
00:05:32,920 --> 00:05:34,400
每次单算子调度的时候

153
00:05:34,720 --> 00:05:36,880
都可以去调用我们的一个算子库

154
00:05:36,880 --> 00:05:38,760
然后跑在我们的硬件上面的

155
00:05:39,800 --> 00:05:41,320
由于整个AI编译器

156
00:05:41,320 --> 00:05:42,960
或者在我们的AI框架里面

157
00:05:43,080 --> 00:05:44,760
大部分都是分层结合的

158
00:05:44,920 --> 00:05:46,160
所以很有可能

159
00:05:46,160 --> 00:05:47,840
我们是走了Graph IR之后

160
00:05:48,160 --> 00:05:49,400
再去调我们的WinTime

161
00:05:49,400 --> 00:05:50,960
或者调我们的算子库

162
00:05:51,200 --> 00:05:52,280
不一定在WinTime里面

163
00:05:52,440 --> 00:05:53,840
可能直接调我们的算子库

164
00:05:54,120 --> 00:05:55,560
然后再执行在WinTime里面

165
00:05:56,240 --> 00:05:58,560
最后在我们的硬件上面去跑的

166
00:05:58,840 --> 00:06:00,600
所以说每一层都是分层结合的

167
00:06:00,840 --> 00:06:02,760
大家不要觉得AI编译器里面

168
00:06:02,760 --> 00:06:04,880
每一层我都要实现对应的功能

169
00:06:04,880 --> 00:06:07,800
其实每一层我们都有可替换的方案

170
00:06:08,280 --> 00:06:11,520
或者可替换的对应的开源的项目

171
00:06:12,400 --> 00:06:14,760
现在我们看一下一个正式的内容

172
00:06:14,760 --> 00:06:16,720
也是接下来我要给大家汇报的

173
00:06:17,000 --> 00:06:19,520
就是AI编译器的算子优化

174
00:06:20,960 --> 00:06:22,280
其实算子优化这里面

175
00:06:22,680 --> 00:06:24,720
我对这里面的算子优化的

176
00:06:24,720 --> 00:06:26,040
一个调度的方法

177
00:06:26,040 --> 00:06:27,640
分为三大个类型

178
00:06:27,640 --> 00:06:29,560
第一个就是循环优化

179
00:06:29,560 --> 00:06:31,800
我们叫做loop optimization

180
00:06:32,120 --> 00:06:33,920
第二个就是指令优化

181
00:06:33,920 --> 00:06:35,400
instruction optimization

182
00:06:36,200 --> 00:06:38,240
第三个就是存储的优化

183
00:06:38,240 --> 00:06:39,680
memory optimization

184
00:06:40,040 --> 00:06:42,160
现在我们逐个的去看一下

185
00:06:42,440 --> 00:06:45,240
为啥循环优化会有这么多内容呢

186
00:06:48,000 --> 00:06:50,600
最重要的原因是因为我们计算的特征

187
00:06:50,600 --> 00:06:52,040
特别是对于神经网络

188
00:06:52,040 --> 00:06:54,200
AI编译器里面的计算的特征

189
00:06:54,440 --> 00:06:56,840
我们是以多重循环嵌套

190
00:06:56,840 --> 00:06:58,400
作为一个主要的特点的

191
00:06:58,680 --> 00:07:00,800
第6个是以多维张量计算

192
00:07:01,080 --> 00:07:02,520
作为一个主要的数据结构

193
00:07:02,520 --> 00:07:03,760
所以算子的优化

194
00:07:03,760 --> 00:07:06,000
或者我们的ops optimizer

195
00:07:06,560 --> 00:07:07,480
后端的优化

196
00:07:07,560 --> 00:07:09,160
大部分集中在对我们的

197
00:07:09,160 --> 00:07:12,840
循环便利迭代loop进行一个优化

198
00:07:14,000 --> 00:07:15,560
而优化的方法特别多

199
00:07:15,560 --> 00:07:18,120
我们会对循环进行展开envolving

200
00:07:18,120 --> 00:07:20,360
我们还会对循环进行分块

201
00:07:20,360 --> 00:07:23,160
接着还有循环的重排

202
00:07:23,160 --> 00:07:24,840
reorder 融合fusion

203
00:07:24,840 --> 00:07:26,240
还有拆分split

204
00:07:27,080 --> 00:07:28,680
而指令优化的更多是

205
00:07:28,680 --> 00:07:30,760
对应到具体硬件的芯片

206
00:07:30,760 --> 00:07:31,760
例如向量化

207
00:07:31,760 --> 00:07:33,080
还有张量化

208
00:07:33,520 --> 00:07:35,040
根据硬件的simp

209
00:07:35,040 --> 00:07:36,560
或者simp的方式

210
00:07:36,560 --> 00:07:37,760
进行一个优化的

211
00:07:38,120 --> 00:07:40,080
最后就是存储优化

212
00:07:40,080 --> 00:07:41,520
有可能部分的存储优化

213
00:07:41,520 --> 00:07:42,680
叫做并行的优化

214
00:07:43,200 --> 00:07:44,720
因为cpu跟npu的并行

215
00:07:44,880 --> 00:07:46,800
我们可以变成我们的存储分配

216
00:07:47,320 --> 00:07:48,120
或者存储延迟

217
00:07:48,120 --> 00:07:49,480
隐藏的这种功能

218
00:07:50,040 --> 00:07:51,760
但是这里面大部分的内容

219
00:07:51,920 --> 00:07:53,440
都是跟我们的存储相关的

220
00:07:53,800 --> 00:07:55,200
所以我叫做存储优化

221
00:07:55,200 --> 00:07:57,320
而存储优化主要分为两个功能

222
00:07:57,320 --> 00:07:59,240
第一个就是仿存的延迟

223
00:07:59,880 --> 00:08:01,560
第二个就是存储的分配

224
00:08:03,080 --> 00:08:03,400
好了

225
00:08:03,400 --> 00:08:05,000
今天的内容到这里为止

226
00:08:05,200 --> 00:08:06,880
我们将会在下一节里面

227
00:08:06,880 --> 00:08:08,120
去详细剪开

228
00:08:08,680 --> 00:08:11,600
具体每个雕度优化的方式和方法

229
00:08:12,680 --> 00:08:13,240
谢谢各位

230
00:08:13,680 --> 00:08:14,400
拜了个拜

231
00:08:15,120 --> 00:08:15,840
卷的不行了

232
00:08:15,840 --> 00:08:16,680
卷的不行了

233
00:08:16,680 --> 00:08:18,360
记得一键三连加关注哦

234
00:08:18,680 --> 00:08:19,880
所有的内容都会开源

235
00:08:19,880 --> 00:08:21,520
在下面这条链接里面

236
00:08:22,200 --> 00:08:22,840
拜了个拜

