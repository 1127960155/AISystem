1
00:00:00,000 --> 00:00:09,000
嗨,大家早上好,我是宗明

2
00:00:09,000 --> 00:00:14,000
那在这一节里面呢,我们还是在AI编译器里面的前端优化

3
00:00:14,000 --> 00:00:18,000
今天我要给大家汇报的内容呢,叫做死代码消除

4
00:00:18,000 --> 00:00:24,000
那死代码消除的缩写叫做DCE Datacore Enumeration

5
00:00:24,000 --> 00:00:28,000
今天我主要分开两个内容给大家去汇报的

6
00:00:28,000 --> 00:00:31,000
第一个就是DCE的概念的定义

7
00:00:31,000 --> 00:00:35,000
第二个就是AI编译器里面的DCE是怎么实现的

8
00:00:35,000 --> 00:00:37,000
实不宜迟,我们马上开始

9
00:00:42,000 --> 00:00:47,000
首先第一个内容就是死代码消除DCE的一个概念的定义

10
00:00:47,000 --> 00:00:49,000
那死代码其实很简单

11
00:00:49,000 --> 00:00:54,000
我们理解一下这里面的有一段简单的代码,一个负的函数

12
00:00:54,000 --> 00:00:57,000
那我们看一下这个函数里面实现的哪些功能

13
00:00:57,000 --> 00:01:01,000
首先定义一个A,再定义一个B,接着定义一个C

14
00:01:01,000 --> 00:01:04,000
然后呢C是通过A来去做一个移位的

15
00:01:04,000 --> 00:01:07,000
然后现在呢我们去返回一个between C

16
00:01:07,000 --> 00:01:12,000
接着我又对B进行一个重新的复制,最后返回0

17
00:01:12,000 --> 00:01:14,000
在第八行的时候我已经between C了

18
00:01:14,000 --> 00:01:16,000
所以这里面的函数已经结束

19
00:01:16,000 --> 00:01:19,000
第九行对B进行重新复制

20
00:01:19,000 --> 00:01:22,000
这一句话呢是不会被程序所执行的

21
00:01:22,000 --> 00:01:25,000
所以这一句呢我们叫做死代码

22
00:01:25,000 --> 00:01:29,000
在编译器里面呢我们需要把这个第九行和第十行去掉

23
00:01:29,000 --> 00:01:32,000
因为它是没有任何意义的

24
00:01:33,000 --> 00:01:36,000
一般来说呢死代码消除最普遍的方法呢

25
00:01:36,000 --> 00:01:40,000
是通过预处理器来判断代码是否需要被编译或者执行

26
00:01:40,000 --> 00:01:47,000
那所谓的预处理器呢就是通过代入一个数来决定我们这段程序是否被执行

27
00:01:47,000 --> 00:01:51,000
假设我用下面这么一段函数复制了A,B,C

28
00:01:51,000 --> 00:01:53,000
然后C呢进行一个处理

29
00:01:53,000 --> 00:01:55,000
接着我去判断一个if 0

30
00:01:55,000 --> 00:01:57,000
然后print一句话出来

31
00:01:57,000 --> 00:02:00,000
这个if 0的0模样是false

32
00:02:00,000 --> 00:02:02,000
所以它一般是执行不了的

33
00:02:02,000 --> 00:02:04,000
那789它就是一个死代码

34
00:02:04,000 --> 00:02:08,000
在第七行的时候呢我们就会通过一个预先设置的值

35
00:02:08,000 --> 00:02:11,000
来判断这一段程序呢是否会被执行

36
00:02:11,000 --> 00:02:13,000
像789也是一段死代码

37
00:02:15,000 --> 00:02:18,000
诶,尊敏老师你好,为什么我们要做死代码消除呢?

38
00:02:18,000 --> 00:02:20,000
嗯,这个问题很有意思

39
00:02:20,000 --> 00:02:24,000
我们看一下,首先呢做死代码消除就是避免我们在真正执行的时候

40
00:02:24,000 --> 00:02:27,000
执行一些没有必要没有意义的操作

41
00:02:27,000 --> 00:02:29,000
提高了我们整体的运算的效率

42
00:02:29,000 --> 00:02:32,000
减少我们的运算的开销和时间

43
00:02:32,000 --> 00:02:34,000
那这个是它最重要的作用

44
00:02:34,000 --> 00:02:37,000
第二个呢就是节省不必要的资源分配优化空间

45
00:02:37,000 --> 00:02:39,000
可以看到我们刚才那段程序呢

46
00:02:39,000 --> 00:02:41,000
B它是复制了

47
00:02:41,000 --> 00:02:44,000
但实际上它没有必要去从内存里面去读

48
00:02:44,000 --> 00:02:46,000
也没有必要去存B这一个变量

49
00:02:46,000 --> 00:02:49,000
那最后呢就是节省我们的代码的长度

50
00:02:49,000 --> 00:02:50,000
增加可夺性

51
00:02:50,000 --> 00:02:53,000
把一些没有用的冗余的代码给它删掉

52
00:02:55,000 --> 00:02:56,000
下面我们看看

53
00:02:56,000 --> 00:02:59,000
AI编辑器里面的死代码消除是怎么实现的

54
00:02:59,000 --> 00:03:00,000
AI编辑器呢

55
00:03:00,000 --> 00:03:01,000
最主要的术呢

56
00:03:01,000 --> 00:03:03,000
是我们的计算图

57
00:03:03,000 --> 00:03:05,000
AI编辑器最主要的术呢

58
00:03:05,000 --> 00:03:06,000
是计算图

59
00:03:06,000 --> 00:03:07,000
所以死代码消除呢

60
00:03:07,000 --> 00:03:10,000
可以优化我们计算图的计算和存储效率

61
00:03:10,000 --> 00:03:12,000
就减少我们计算图里面的节点

62
00:03:12,000 --> 00:03:15,000
存一些更小的变量或者权重参数

63
00:03:16,000 --> 00:03:17,000
整体上来说呢

64
00:03:17,000 --> 00:03:19,000
是减快我们整个计算图的结构

65
00:03:19,000 --> 00:03:23,000
方便我们后续的其他优化的Path去进行的

66
00:03:23,000 --> 00:03:25,000
那其实有一点很重要的就是

67
00:03:25,000 --> 00:03:27,000
死代码消除一般不是在

68
00:03:27,000 --> 00:03:30,000
定义神经网络模型的时候所引起的

69
00:03:30,000 --> 00:03:31,000
这句话的意思就是

70
00:03:31,000 --> 00:03:33,000
我们的算法工程师其实没那么傻

71
00:03:33,000 --> 00:03:35,000
写那么多没有用的代码

72
00:03:35,000 --> 00:03:36,000
这些死代码呢

73
00:03:36,000 --> 00:03:40,000
一般来说是其他图优化的Path所造成的

74
00:03:40,000 --> 00:03:41,000
因此呢

75
00:03:41,000 --> 00:03:42,000
死代码消除这个Path呢

76
00:03:42,000 --> 00:03:46,000
一般都会放在其他图优化的Path后面去执行

77
00:03:48,000 --> 00:03:51,000
左边这个就是计算图里面的一部分

78
00:03:51,000 --> 00:03:53,000
现在呢我们有三个算子

79
00:03:53,000 --> 00:03:55,000
一个是OP2,OP3和OP4

80
00:03:55,000 --> 00:03:57,000
它的输入呢有两个

81
00:03:57,000 --> 00:03:58,000
一个是A和B

82
00:03:58,000 --> 00:04:00,000
假设OP3最后的输出呢

83
00:04:00,000 --> 00:04:03,000
是对应我们神经网络图里面的最后的输出

84
00:04:03,000 --> 00:04:04,000
而OP4呢

85
00:04:04,000 --> 00:04:06,000
它就没有了任何输出

86
00:04:06,000 --> 00:04:08,000
就它到这个节点之后就停止了

87
00:04:08,000 --> 00:04:09,000
这个时候呢

88
00:04:09,000 --> 00:04:11,000
我们可以认为输入的张量B

89
00:04:11,000 --> 00:04:13,000
还有我们的OP4算子呢

90
00:04:13,000 --> 00:04:16,000
它其实对应计算图里面的死代码

91
00:04:16,000 --> 00:04:18,000
于是呢我们就可以把它干掉

92
00:04:18,000 --> 00:04:20,000
可以对这个计算图进行优化

93
00:04:20,000 --> 00:04:22,000
最后变成我们右边的这个图

94
00:04:22,000 --> 00:04:23,000
只有两个算子

95
00:04:23,000 --> 00:04:25,000
两个输入的张量

96
00:04:27,000 --> 00:04:28,000
下面值得重点去提一提

97
00:04:28,000 --> 00:04:30,000
或者我之前踩过的坑就是

98
00:04:30,000 --> 00:04:32,000
我们在网络模型训练的时候

99
00:04:32,000 --> 00:04:34,000
跟我们网络模型推理的时候

100
00:04:34,000 --> 00:04:36,000
除了反向图没有用

101
00:04:36,000 --> 00:04:38,000
我们要删除反向图之外呢

102
00:04:38,000 --> 00:04:39,000
训练的时候呢

103
00:04:39,000 --> 00:04:41,000
会产生很多额外的子图

104
00:04:41,000 --> 00:04:42,000
那这个时候呢

105
00:04:42,000 --> 00:04:44,000
我们转换成为推理的时候呢

106
00:04:44,000 --> 00:04:46,000
也会执行死代码消除

107
00:04:46,000 --> 00:04:47,000
帮我们训练的时候用到

108
00:04:47,000 --> 00:04:48,000
但是推理的时候呢

109
00:04:48,000 --> 00:04:51,000
没有用到的一些子图死代码

110
00:04:51,000 --> 00:04:52,000
把它删掉

111
00:04:53,000 --> 00:04:55,000
第二个值得注意的就是

112
00:04:55,000 --> 00:04:57,000
有一些没有用的控制流

113
00:04:57,000 --> 00:04:59,000
也会对它进行删掉

114
00:05:00,000 --> 00:05:01,000
最后呢

115
00:05:01,000 --> 00:05:03,000
我们看一下死代码消除的一个

116
00:05:03,000 --> 00:05:04,000
最简单的算法

117
00:05:04,000 --> 00:05:05,000
那第一步呢

118
00:05:05,000 --> 00:05:08,000
我们输入的是我们的计算图的IR

119
00:05:08,000 --> 00:05:09,000
第二步呢

120
00:05:09,000 --> 00:05:10,000
就是对我们的计算图

121
00:05:10,000 --> 00:05:12,000
进行深度优先编译

122
00:05:12,000 --> 00:05:13,000
那深度优先编译呢

123
00:05:13,000 --> 00:05:15,000
从我们的输出节点出发

124
00:05:15,000 --> 00:05:17,000
去过去我们的逆后续节点

125
00:05:17,000 --> 00:05:18,000
接着呢

126
00:05:18,000 --> 00:05:19,000
去编译这个逆后续节点

127
00:05:19,000 --> 00:05:22,000
去判断我们有没有死代码

128
00:05:22,000 --> 00:05:23,000
如果有的话

129
00:05:23,000 --> 00:05:24,000
我们就把这个死代码删掉

130
00:05:24,000 --> 00:05:26,000
重新去执行步骤一

131
00:05:26,000 --> 00:05:27,000
这个就是最简单

132
00:05:27,000 --> 00:05:28,000
最原始

133
00:05:28,000 --> 00:05:29,000
最naive的算法

134
00:05:31,000 --> 00:05:32,000
接着呢

135
00:05:32,000 --> 00:05:33,000
我们看两个值得注意的点

136
00:05:33,000 --> 00:05:34,000
就是我们可以通过

137
00:05:34,000 --> 00:05:36,000
迭代式的深度优先编译

138
00:05:36,000 --> 00:05:37,000
就DFS呢

139
00:05:37,000 --> 00:05:38,000
去找到我们的死代码

140
00:05:38,000 --> 00:05:40,000
或者叫做死节点

141
00:05:40,000 --> 00:05:41,000
就类似于OP4

142
00:05:41,000 --> 00:05:42,000
还有张亮B

143
00:05:44,000 --> 00:05:45,000
另外呢

144
00:05:45,000 --> 00:05:46,000
我们可以建立节点使用的

145
00:05:46,000 --> 00:05:47,000
一个TOP序列

146
00:05:47,000 --> 00:05:49,000
就标明我OP4被什么使用了

147
00:05:49,000 --> 00:05:51,000
我的张亮B被什么使用了

148
00:05:51,000 --> 00:05:53,000
如果他没有被使用

149
00:05:53,000 --> 00:05:54,000
或者他OP4呢

150
00:05:54,000 --> 00:05:56,000
没有被输出节点引用

151
00:05:56,000 --> 00:05:57,000
OP4的使用的次数呢

152
00:05:57,000 --> 00:05:58,000
就是0

153
00:05:58,000 --> 00:06:00,000
那这个时候我可以把OP4

154
00:06:00,000 --> 00:06:01,000
删掉

155
00:06:01,000 --> 00:06:03,000
然后再把我们的张亮删掉

156
00:06:04,000 --> 00:06:05,000
通过建立使用的TOP

157
00:06:05,000 --> 00:06:06,000
也可以实现

158
00:06:06,000 --> 00:06:08,000
所以死代码销售的算法呢

159
00:06:08,000 --> 00:06:09,000
有很多

160
00:06:09,000 --> 00:06:10,000
具体取决于

161
00:06:10,000 --> 00:06:13,000
我们怎么高效的去实现

162
00:06:13,000 --> 00:06:14,000
好了

163
00:06:14,000 --> 00:06:15,000
谢谢各位

