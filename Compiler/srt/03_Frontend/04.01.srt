1
00:00:00,000 --> 00:00:07,680
Hello,大家好

2
00:00:07,680 --> 00:00:08,560
我是ZOMI

3
00:00:08,560 --> 00:00:11,840
今天我们来到AI编译器系列里面的前端优化

4
00:00:11,840 --> 00:00:14,280
来讲讲数据布局转换

5
00:00:15,720 --> 00:00:16,920
在之前的内容里面

6
00:00:17,040 --> 00:00:18,880
我们讲了一个图层的IR

7
00:00:18,880 --> 00:00:19,960
就是我们的计算图

8
00:00:19,960 --> 00:00:22,800
怎么转换成我们AI编译器的前端的输入

9
00:00:22,840 --> 00:00:24,560
接着我们去了解了一下

10
00:00:24,560 --> 00:00:26,800
算子融合的一个基础的原理

11
00:00:26,800 --> 00:00:28,160
和算子融合的方式

12
00:00:28,160 --> 00:00:31,320
今天我们来讲讲数据布局的转换

13
00:00:31,320 --> 00:00:33,080
其实很多人对数据布局

14
00:00:33,080 --> 00:00:35,080
其实不是说非常的敏感

15
00:00:35,080 --> 00:00:36,080
但是数据布局

16
00:00:36,240 --> 00:00:37,760
对我们的AI编译器来说

17
00:00:37,760 --> 00:00:40,040
是非常重要的一个环节

18
00:00:40,040 --> 00:00:41,440
我们的数据布局

19
00:00:41,440 --> 00:00:43,640
主要是layout transformation

20
00:00:43,640 --> 00:00:46,600
然后今天我们会分开几个内容去介绍的

21
00:00:46,800 --> 00:00:48,600
如果十来分钟介绍不完

22
00:00:48,600 --> 00:00:50,400
我们会拆开两个内容

23
00:00:50,600 --> 00:00:51,360
首先我们看看

24
00:00:51,360 --> 00:00:54,240
今天我们要给大家汇报哪些知识点

25
00:00:54,240 --> 00:00:57,040
首先第一个就是数据内存的排布

26
00:00:57,080 --> 00:00:58,280
第二个我们去看看

27
00:00:58,280 --> 00:01:01,200
张亮的一个数据具体内存是怎么排布的

28
00:01:01,200 --> 00:01:02,720
再往下我们会去看看

29
00:01:02,720 --> 00:01:06,160
NCHW和NHWC之间的数据排布

30
00:01:06,160 --> 00:01:07,440
具体有什么作用

31
00:01:07,440 --> 00:01:08,440
有什么不同

32
00:01:08,440 --> 00:01:09,520
对于硬件来说

33
00:01:09,520 --> 00:01:11,960
我们更倾大于采用哪种方式

34
00:01:11,960 --> 00:01:14,960
往下就是我们自己华为生腾的产品

35
00:01:14,960 --> 00:01:18,400
去看看华为生腾的一个数据布局的排布

36
00:01:18,400 --> 00:01:19,640
到底是怎么样的

37
00:01:19,640 --> 00:01:23,880
又怎么如何跟NCHW或者NHWC进行融合

38
00:01:24,000 --> 00:01:27,840
最后我们去看看AI编译器的数据布局转换

39
00:01:27,840 --> 00:01:29,280
是怎么做优化

40
00:01:30,120 --> 00:01:32,120
现在我们回头来看看

41
00:01:32,120 --> 00:01:33,840
我们在哪个位置

42
00:01:33,840 --> 00:01:37,080
前端我们把python的代码进行解析

43
00:01:37,080 --> 00:01:38,240
这个解析的过程

44
00:01:38,400 --> 00:01:41,240
是通过我们的AI框架去实现的

45
00:01:41,240 --> 00:01:42,040
解析完之后

46
00:01:42,040 --> 00:01:43,480
我们得到一个计算图

47
00:01:43,680 --> 00:01:46,920
计算图就传给我们AI编译器的第一层

48
00:01:46,920 --> 00:01:48,760
我们的图层的IR的优化

49
00:01:48,760 --> 00:01:50,640
我们现在在这个地方

50
00:01:50,640 --> 00:01:51,960
数据布局转换

51
00:01:52,000 --> 00:01:55,160
作为我们图层IR前端优化的一个Path

52
00:01:56,800 --> 00:01:59,000
接下来我们看一下我们的第一个内容

53
00:01:59,000 --> 00:02:01,120
数据内存的排布

54
00:02:02,360 --> 00:02:03,560
钟鸣老师你好

55
00:02:03,560 --> 00:02:05,840
我想问一下什么是内存对齐

56
00:02:06,080 --> 00:02:08,480
我们为什么要对内存进行对齐

57
00:02:10,280 --> 00:02:12,120
这位同学问的问题非常好

58
00:02:12,200 --> 00:02:14,160
这也是我们第一个内容

59
00:02:15,040 --> 00:02:17,120
还是我自己问自己答的

60
00:02:17,120 --> 00:02:19,680
第一个内容就是讲数据内存的排布

61
00:02:19,720 --> 00:02:21,240
首先我们要了解一个概念

62
00:02:21,240 --> 00:02:23,320
就是内存的对齐和数据

63
00:02:23,320 --> 00:02:25,880
在内存里面的位置是相关的

64
00:02:26,120 --> 00:02:28,440
现在我们看一下左边的图

65
00:02:28,720 --> 00:02:30,520
我们这里面是我们的memory

66
00:02:30,520 --> 00:02:32,120
就是我们的内存的地址

67
00:02:32,120 --> 00:02:35,160
这些存的都是我们内存的一个具体的地址

68
00:02:35,160 --> 00:02:38,080
而右边的这个就是我们实际的数据

69
00:02:38,080 --> 00:02:40,600
我们数据是存放在我们的内存

70
00:02:40,600 --> 00:02:42,040
某个地址里面的

71
00:02:42,040 --> 00:02:45,280
而内存是以字节为单位进行存储

72
00:02:45,280 --> 00:02:46,480
如果我们一个变量

73
00:02:46,480 --> 00:02:48,320
或者一个数据的内存的地址

74
00:02:48,480 --> 00:02:50,440
刚好等于它的长度的倍数

75
00:02:50,440 --> 00:02:52,920
那我们这个就称为自然对齐

76
00:02:52,920 --> 00:02:55,880
理论上我们其实可以从任意地址开始

77
00:02:55,880 --> 00:02:57,920
进行读取和写入的

78
00:02:57,920 --> 00:02:59,760
如果数据内存没有对齐

79
00:02:59,960 --> 00:03:01,160
可能就比较麻烦

80
00:03:01,160 --> 00:03:02,360
我们读取数据的时候

81
00:03:02,520 --> 00:03:03,520
就没有那么方便

82
00:03:03,520 --> 00:03:05,160
要对数据进行一个偏移

83
00:03:05,160 --> 00:03:06,600
再读取然后再合并

84
00:03:06,960 --> 00:03:09,920
尽管现在的内存是以字节为单位的

85
00:03:09,920 --> 00:03:11,800
但是我们现在的处理器

86
00:03:11,920 --> 00:03:14,680
是以字为单位进行一个读写和访问的

87
00:03:14,680 --> 00:03:17,320
我们的CPU或者不管是intel

88
00:03:17,320 --> 00:03:18,320
还是ARM的CPU

89
00:03:18,320 --> 00:03:20,800
还是按字节快的方式来去读取的

90
00:03:20,800 --> 00:03:22,920
而一般我们有几种读取方式

91
00:03:22,920 --> 00:03:26,560
就是以字节2 4 8 16

92
00:03:26,560 --> 00:03:28,360
这种字节的方式为力度

93
00:03:28,520 --> 00:03:29,960
进行内存的读写

94
00:03:29,960 --> 00:03:31,600
既然我们的CPU和系统

95
00:03:31,760 --> 00:03:34,320
是根据这些字节为单位进行读取

96
00:03:34,320 --> 00:03:36,920
所以我们尽可能的把我们的数据

97
00:03:36,920 --> 00:03:39,160
根据这个单位进行对齐

98
00:03:39,160 --> 00:03:41,520
才能够高效的去利用我们的硬件

99
00:03:41,520 --> 00:03:44,000
充分的发挥硬件的性能

100
00:03:44,000 --> 00:03:45,240
现在我们来看看

101
00:03:45,280 --> 00:03:48,400
假设我们的数据内存没有对齐

102
00:03:48,400 --> 00:03:50,520
会产生一个什么样的情况

103
00:03:50,520 --> 00:03:51,640
那下面这个图

104
00:03:52,040 --> 00:03:54,360
我们以4字节存储的力度

105
00:03:54,360 --> 00:03:57,000
为单位读取一个int一个变量

106
00:03:57,000 --> 00:03:59,800
int有4个字节32bit

107
00:03:59,800 --> 00:04:01,320
处理器去读取的时候

108
00:04:01,480 --> 00:04:05,080
会默认从4的倍数的地址开始进行读取

109
00:04:05,080 --> 00:04:08,520
假设我这个位置的地址是0x0000

110
00:04:08,520 --> 00:04:12,120
那这个位置的地址可能是0x0004

111
00:04:12,120 --> 00:04:14,240
假设我们现在的数据存储

112
00:04:14,400 --> 00:04:17,120
是没有以4字节为单位进行一个存储的

113
00:04:17,120 --> 00:04:18,520
我们现在去读取的时候

114
00:04:18,680 --> 00:04:22,240
先读取上面红色的这一块的前三个bit

115
00:04:22,240 --> 00:04:25,280
然后我们再读取这蓝色的这一块的

116
00:04:25,280 --> 00:04:26,400
第一个load bit

117
00:04:26,400 --> 00:04:29,000
就是我们第一个最低的位置地址

118
00:04:29,000 --> 00:04:31,400
就是我红色的这个位置

119
00:04:31,400 --> 00:04:34,360
这个时候我就需要访问两次内存的

120
00:04:34,360 --> 00:04:37,240
第一次就是读取红色的高位的地址

121
00:04:37,240 --> 00:04:40,120
第二次就是读取蓝色的低位的地址

122
00:04:40,120 --> 00:04:41,120
读取完之后

123
00:04:41,480 --> 00:04:43,280
我们第一次从0地址读取

124
00:04:43,280 --> 00:04:45,760
然后把首个字节剔除出来

125
00:04:45,760 --> 00:04:48,080
第二次从4地址开始读取

126
00:04:48,080 --> 00:04:50,760
只读取首个字节

127
00:04:50,760 --> 00:04:53,720
最后我们把这两块地址合并起来

128
00:04:53,720 --> 00:04:56,560
变成我们一个int32位就取一个数

129
00:04:56,560 --> 00:04:58,560
假设我们现在只取了一个1000的数

130
00:04:58,560 --> 00:05:00,880
但是我们读内存要读两次

131
00:05:00,880 --> 00:05:03,400
这是非常耗费我们的硬件的资源的

132
00:05:03,680 --> 00:05:04,920
刚才1000这个数

133
00:05:05,080 --> 00:05:07,880
已经存在我们的红色这块地址

134
00:05:07,880 --> 00:05:10,680
这种情况我们叫做做了一个数据

135
00:05:10,680 --> 00:05:13,040
跟我们的内存一个严格对齐

136
00:05:13,280 --> 00:05:16,640
读取的时候起始位置作为4的倍数

137
00:05:16,640 --> 00:05:18,520
然后只需要进行一次读取

138
00:05:18,520 --> 00:05:19,960
就可以从我们的memory

139
00:05:19,960 --> 00:05:21,600
然后把我们的数据搬到一个

140
00:05:21,600 --> 00:05:22,480
集存器里面了

141
00:05:22,480 --> 00:05:24,320
最后给我们的XLA进行计算

142
00:05:25,560 --> 00:05:27,640
以字节大小为力度进行内存访问

143
00:05:27,640 --> 00:05:28,680
其实有两个好处

144
00:05:28,680 --> 00:05:30,680
第一个就是提升我们的访问速率

145
00:05:30,680 --> 00:05:32,000
为什么提升我们的访问速率

146
00:05:32,000 --> 00:05:34,840
我们刚才其实已经用一个简单的例子讲了

147
00:05:34,840 --> 00:05:37,680
第2个就是保存我们数据的一个原子性

148
00:05:37,680 --> 00:05:40,520
现在我们简单的来看看两个的好处

149
00:05:40,560 --> 00:05:43,800
我们现在CPU大部分都有多个高级的缓存

150
00:05:43,800 --> 00:05:46,800
数据必须通过这些高级缓存去读取数据的

151
00:05:46,800 --> 00:05:49,160
而以字节大小力度进行内存访问

152
00:05:49,160 --> 00:05:52,080
可以整体提升我们的CPU的吞吐量

153
00:05:52,080 --> 00:05:54,800
第2点就是原子性的问题

154
00:05:54,800 --> 00:05:57,560
CPU可以在一个对齐的内存上面进行操作

155
00:05:57,560 --> 00:05:59,120
这意味着我们没有指令

156
00:05:59,120 --> 00:06:00,840
可以中断我们的访问操作

157
00:06:00,840 --> 00:06:03,320
对于很多没有锁的数据或者数据结构来说

158
00:06:03,320 --> 00:06:05,440
可以提升我们的并发的正确性

159
00:06:05,440 --> 00:06:07,000
这个就是两个好处

160
00:06:08,000 --> 00:06:10,120
接下来回到我们的AI的概念

161
00:06:10,120 --> 00:06:10,960
就是脏量

162
00:06:10,960 --> 00:06:12,760
脏量的数据又是如何布局

163
00:06:12,760 --> 00:06:15,280
我们刚才只是讲了在普通的插排路上面

164
00:06:15,280 --> 00:06:17,680
我们的数据是怎么进行一个存储的

165
00:06:17,680 --> 00:06:19,320
我们数据的存储方式

166
00:06:19,320 --> 00:06:22,000
是根据我们数据在组成里面的存储的方式

167
00:06:22,000 --> 00:06:23,320
之上作为基础的

168
00:06:25,560 --> 00:06:29,040
现在我们来看看脏量和内存的排布的方式

169
00:06:29,040 --> 00:06:31,040
那我们脏量是一个多维的数组

170
00:06:31,040 --> 00:06:33,160
我们先看看简单的一个数

171
00:06:33,280 --> 00:06:34,440
我们叫做标量

172
00:06:34,440 --> 00:06:35,320
它只有一个数

173
00:06:35,320 --> 00:06:36,600
而我们有多个数的时候

174
00:06:36,800 --> 00:06:37,960
我们叫做向量

175
00:06:37,960 --> 00:06:39,360
就是一维的脏量

176
00:06:39,360 --> 00:06:41,480
如果我们的数据是一个矩阵的时候

177
00:06:41,600 --> 00:06:43,040
我们叫做二维的脏量

178
00:06:43,040 --> 00:06:44,240
当我们的数据

179
00:06:44,240 --> 00:06:46,200
假设像我们这样一张图片

180
00:06:46,400 --> 00:06:47,960
图片有长宽高

181
00:06:47,960 --> 00:06:49,080
还有一个通道数

182
00:06:49,080 --> 00:06:49,800
RGB

183
00:06:50,000 --> 00:06:52,240
这个时候就会变成三维的脏量

184
00:06:52,240 --> 00:06:52,800
当然了

185
00:06:52,800 --> 00:06:54,280
我们在神级网络处理的时候

186
00:06:54,520 --> 00:06:56,080
我们会有一个Batch Size

187
00:06:56,080 --> 00:06:57,960
作为我们的P数据处理的方式

188
00:06:58,080 --> 00:07:00,200
这个时候就变成四维的脏量了

189
00:07:00,200 --> 00:07:01,520
而作为0维脏量

190
00:07:01,520 --> 00:07:02,560
我们单单一个数

191
00:07:02,760 --> 00:07:04,560
以字节为单位进行存储

192
00:07:04,560 --> 00:07:06,120
向量里面每一个元素

193
00:07:06,240 --> 00:07:08,120
都是按字节为单位进行存储

194
00:07:08,120 --> 00:07:10,120
但是当我们的维度越来越高

195
00:07:10,120 --> 00:07:11,560
我们的内存数据地址

196
00:07:11,720 --> 00:07:13,080
是按列进行排布的

197
00:07:13,080 --> 00:07:14,480
所以存储一维脏量的时候

198
00:07:14,480 --> 00:07:15,920
大家比较好理解

199
00:07:15,920 --> 00:07:17,640
这里面5我存在一个地址

200
00:07:17,640 --> 00:07:18,600
4存在一个地址

201
00:07:18,600 --> 00:07:19,600
3存在一个地址

202
00:07:19,600 --> 00:07:20,680
2存在一个地址

203
00:07:20,680 --> 00:07:22,240
但是当我们矩阵的时候

204
00:07:22,240 --> 00:07:23,120
我们可能

205
00:07:23,240 --> 00:07:25,080
1存在一个地址里面

206
00:07:25,080 --> 00:07:26,080
不断的往下排

207
00:07:26,080 --> 00:07:27,360
2存在一个地址里面

208
00:07:27,360 --> 00:07:28,480
不断的往下排

209
00:07:28,480 --> 00:07:29,320
3也是

210
00:07:29,440 --> 00:07:31,320
但是我们的脏量的维度

211
00:07:31,320 --> 00:07:32,400
越来越高的时候

212
00:07:32,400 --> 00:07:33,840
我们是先存列了

213
00:07:33,840 --> 00:07:35,240
还是先存行了

214
00:07:35,280 --> 00:07:36,960
还是先存我们的

215
00:07:36,960 --> 00:07:38,240
channel的数量了

216
00:07:38,240 --> 00:07:40,160
如果我们再加一个维度的时候

217
00:07:40,160 --> 00:07:41,600
数据应该怎么存呢

218
00:07:41,600 --> 00:07:43,240
这个时候就引起我们脏量

219
00:07:43,240 --> 00:07:45,000
与内存排布的一个问题了

220
00:07:46,760 --> 00:07:48,960
我们现在先以一个简单形状的

221
00:07:48,960 --> 00:07:51,040
3x2x2的一个三维脏量

222
00:07:51,040 --> 00:07:53,320
进行一个存储排布的一个讲解

223
00:07:53,320 --> 00:07:54,560
或者作为一个例子

224
00:07:54,560 --> 00:07:57,880
我们假设先按行优先进行数据排布

225
00:07:57,880 --> 00:08:00,520
红色的这个我们叫做按行进行排布

226
00:08:00,520 --> 00:08:03,280
我们现在是一个3x2x2的三维脏量

227
00:08:03,280 --> 00:08:04,960
那我们会以行进行排布

228
00:08:05,000 --> 00:08:06,840
先把红色的排起来

229
00:08:06,840 --> 00:08:08,800
然后再把橙色的排起来

230
00:08:08,800 --> 00:08:11,360
接着再排绿色的这一个位置

231
00:08:11,360 --> 00:08:14,400
最后我们再排底下蓝色的这个位置

232
00:08:14,400 --> 00:08:15,720
而我们现在看到

233
00:08:15,720 --> 00:08:18,120
虽然作为3x2x2的三维脏量

234
00:08:18,120 --> 00:08:20,880
实际我们这内存里面就是排成一排

235
00:08:20,880 --> 00:08:23,080
因为内存是以列进行排布的

236
00:08:23,080 --> 00:08:26,280
当然最终它可能是一排过就打数的

237
00:08:26,280 --> 00:08:27,040
但是没关系

238
00:08:27,040 --> 00:08:28,600
这不影响我们的理解

239
00:08:29,440 --> 00:08:32,240
接下来我们再看以列优先进行一个数据排布

240
00:08:32,280 --> 00:08:34,960
列优先就是我们先按列的进行走

241
00:08:34,960 --> 00:08:36,040
那我们先存红的

242
00:08:36,040 --> 00:08:37,040
然后再存橙的

243
00:08:37,040 --> 00:08:38,520
先存红的再存橙的

244
00:08:38,520 --> 00:08:41,400
就变成红橙红橙红橙

245
00:08:41,400 --> 00:08:42,640
这种排布方式

246
00:08:42,640 --> 00:08:44,680
接下来我们对第二个圈楼

247
00:08:44,680 --> 00:08:46,560
就是后面的维度进行排列

248
00:08:46,560 --> 00:08:48,120
先存绿的再存蓝的

249
00:08:48,120 --> 00:08:49,440
先存绿的再存蓝的

250
00:08:49,440 --> 00:08:52,440
就变成我们绿蓝绿蓝绿蓝

251
00:08:52,440 --> 00:08:54,320
这种存储排布方式

252
00:08:54,320 --> 00:08:56,160
所以我们看到的脏量

253
00:08:56,360 --> 00:08:58,080
它的形状有非常多

254
00:08:58,080 --> 00:08:59,760
但是我们按行排布

255
00:08:59,760 --> 00:09:00,760
按列排布

256
00:09:00,760 --> 00:09:04,080
后面就会有非常多的内存排布的方式

257
00:09:05,000 --> 00:09:07,800
现在我们以2x2x2的一个三维脏量

258
00:09:07,800 --> 00:09:09,600
看看我们的数据内存排布

259
00:09:09,600 --> 00:09:11,040
有非常多的方式

260
00:09:11,040 --> 00:09:13,200
那我们假设现在有三个方向

261
00:09:13,200 --> 00:09:15,320
第一个方向是横向的

262
00:09:15,320 --> 00:09:17,320
这个方向我们叫做D1

263
00:09:17,320 --> 00:09:18,920
第二个是以列方向

264
00:09:18,920 --> 00:09:21,000
我们这个方向叫做D2

265
00:09:21,000 --> 00:09:24,840
那第三个我们以圈楼这个族为方向

266
00:09:24,840 --> 00:09:26,440
我们叫做D3

267
00:09:26,440 --> 00:09:28,640
我们以D1 D2 D3

268
00:09:28,640 --> 00:09:30,040
这种方式就先排D1

269
00:09:30,040 --> 00:09:31,600
再排D2 再排D3

270
00:09:31,600 --> 00:09:33,120
那这种方式进行排布

271
00:09:33,120 --> 00:09:34,880
有一种这种方式

272
00:09:34,880 --> 00:09:38,160
假设我们以D1 D3 D2这种排布

273
00:09:38,160 --> 00:09:39,480
我们有这种方式

274
00:09:39,480 --> 00:09:40,600
先排了红的

275
00:09:40,600 --> 00:09:42,000
然后再排一个绿的

276
00:09:42,000 --> 00:09:43,240
然后再排橙色的

277
00:09:43,240 --> 00:09:44,400
最后排蓝色的

278
00:09:44,400 --> 00:09:46,000
所以我们可以看到这里面有

279
00:09:46,000 --> 00:09:49,480
1 2 3 4 5 6

280
00:09:49,480 --> 00:09:51,080
6种数据的排布

281
00:09:51,080 --> 00:09:53,240
仅仅是2x2的三维脏量

282
00:09:53,240 --> 00:09:56,480
就已经有6种数据排布的方式了

283
00:10:00,880 --> 00:10:05,440
了解完脏量的数据排布之后

284
00:10:05,440 --> 00:10:08,120
我们迎来了一个比较重要的内容

285
00:10:08,120 --> 00:10:11,560
就是NCHW和NHWC

286
00:10:11,560 --> 00:10:13,600
我们到底是采用NCHW

287
00:10:13,600 --> 00:10:15,880
还是NHWC这种数据格式

288
00:10:15,880 --> 00:10:18,280
我们往下去看一看

289
00:10:18,280 --> 00:10:21,680
首先我们还是回顾我们刚才的一个概念

290
00:10:21,680 --> 00:10:24,920
尽管我们的数据实际上都是一样的数据

291
00:10:24,920 --> 00:10:27,840
但是不同的顺序会导致我们数据的

292
00:10:27,880 --> 00:10:30,080
访问的性能是不一样的

293
00:10:30,080 --> 00:10:31,880
所以这里面就会衍生了

294
00:10:31,880 --> 00:10:34,120
很多不同数据的排布方式

295
00:10:34,120 --> 00:10:37,280
那NCHW还是NHWC

296
00:10:37,280 --> 00:10:38,400
我们在这里面

297
00:10:38,400 --> 00:10:41,160
简单的去看看每一个维度

298
00:10:41,160 --> 00:10:43,200
代表的是什么意思

299
00:10:43,200 --> 00:10:45,840
N就是我们Batch Size的一个数量

300
00:10:45,840 --> 00:10:47,360
我们的P处理的数量

301
00:10:47,360 --> 00:10:49,640
H就是我们图片的高度

302
00:10:49,640 --> 00:10:51,680
W我们图片的宽度

303
00:10:51,680 --> 00:10:54,680
而Channel就是我们图片的通道数

304
00:10:54,680 --> 00:10:57,000
也可以称为特征图的通道数

305
00:10:57,000 --> 00:10:59,800
这里面只是以CNN卷集神经网络

306
00:10:59,800 --> 00:11:02,680
就是专门处理图像进行介绍的

307
00:11:02,680 --> 00:11:05,760
现在我们来看看第一个数据存储的方式

308
00:11:05,760 --> 00:11:08,600
NCHW这种格式

309
00:11:08,600 --> 00:11:10,000
我们以图片作为例子

310
00:11:10,000 --> 00:11:12,120
假设这是一个单通道的图片

311
00:11:12,120 --> 00:11:14,040
后面也是一个单通道的图片

312
00:11:14,040 --> 00:11:16,160
在后面也是一个单通道的图片

313
00:11:16,160 --> 00:11:18,640
这个时候我同一通道的数值

314
00:11:18,640 --> 00:11:19,880
是连续的排布的

315
00:11:19,880 --> 00:11:21,360
也就是123456

316
00:11:21,360 --> 00:11:23,720
然后同时排在第一个位置

317
00:11:23,720 --> 00:11:25,440
接着第二个通道的数据

318
00:11:25,440 --> 00:11:26,280
连续排布

319
00:11:26,280 --> 00:11:27,800
最后第三个通道的数据

320
00:11:27,800 --> 00:11:28,920
再连续排布

321
00:11:28,920 --> 00:11:30,680
这种排布方式更适合

322
00:11:30,680 --> 00:11:32,920
需要对每个通道单独运算的操作

323
00:11:32,920 --> 00:11:34,080
例如Max Pooling

324
00:11:34,080 --> 00:11:34,880
在计算的时候

325
00:11:34,880 --> 00:11:36,840
我们LU就是我们的计算单元

326
00:11:36,840 --> 00:11:39,040
单独的对单个通道进行计算

327
00:11:39,040 --> 00:11:41,200
接着再对下一个通道进行计算

328
00:11:41,200 --> 00:11:42,600
这种存储方式的缺点

329
00:11:42,600 --> 00:11:44,520
就是需要的内存比较大

330
00:11:44,520 --> 00:11:46,760
可能我们需要把整个通道的数量

331
00:11:46,760 --> 00:11:48,960
都加载到我们的内存或者显存里面

332
00:11:48,960 --> 00:11:51,360
所以说它比较适合GPU进行运算

333
00:11:51,360 --> 00:11:53,440
利用GPU的内存和带宽比较大

334
00:11:53,440 --> 00:11:55,480
并行能力特别强的这种特性

335
00:11:55,480 --> 00:11:56,880
这么说还是有点抽象

336
00:11:56,880 --> 00:11:58,840
我们接下来再往下看一看

337
00:11:58,840 --> 00:12:01,000
假设我们现在把刚才的数据

338
00:12:01,000 --> 00:12:03,160
按NCHW的方式进行处理

339
00:12:03,160 --> 00:12:05,560
现在数据已经攒成一排了

340
00:12:05,560 --> 00:12:06,760
接着我在计算的时候

341
00:12:06,760 --> 00:12:08,160
我先算第一个通道

342
00:12:08,160 --> 00:12:09,560
然后乘以0.299

343
00:12:09,560 --> 00:12:10,600
然后第二个通道

344
00:12:10,600 --> 00:12:12,160
我再进行一个操作

345
00:12:12,160 --> 00:12:14,240
第三次我整一个通道

346
00:12:14,240 --> 00:12:16,000
再进行一个操作

347
00:12:16,000 --> 00:12:17,760
这个时候就每一个通道

348
00:12:17,760 --> 00:12:20,000
充分的利用了GPU的并行能力

349
00:12:20,000 --> 00:12:21,720
最后把三个通道计算的结果

350
00:12:21,720 --> 00:12:22,480
进行先加

351
00:12:22,480 --> 00:12:24,200
得到我们的整体的灰度值

352
00:12:24,200 --> 00:12:27,200
这种方式就是GPU最擅长的一个操作

353
00:12:27,200 --> 00:12:30,080
利用GPU的并行能力进行一个计算

354
00:12:31,160 --> 00:12:32,880
现在我们看看第二种方式

355
00:12:32,880 --> 00:12:35,000
就是NHWC的排布方式

356
00:12:35,000 --> 00:12:37,200
NHWC的排布方式很有意思

357
00:12:37,200 --> 00:12:40,040
就是每一个通道单独存储一个数据

358
00:12:40,040 --> 00:12:42,600
每一个通道单独再存储一个数据

359
00:12:42,600 --> 00:12:46,360
我存17131713到284284

360
00:12:46,360 --> 00:12:48,160
这种方式去进行存储的

361
00:12:48,160 --> 00:12:50,240
这种存储方式更适合那些

362
00:12:50,240 --> 00:12:53,080
不需要对通道数进行逐一操作的方式

363
00:12:53,080 --> 00:12:54,800
例如一乘一的卷积

364
00:12:54,800 --> 00:12:57,720
而且比较适合多核CPU进行计算的

365
00:12:57,720 --> 00:13:00,400
CPU会对我们每一个元素进行计算

366
00:13:00,400 --> 00:13:02,960
假设1我们是CPU A进行计算

367
00:13:02,960 --> 00:13:05,440
7我们CPU 2进行计算

368
00:13:05,440 --> 00:13:07,880
13我们是CPU 3进行计算

369
00:13:07,880 --> 00:13:10,400
每一个元素交给一个独立的

370
00:13:10,400 --> 00:13:12,120
CPU独立的核进行计算

371
00:13:12,120 --> 00:13:13,760
提高CPU的并发率

372
00:13:13,760 --> 00:13:14,640
而大家都知道

373
00:13:14,640 --> 00:13:16,560
CPU是分为多级缓存的

374
00:13:16,560 --> 00:13:18,880
主进行器带宽相对较小

375
00:13:18,920 --> 00:13:21,000
但是每个数据的计算时间比较低

376
00:13:21,000 --> 00:13:22,240
临时空间也很小

377
00:13:22,240 --> 00:13:24,320
采用NHWC这种存储方式

378
00:13:24,520 --> 00:13:26,680
有变异CPU采宠异步的方式

379
00:13:26,680 --> 00:13:28,120
边读边计算来减少我们的

380
00:13:28,120 --> 00:13:29,000
仿存的时间

381
00:13:29,000 --> 00:13:30,640
控制起来也比较灵活

382
00:13:31,640 --> 00:13:34,640
下面我们来看看一个更加具体的例子

383
00:13:34,640 --> 00:13:35,880
或者跟形象的一个例子

384
00:13:35,880 --> 00:13:38,080
假设我们刚才把NHWC的数据

385
00:13:38,080 --> 00:13:39,000
已经排起来了

386
00:13:39,000 --> 00:13:41,320
接下来我们现在有三个CPU的核

387
00:13:41,320 --> 00:13:43,720
三个CPU的核分别单独的去处理

388
00:13:43,720 --> 00:13:44,760
其中一个数值

389
00:13:44,760 --> 00:13:46,400
然后对它进行一个操作

390
00:13:46,400 --> 00:13:48,560
操作完之后再进行一个累加

391
00:13:48,560 --> 00:13:51,000
最后得到我们的图像的灰度值

392
00:13:51,000 --> 00:13:54,920
这种就是NHWC数据排布的一个方式

393
00:13:56,640 --> 00:13:58,760
由于我们的数据在内存里面

394
00:13:58,880 --> 00:14:00,760
只能是通过线性的处理

395
00:14:00,760 --> 00:14:02,960
这四个维度的数据的存储的方式

396
00:14:03,080 --> 00:14:04,600
是有对应的顺序的

397
00:14:04,600 --> 00:14:05,560
不同的AI框架

398
00:14:05,680 --> 00:14:07,280
会使用不同的存储方式

399
00:14:07,400 --> 00:14:08,160
对我们的数据

400
00:14:08,160 --> 00:14:09,640
或者对我们的特征图

401
00:14:09,640 --> 00:14:10,920
feature map进行存储

402
00:14:10,920 --> 00:14:12,480
以NPU或者GPU为例子

403
00:14:12,600 --> 00:14:14,400
就是我们的PyTorch和Mouseboard

404
00:14:14,400 --> 00:14:17,320
默认使用NCHW这种格式方式存储的

405
00:14:17,320 --> 00:14:19,360
NHWC就是先存Batch

406
00:14:19,360 --> 00:14:20,520
然后再存Channel

407
00:14:20,520 --> 00:14:22,320
再存我们的宽高

408
00:14:22,320 --> 00:14:24,360
那就是我们第一种方式

409
00:14:24,360 --> 00:14:25,240
而第二种方式

410
00:14:25,480 --> 00:14:27,920
NHWC就是我们Tensorflow

411
00:14:27,920 --> 00:14:29,520
一开始时候采用的一种方式

412
00:14:29,520 --> 00:14:30,480
就是先存Batch

413
00:14:30,480 --> 00:14:31,400
然后Hive, Wife

414
00:14:31,400 --> 00:14:32,480
然后再存Channel

415
00:14:32,480 --> 00:14:34,760
就是下面的这种存储方式

416
00:14:38,000 --> 00:14:40,480
接下来我们添加一个额外的知识点

417
00:14:40,480 --> 00:14:42,840
就是连续和非连续的问题

418
00:14:43,000 --> 00:14:45,360
我们看看什么叫做连续的占量存储

419
00:14:45,360 --> 00:14:46,680
123456

420
00:14:46,880 --> 00:14:49,560
这种方式就是连续的数据处理方式

421
00:14:49,840 --> 00:14:52,600
第二种就是非连续的占量存储方式

422
00:14:52,600 --> 00:14:55,200
就是我们假设现在有一个二乘三的矩阵

423
00:14:55,400 --> 00:14:57,920
数据存储的时候是142536

424
00:14:57,920 --> 00:14:59,880
就是以这种方式进行存储的

425
00:15:00,160 --> 00:15:02,280
这种叫做非连续的占量

426
00:15:02,920 --> 00:15:04,400
对于一些非连续的占量

427
00:15:04,480 --> 00:15:05,880
我们执行操作变换的时候

428
00:15:06,080 --> 00:15:08,760
我们需要重新的去开辟内存空间

429
00:15:08,760 --> 00:15:11,080
也就开辟一个一样大小的内存空间

430
00:15:11,080 --> 00:15:12,200
然后进行处理的

431
00:15:12,400 --> 00:15:13,760
这种非连续的存储方式

432
00:15:13,880 --> 00:15:15,160
其实我们是不太建议的

433
00:15:15,160 --> 00:15:17,160
更建议是按照连续的存储方式

434
00:15:17,160 --> 00:15:18,760
但有时候我们在处理的时候

435
00:15:18,760 --> 00:15:21,360
不可避免的会出现非连续的占量的方式

436
00:15:21,360 --> 00:15:23,240
所以大家知道我们的内存空间

437
00:15:23,240 --> 00:15:25,720
对我们实际的AI框架来说是非常有用的

438
00:15:25,720 --> 00:15:27,520
可能大家在平时写代码

439
00:15:27,520 --> 00:15:28,560
或者写算法来说

440
00:15:28,960 --> 00:15:30,960
没有太注意数据的存储方式

441
00:15:30,960 --> 00:15:32,760
但是作为AI框架的开发者

442
00:15:32,760 --> 00:15:34,400
或者对我们的系统的工程师来说

443
00:15:34,680 --> 00:15:37,440
这是一个非常严峻非常大的一个挑战

444
00:15:38,720 --> 00:15:40,280
好了 我们回顾一下

445
00:15:40,280 --> 00:15:42,960
今天我们讲了一个数据内存的排布

446
00:15:42,960 --> 00:15:45,080
一般是以自己为单位进行一个存储的

447
00:15:45,240 --> 00:15:47,720
这是因为我们的硬件逻辑粒子所决定的

448
00:15:48,320 --> 00:15:49,480
第二个点我们讲了

449
00:15:49,480 --> 00:15:51,600
张亮的一个数据的排布方式

450
00:15:51,600 --> 00:15:54,080
张亮的数据排布方式其实有非常多的

451
00:15:54,080 --> 00:15:55,680
刚才以一个2x2x2

452
00:15:55,680 --> 00:15:57,080
三维的张亮进行一个粒子

453
00:15:57,200 --> 00:15:59,160
就已经有6种数据的排布方式了

454
00:15:59,160 --> 00:16:00,480
每一种数据排布方式

455
00:16:00,480 --> 00:16:03,440
对我们的硬件的计算其实是有影响的

456
00:16:03,440 --> 00:16:06,480
于是我们以NCHW和NHWC

457
00:16:06,480 --> 00:16:08,600
这两种不同的硬件存储方式

458
00:16:08,600 --> 00:16:09,880
进行了一个介绍

459
00:16:09,880 --> 00:16:13,200
像NHWC更适合在我们的NPU或者GPU

460
00:16:13,200 --> 00:16:14,720
这些加速芯片进行计算的

461
00:16:14,960 --> 00:16:16,560
NHWC这种方式

462
00:16:16,760 --> 00:16:19,480
更适合在我们的CPU上面进行一个存储的

463
00:16:20,000 --> 00:16:21,840
我们今天的内容到此为止

464
00:16:21,840 --> 00:16:22,400
好了

465
00:16:22,400 --> 00:16:23,120
谢谢各位

466
00:16:23,120 --> 00:16:23,480
拜了

467
00:16:23,480 --> 00:16:24,040
拜拜

468
00:16:24,960 --> 00:16:25,720
卷的不行了

469
00:16:25,720 --> 00:16:26,560
卷的不行了

470
00:16:26,560 --> 00:16:27,880
记得一键三连加关注

