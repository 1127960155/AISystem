1
00:00:00,000 --> 00:00:04,560
巴巴巴巴巴巴巴巴巴巴

2
00:00:05,280 --> 00:00:07,120
哈喽 大家晚上好

3
00:00:07,120 --> 00:00:08,000
我是宗明

4
00:00:08,000 --> 00:00:11,000
那今天我们来到一个新的内容

5
00:00:11,000 --> 00:00:13,240
AI编译器的前端优化

6
00:00:13,240 --> 00:00:15,760
那这个就是一个全新的内容了

7
00:00:15,760 --> 00:00:17,080
讲到我们的AI编译器

8
00:00:17,080 --> 00:00:19,520
肯定会有前端的一些优化

9
00:00:19,520 --> 00:00:20,520
那前端的优化

10
00:00:20,640 --> 00:00:22,240
其实我们之前已经介绍过了

11
00:00:22,240 --> 00:00:25,360
前端主要是关注于图层的一些优化

12
00:00:25,360 --> 00:00:26,440
那在图层的优化

13
00:00:26,560 --> 00:00:27,880
实际上我们有非常多

14
00:00:27,880 --> 00:00:29,920
这里面会简单的去给大家

15
00:00:30,000 --> 00:00:32,280
足够的介绍相关的Path

16
00:00:32,280 --> 00:00:33,240
首先第一种

17
00:00:33,360 --> 00:00:35,480
我们把它分成左右两边了

18
00:00:35,480 --> 00:00:37,480
左边这种我把它定义为

19
00:00:37,480 --> 00:00:40,400
真正的面向图层的一些IR

20
00:00:40,400 --> 00:00:42,400
或者图层的一些Path的优化

21
00:00:42,400 --> 00:00:45,200
右边的这种面向于更传统的

22
00:00:45,200 --> 00:00:47,520
一些DAG图的一些优化

23
00:00:47,520 --> 00:00:48,520
那我们看看左边

24
00:00:48,520 --> 00:00:49,240
我们会讲到

25
00:00:49,240 --> 00:00:50,120
算子的融合

26
00:00:50,120 --> 00:00:51,320
就把算子合起来

27
00:00:51,320 --> 00:00:53,640
那第二个就是布局的转换

28
00:00:53,640 --> 00:00:54,560
那这个布局转换

29
00:00:54,720 --> 00:00:56,920
更多的是指内存的布局

30
00:00:56,920 --> 00:00:58,000
内存的排布

31
00:00:58,040 --> 00:01:00,560
那第三个就是内存的分配

32
00:01:00,560 --> 00:01:02,960
这个跟刚才上面布局是不一样的

33
00:01:02,960 --> 00:01:04,880
上面是指内存的数据

34
00:01:04,880 --> 00:01:07,280
那这个就是指内存的地址

35
00:01:07,280 --> 00:01:08,720
和内存的空间

36
00:01:08,720 --> 00:01:10,160
进行一个分配

37
00:01:10,160 --> 00:01:12,560
那接着我们会有一些常量折叠

38
00:01:12,560 --> 00:01:14,200
常量折叠主要是讲

39
00:01:14,200 --> 00:01:15,400
我们的神经网络里面

40
00:01:15,600 --> 00:01:17,440
可能会出现一些常量

41
00:01:17,440 --> 00:01:20,040
这个时候我们把它预先的计算了

42
00:01:20,040 --> 00:01:22,000
另外下面的几个概念

43
00:01:22,200 --> 00:01:24,840
传统编译器LLVM里面也会有的

44
00:01:24,840 --> 00:01:27,040
这里面我们简单的去带过一下

45
00:01:27,040 --> 00:01:30,000
就是有公共词表达式的一个消除

46
00:01:30,000 --> 00:01:31,880
还有死代码的消除

47
00:01:31,880 --> 00:01:34,760
另外还会有代数的简化

48
00:01:34,920 --> 00:01:37,560
下面我们将会分为这些内容

49
00:01:37,560 --> 00:01:39,240
去给大家介绍的

50
00:01:39,240 --> 00:01:42,160
那现在我们看看前端的优化的

51
00:01:42,160 --> 00:01:44,120
一个整体的框图

52
00:01:44,120 --> 00:01:47,480
那首先最上面就是我们的AI框架

53
00:01:47,480 --> 00:01:49,200
TensorFlow的PyTorch

54
00:01:49,200 --> 00:01:49,920
MineSport

55
00:01:49,920 --> 00:01:52,160
还有国内的一些AI框架

56
00:01:52,160 --> 00:01:54,520
这些AI框架最重要的一个事情

57
00:01:54,520 --> 00:01:56,800
就是产生一个计算图

58
00:01:56,840 --> 00:01:58,120
那拿到这个计算图

59
00:01:58,320 --> 00:02:00,680
我们就会把它变成一个Graph IR

60
00:02:00,680 --> 00:02:03,160
传给我们编译器的前端

61
00:02:03,160 --> 00:02:04,680
当然了编辑器有前端

62
00:02:04,680 --> 00:02:06,120
中间优化还有后端

63
00:02:06,120 --> 00:02:07,680
这个我们在LLVM里面

64
00:02:07,800 --> 00:02:09,240
是详细的介绍过的

65
00:02:09,240 --> 00:02:12,520
而我们今天主要是聚焦于前端优化

66
00:02:12,520 --> 00:02:14,240
那就会有非常多的Path

67
00:02:14,240 --> 00:02:15,600
每个Path的概念

68
00:02:15,680 --> 00:02:17,360
我们在前面其实介绍过了

69
00:02:18,040 --> 00:02:19,920
所以它会有非常多的Path

70
00:02:20,080 --> 00:02:20,800
不同的Path

71
00:02:21,000 --> 00:02:23,040
执行不同的优化逻辑

72
00:02:23,960 --> 00:02:25,080
接着我们看看

73
00:02:25,080 --> 00:02:26,920
在整体的AI编辑器里面

74
00:02:26,920 --> 00:02:29,080
我们现在所处在哪个位置

75
00:02:29,440 --> 00:02:30,240
在最上层

76
00:02:30,400 --> 00:02:32,440
我们用Python写了一些代码

77
00:02:32,440 --> 00:02:33,840
经过我们的AI框架

78
00:02:33,840 --> 00:02:34,840
对这些Python代码

79
00:02:35,040 --> 00:02:36,280
进行一个解析

80
00:02:36,280 --> 00:02:38,360
最后变成我们的Graph IR

81
00:02:38,360 --> 00:02:40,080
就是我们的计算图的IR

82
00:02:40,080 --> 00:02:43,080
或者计算图所衍生出来的一个IR

83
00:02:43,080 --> 00:02:44,320
IR是中间表达

84
00:02:45,640 --> 00:02:48,520
接着就会有一个前端的优化

85
00:02:48,640 --> 00:02:49,320
前端的优化

86
00:02:49,320 --> 00:02:51,640
就是我们刚才讲到的一些优化

87
00:02:51,840 --> 00:02:53,240
接下来下面的内容

88
00:02:53,280 --> 00:02:55,800
我们将会在比较往后的章节

89
00:02:55,800 --> 00:02:57,840
去给大家分享汇报

90
00:02:58,720 --> 00:03:00,200
现在我们来看看前端优化

91
00:03:00,200 --> 00:03:01,640
我们都做了哪些内容

92
00:03:01,640 --> 00:03:02,720
其实很简单

93
00:03:02,720 --> 00:03:04,400
前端优化我们输进去了

94
00:03:04,400 --> 00:03:06,000
是一个类似于Graph的IR

95
00:03:06,000 --> 00:03:07,280
就是图层的IR

96
00:03:07,280 --> 00:03:09,280
然后经过长量字叠之后

97
00:03:09,280 --> 00:03:11,120
输出一个图的IR

98
00:03:11,120 --> 00:03:12,400
接着图的IR

99
00:03:12,400 --> 00:03:13,920
重新丢给我们的Path

100
00:03:13,920 --> 00:03:15,400
然后经过长量传播

101
00:03:15,400 --> 00:03:16,640
或者算子融合

102
00:03:16,640 --> 00:03:18,360
得到另外一个新的IR

103
00:03:18,360 --> 00:03:20,440
接着又重新传回来

104
00:03:20,840 --> 00:03:23,440
每一次传它都是一个图的表达

105
00:03:23,440 --> 00:03:24,320
图的形式

106
00:03:24,320 --> 00:03:26,240
所以我们叫做图层的IR

107
00:03:27,680 --> 00:03:28,240
好了

108
00:03:28,240 --> 00:03:30,120
今天的内容到这里为止

109
00:03:30,120 --> 00:03:33,240
后面想要了解更多AI编辑器的内容

110
00:03:33,400 --> 00:03:35,320
请关注这门课程

111
00:03:35,320 --> 00:03:36,240
谢谢各位

112
00:03:36,520 --> 00:03:37,360
卷的不行了

113
00:03:37,360 --> 00:03:38,240
卷的不行了

114
00:03:38,240 --> 00:03:39,640
记得一键三连加关注

115
00:03:40,040 --> 00:03:41,400
所有的内容都会开源

116
00:03:41,400 --> 00:03:43,240
在下面这条链接里面

117
00:03:43,600 --> 00:03:44,560
摆了个拜

