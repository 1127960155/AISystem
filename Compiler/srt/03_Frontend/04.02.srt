1
00:00:00,000 --> 00:00:04,560
巴巴巴巴巴巴巴巴巴巴

2
00:00:05,840 --> 00:00:06,640
嘟哒哒

3
00:00:06,640 --> 00:00:08,080
诶诶大家好

4
00:00:08,080 --> 00:00:09,480
那个我是周米

5
00:00:09,600 --> 00:00:14,640
今天我们来到一个AI编译器系列之前端优化的布局转换

6
00:00:14,640 --> 00:00:17,480
这里面的布局转换主要是指数据布局

7
00:00:17,800 --> 00:00:19,280
其实我们在上一个内容里面

8
00:00:19,360 --> 00:00:21,360
已经详细的去展开过了

9
00:00:21,360 --> 00:00:23,800
布局转换里面的前面的部分的内容

10
00:00:23,800 --> 00:00:26,680
第一个就是数据内存的排布

11
00:00:26,680 --> 00:00:29,880
数据在我们的内存里面是怎么个排放的

12
00:00:30,000 --> 00:00:33,920
第二个我们讲了张量数据具体的排布方式

13
00:00:33,920 --> 00:00:36,160
第三个我们举了两个经典的例子

14
00:00:36,160 --> 00:00:40,800
NCHW和NHWC具体有什么区别

15
00:00:41,080 --> 00:00:43,000
接下来我们在这一节里面

16
00:00:43,160 --> 00:00:45,120
主要是讲下面这两个内容

17
00:00:45,280 --> 00:00:50,200
第一个就是华为生腾AI芯片的一个数据的排布方式

18
00:00:50,880 --> 00:00:52,960
这个内容我觉得是非常有意思的

19
00:00:52,960 --> 00:00:54,840
它不仅是代表华为生腾

20
00:00:54,840 --> 00:00:56,840
也代表其他AI芯片厂商

21
00:00:56,880 --> 00:00:58,360
针对自己的芯片位架构

22
00:00:58,680 --> 00:01:01,400
提供特殊的数据存储和数据排布的方式

23
00:01:01,760 --> 00:01:04,520
最后一个就是真正的回到我们今天的话题

24
00:01:04,520 --> 00:01:05,720
了解完基础知识之后

25
00:01:06,040 --> 00:01:09,880
我们来了解AI编译器对于数据布局

26
00:01:09,880 --> 00:01:12,920
转换优化的一个Path具体是怎么实现的

27
00:01:14,800 --> 00:01:16,160
接下来我们去了解一下

28
00:01:16,160 --> 00:01:19,320
华为生腾处理器的一个数据排布

29
00:01:20,080 --> 00:01:21,920
在华为生腾AI处理器当中

30
00:01:22,040 --> 00:01:24,920
为了提高整体的一个通用矩阵乘法

31
00:01:24,920 --> 00:01:28,320
即GMM的一个运算速率和仿存的效率

32
00:01:28,320 --> 00:01:31,400
所以我们所有的张量一般来说

33
00:01:31,400 --> 00:01:34,080
都不会使用NCHW这种方式

34
00:01:34,080 --> 00:01:36,240
而是把C进行切分

35
00:01:36,240 --> 00:01:39,080
采用的NCHW-C0的方式

36
00:01:39,360 --> 00:01:43,000
有时候我们内部叫做5HD的数据的方式

37
00:01:43,600 --> 00:01:47,080
我现在我们以一个三维的数据作为例子

38
00:01:47,080 --> 00:01:48,800
就是HWC

39
00:01:49,160 --> 00:01:51,880
H就是我们feature map的一个长和宽

40
00:01:51,880 --> 00:01:54,120
C就是我们channel的大小

41
00:01:54,440 --> 00:01:55,480
这个是三维的

42
00:01:55,480 --> 00:01:57,840
然后我们会把NHWC

43
00:01:57,840 --> 00:01:59,520
我们N其实还有一维

44
00:01:59,520 --> 00:02:01,240
Batch size的那个维度N

45
00:02:01,360 --> 00:02:03,240
我们现在先把它抛到一边

46
00:02:03,240 --> 00:02:04,880
因为它基本上没有变化

47
00:02:05,880 --> 00:02:09,160
接着我们对HWC里面的C channel进行切分

48
00:02:09,160 --> 00:02:12,600
里面切分成为C1个C0

49
00:02:13,240 --> 00:02:15,960
所以我们可以看到传统的C这个channel

50
00:02:16,040 --> 00:02:17,920
我们把它切成多个C0

51
00:02:17,920 --> 00:02:19,720
C1就等于4了

52
00:02:19,720 --> 00:02:21,360
1 2 3 4

53
00:02:21,360 --> 00:02:23,680
分别由4个延时去代替

54
00:02:23,760 --> 00:02:26,000
而这里面最后我们可以看到

55
00:02:26,000 --> 00:02:28,000
HW是正常的

56
00:02:28,600 --> 00:02:30,520
channel数就变成C0

57
00:02:30,520 --> 00:02:32,040
而C1有4个

58
00:02:32,040 --> 00:02:33,840
这个就是华为圣诞处理器的

59
00:02:33,840 --> 00:02:35,880
5HW的数据存储格式

60
00:02:38,640 --> 00:02:39,880
诶 教明老师

61
00:02:40,000 --> 00:02:41,080
我有一个疑问

62
00:02:41,560 --> 00:02:44,760
为什么我们要把C这个轴切出来

63
00:02:44,960 --> 00:02:47,560
切成两个C0和C1的两个轴呢

64
00:02:49,440 --> 00:02:52,000
其实C0这个轴和C0这个数字

65
00:02:52,120 --> 00:02:53,320
是跟我们的

66
00:02:53,320 --> 00:02:55,640
生腾里面的达芬奇的V架构是相关的

67
00:02:55,640 --> 00:02:57,240
等于我们AI core里面

68
00:02:57,240 --> 00:02:59,120
矩阵计算单元的大小

69
00:02:59,480 --> 00:03:00,760
对于Fp16内型

70
00:03:00,920 --> 00:03:02,920
我们这个C0就为16

71
00:03:02,920 --> 00:03:04,080
对于int8这个类型

72
00:03:04,200 --> 00:03:05,160
我们为32

73
00:03:05,160 --> 00:03:06,840
刚好是对应我们4个字节

74
00:03:06,840 --> 00:03:09,200
Fp16对应我们两个字节

75
00:03:09,200 --> 00:03:12,000
这部分的数据需要连续的存储的

76
00:03:12,000 --> 00:03:13,520
所以C1等于C

77
00:03:13,520 --> 00:03:15,680
所以C0如果结果不整出

78
00:03:15,840 --> 00:03:17,280
就要向上取整了

79
00:03:17,280 --> 00:03:19,960
保证我们所有的数据都能够对齐

80
00:03:20,160 --> 00:03:21,880
至于数据为什么需要对齐

81
00:03:21,880 --> 00:03:22,440
这个概念

82
00:03:22,600 --> 00:03:24,320
我们在前一个内容里面

83
00:03:24,320 --> 00:03:26,400
其实已经跟大家汇报过了

84
00:03:28,040 --> 00:03:29,320
接下来我们看一下

85
00:03:29,320 --> 00:03:31,400
NHWC或者NCHW

86
00:03:31,760 --> 00:03:35,040
是怎么变成我们的NCHWC0的

87
00:03:35,720 --> 00:03:38,320
我们以NHWC作为一个例子

88
00:03:38,320 --> 00:03:40,480
其实不是说非常难

89
00:03:41,400 --> 00:03:43,480
这次里面我们会分为两步

90
00:03:43,720 --> 00:03:46,200
第一步就是把我们的NHWC的数据

91
00:03:46,200 --> 00:03:48,360
在C轴的维度进行分割

92
00:03:48,360 --> 00:03:51,600
变成一个C1份NHWC0

93
00:03:51,880 --> 00:03:54,960
接着我们会把C1份的NHWC0

94
00:03:55,120 --> 00:03:57,520
在内存里面连续的排列

95
00:03:57,960 --> 00:04:01,080
最后就变成NCHWC0

96
00:04:01,280 --> 00:04:02,760
具体在PyTorch里面

97
00:04:02,880 --> 00:04:04,200
我们可能进行一个

98
00:04:04,200 --> 00:04:06,800
with shape 等NHWC1C0

99
00:04:06,800 --> 00:04:09,880
然后transpose 等03124

100
00:04:12,200 --> 00:04:13,560
接下来我们分享一个

101
00:04:13,560 --> 00:04:15,000
在达芬奇微架构里面

102
00:04:15,000 --> 00:04:17,040
一个比较有意思的一个点

103
00:04:17,240 --> 00:04:19,920
我们会额外提供两个数据的格式

104
00:04:19,920 --> 00:04:22,720
一个叫做FATICAL-NZ

105
00:04:23,160 --> 00:04:25,280
一个叫做FATICAL-NZ

106
00:04:25,480 --> 00:04:28,200
FATICAL它是分型的意思

107
00:04:28,560 --> 00:04:31,480
因为达芬奇它是一个SIMD的架构

108
00:04:31,480 --> 00:04:33,400
我们的Cube核就是AIRCORE

109
00:04:34,240 --> 00:04:38,760
输出的格式其实是NW1 H1 H0 W0

110
00:04:39,080 --> 00:04:39,760
比较复杂

111
00:04:39,760 --> 00:04:41,640
但是我们从下面这个图里面

112
00:04:41,760 --> 00:04:43,120
简单的去理解一下

113
00:04:43,120 --> 00:04:44,520
假设我们现在一次过

114
00:04:44,640 --> 00:04:46,320
除以一行的数据

115
00:04:46,520 --> 00:04:48,160
这里面我每一次丢进去

116
00:04:48,160 --> 00:04:49,280
我们的AIRCORE里面

117
00:04:49,400 --> 00:04:51,520
我就会直接去把这里面的

118
00:04:51,520 --> 00:04:53,600
一个小窗口的数据处理完

119
00:04:53,840 --> 00:04:55,120
处理这个小窗口的数据

120
00:04:55,440 --> 00:04:57,320
有点类似于进行卷集计算的时候

121
00:04:57,440 --> 00:04:59,760
就把一个小窗口的数据算完

122
00:04:59,760 --> 00:05:01,360
让我们有非常多的Cube核

123
00:05:01,360 --> 00:05:03,480
所以我们可以同时去计算

124
00:05:03,480 --> 00:05:05,080
非常多的这种小窗口

125
00:05:05,080 --> 00:05:06,480
而这种小窗口的数据

126
00:05:06,600 --> 00:05:07,720
具体是怎么排布的

127
00:05:08,120 --> 00:05:10,240
这里面有好几种不同的方式

128
00:05:10,240 --> 00:05:12,360
一个就是小J大J

129
00:05:12,520 --> 00:05:13,560
小J就像这种

130
00:05:13,560 --> 00:05:14,800
我先按行排布

131
00:05:14,800 --> 00:05:15,840
然后下一个

132
00:05:16,040 --> 00:05:17,080
在这个小窗口里面

133
00:05:17,200 --> 00:05:18,560
再按行进行取数据

134
00:05:18,560 --> 00:05:20,400
然后再按行进行取数据

135
00:05:20,400 --> 00:05:21,680
这种就是小J

136
00:05:21,680 --> 00:05:23,360
那大J就是在我们整个

137
00:05:23,360 --> 00:05:24,240
大的featurement里面

138
00:05:24,600 --> 00:05:26,080
不断的按行进行取

139
00:05:26,080 --> 00:05:27,680
然后不断的按行进行取

140
00:05:27,920 --> 00:05:29,680
这种就是大J的意思

141
00:05:30,040 --> 00:05:31,520
所谓的小N大J

142
00:05:32,040 --> 00:05:34,560
在快列我们按列的方式进行排序

143
00:05:34,560 --> 00:05:35,640
我先取完这一列

144
00:05:35,640 --> 00:05:36,440
再取第二列

145
00:05:36,440 --> 00:05:37,480
再取第三列

146
00:05:37,720 --> 00:05:39,920
快字间按行的方式去处理

147
00:05:39,920 --> 00:05:41,840
就是我们的小N大J

148
00:05:41,840 --> 00:05:43,200
利用我们的权重的数据

149
00:05:43,400 --> 00:05:45,200
会以这种方式进行存储

150
00:05:45,520 --> 00:05:47,560
最后一个就是小J大N

151
00:05:47,560 --> 00:05:50,040
我们快列跟第一个的内容是相同的

152
00:05:50,040 --> 00:05:51,640
快列按行进行排列

153
00:05:51,640 --> 00:05:54,240
但是快间我们是按列进行排列的

154
00:05:54,520 --> 00:05:55,680
例如卷积输出结果

155
00:05:55,800 --> 00:05:58,120
我们都会以小J大N的方式进行排列

156
00:05:58,400 --> 00:06:00,680
这个只是额外新增的知识

157
00:06:00,680 --> 00:06:02,400
至于为什么要这么排列

158
00:06:02,400 --> 00:06:04,200
为什么我们要用小J大J

159
00:06:04,200 --> 00:06:05,880
来去存储我们的featurement

160
00:06:05,880 --> 00:06:07,720
为什么要用小N大J

161
00:06:07,720 --> 00:06:08,960
来去存储我们的卷积

162
00:06:09,680 --> 00:06:11,880
我们在后面的AI芯片

163
00:06:11,880 --> 00:06:13,560
去介绍达芬奇架构的时候

164
00:06:13,560 --> 00:06:14,880
会给大家去展开

165
00:06:14,880 --> 00:06:16,560
只是在内存数据转换

166
00:06:16,560 --> 00:06:19,240
这个内容里面简单给大家演示

167
00:06:19,240 --> 00:06:20,280
不同的芯片厂商

168
00:06:20,280 --> 00:06:21,080
不同的硬件

169
00:06:21,080 --> 00:06:23,200
它会有自己的一个数据存储的格式

170
00:06:23,200 --> 00:06:24,680
而数据存储的格式

171
00:06:24,920 --> 00:06:26,680
是根据硬件的读取方式

172
00:06:26,680 --> 00:06:29,280
或者硬件的计算方式所决定的

173
00:06:30,600 --> 00:06:32,960
接下来我们来到了一个最重要的内容

174
00:06:32,960 --> 00:06:35,560
就是编译布局转换的一个优化

175
00:06:35,560 --> 00:06:37,840
就是我们在真正的AI编辑器里面

176
00:06:37,840 --> 00:06:39,480
是如何对我们的数据

177
00:06:39,480 --> 00:06:41,000
进行转换优化的

178
00:06:41,280 --> 00:06:43,200
其实我们现在还是这个内容

179
00:06:43,200 --> 00:06:45,440
只是现在我们真正的了解完

180
00:06:45,440 --> 00:06:46,200
基础知识之后

181
00:06:46,320 --> 00:06:48,200
我们深入到我们的AI编辑器里面

182
00:06:48,200 --> 00:06:50,520
具体怎么做转换

183
00:06:51,720 --> 00:06:52,600
我们来看看

184
00:06:52,600 --> 00:06:54,360
实际上我们在AI编辑器里面的

185
00:06:54,360 --> 00:06:55,600
Layout Transformation的目的

186
00:06:55,600 --> 00:06:57,000
就是希望将我们的内部的

187
00:06:57,000 --> 00:06:59,040
数据的布局转换成为后端

188
00:06:59,040 --> 00:07:00,200
就是我们的硬件

189
00:07:00,200 --> 00:07:01,920
很友好的方式

190
00:07:01,920 --> 00:07:03,080
所以我们刚才说了

191
00:07:03,080 --> 00:07:04,400
我们的数据怎么排布

192
00:07:04,400 --> 00:07:07,560
是根据我们的硬件的执行方式相关联的

193
00:07:07,560 --> 00:07:08,880
不是说我随便排都行

194
00:07:08,880 --> 00:07:10,040
我们在CPU里面

195
00:07:10,040 --> 00:07:12,280
在GPU里面的排布方式是不一样的

196
00:07:12,280 --> 00:07:14,160
包括我们在生成处理器里面的

197
00:07:14,160 --> 00:07:15,760
排布方式也是不同的

198
00:07:16,000 --> 00:07:17,320
我们最重要的方式

199
00:07:17,440 --> 00:07:19,040
就是找到在计算图当中

200
00:07:19,040 --> 00:07:20,320
存储这个张量

201
00:07:20,320 --> 00:07:22,320
最佳的数据布局

202
00:07:22,320 --> 00:07:23,680
大家注意一个概念

203
00:07:23,880 --> 00:07:26,240
这里面我们是谈的计算图

204
00:07:26,720 --> 00:07:28,160
所以我们会在图层AI里面

205
00:07:28,160 --> 00:07:29,280
去实现Path

206
00:07:29,280 --> 00:07:30,680
或者实现转换

207
00:07:30,680 --> 00:07:32,040
然后将数据布局

208
00:07:32,160 --> 00:07:34,160
转换成为具体的节点

209
00:07:34,160 --> 00:07:35,760
插到我们的图中的

210
00:07:36,160 --> 00:07:37,280
值得注意的方式

211
00:07:37,280 --> 00:07:38,440
就是我们的数据布局

212
00:07:38,560 --> 00:07:40,160
是最终对我们的性能

213
00:07:40,160 --> 00:07:41,600
有非常大的影响

214
00:07:41,600 --> 00:07:43,200
而且转换的操作

215
00:07:43,200 --> 00:07:44,840
也有非常大的开销

216
00:07:44,920 --> 00:07:46,200
每一次数据的转换

217
00:07:46,200 --> 00:07:47,240
就涉及到Io

218
00:07:47,240 --> 00:07:48,840
涉及到我们的仿存

219
00:07:49,680 --> 00:07:51,040
回顾一些之前讲过的

220
00:07:51,040 --> 00:07:52,640
一些比较通用的概念

221
00:07:52,640 --> 00:07:55,200
第一个就是NCHW这种格式

222
00:07:55,400 --> 00:07:56,600
在我们的GPU上面

223
00:07:56,600 --> 00:07:58,120
是运行的比较快的

224
00:07:58,120 --> 00:07:59,680
所以GPU上面默认的

225
00:07:59,680 --> 00:08:02,040
去使用NCHW这种格式

226
00:08:02,040 --> 00:08:03,400
利用我们的达芬奇架构

227
00:08:03,560 --> 00:08:05,120
就会提供一个CAND

228
00:08:05,120 --> 00:08:06,240
这个硬件的库

229
00:08:06,600 --> 00:08:07,480
芯片使用层

230
00:08:07,680 --> 00:08:09,600
去解决这些问题的

231
00:08:09,880 --> 00:08:11,120
还有第三点

232
00:08:11,280 --> 00:08:13,080
就是一些边缘的设备

233
00:08:13,080 --> 00:08:14,080
例如很简单的

234
00:08:14,120 --> 00:08:15,520
就是我们的手机

235
00:08:15,520 --> 00:08:16,960
手机这块SoC

236
00:08:17,080 --> 00:08:18,440
里面有丰富的IP

237
00:08:18,440 --> 00:08:20,200
包括我们的ARM端测的GPU

238
00:08:20,200 --> 00:08:21,040
还有ISP

239
00:08:21,040 --> 00:08:22,120
还有DPU等

240
00:08:22,120 --> 00:08:24,360
不同的一些计算单元

241
00:08:24,600 --> 00:08:25,800
不同的计算单元之间

242
00:08:25,920 --> 00:08:28,280
可能会有不同的数据排布

243
00:08:28,280 --> 00:08:29,960
所以针对边缘设备

244
00:08:29,960 --> 00:08:31,000
可能我们就会有

245
00:08:31,000 --> 00:08:32,120
异构的计算单元

246
00:08:32,120 --> 00:08:33,880
这个时候数据的转换

247
00:08:34,080 --> 00:08:36,200
就显得非常的重要了

248
00:08:36,200 --> 00:08:37,280
我们的AI编译器

249
00:08:37,480 --> 00:08:38,960
就是希望能够提供一种

250
00:08:38,960 --> 00:08:41,160
跨硬件的一个数据排布

251
00:08:41,160 --> 00:08:42,280
转换的方式

252
00:08:42,320 --> 00:08:44,480
方便我们对接到不同的后端

253
00:08:44,960 --> 00:08:46,960
所以这个故事就告诉我们

254
00:08:47,080 --> 00:08:48,240
在我们写AI算法

255
00:08:48,240 --> 00:08:49,560
或者实现AI算法的时候

256
00:08:49,760 --> 00:08:51,280
其实AI框架

257
00:08:51,280 --> 00:08:52,120
或者AI编译器

258
00:08:52,240 --> 00:08:53,040
帮我们做了

259
00:08:53,040 --> 00:08:55,040
很多我们感知不到的工作

260
00:08:55,040 --> 00:08:56,200
不要以为AI框架

261
00:08:56,200 --> 00:08:57,640
只是一个简单的库

262
00:08:57,640 --> 00:08:59,600
直接调用我们的算子就完了

263
00:08:59,600 --> 00:09:00,400
AI框架

264
00:09:00,400 --> 00:09:02,400
其实里面的技术含量

265
00:09:02,400 --> 00:09:03,520
还是非常高的

266
00:09:03,800 --> 00:09:05,080
现在我们看看

267
00:09:05,080 --> 00:09:06,480
具体的数据转换

268
00:09:06,480 --> 00:09:07,800
是怎么样操作的

269
00:09:07,840 --> 00:09:09,920
首先假设我输进去的数据

270
00:09:10,080 --> 00:09:12,240
是一个NHWC的数据

271
00:09:12,560 --> 00:09:13,480
我输出的时候

272
00:09:13,680 --> 00:09:15,400
我是一个NCHW

273
00:09:15,640 --> 00:09:17,200
这个时候我就进行了一个

274
00:09:17,200 --> 00:09:19,000
数据格式的转换了

275
00:09:19,360 --> 00:09:20,200
数据转换

276
00:09:20,440 --> 00:09:22,320
我们假设它是一个算子

277
00:09:22,320 --> 00:09:23,720
然后这个算子

278
00:09:23,720 --> 00:09:26,240
是对我们的内存排布进行修改的

279
00:09:26,240 --> 00:09:27,440
我们这个算子叫做

280
00:09:27,440 --> 00:09:28,480
Custom Data

281
00:09:28,480 --> 00:09:31,160
NHWC to NCHW

282
00:09:31,560 --> 00:09:32,880
另外还有另外一种情况

283
00:09:32,880 --> 00:09:34,680
就把它们反过来

284
00:09:34,680 --> 00:09:37,400
我们的数是NCHW

285
00:09:37,680 --> 00:09:39,840
我的输出是NHWC

286
00:09:39,840 --> 00:09:41,680
中间插一个Custom算子

287
00:09:41,840 --> 00:09:43,080
这个Custom Data的算子

288
00:09:43,400 --> 00:09:45,760
是把NCHW的数据格式

289
00:09:45,760 --> 00:09:49,000
转换到NHWC的数据格式

290
00:09:49,000 --> 00:09:51,320
接下来我们看一个更复杂的例子

291
00:09:51,320 --> 00:09:52,880
就是我们常见的

292
00:09:52,880 --> 00:09:54,760
数据转换的一个节点

293
00:09:55,200 --> 00:09:56,440
其实很简单

294
00:09:56,800 --> 00:09:58,760
我们以左边的第一个图来看

295
00:09:58,760 --> 00:10:01,040
首先我们现在有两个算子

296
00:10:01,040 --> 00:10:01,720
第一个算子

297
00:10:02,000 --> 00:10:04,480
执行的是NCHW的格式

298
00:10:04,480 --> 00:10:06,600
它的输出也是NCHW

299
00:10:06,840 --> 00:10:07,480
第二个算子

300
00:10:07,680 --> 00:10:09,200
它的输入和输出

301
00:10:09,200 --> 00:10:11,080
也是NCHW

302
00:10:11,280 --> 00:10:11,800
这个时候

303
00:10:11,920 --> 00:10:13,760
我们在神经网络里面处理的时候

304
00:10:13,920 --> 00:10:15,320
其实是不感知的

305
00:10:15,320 --> 00:10:16,960
就我输入一个数据

306
00:10:16,960 --> 00:10:17,920
已经定义好了

307
00:10:17,920 --> 00:10:20,400
输出还是这种数据的格式

308
00:10:20,760 --> 00:10:22,440
但是有些情况下

309
00:10:22,440 --> 00:10:23,640
我们的算子

310
00:10:23,640 --> 00:10:26,680
它处理的是一个NCHW

311
00:10:26,680 --> 00:10:27,400
我们的输入

312
00:10:27,560 --> 00:10:29,760
是一个NHW的数据的时候

313
00:10:30,000 --> 00:10:33,040
我这里面就需要做一个数据的转换

314
00:10:33,040 --> 00:10:34,120
然后输出的时候

315
00:10:34,120 --> 00:10:36,240
可能我还是变成NCHW

316
00:10:36,240 --> 00:10:38,440
我们就需要再插一个算子

317
00:10:38,440 --> 00:10:40,080
进行数据的转换

318
00:10:40,120 --> 00:10:40,640
当然了

319
00:10:40,640 --> 00:10:42,800
我们还会遇到一个最复杂的方式

320
00:10:42,800 --> 00:10:45,120
就是我上一个算子的输入输出

321
00:10:45,120 --> 00:10:47,200
跟下一个算子的输出

322
00:10:47,200 --> 00:10:49,320
是完全不对等的

323
00:10:49,320 --> 00:10:50,960
这个时候AI框架

324
00:10:50,960 --> 00:10:51,800
或者AI编译器

325
00:10:52,040 --> 00:10:53,600
就需要去插入

326
00:10:53,600 --> 00:10:55,400
不同的数据转换的算子

327
00:10:55,400 --> 00:10:57,400
然后才能够使得我们整图

328
00:10:57,400 --> 00:10:58,320
能够跑得通

329
00:10:59,600 --> 00:11:01,400
接下来我们讲两个例子

330
00:11:01,400 --> 00:11:01,960
第一个例子

331
00:11:02,080 --> 00:11:04,080
是在我们的训练场景

332
00:11:04,080 --> 00:11:05,560
训练场景的AI编辑器

333
00:11:05,560 --> 00:11:07,160
跟我们推理的场景的AI编辑器

334
00:11:07,160 --> 00:11:08,960
可能有一点点不同

335
00:11:09,040 --> 00:11:11,960
我们简单的来去从训练场景去看看

336
00:11:12,440 --> 00:11:14,120
假设我们现在有一个例子

337
00:11:14,120 --> 00:11:16,160
我们现在这里面有一个卷积

338
00:11:16,160 --> 00:11:17,960
然后下一层也有一个卷积

339
00:11:17,960 --> 00:11:19,240
但是上一层的卷积

340
00:11:19,360 --> 00:11:20,720
是一个一层一的卷积

341
00:11:20,720 --> 00:11:21,800
下一层的卷积

342
00:11:21,800 --> 00:11:23,400
是一个三层三的卷积

343
00:11:23,760 --> 00:11:24,800
例如一层一的卷积

344
00:11:24,960 --> 00:11:27,200
我们使用NHWC的格式

345
00:11:27,200 --> 00:11:28,480
但是下层的卷积

346
00:11:28,480 --> 00:11:29,800
是一个三层三的卷积

347
00:11:29,800 --> 00:11:32,040
我们会用NCHW这种格式

348
00:11:32,040 --> 00:11:34,320
这个时候我们就要像B图那样

349
00:11:34,320 --> 00:11:35,440
针对特定的格式

350
00:11:35,640 --> 00:11:37,560
插入具体的转换的算子

351
00:11:37,600 --> 00:11:40,080
AI编辑器就会感知整个图的情况

352
00:11:40,080 --> 00:11:41,240
感知上下文

353
00:11:41,240 --> 00:11:42,520
就是上面的算子

354
00:11:42,520 --> 00:11:44,240
下面的算子的存储格式

355
00:11:44,240 --> 00:11:46,880
接着插入具体的转换算子

356
00:11:46,880 --> 00:11:48,680
这个就是我们第二种方式

357
00:11:48,920 --> 00:11:50,920
当然了我们还有第三种方式

358
00:11:50,920 --> 00:11:53,800
假设我是三个连续的一层一的卷积

359
00:11:53,960 --> 00:11:56,360
这时候我有非常多的这种转换算子

360
00:11:56,360 --> 00:11:58,520
但实际上我卷积一层一的算子

361
00:11:58,520 --> 00:12:00,600
我的输出都是相同的

362
00:12:00,600 --> 00:12:01,160
这个时候

363
00:12:01,280 --> 00:12:04,000
AI编辑器就会去取消转换的算子

364
00:12:04,000 --> 00:12:06,080
就是把一些转换的算子删掉

365
00:12:06,120 --> 00:12:08,040
重新变回我们的A图

366
00:12:08,040 --> 00:12:09,320
就是一层一的卷积

367
00:12:09,320 --> 00:12:11,200
然后下一个一层一的卷积

368
00:12:11,200 --> 00:12:13,720
使用的都是NCHW这种格式

369
00:12:13,720 --> 00:12:15,640
这就是我们整体训练场景

370
00:12:15,640 --> 00:12:17,800
AI编辑器会帮我们做的工作

371
00:12:17,800 --> 00:12:20,200
这也是我们华为生产CAN里面

372
00:12:20,200 --> 00:12:22,480
帮用户去解决的一些问题

373
00:12:25,120 --> 00:12:27,320
推理场景其实很重要的一点

374
00:12:27,320 --> 00:12:30,400
就是我们会对权重的布局进行转换

375
00:12:30,960 --> 00:12:33,880
这个时候小新可能会又想跳出来去问

376
00:12:33,920 --> 00:12:37,440
为什么我们要对权重的数据布局进行转换

377
00:12:38,200 --> 00:12:40,040
假设我们现在在GPU上面

378
00:12:40,040 --> 00:12:41,600
去训练我们的神级网络

379
00:12:41,600 --> 00:12:43,160
但是我们在推理的时候

380
00:12:43,480 --> 00:12:45,800
就会到手机上面去进行推理

381
00:12:46,080 --> 00:12:48,520
手机上面主要是跑在CPU上面

382
00:12:48,760 --> 00:12:50,120
我们的权重的数据布局

383
00:12:50,240 --> 00:12:52,560
就跟我们的GPU训练的时候的权重布局

384
00:12:52,560 --> 00:12:53,280
就会不一样

385
00:12:53,280 --> 00:12:55,400
所以我们会在AI推理编辑器

386
00:12:55,400 --> 00:12:56,800
或者AI转换模块里面

387
00:12:57,160 --> 00:12:59,600
做一个权重布局的转换

388
00:13:01,720 --> 00:13:02,880
在这两节课里面

389
00:13:03,000 --> 00:13:04,240
我们主要是了解了

390
00:13:04,240 --> 00:13:06,200
数据内存的一个排布方式

391
00:13:06,200 --> 00:13:09,160
了解了张亮的数据的整体的布局

392
00:13:09,160 --> 00:13:10,520
其实是非常复杂的

393
00:13:10,520 --> 00:13:12,160
另外还举了两个例子

394
00:13:12,160 --> 00:13:14,640
NCHW和NHWC

395
00:13:14,640 --> 00:13:16,160
两个具体的形态

396
00:13:16,160 --> 00:13:17,600
接着去看了一下

397
00:13:17,600 --> 00:13:19,520
华为升腾达芬奇架构

398
00:13:19,520 --> 00:13:21,360
具体的数据排布的方式

399
00:13:21,360 --> 00:13:23,520
有分型的J分型的NZ

400
00:13:23,520 --> 00:13:26,760
NHCEWC0这种方式

401
00:13:26,760 --> 00:13:28,960
另外我们还了解了编译器

402
00:13:28,960 --> 00:13:30,400
特别是AI编译器里面

403
00:13:30,600 --> 00:13:32,840
数据布局转换优化了一个具体的

404
00:13:32,840 --> 00:13:33,520
算法

405
00:13:33,520 --> 00:13:34,760
对我们的计算图

406
00:13:34,920 --> 00:13:36,080
插入我们的CustData

407
00:13:36,080 --> 00:13:37,240
或者对我们的CustData

408
00:13:37,320 --> 00:13:38,480
进行一个消除

409
00:13:38,480 --> 00:13:39,920
使得我们整个计算图

410
00:13:40,200 --> 00:13:41,960
能够在对应的硬件上面

411
00:13:41,960 --> 00:13:43,360
真正的执行起来

412
00:13:44,280 --> 00:13:45,000
谢谢各位

413
00:13:45,000 --> 00:13:46,080
卷的不行了

414
00:13:46,080 --> 00:13:46,920
卷的不行了

415
00:13:46,920 --> 00:13:48,360
记得一键三连加关注

416
00:13:48,760 --> 00:13:50,120
所有的内容都会开源

417
00:13:50,120 --> 00:13:51,880
在下面这条链接里面

418
00:13:52,320 --> 00:13:53,200
摆了个掰

