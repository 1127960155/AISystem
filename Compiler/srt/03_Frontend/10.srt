1
00:00:00,000 --> 00:00:04,500
巴巴巴巴巴巴巴巴巴巴

2
00:00:06,500 --> 00:00:08,500
嗨,大家好,我是ZOMI

3
00:00:08,500 --> 00:00:12,000
今天呢,这是一个额外加的鸡腿

4
00:00:12,000 --> 00:00:15,000
AI编译系列的前端优化里面

5
00:00:15,000 --> 00:00:17,000
单独提了一个Summary

6
00:00:17,000 --> 00:00:20,000
那Summary里面主要讲啥内容呢?

7
00:00:20,000 --> 00:00:24,000
有一个同学问我前端这么多优化,这么多不同的Path

8
00:00:24,000 --> 00:00:26,000
到底哪个在先,哪个在后

9
00:00:26,000 --> 00:00:29,500
有没有固定的顺序或者一些比较好的参考资料呢?

10
00:00:30,000 --> 00:00:32,500
我认为你应该可以帮帮我

11
00:00:35,500 --> 00:00:37,500
那这里面呢,我想回答这个问题

12
00:00:37,500 --> 00:00:40,500
所以加了一节鸡腿,首先我们搞清楚几个概念

13
00:00:40,500 --> 00:00:44,500
我们讲的前端优化,图层优化,还有计算图的优化呢

14
00:00:44,500 --> 00:00:46,500
都是相同的概念

15
00:00:46,500 --> 00:00:50,500
在我们的AI编译器都是指的相同的一个概念

16
00:00:52,500 --> 00:00:54,500
在整个AI编译器里面呢

17
00:00:54,500 --> 00:00:57,500
我们的AI框架前端对Python的代码解析

18
00:00:57,500 --> 00:00:59,500
变成一个计算图

19
00:00:59,500 --> 00:01:02,500
那这个计算图呢,传给我们的整个AI编译器呢

20
00:01:02,500 --> 00:01:04,500
我们叫做前端优化

21
00:01:04,500 --> 00:01:07,500
也可以叫做图层优化,或者计算图的优化

22
00:01:07,500 --> 00:01:11,500
而这里面呢,先不要管右边的这些内容可能会有错误

23
00:01:11,500 --> 00:01:14,500
但是呢,我们现在处在红色框所在的位置

24
00:01:14,500 --> 00:01:16,500
这些Path,它是有一定的顺序

25
00:01:16,500 --> 00:01:19,500
但是呢,没有一个完全固定的顺序

26
00:01:19,500 --> 00:01:22,500
我们往下看一下正式的一个目录

27
00:01:22,500 --> 00:01:25,500
当时设计的时候呢,分开了左右两边

28
00:01:25,500 --> 00:01:29,500
那左边呢,更关注的就是神经网络相关的优化

29
00:01:29,500 --> 00:01:31,500
就跟我们的神经网络更相关的

30
00:01:31,500 --> 00:01:34,500
而这里面呢,其实是有一定的顺序

31
00:01:34,500 --> 00:01:36,500
但这些顺序呢,不一定对

32
00:01:36,500 --> 00:01:39,500
所以呢,是给大家作为一个参考

33
00:01:39,500 --> 00:01:42,500
首先第一步就是计算图传进来之后呢

34
00:01:42,500 --> 00:01:45,500
其实我们有非常多的散的算子或者小的算子

35
00:01:45,500 --> 00:01:48,500
最重要的一个加速功能就是融合算子

36
00:01:48,500 --> 00:01:50,500
把一些小的算子变成一个大算子

37
00:01:50,500 --> 00:01:54,500
算子融合了一般来说,我都会把它排在前面

38
00:01:54,500 --> 00:01:55,500
融合了新的算子之后呢

39
00:01:55,500 --> 00:01:58,500
我们就会产生新的算子,新的大算子

40
00:01:58,500 --> 00:02:00,500
而新的算子,不同的算子之间

41
00:02:00,500 --> 00:02:03,500
它的数据内存排布是不同的

42
00:02:03,500 --> 00:02:05,500
所以接着呢,有了新的算子之后

43
00:02:05,500 --> 00:02:08,500
我们需要对数据内存排布进行一个转换

44
00:02:08,500 --> 00:02:10,500
使得我们这个计算图呢

45
00:02:10,500 --> 00:02:12,500
是符合真正运行的时候计算图

46
00:02:12,500 --> 00:02:15,500
有了真正能够运行的计算图之后呢

47
00:02:15,500 --> 00:02:19,500
就需要对这个计算图的动态内存和静态内存

48
00:02:19,500 --> 00:02:21,500
进行一个合理的分配

49
00:02:21,500 --> 00:02:24,500
于是呢,我们就来到了内存分配

50
00:02:24,500 --> 00:02:26,500
Memory Allocation 这个内容

51
00:02:26,500 --> 00:02:29,500
所以说,算子融合,布局转换,内存分配

52
00:02:29,500 --> 00:02:32,500
那这三个呢,都是跟神经网络相关的

53
00:02:32,500 --> 00:02:35,500
而这三个呢,其实是有一定的关联顺序

54
00:02:37,500 --> 00:02:38,500
下面我们来看看

55
00:02:38,500 --> 00:02:41,500
刚才讲的更多的是一个训练的场景

56
00:02:41,500 --> 00:02:43,500
其实在推理场景里面呢

57
00:02:43,500 --> 00:02:44,500
因为我们训练的框架

58
00:02:44,500 --> 00:02:48,500
可以用 PyTorch,可以用 MySQL,可以用 TensorFlow

59
00:02:48,500 --> 00:02:51,500
不同的AI框架呢,有不同的算子的定义

60
00:02:51,500 --> 00:02:53,500
在我们的推理框架里面呢

61
00:02:53,500 --> 00:02:55,500
可能就会多了这么一层算子替换

62
00:02:55,500 --> 00:02:57,500
有时候算子替换呢

63
00:02:57,500 --> 00:03:00,500
也可以在我们训练的AI编辑里面实现

64
00:03:01,500 --> 00:03:04,500
所以说,它们之间没有一个明确的gap和定义

65
00:03:04,500 --> 00:03:06,500
但是呢,有一定的规律顺序

66
00:03:06,500 --> 00:03:09,500
那接着我们看看右边这一部分

67
00:03:09,500 --> 00:03:10,500
右边这一部分呢

68
00:03:10,500 --> 00:03:11,500
我们看到了常量折叠啊

69
00:03:11,500 --> 00:03:13,500
公共词表达式消除

70
00:03:13,500 --> 00:03:14,500
死代码消除

71
00:03:14,500 --> 00:03:15,500
怠速简化

72
00:03:15,500 --> 00:03:16,500
这些内容呢

73
00:03:16,500 --> 00:03:18,500
更偏向于我们对代码层面

74
00:03:18,500 --> 00:03:20,500
对计算层面

75
00:03:20,500 --> 00:03:21,500
对数学层面

76
00:03:21,500 --> 00:03:23,500
对代数层面进行的一些优化

77
00:03:23,500 --> 00:03:25,500
那这些优化呢

78
00:03:25,500 --> 00:03:27,500
跟传统编译器的概念呢

79
00:03:27,500 --> 00:03:28,500
更加相像

80
00:03:28,500 --> 00:03:31,500
也是把传统编译器一些优化的pass呢

81
00:03:31,500 --> 00:03:33,500
往我们的计算图上面去套

82
00:03:33,500 --> 00:03:35,500
或者往我们计算图上面去迁移

83
00:03:35,500 --> 00:03:37,500
那这种优化的pass呢

84
00:03:37,500 --> 00:03:38,500
是往后排的

85
00:03:39,500 --> 00:03:41,500
常量折叠我把它往前排

86
00:03:41,500 --> 00:03:43,500
是因为我们在推理场景里面呢

87
00:03:43,500 --> 00:03:44,500
经常会用到

88
00:03:44,500 --> 00:03:46,500
而且使用的概率非常高

89
00:03:46,500 --> 00:03:48,500
有可能我能够容忍

90
00:03:48,500 --> 00:03:50,500
一些公共词表达式没有消除掉

91
00:03:50,500 --> 00:03:51,500
但是呢

92
00:03:51,500 --> 00:03:53,500
常量折叠确实给我们的性能

93
00:03:53,500 --> 00:03:55,500
带来很大的收益

94
00:03:55,500 --> 00:03:57,500
而且它跟神经网络的其实是

95
00:03:57,500 --> 00:03:58,500
比较相关

96
00:03:58,500 --> 00:04:01,500
但它属于怠速和计算层面的一个优化

97
00:04:01,500 --> 00:04:03,500
所以把它摆在第一的位置

98
00:04:04,500 --> 00:04:05,500
接下来呢

99
00:04:05,500 --> 00:04:09,500
更多的是公共词表达式的消除和怠速的简化

100
00:04:09,500 --> 00:04:10,500
这两个呢

101
00:04:10,500 --> 00:04:11,500
其实没有明确的上下关系

102
00:04:11,500 --> 00:04:13,500
它们两个可以互相调用

103
00:04:13,500 --> 00:04:16,500
放在最后的应该是死代码的消除

104
00:04:16,500 --> 00:04:17,500
那死代码的消除

105
00:04:17,500 --> 00:04:19,500
我觉得是必须要有

106
00:04:19,500 --> 00:04:21,500
而且放在最后可能会更加合理

107
00:04:21,500 --> 00:04:23,500
把一些没有用的勇于的代码

108
00:04:23,500 --> 00:04:24,500
我们把它干掉

109
00:04:25,500 --> 00:04:26,500
虽然叫死代码消除

110
00:04:26,500 --> 00:04:29,500
但实际上它消除的是我们的计算的节点

111
00:04:31,500 --> 00:04:35,500
现在了解完我们整个AI编译器的前端优化之后呢

112
00:04:35,500 --> 00:04:37,500
我们将会在后面去详细的展开

113
00:04:37,500 --> 00:04:39,500
AI编译器的后端的优化

114
00:04:39,500 --> 00:04:43,500
去了解一下我们后端到底有哪些好玩的东西

115
00:04:44,500 --> 00:04:46,500
有哪些核心的基础点

116
00:04:46,500 --> 00:04:47,500
好了谢谢各位

117
00:04:47,500 --> 00:04:48,500
摆了个拜

118
00:04:48,500 --> 00:04:50,500
卷的不行了卷的不行了

119
00:04:50,500 --> 00:04:52,500
记得一键三连加关注哦

120
00:04:52,500 --> 00:04:55,500
所有的内容都会开源在下面这条链接里面

121
00:04:55,500 --> 00:04:56,500
摆了个拜

