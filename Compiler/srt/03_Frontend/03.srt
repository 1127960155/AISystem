1
00:00:00,000 --> 00:00:08,080
Hello,大家好,我是DOMI

2
00:00:08,080 --> 00:00:12,720
今天我们还是回到我们AI编辑器系列里面的前端优化

3
00:00:12,720 --> 00:00:15,840
而前端优化上一节我们讲了一个图层的IR

4
00:00:15,840 --> 00:00:16,920
有了图层IR之后

5
00:00:16,920 --> 00:00:19,160
我们第一个part就是算子融合

6
00:00:19,160 --> 00:00:22,080
算子融合我们又叫做OPFusion

7
00:00:22,080 --> 00:00:23,560
在今天算子融合里面

8
00:00:23,560 --> 00:00:26,680
我们主要分开三个内容给大家介绍的

9
00:00:26,680 --> 00:00:29,680
第一个就是算子融合的方式

10
00:00:29,680 --> 00:00:31,280
算子融合有很多种方式的

11
00:00:31,280 --> 00:00:33,640
大家不要觉得算子融合是很简单

12
00:00:33,640 --> 00:00:37,240
我们平时觉得简单是因为我们看的更多的是

13
00:00:37,240 --> 00:00:40,040
卷起边录这种算子的融合的策略

14
00:00:40,040 --> 00:00:41,560
有了这些策略之后

15
00:00:41,560 --> 00:00:43,320
我们就会对它进行总结

16
00:00:43,320 --> 00:00:47,560
然后变成一个具体的优化的part和优化的算法

17
00:00:47,560 --> 00:00:51,040
接着我们来看看现在我们处于哪个位置

18
00:00:51,040 --> 00:00:53,080
第一个就是我们的AI框架

19
00:00:53,080 --> 00:00:56,480
好多的AI框架会对我们的python的代码进行解析

20
00:00:56,480 --> 00:00:57,960
变成一个图层的IR

21
00:00:57,960 --> 00:00:59,280
就是我们的计算图

22
00:00:59,320 --> 00:01:02,640
有了计算图之后就丢给我们真正的AI编译器

23
00:01:02,640 --> 00:01:04,600
AI编译器就会对我们的代码

24
00:01:04,600 --> 00:01:08,240
对我们的图层的IR进行前端的优化

25
00:01:08,240 --> 00:01:10,680
而现在我们还是在这个位置

26
00:01:11,440 --> 00:01:14,040
算子融合作为前端的一个part

27
00:01:14,040 --> 00:01:16,080
对我们的graph IR进行改变

28
00:01:16,080 --> 00:01:18,480
把一些小的算子变成一个大的算子

29
00:01:19,240 --> 00:01:21,320
现在我们来看看第一个最重要的内容

30
00:01:21,320 --> 00:01:23,520
就是算子的融合方式

31
00:01:23,960 --> 00:01:25,800
其实在真正做调研的时候

32
00:01:25,920 --> 00:01:28,800
我并不觉得算子的融合方式有多难

33
00:01:28,800 --> 00:01:30,480
但是真正看了之后我才发现

34
00:01:30,960 --> 00:01:33,440
原来算子的融合方式还能这么多吗

35
00:01:34,320 --> 00:01:35,200
好像有点大声

36
00:01:35,760 --> 00:01:38,040
小声点 不然吵到隔壁路客的时候

37
00:01:38,560 --> 00:01:40,400
现在我们来看看网络模型的结构

38
00:01:40,520 --> 00:01:42,800
网络模型的结构其实也非常复杂

39
00:01:42,800 --> 00:01:44,640
我们可以看到一串串下来

40
00:01:44,880 --> 00:01:48,000
大部分网络模型都是以这种方式来去组织的

41
00:01:48,280 --> 00:01:50,480
而我们其实有非常多的小算子

42
00:01:50,720 --> 00:01:53,160
能不能把这些小算子合成一个大的算子

43
00:01:53,400 --> 00:01:55,320
减少我们对kernel的调度

44
00:01:55,320 --> 00:01:56,960
然后减少我们对内存的访问

45
00:01:57,080 --> 00:02:01,280
这个就是我们做算子融合最大的一个目的

46
00:02:01,720 --> 00:02:03,880
现在我们来看看融合有哪种方式

47
00:02:03,880 --> 00:02:07,240
假设我们现在有这么一个左边的计算图

48
00:02:07,240 --> 00:02:08,800
让我做一个纵向的融合

49
00:02:08,800 --> 00:02:11,400
把C算子和D算子进行融合

50
00:02:11,400 --> 00:02:15,400
这个时候我们已经减少了一次的kernel的开销

51
00:02:15,400 --> 00:02:18,760
而且也减少了一次中间的数据的访存

52
00:02:20,280 --> 00:02:23,280
第二种方式就是我算子A计算完之后

53
00:02:23,440 --> 00:02:26,320
分别给B算子和C算子进行执行

54
00:02:26,440 --> 00:02:29,920
而B算子和C算子它是一个并行的执行

55
00:02:30,040 --> 00:02:32,240
就是B和C是同时执行的

56
00:02:32,240 --> 00:02:34,960
但这里面就会有两次的访存

57
00:02:35,240 --> 00:02:36,760
我向右边的这个手势

58
00:02:36,760 --> 00:02:39,840
我把A算子和B算子一起去执行

59
00:02:39,840 --> 00:02:42,320
再把A算子和C算子进行执行

60
00:02:42,320 --> 00:02:44,920
AB跟AC是同时并行的

61
00:02:44,920 --> 00:02:48,200
这个时候我只执行两次kernel的开销

62
00:02:48,200 --> 00:02:50,320
而且并发只有一个来回

63
00:02:50,560 --> 00:02:52,480
我只需要一次的访存

64
00:02:52,480 --> 00:02:54,080
这种方式也是可以的

65
00:02:54,600 --> 00:02:56,200
另外图还是这个图

66
00:02:56,200 --> 00:02:57,440
它的方式有很多

67
00:02:57,440 --> 00:03:01,080
像现在我们左边的B和C需要并发

68
00:03:01,080 --> 00:03:03,360
然后它需要调用两次的kernel开销

69
00:03:03,360 --> 00:03:06,280
而右边我把B和C进行融合

70
00:03:06,280 --> 00:03:10,320
这种横向的融合我们确实叫做横向融合

71
00:03:10,320 --> 00:03:12,960
这里面减少了一次kernel的调度

72
00:03:12,960 --> 00:03:14,640
而且两次的计算结果

73
00:03:14,800 --> 00:03:17,200
都放在我们同一个内存块里面

74
00:03:17,200 --> 00:03:20,040
加快了我们内存访问的效率

75
00:03:21,040 --> 00:03:24,360
没想到这里面这种图还有这么多融合方式

76
00:03:24,360 --> 00:03:25,680
现在我们来看看

77
00:03:25,680 --> 00:03:28,080
ABC三个算子进行计算的时候

78
00:03:28,080 --> 00:03:29,920
会有三次的kernel开销

79
00:03:29,920 --> 00:03:32,040
如果我把A和B进行融合

80
00:03:32,040 --> 00:03:34,000
就是A和B进行融合

81
00:03:34,360 --> 00:03:35,520
然后合并完之后

82
00:03:35,520 --> 00:03:37,960
把所有的结果丢在我们的内存里面

83
00:03:37,960 --> 00:03:40,200
这个时候再给C进行计算

84
00:03:40,200 --> 00:03:42,520
另外一个结果给下一个进行计算

85
00:03:42,520 --> 00:03:45,520
这个时候可以提高我们的内存的使用效率

86
00:03:45,520 --> 00:03:46,720
从上面几个例子

87
00:03:46,720 --> 00:03:49,160
我们可以看出不同的算子融合策略

88
00:03:49,160 --> 00:03:51,160
会产生不同的算子的开销

89
00:03:51,160 --> 00:03:54,520
也可以带来不同的内存访问的性能的提升

90
00:03:55,280 --> 00:03:58,640
我们现在来看看一个比较综合性的

91
00:03:58,640 --> 00:04:00,280
一个融合的方式

92
00:04:00,280 --> 00:04:02,280
现在我们有一个卷积渲子

93
00:04:02,280 --> 00:04:03,440
1x1x256

94
00:04:03,440 --> 00:04:05,400
然后有一个转积渲子

95
00:04:05,400 --> 00:04:07,200
3x3x256

96
00:04:07,200 --> 00:04:09,920
我会把鼠标所在的卷积的算子

97
00:04:10,120 --> 00:04:11,720
把它进行一个扩充

98
00:04:11,720 --> 00:04:13,240
inlatch我们的卷积

99
00:04:13,240 --> 00:04:15,320
然后变成一个3x3x256

100
00:04:15,320 --> 00:04:18,800
接着对这两个3x3x256的进行一个合并

101
00:04:18,840 --> 00:04:20,200
合并成一个算子

102
00:04:20,200 --> 00:04:22,760
变成我们的卷积3x3x252

103
00:04:22,760 --> 00:04:25,000
有了这个横向的融合之后

104
00:04:25,160 --> 00:04:27,040
我们想做一个纵向的融合

105
00:04:27,040 --> 00:04:27,840
纵向的融合

106
00:04:28,000 --> 00:04:29,160
我们现在有个Split

107
00:04:29,160 --> 00:04:30,440
有个卷积有个Add

108
00:04:30,440 --> 00:04:33,080
现在我们把Split 卷积 Add

109
00:04:33,080 --> 00:04:34,600
把它合成一个算子

110
00:04:34,600 --> 00:04:36,680
变成卷积2D 3x3x256

111
00:04:36,680 --> 00:04:37,840
但是我觉得还不够

112
00:04:37,840 --> 00:04:39,240
像激活一般来说

113
00:04:39,240 --> 00:04:41,760
都可以合并在我们前一个计算里面

114
00:04:41,760 --> 00:04:44,600
所以我们要把卷积V2合并起来

115
00:04:45,120 --> 00:04:46,480
这个操作很有意思的

116
00:04:46,480 --> 00:04:48,960
就是我们一开始的计算图是比较复杂的

117
00:04:48,960 --> 00:04:49,920
比较多算子的

118
00:04:49,920 --> 00:04:50,960
最后融合起来了

119
00:04:50,960 --> 00:04:53,080
我们就算子就减少了很多

120
00:04:53,080 --> 00:04:55,400
虽然有部分的计算可能会变大

121
00:04:55,400 --> 00:04:56,560
但是总体来说

122
00:04:56,560 --> 00:04:58,480
我们减少了颗脑的开销

123
00:04:58,480 --> 00:05:01,080
我们减少了对内存的不断的访问

124
00:05:03,640 --> 00:05:04,920
刚才上面那个例子

125
00:05:05,080 --> 00:05:07,720
其实我们已经很清楚的看到了

126
00:05:08,320 --> 00:05:10,760
算子融合确实对我们整个计算图

127
00:05:10,760 --> 00:05:11,880
或者整个运算的时候

128
00:05:12,000 --> 00:05:13,240
产生很大的收益

129
00:05:13,440 --> 00:05:14,920
我们主要是解决两个问题

130
00:05:14,920 --> 00:05:16,920
一个是内存墙的问题

131
00:05:16,920 --> 00:05:19,360
就是减少我们的访问内存

132
00:05:19,360 --> 00:05:21,920
那第二个就是并行墙的问题

133
00:05:21,920 --> 00:05:23,920
将我们计算图的算子的节点

134
00:05:24,200 --> 00:05:25,320
并行的编排

135
00:05:25,320 --> 00:05:28,040
从而提升整体的并行的效率

136
00:05:28,040 --> 00:05:30,440
这个就是做算子融合的目的

137
00:05:31,840 --> 00:05:33,800
现在我们有一个非常经典的

138
00:05:33,800 --> 00:05:36,960
卷积BnV2三个算子

139
00:05:36,960 --> 00:05:39,760
和三个非常经典的算子进行融合

140
00:05:39,760 --> 00:05:41,520
看看它到底是怎么操作的

141
00:05:41,760 --> 00:05:42,920
首先我们看一下

142
00:05:42,920 --> 00:05:44,200
Bn在计算的时候

143
00:05:44,360 --> 00:05:46,880
我们需要去求输入数据

144
00:05:46,880 --> 00:05:49,800
特别是x的一个均值和方差

145
00:05:49,800 --> 00:05:52,480
在这里面我们先对x求我们的均值

146
00:05:52,480 --> 00:05:54,400
然后再求我们的方差

147
00:05:54,400 --> 00:05:56,680
然后使用均值和方差

148
00:05:56,680 --> 00:05:58,080
对我们每一个数据

149
00:05:58,080 --> 00:05:59,200
输入的数据

150
00:05:59,200 --> 00:06:01,320
做一个规划和缩放的

151
00:06:01,960 --> 00:06:05,800
而均值和方差是学习的一个参数

152
00:06:05,800 --> 00:06:08,000
而x就是我们前面卷积

153
00:06:08,000 --> 00:06:09,480
算出来的一个输入

154
00:06:09,480 --> 00:06:11,720
接着给我们的V2进行计算

155
00:06:11,760 --> 00:06:14,880
这个就是我们Bn的一个正常的流程

156
00:06:16,080 --> 00:06:17,400
我们看看正向的时候

157
00:06:17,400 --> 00:06:18,880
其实还是很简单

158
00:06:18,880 --> 00:06:20,280
但是反向的时候

159
00:06:20,280 --> 00:06:22,600
问题就变得非常复杂了

160
00:06:22,600 --> 00:06:23,640
我们反向的时候

161
00:06:23,800 --> 00:06:25,920
数据是从后面往前流的

162
00:06:25,920 --> 00:06:27,280
就我先算完V2

163
00:06:27,280 --> 00:06:28,240
再算Bn

164
00:06:28,240 --> 00:06:29,720
再算卷积

165
00:06:29,720 --> 00:06:30,960
我在反向的时候

166
00:06:31,160 --> 00:06:33,080
首先我要求参数的误差

167
00:06:33,080 --> 00:06:34,680
例如我们的Δγ

168
00:06:34,680 --> 00:06:35,560
Δβ

169
00:06:35,560 --> 00:06:37,240
而这两个参数误差

170
00:06:37,480 --> 00:06:40,520
会依赖于我们的输入Δy

171
00:06:41,080 --> 00:06:43,520
和我们的之前的输入x

172
00:06:43,520 --> 00:06:45,960
这个x也会对它产生影响

173
00:06:45,960 --> 00:06:47,800
所以反向的过程

174
00:06:47,960 --> 00:06:49,880
包括求参数误差

175
00:06:49,880 --> 00:06:52,600
还有求输入误差两个部分

176
00:06:52,600 --> 00:06:53,480
Bn这个算子

177
00:06:53,640 --> 00:06:55,160
在反向计算的时候

178
00:06:55,360 --> 00:06:56,600
关键的仿存特征

179
00:06:56,600 --> 00:06:59,160
就是我需要对内存里面的这些参数

180
00:06:59,160 --> 00:07:00,440
进行访问

181
00:07:00,440 --> 00:07:00,840
第二个

182
00:07:01,040 --> 00:07:03,800
我需要大量的去访问我们的Δy

183
00:07:03,800 --> 00:07:06,680
把我们之前反向计算出来的一个输出

184
00:07:06,680 --> 00:07:07,080
误差

185
00:07:07,080 --> 00:07:09,040
给到我们的Δγ计算

186
00:07:09,080 --> 00:07:10,720
给到我们的Δβ计算

187
00:07:10,720 --> 00:07:13,680
还给它我们的Δx进行计算

188
00:07:13,680 --> 00:07:14,400
这种方式

189
00:07:14,600 --> 00:07:16,120
就引起我们的计算

190
00:07:16,120 --> 00:07:18,560
对内存进行大量的访问

191
00:07:18,680 --> 00:07:20,920
在实际的AI框架计算里面

192
00:07:21,080 --> 00:07:23,920
它Δy不是单单一个数

193
00:07:23,920 --> 00:07:24,720
而是一个向量

194
00:07:24,720 --> 00:07:25,320
一个矩阵

195
00:07:25,320 --> 00:07:26,400
一个张量

196
00:07:26,400 --> 00:07:28,440
就可能甚至是高维的张量

197
00:07:28,440 --> 00:07:29,720
数据量是非常大的

198
00:07:29,720 --> 00:07:32,080
所以它对仿存的要求是非常高的

199
00:07:32,080 --> 00:07:34,400
我们现在来看看计算仿存的分析

200
00:07:34,400 --> 00:07:37,520
就是对仿存进行一个简单的分析

201
00:07:37,920 --> 00:07:39,760
在网络模型训练的过程当中

202
00:07:39,760 --> 00:07:43,280
我们需要保存每一层的前项的计算的结果

203
00:07:43,280 --> 00:07:45,520
就是我们刚才所谓的BnΔx

204
00:07:45,520 --> 00:07:47,960
在反向计算误差的时候用到的

205
00:07:47,960 --> 00:07:50,720
但是随着我们深度模型的网络模型

206
00:07:50,720 --> 00:07:51,240
越大

207
00:07:51,240 --> 00:07:52,520
模型层数越深

208
00:07:52,520 --> 00:07:55,160
我们需要保存的中间结果和参数量了

209
00:07:55,160 --> 00:07:56,840
就会急剧的增加

210
00:07:56,840 --> 00:07:59,240
这个时候就需要消耗大量的内存

211
00:07:59,240 --> 00:08:01,560
所以我们在训练一个大一点的网络模型的时候

212
00:08:01,560 --> 00:08:02,920
经常说内存不够了

213
00:08:02,920 --> 00:08:05,480
希望我们的内存或者显存更大

214
00:08:05,480 --> 00:08:06,280
而另一方面

215
00:08:06,400 --> 00:08:09,400
因为我们的加速器或者NPU或者芯片上面的

216
00:08:09,400 --> 00:08:11,520
仿存容量是非常有限的

217
00:08:11,520 --> 00:08:14,240
没办法无限制的去保存我们的数据

218
00:08:14,240 --> 00:08:16,640
所以这个时候我们就需要把中间结果

219
00:08:16,640 --> 00:08:20,000
可能会offload到我们的CPU内存里面

220
00:08:20,000 --> 00:08:22,440
并且在反向的时候再读取出来

221
00:08:22,440 --> 00:08:24,680
这种方式是非常低效的

222
00:08:25,120 --> 00:08:27,840
下面我们来看看一个更加明确的例子

223
00:08:27,840 --> 00:08:30,400
还是刚才的卷集BNV路三个算子

224
00:08:30,400 --> 00:08:33,280
中间的横框就是我们的内存

225
00:08:33,480 --> 00:08:35,880
假设我们现在有两块内存

226
00:08:35,920 --> 00:08:38,400
正向的时候我们需要J1W1

227
00:08:38,400 --> 00:08:40,760
进行完卷集计算我们输出X

228
00:08:40,760 --> 00:08:43,560
在边计算的时候我需要把X输进去

229
00:08:43,560 --> 00:08:45,080
把γBeta输进去

230
00:08:45,080 --> 00:08:47,480
求得我们的平均值和方差

231
00:08:47,480 --> 00:08:48,560
还有Y

232
00:08:48,560 --> 00:08:50,560
这个时候我Y输给我的V路

233
00:08:50,560 --> 00:08:51,680
输出我的J

234
00:08:51,680 --> 00:08:52,720
在反向的时候

235
00:08:52,920 --> 00:08:55,360
我同样需要把刚才计算的Y

236
00:08:55,360 --> 00:08:56,640
把我们刚才的X

237
00:08:56,640 --> 00:08:58,160
还有我们的ΔX

238
00:08:58,160 --> 00:08:59,760
ΔγΔBeta

239
00:08:59,760 --> 00:09:03,280
ΔX也是需要计算和存储的

240
00:09:03,280 --> 00:09:04,240
可以看到这个图

241
00:09:04,440 --> 00:09:05,840
我们有大量的箭头

242
00:09:05,840 --> 00:09:07,400
而每种箭头都不一样

243
00:09:07,400 --> 00:09:10,960
实线红色就是我们正向对内存的访问

244
00:09:10,960 --> 00:09:13,800
虚线红色的就是我们求参数误差

245
00:09:13,800 --> 00:09:15,120
对内存的访问

246
00:09:15,120 --> 00:09:16,520
而绿色的虚线

247
00:09:16,680 --> 00:09:18,600
就是我们求数目的误差

248
00:09:18,600 --> 00:09:20,080
对内存的访问

249
00:09:20,080 --> 00:09:22,040
可以看到对内存的访问次数

250
00:09:22,040 --> 00:09:23,320
非常的多

251
00:09:23,320 --> 00:09:24,960
每次都要大量的交互

252
00:09:24,960 --> 00:09:28,440
所以我们希望把这些零散的算子

253
00:09:28,440 --> 00:09:29,800
合成一个大的kernel

254
00:09:29,800 --> 00:09:32,240
把这些零散的一些数据

255
00:09:32,240 --> 00:09:33,840
直接一次性的读取

256
00:09:33,840 --> 00:09:35,120
一次性的读出

257
00:09:36,000 --> 00:09:37,360
针对卷积边域路

258
00:09:37,560 --> 00:09:40,040
我们把边重构成为BNB

259
00:09:40,040 --> 00:09:40,920
还有BNA

260
00:09:40,920 --> 00:09:43,400
就把一个边算子拆成两个

261
00:09:43,400 --> 00:09:46,680
首先BNA来算我们的均值和方差

262
00:09:46,680 --> 00:09:49,720
BNB就完成我们的规划和刷放

263
00:09:49,720 --> 00:09:50,720
像我们刚才说到

264
00:09:50,720 --> 00:09:53,040
把这些参数统一的计算完之后

265
00:09:53,200 --> 00:09:54,960
输给我们的一个BNB

266
00:09:54,960 --> 00:09:57,040
然后给我们的V路进行执行

267
00:09:57,040 --> 00:09:58,040
V路执行完之后

268
00:09:58,040 --> 00:10:00,120
再给我们的卷积进行执行

269
00:10:00,120 --> 00:10:01,400
卷积执行完之后

270
00:10:01,600 --> 00:10:03,480
再求我们的误差和方差

271
00:10:03,520 --> 00:10:05,640
并把计算后的最终的结果

272
00:10:05,640 --> 00:10:07,480
写到我们的内存里面

273
00:10:07,680 --> 00:10:10,360
这种方式就是把算子进行融合

274
00:10:10,360 --> 00:10:12,680
可能看这个图你不是很直观

275
00:10:12,680 --> 00:10:15,040
下面我们来看看具体的计算公式

276
00:10:15,040 --> 00:10:17,000
假设我们的卷积公式是

277
00:10:17,000 --> 00:10:18,960
W乘以X加B等于Z

278
00:10:18,960 --> 00:10:21,680
在BN的计算就是我把Z计算完的

279
00:10:21,680 --> 00:10:22,560
然后减去min

280
00:10:22,560 --> 00:10:24,240
然后做一个BN的计算

281
00:10:24,240 --> 00:10:26,040
这个就是我们的BN计算公式

282
00:10:26,040 --> 00:10:27,080
得到我们的Y

283
00:10:27,080 --> 00:10:28,640
Y再进行一个V路

284
00:10:28,840 --> 00:10:31,440
我们可以把V路先抛开一边

285
00:10:31,520 --> 00:10:33,520
我们融化后的减化的算子

286
00:10:33,520 --> 00:10:35,800
融合减化的卷积和BN之间

287
00:10:36,000 --> 00:10:37,160
就是这种关系

288
00:10:37,160 --> 00:10:38,520
我先求W一撇

289
00:10:38,520 --> 00:10:39,560
再求B一撇

290
00:10:39,560 --> 00:10:42,240
最后再求我们的Y真正的输出

291
00:10:44,520 --> 00:10:46,560
下面我们来看看TVM定义的

292
00:10:46,560 --> 00:10:48,560
一个融合规则和具体的算法

293
00:10:48,680 --> 00:10:51,360
首先我们要了解一下TVM的一个支配数

294
00:10:51,680 --> 00:10:53,120
我们先来讲讲TVM

295
00:10:53,560 --> 00:10:55,240
TVM实际上是一个

296
00:10:55,240 --> 00:10:57,120
曾经其主导的开源项目

297
00:10:57,240 --> 00:11:00,040
之前主要是用来做一个推理的AI编译器

298
00:11:00,360 --> 00:11:01,800
现在我们来看看TVM

299
00:11:01,800 --> 00:11:03,680
其实整体的算子融合的策略

300
00:11:03,680 --> 00:11:05,360
是基于支配数来实现的

301
00:11:06,520 --> 00:11:07,840
那什么是支配数吗

302
00:11:08,840 --> 00:11:12,200
支配数实际上是由各个支配点来构成的数

303
00:11:13,760 --> 00:11:15,360
那什么又是支配点呢

304
00:11:16,400 --> 00:11:18,120
支配点就是所有能够达到

305
00:11:18,120 --> 00:11:21,400
当前节点路径的公共主线节点

306
00:11:21,600 --> 00:11:23,600
我们叫做LCA

307
00:11:24,080 --> 00:11:25,480
听上去有点拗口

308
00:11:26,120 --> 00:11:28,040
我们来看看一个真正的图

309
00:11:28,680 --> 00:11:31,080
右边的这个图就是我们的支配数

310
00:11:31,080 --> 00:11:33,400
每个节点就是我们每个支配点

311
00:11:33,400 --> 00:11:35,520
其实都有一个对应的数值

312
00:11:35,520 --> 00:11:38,640
而这个数值跟这个数值可能会串起来

313
00:11:38,640 --> 00:11:41,400
像这个我们叫它叫做一个支配点

314
00:11:41,400 --> 00:11:44,360
像这个inPace它就是一个支配点

315
00:11:44,360 --> 00:11:46,240
每一个算子都是一个支配点

316
00:11:46,240 --> 00:11:48,040
这么几个算子组合起来

317
00:11:48,040 --> 00:11:49,720
能到达我们的支配点

318
00:11:49,720 --> 00:11:51,160
这几个算子组合起来

319
00:11:51,160 --> 00:11:52,760
也能到达我们的支配点

320
00:11:52,760 --> 00:11:55,160
这几个算子这种方式组合

321
00:11:55,160 --> 00:11:57,280
也能够达到我们的支配点

322
00:11:58,560 --> 00:12:00,960
那为什么我们需要支配数呢

323
00:12:00,960 --> 00:12:02,160
有了支配数

324
00:12:02,160 --> 00:12:04,480
我们就非常的方便的去检查

325
00:12:04,480 --> 00:12:07,000
我们每一个node到支配点的node

326
00:12:07,000 --> 00:12:08,920
是否符合融合的策略

327
00:12:08,920 --> 00:12:13,040
假设我现在把478做了一个融合

328
00:12:13,040 --> 00:12:16,600
那这个时候478这个算子已经融合掉了

329
00:12:16,600 --> 00:12:20,000
578这几个算子是没办法进行融合的了

330
00:12:20,000 --> 00:12:23,120
因为78我已经跟4融合成一个大的算子

331
00:12:23,120 --> 00:12:25,600
有了这个支配数和这个支配点

332
00:12:25,600 --> 00:12:29,640
我们就知道哪些节点能够符合我们的融合规则

333
00:12:29,640 --> 00:12:31,240
哪些剩下的节点

334
00:12:31,240 --> 00:12:34,040
不会对我们的融合规则产生问题

335
00:12:34,040 --> 00:12:36,360
而支配数的生成有几个步骤

336
00:12:36,360 --> 00:12:38,520
就是根据我们的计算图

337
00:12:38,520 --> 00:12:40,760
或者我们计算图其实是一个DAG图

338
00:12:40,760 --> 00:12:44,080
生成一个深度优先搜索的数

339
00:12:44,080 --> 00:12:46,800
那接着我们根据这个深度优先搜索的数

340
00:12:46,800 --> 00:12:48,600
产生我们的边

341
00:12:48,600 --> 00:12:50,920
接下来会根据深度优先搜索数

342
00:12:50,920 --> 00:12:54,000
对应的边产生我们的DAM数

343
00:12:54,040 --> 00:12:56,680
然后我们加入一个数据结构叫做GOOP

344
00:12:56,680 --> 00:13:00,120
来描述多个的node能够被融合

345
00:13:01,040 --> 00:13:02,480
那这是一个node

346
00:13:02,480 --> 00:13:03,320
这也是一个node

347
00:13:03,320 --> 00:13:04,200
这也是一个node

348
00:13:04,200 --> 00:13:05,600
这些都是一个节点

349
00:13:05,600 --> 00:13:08,520
通过这个数去描述我们的那些node

350
00:13:08,520 --> 00:13:09,320
我们的节点

351
00:13:09,320 --> 00:13:10,120
我们的算子

352
00:13:10,120 --> 00:13:13,160
这个就是整体TUM支配数的一个作用

353
00:13:13,160 --> 00:13:14,640
那了解完大概的作用之后

354
00:13:14,640 --> 00:13:17,760
我们看看TUM的算子的融合的流程

355
00:13:17,760 --> 00:13:19,720
首先我们会通过AST

356
00:13:19,720 --> 00:13:21,240
就是我们的源码转换

357
00:13:21,320 --> 00:13:23,040
把我们的计算图的IR

358
00:13:23,040 --> 00:13:25,160
转换成为我们的relay的IR

359
00:13:25,160 --> 00:13:26,320
那这个relay的IR

360
00:13:26,320 --> 00:13:28,160
是TUM里面自己的IR

361
00:13:28,160 --> 00:13:30,360
接着去编译这个relay的IR

362
00:13:30,360 --> 00:13:31,800
编译完这个relay的IR

363
00:13:31,800 --> 00:13:33,240
会利用relay的IR

364
00:13:33,240 --> 00:13:35,840
建立我们刚才所说的DAG数

365
00:13:35,840 --> 00:13:39,240
那DAG数主要是生成我们的支配数的

366
00:13:39,240 --> 00:13:40,720
生成我们的支配数之后

367
00:13:40,720 --> 00:13:44,800
就可以应用我们的算子的融合的算法和规则了

368
00:13:44,800 --> 00:13:47,280
现在我们来打开来具体看看

369
00:13:47,280 --> 00:13:49,920
第一个我们的输入是一个DAG的图

370
00:13:49,920 --> 00:13:51,720
就是我们计算图是一个DAG

371
00:13:51,720 --> 00:13:53,320
进行深度优先编译

372
00:13:53,320 --> 00:13:55,240
生成我们的DFS数

373
00:13:55,240 --> 00:13:56,960
那在这里面生成的过程当中

374
00:13:56,960 --> 00:14:00,840
除了单纯的记录每一个node的节点的深度之外

375
00:14:00,840 --> 00:14:02,760
node就是我们的算子

376
00:14:02,760 --> 00:14:06,240
我们还需要为每一个节点保存它相连的边

377
00:14:06,240 --> 00:14:07,720
保存的是它相连的边

378
00:14:07,720 --> 00:14:09,600
我们就知道对应的索引

379
00:14:09,600 --> 00:14:11,840
才好找到我们的LCA

380
00:14:11,840 --> 00:14:15,520
找到能够达到当前节点的公共子路径

381
00:14:17,240 --> 00:14:18,920
接着我们在第二步

382
00:14:18,920 --> 00:14:20,760
就是根据我们的DFS数

383
00:14:20,760 --> 00:14:22,560
因为刚才已经建立了DFS数

384
00:14:22,560 --> 00:14:24,320
生成一个DOM的数

385
00:14:24,320 --> 00:14:26,440
那TVM就使用group这个概念

386
00:14:26,440 --> 00:14:28,920
那这个概念实际上它是一个数据结构

387
00:14:28,920 --> 00:14:30,520
来描述我们这些node

388
00:14:30,520 --> 00:14:32,680
这些算子能不能做融合

389
00:14:32,680 --> 00:14:35,280
如果一个算子不能和其他算子融合

390
00:14:35,280 --> 00:14:37,680
那这个group由自己去组成

391
00:14:37,680 --> 00:14:39,120
如果这几个算子

392
00:14:39,120 --> 00:14:42,320
例如我遇到卷积BM维度的时候

393
00:14:42,320 --> 00:14:44,880
我就把这几个算子合并成一个group

394
00:14:44,880 --> 00:14:46,840
这个时候只有一个group

395
00:14:46,840 --> 00:14:49,000
最后一步就是定义好我的group之后

396
00:14:49,000 --> 00:14:50,560
我们去变立每一个node

397
00:14:50,560 --> 00:14:52,840
找到它的支配点所带的路径

398
00:14:52,840 --> 00:14:55,520
是否符合我们的融合规则

399
00:14:55,520 --> 00:14:59,120
而这个时候融合规则就变得异常的重要

400
00:14:59,120 --> 00:15:02,160
我们现在来看看有哪几种融合规则

401
00:15:02,160 --> 00:15:05,160
首先我们有一种就是映射

402
00:15:05,160 --> 00:15:06,640
Injective

403
00:15:06,640 --> 00:15:09,160
类似于加还有Pointwise这种节点

404
00:15:09,160 --> 00:15:11,000
我们就可以做一个Injective

405
00:15:11,000 --> 00:15:12,600
然后做一个融合

406
00:15:12,600 --> 00:15:14,440
例如我这里是一个加号

407
00:15:14,440 --> 00:15:16,080
第二次也是一个加号

408
00:15:16,080 --> 00:15:18,200
这个时候我们就可以把两次的加号

409
00:15:18,200 --> 00:15:20,120
变成一次的相乘

410
00:15:20,120 --> 00:15:22,120
那现在我们还有reduction

411
00:15:22,120 --> 00:15:23,800
就是简约函数

412
00:15:23,800 --> 00:15:25,760
这个简约函数也比较好理解

413
00:15:25,760 --> 00:15:28,520
就是输入到输出具有降维的性质

414
00:15:28,520 --> 00:15:30,080
例如summaxmin

415
00:15:30,080 --> 00:15:32,080
就是求最大值求最小值

416
00:15:32,080 --> 00:15:34,640
这些我们都可以把它进行融合

417
00:15:34,640 --> 00:15:36,920
例如我加完之后求最大值

418
00:15:36,920 --> 00:15:38,880
那这个时候我们可能可以把它

419
00:15:38,880 --> 00:15:40,840
合成一个具体的算子

420
00:15:41,520 --> 00:15:45,000
另外第三种就是我们的人工定义的规则

421
00:15:45,000 --> 00:15:46,480
我们人工的去发现一些

422
00:15:46,480 --> 00:15:48,280
例如卷积BN比录

423
00:15:48,280 --> 00:15:49,480
这是可以融合的

424
00:15:49,480 --> 00:15:52,880
我们人工的去设定一些融合的规则

425
00:15:52,880 --> 00:15:54,360
当然了人工融合的规则

426
00:15:54,360 --> 00:15:55,520
除了卷积BN比录

427
00:15:55,680 --> 00:15:57,520
我们可能还有add square

428
00:15:57,520 --> 00:15:59,960
还有相乘再相加

429
00:15:59,960 --> 00:16:02,040
那像这种我们会人工的定义了

430
00:16:02,040 --> 00:16:03,560
非常多的Path

431
00:16:03,560 --> 00:16:05,960
编译器虽然看上去很高大上

432
00:16:05,960 --> 00:16:07,200
很深奥的技术

433
00:16:07,200 --> 00:16:09,720
实际上在做到编译器底层的时候

434
00:16:09,720 --> 00:16:12,560
我们还是定义了很多人工的规则

435
00:16:12,600 --> 00:16:14,520
通过工程师去抽象了

436
00:16:14,520 --> 00:16:16,280
很多不同的规则出来

437
00:16:16,280 --> 00:16:19,000
然后把这些规则写到AI编译器里面

438
00:16:19,000 --> 00:16:21,000
最后变成一个通用的法则

439
00:16:21,000 --> 00:16:22,000
或者通用的方式

440
00:16:22,000 --> 00:16:23,520
或者通用的Path函数

441
00:16:23,520 --> 00:16:26,000
最后一种就是没有办法进行融合的

442
00:16:26,000 --> 00:16:27,480
例如short这种排序的

443
00:16:27,480 --> 00:16:28,640
没办法进行融合

444
00:16:28,640 --> 00:16:31,320
那我们只能单独的把它拿出来

445
00:16:32,160 --> 00:16:34,080
那最后我们看看实验的结果

446
00:16:34,240 --> 00:16:35,680
像卷积BN比录

447
00:16:35,680 --> 00:16:37,400
然后double x卷积BN比录

448
00:16:37,400 --> 00:16:39,240
还有INN LSTM这些

449
00:16:39,240 --> 00:16:41,040
都可以做算子融合的

450
00:16:41,080 --> 00:16:43,720
融合之后就是我们的蓝色这条线

451
00:16:43,720 --> 00:16:46,000
实际上执行的效率更高

452
00:16:46,000 --> 00:16:47,120
我们减少了仿存

453
00:16:47,120 --> 00:16:49,000
减少了科诺调动的次数

454
00:16:49,000 --> 00:16:50,880
所以说会比我们绿色的

455
00:16:51,440 --> 00:16:54,040
没有进行融合的时候效率更高

456
00:16:55,400 --> 00:16:55,800
好了

457
00:16:55,800 --> 00:16:57,040
我们今天来回顾一下

458
00:16:57,040 --> 00:16:58,200
其实算子的融合

459
00:16:58,400 --> 00:17:00,800
分开横向融合和纵向融合

460
00:17:00,800 --> 00:17:03,440
但实际上我们会根据AI模型的排布

461
00:17:03,440 --> 00:17:06,400
衍生出更多不同的融合的策略

462
00:17:06,960 --> 00:17:08,000
后面我们第二个

463
00:17:08,160 --> 00:17:10,400
就是通过卷积BN比录这个算子

464
00:17:10,520 --> 00:17:12,840
了解到对算子如何进行融合

465
00:17:12,840 --> 00:17:14,480
还有融合后的计算

466
00:17:14,480 --> 00:17:16,080
基本上可以极大的减少

467
00:17:16,080 --> 00:17:17,640
我们对仿存的压力

468
00:17:17,640 --> 00:17:19,040
但是这个算子的融合

469
00:17:19,160 --> 00:17:22,400
我们需要在数学上保持语义的一致

470
00:17:22,400 --> 00:17:24,440
那第三个就是在AI编译器里面

471
00:17:24,600 --> 00:17:25,720
一般我们的融合规则

472
00:17:25,720 --> 00:17:27,440
都是通过Path来承载的

473
00:17:27,440 --> 00:17:30,080
不同的Path处理不同的融合规则

474
00:17:30,080 --> 00:17:32,360
而融合规则就是需要我们人工

475
00:17:32,360 --> 00:17:35,080
我们工程师去预先定义好的

476
00:17:35,520 --> 00:17:35,920
好了

477
00:17:35,920 --> 00:17:37,000
今天到此为止

478
00:17:37,000 --> 00:17:37,720
谢谢各位

479
00:17:37,720 --> 00:17:38,600
拜了个拜

480
00:17:38,920 --> 00:17:39,720
卷的不行了

481
00:17:39,760 --> 00:17:40,600
卷的不行了

482
00:17:40,600 --> 00:17:42,440
记得一键三连加关注哦

483
00:17:42,440 --> 00:17:43,800
所有的内容都会开源

484
00:17:43,800 --> 00:17:45,680
在下面这条链接里面

485
00:17:46,040 --> 00:17:46,960
拜了个拜

