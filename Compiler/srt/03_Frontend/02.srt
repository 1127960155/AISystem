1
00:00:00,000 --> 00:00:08,000
Hello,大家好,我是宗咪

2
00:00:08,000 --> 00:00:10,080
欢迎来到今天的课程

3
00:00:10,080 --> 00:00:12,600
今天的课程主要是给大家汇报一下

4
00:00:12,600 --> 00:00:15,920
AI编辑器里面的简短优化里面的第一节

5
00:00:15,920 --> 00:00:17,400
图层的IR

6
00:00:17,400 --> 00:00:18,640
了解到图层IR

7
00:00:18,640 --> 00:00:20,520
今天我们就来复习一下

8
00:00:20,520 --> 00:00:22,480
我们之前讲到过的内容

9
00:00:22,480 --> 00:00:24,120
就是计算图

10
00:00:24,120 --> 00:00:25,520
在计算图这里面

11
00:00:25,600 --> 00:00:27,680
我们看看今天会讲哪几个内容

12
00:00:27,680 --> 00:00:30,600
今天我们主要是讲计算图的基本构成

13
00:00:30,600 --> 00:00:31,640
在AI框架基础

14
00:00:31,840 --> 00:00:34,080
其实我们已经详细的去介绍过

15
00:00:34,080 --> 00:00:36,520
计算图的相关的知识

16
00:00:36,520 --> 00:00:39,040
这里面会有一个专门的内容

17
00:00:39,040 --> 00:00:40,080
去讲计算图的

18
00:00:40,080 --> 00:00:41,320
我在这了

19
00:00:41,320 --> 00:00:42,120
找到计算图

20
00:00:42,120 --> 00:00:44,840
我们会讲讲计算图的整体的介绍

21
00:00:44,840 --> 00:00:47,240
然后跟自动微分什么关系

22
00:00:47,240 --> 00:00:47,880
图的调度

23
00:00:47,880 --> 00:00:49,360
还有怎么表示空字流

24
00:00:49,360 --> 00:00:51,680
在这里面我们重新的回顾一下

25
00:00:51,680 --> 00:00:53,800
接着去看看静态的计算图

26
00:00:53,800 --> 00:00:55,240
和动态的计算图

27
00:00:55,480 --> 00:00:56,840
现在大部分AI框架

28
00:00:56,960 --> 00:00:58,560
都是从动态的计算图

29
00:00:58,560 --> 00:01:00,120
转到静态的计算图

30
00:01:00,320 --> 00:01:01,120
像MathMall这种

31
00:01:01,240 --> 00:01:03,680
就是一开始是先支持静态的计算图

32
00:01:03,680 --> 00:01:07,320
最后支持动静统一的动静态计算图

33
00:01:07,320 --> 00:01:08,240
这种方式

34
00:01:08,440 --> 00:01:09,640
接着我们来看看

35
00:01:09,640 --> 00:01:12,680
AI框架是怎么产生计算图的

36
00:01:12,680 --> 00:01:14,360
就我们讲了很多计算图

37
00:01:14,360 --> 00:01:15,640
它到底是怎么来的

38
00:01:15,760 --> 00:01:17,240
最后我们去讲讲

39
00:01:17,240 --> 00:01:18,640
有了计算图之后

40
00:01:19,120 --> 00:01:20,480
对我们的AI编辑

41
00:01:20,480 --> 00:01:21,920
到底有什么作用

42
00:01:22,440 --> 00:01:23,080
好了

43
00:01:23,080 --> 00:01:24,920
我们现在接着往下走

44
00:01:26,240 --> 00:01:30,120
第一个我们先看看计算图的基本构成

45
00:01:30,120 --> 00:01:31,600
其实计算图比较简单

46
00:01:31,600 --> 00:01:33,760
我们现在来看看它的一个主要的作用

47
00:01:33,760 --> 00:01:35,200
主要是用来表示

48
00:01:35,200 --> 00:01:38,160
深度学习的一个推理训练的过程当中的

49
00:01:38,160 --> 00:01:39,440
计算逻辑

50
00:01:39,440 --> 00:01:42,680
主要是表达我们整个网络模型的

51
00:01:42,920 --> 00:01:44,080
我们可以看到计算图

52
00:01:44,240 --> 00:01:46,320
主要是由基本的数据结构

53
00:01:46,320 --> 00:01:46,800
张量

54
00:01:46,800 --> 00:01:49,440
还有我们的算子去组成的

55
00:01:49,440 --> 00:01:50,600
在我们的计算图

56
00:01:50,600 --> 00:01:51,760
它既然是一个图

57
00:01:52,320 --> 00:01:54,040
它肯定会有节点和边

58
00:01:54,280 --> 00:01:56,920
这个节点就是我们的算子

59
00:01:56,920 --> 00:01:58,640
节点跟节点之间

60
00:01:58,640 --> 00:02:00,200
就是算子跟算子之间

61
00:02:00,360 --> 00:02:01,240
会有一个连接

62
00:02:01,240 --> 00:02:02,040
有一条边

63
00:02:02,240 --> 00:02:03,560
这个边流动的数据

64
00:02:03,680 --> 00:02:04,960
就是我们的张量

65
00:02:05,320 --> 00:02:06,560
所以我们会说

66
00:02:06,560 --> 00:02:08,800
计算图的一个最基本的构成

67
00:02:08,960 --> 00:02:10,280
就是由我们的tensor

68
00:02:10,280 --> 00:02:12,600
还有我们的基本的运算单元

69
00:02:12,600 --> 00:02:14,320
算子来去组成的

70
00:02:14,320 --> 00:02:16,720
算子这个概念也是来自于这

71
00:02:16,720 --> 00:02:19,400
而AI框架是产生计算图的

72
00:02:19,400 --> 00:02:21,680
所以我们所以经常谈到的算子

73
00:02:22,040 --> 00:02:24,560
还是AI框架的一个概念

74
00:02:24,760 --> 00:02:26,360
真正在我们的硬件底层

75
00:02:26,360 --> 00:02:27,600
或者我们用CUDA

76
00:02:27,600 --> 00:02:29,880
写一些算子表达的时候

77
00:02:30,200 --> 00:02:32,080
我们叫做CUDA的kernel

78
00:02:33,080 --> 00:02:33,960
刚才那个概念

79
00:02:34,080 --> 00:02:35,640
大家可以忘记它

80
00:02:35,640 --> 00:02:37,520
你理解为都算子就行了

81
00:02:37,520 --> 00:02:38,240
你都叫算子

82
00:02:38,680 --> 00:02:40,120
反正也无所谓了

83
00:02:40,160 --> 00:02:43,080
然后后面我们既然是一个图

84
00:02:43,640 --> 00:02:45,600
这个图肯定会有一个自己的概念

85
00:02:45,600 --> 00:02:48,920
这里面主要是基于一个DAG的图

86
00:02:49,920 --> 00:02:51,680
DAG就是有项无环图

87
00:02:51,680 --> 00:02:52,400
我们可以看到

88
00:02:52,400 --> 00:02:54,600
下面这个就是有项无环图的演示

89
00:02:54,600 --> 00:02:56,800
我们从上面input输入数据

90
00:02:56,800 --> 00:02:58,360
然后经过我们的算子

91
00:02:58,360 --> 00:03:00,160
经过我们的边下一个算子

92
00:03:00,160 --> 00:03:01,840
经过我们边下一个算子

93
00:03:01,840 --> 00:03:03,920
而这条边流传的数据

94
00:03:04,080 --> 00:03:06,240
就是我们的tensor最后输出

95
00:03:06,240 --> 00:03:09,200
而我们经常会遇到反向传播的时候

96
00:03:09,200 --> 00:03:10,800
也是一个有项无环图

97
00:03:10,800 --> 00:03:11,400
可以看到

98
00:03:11,400 --> 00:03:13,920
这边是一个有项的顺序

99
00:03:13,920 --> 00:03:16,280
它是每一次都有自己的顺序的

100
00:03:16,280 --> 00:03:18,560
但是它没有形成一个款

101
00:03:18,600 --> 00:03:21,160
最后它会进行一个输出

102
00:03:21,440 --> 00:03:24,040
而在这里面有两点需要注意的

103
00:03:24,040 --> 00:03:26,400
就是我们会遇到特殊的操作

104
00:03:26,400 --> 00:03:27,840
和特殊的边

105
00:03:27,840 --> 00:03:29,040
而这个所谓的特殊

106
00:03:29,240 --> 00:03:31,760
主要是指我们的控制流

107
00:03:31,880 --> 00:03:34,200
控制流是在我们计算图里面

108
00:03:34,200 --> 00:03:35,800
比较难表示的

109
00:03:35,840 --> 00:03:37,640
下面我们来看看AI框架

110
00:03:37,760 --> 00:03:39,960
是怎么样去生成计算图的

111
00:03:39,960 --> 00:03:41,960
计算图跟自动维分有什么关系

112
00:03:42,080 --> 00:03:43,680
我们知道刚才讲的计算图

113
00:03:43,840 --> 00:03:45,480
是一个有项的无环图

114
00:03:45,640 --> 00:03:47,000
我们在平时写代码的时候

115
00:03:47,160 --> 00:03:49,840
一般我们只写了一个正向的图

116
00:03:49,840 --> 00:03:51,720
或者做了一个神经网络

117
00:03:51,720 --> 00:03:52,880
对正向的表达

118
00:03:52,880 --> 00:03:54,120
实际上的AI框架

119
00:03:54,120 --> 00:03:55,920
会帮我们去自动建好

120
00:03:55,920 --> 00:03:57,200
我们的反向图

121
00:03:57,200 --> 00:03:59,360
然后整体变成一个计算图

122
00:03:59,360 --> 00:04:01,160
下发给我们的AI编译器的

123
00:04:01,280 --> 00:04:03,840
AI框架生成一个计算图

124
00:04:03,840 --> 00:04:04,920
有第一种方式

125
00:04:04,920 --> 00:04:06,440
就是静态的计算图

126
00:04:06,440 --> 00:04:08,480
静态计算图比较好表示

127
00:04:08,720 --> 00:04:10,360
例如我们现在有一个

128
00:04:10,360 --> 00:04:12,520
用MineSport写的一些伪代码

129
00:04:12,520 --> 00:04:13,240
我们用MineSport

130
00:04:13,240 --> 00:04:14,680
写完伪代码之后

131
00:04:15,000 --> 00:04:16,440
我们会把这些代码

132
00:04:16,440 --> 00:04:18,800
通过我们AI框架的前端定义

133
00:04:18,800 --> 00:04:20,400
就是我们调用这些接口

134
00:04:20,400 --> 00:04:21,200
NNSequence

135
00:04:21,360 --> 00:04:22,200
NNwithRoot

136
00:04:22,520 --> 00:04:23,320
NNDense

137
00:04:23,480 --> 00:04:25,000
然后GPython的代码

138
00:04:25,120 --> 00:04:26,520
做一个源码的转换

139
00:04:26,520 --> 00:04:27,360
对这些源码

140
00:04:27,520 --> 00:04:29,160
进行一个分析和重构

141
00:04:29,160 --> 00:04:31,440
变成我们的静态的计算图

142
00:04:31,640 --> 00:04:32,720
这个静态的计算图

143
00:04:32,880 --> 00:04:35,960
实际上它只是一个特殊的数据结构

144
00:04:35,960 --> 00:04:39,120
所以说我们AI框架生成静态图

145
00:04:39,120 --> 00:04:41,200
主要是用我们AI框架

146
00:04:41,200 --> 00:04:43,080
所提供的前端的API

147
00:04:43,080 --> 00:04:45,280
对这些API进行分析重构

148
00:04:45,320 --> 00:04:48,200
然后变成特殊的静态图的数据结构

149
00:04:48,560 --> 00:04:49,920
下面第二种方式

150
00:04:49,920 --> 00:04:52,680
就是AI框架生成动态计算图

151
00:04:52,680 --> 00:04:54,040
这是第二种方式

152
00:04:54,040 --> 00:04:56,360
动态图主要是利用Python

153
00:04:56,360 --> 00:04:57,800
自身的一个解析器

154
00:04:57,800 --> 00:04:59,000
对代码进行解析

155
00:04:59,000 --> 00:05:01,840
然后利用框架本身的一个算子分发能力

156
00:05:01,840 --> 00:05:03,160
然后去执行

157
00:05:03,160 --> 00:05:04,160
那很简单

158
00:05:04,360 --> 00:05:05,600
PyTorch最典型的

159
00:05:05,600 --> 00:05:06,960
就是动态的计算图

160
00:05:06,960 --> 00:05:08,520
利用Python去写完代码

161
00:05:08,520 --> 00:05:10,000
通过AutoGrid这个函数

162
00:05:10,200 --> 00:05:11,320
建立了反向图

163
00:05:11,320 --> 00:05:11,960
反向图之后

164
00:05:12,080 --> 00:05:13,840
就变成整一个计算图了

165
00:05:13,880 --> 00:05:15,480
或者变成一个算子序列

166
00:05:15,480 --> 00:05:17,720
然后不断的去分发到我们的硬件

167
00:05:17,720 --> 00:05:18,280
去执行

168
00:05:18,280 --> 00:05:19,720
并且返回结果

169
00:05:19,920 --> 00:05:21,320
这种就是动态图

170
00:05:21,320 --> 00:05:23,360
它使用的是命令式编程的方式

171
00:05:23,680 --> 00:05:25,560
这个命令式编程的方式是什么意思

172
00:05:26,200 --> 00:05:29,000
这个内容也在我们AI框架基础里面

173
00:05:29,000 --> 00:05:30,320
详细的展开过的

174
00:05:30,320 --> 00:05:31,960
有兴趣的也可以去了解

175
00:05:32,280 --> 00:05:34,480
PyTorch用了命令式编程的方式

176
00:05:34,720 --> 00:05:35,920
使用前端的语言

177
00:05:35,920 --> 00:05:38,120
去构造我们的网络的优点

178
00:05:38,120 --> 00:05:39,880
很明显灵活易用

179
00:05:40,320 --> 00:05:42,240
然后也可以充分的发挥

180
00:05:42,280 --> 00:05:44,960
Python语言的原生的空字流

181
00:05:45,280 --> 00:05:47,320
缺点就是没有编译器

182
00:05:47,320 --> 00:05:48,280
这里面没有编译器

183
00:05:48,280 --> 00:05:51,360
所以没有办法的去提升这些性能

184
00:05:51,560 --> 00:05:53,600
现在我们来看看动态图

185
00:05:53,600 --> 00:05:55,560
和静态图的一个对比

186
00:05:56,040 --> 00:05:58,640
下面这个图就是一个具体的对比

187
00:05:58,640 --> 00:06:00,160
我们可以一般来说

188
00:06:00,320 --> 00:06:01,400
我们在推理场景

189
00:06:01,400 --> 00:06:03,480
基本上都会把它变成一个计算图

190
00:06:03,480 --> 00:06:05,480
就我们可以看到的模型

191
00:06:05,480 --> 00:06:06,160
全中文件

192
00:06:06,320 --> 00:06:09,240
这个全中文件不仅仅只有全众

193
00:06:09,240 --> 00:06:11,560
它大部分都会带有图的信息

194
00:06:11,600 --> 00:06:14,360
而动态图一般是用在训练场景的

195
00:06:14,360 --> 00:06:15,240
我训练完之后

196
00:06:15,240 --> 00:06:16,640
我这个图就没了

197
00:06:16,640 --> 00:06:17,400
消亡掉了

198
00:06:17,400 --> 00:06:19,360
在内存里面也没有办法去保存了

199
00:06:19,360 --> 00:06:21,640
而且静态图可以做一些编译优化

200
00:06:21,640 --> 00:06:23,320
这也是PyTorch 2.0推出的

201
00:06:23,320 --> 00:06:24,720
一个很重要的特性

202
00:06:24,720 --> 00:06:26,480
可以把PyTorch的动态图

203
00:06:26,480 --> 00:06:27,880
变成一个静态图

204
00:06:27,880 --> 00:06:29,000
Dynamo的特性

205
00:06:29,200 --> 00:06:30,600
其实是做得非常好的

206
00:06:30,600 --> 00:06:33,080
宗敏在AI编译器之PyTorch里面

207
00:06:33,200 --> 00:06:36,240
就详细的去展开过这个特性

208
00:06:36,240 --> 00:06:38,800
后面还会补充更多的内容

209
00:06:38,960 --> 00:06:40,560
这里面我们先跳到

210
00:06:40,560 --> 00:06:42,440
我们的主流的业务

211
00:06:42,440 --> 00:06:44,960
还是讲讲我们的AI编译器

212
00:06:48,920 --> 00:06:50,400
下面我们看一下

213
00:06:50,400 --> 00:06:52,720
之前其实已经多次的去强调过

214
00:06:52,720 --> 00:06:54,440
我们动态图转为静态图

215
00:06:54,440 --> 00:06:55,880
主要是有两种方式

216
00:06:55,880 --> 00:06:57,720
第一种是基于trace的

217
00:06:57,720 --> 00:06:59,000
就是基于追踪的方式

218
00:06:59,320 --> 00:07:01,240
第二种就是基于源码转换的

219
00:07:01,240 --> 00:07:04,160
那追踪的方式有PyTorch的FX

220
00:07:04,160 --> 00:07:06,440
源码转换有PyTorch的JIT

221
00:07:06,560 --> 00:07:08,680
在前端获得我们的计算图

222
00:07:08,880 --> 00:07:12,360
最主要的工作就是方便底层进行编优化

223
00:07:12,360 --> 00:07:13,560
而这个图的概念

224
00:07:13,840 --> 00:07:16,000
我们可以用它来保存

225
00:07:16,000 --> 00:07:18,960
或者表示整个神奇网络的全过程

226
00:07:18,960 --> 00:07:20,360
也可以序列化过来

227
00:07:20,360 --> 00:07:22,440
不需要再次编译前端代码

228
00:07:22,440 --> 00:07:25,760
就是可以进行推理或者训练的加速

229
00:07:26,920 --> 00:07:28,760
现在我们来谈谈静态图

230
00:07:28,880 --> 00:07:30,200
产生静态图

231
00:07:30,200 --> 00:07:32,920
对实际AI的编译器的作用

232
00:07:32,920 --> 00:07:35,880
首先第一个就是图的优化

233
00:07:35,880 --> 00:07:38,400
我们其实可以做很多图层的优化

234
00:07:38,400 --> 00:07:39,760
拿到这个图之后

235
00:07:40,440 --> 00:07:41,240
钟鸣老师

236
00:07:41,240 --> 00:07:44,280
为啥我可以做到图的优化呢

237
00:07:44,280 --> 00:07:45,680
我不就得到一个图吗

238
00:07:45,680 --> 00:07:46,560
我能干啥

239
00:07:46,720 --> 00:07:48,400
我这个图去执行就好了

240
00:07:48,800 --> 00:07:50,200
你优化它干嘛

241
00:07:52,000 --> 00:07:54,400
这位同学问得非常好

242
00:07:54,760 --> 00:07:56,800
虽然这个问题问得有点

243
00:07:57,000 --> 00:07:57,760
一言难尽

244
00:07:58,200 --> 00:07:58,960
我们可以看到

245
00:07:59,000 --> 00:08:00,520
其实我们现在拿到了

246
00:08:00,520 --> 00:08:03,320
整个深度学习模型的全局的信息

247
00:08:03,320 --> 00:08:04,200
拿到这个信息

248
00:08:04,280 --> 00:08:06,400
我们就知道未来要执行什么

249
00:08:06,400 --> 00:08:07,920
之前我执行过什么

250
00:08:07,920 --> 00:08:09,320
既然我知道全局信息

251
00:08:09,320 --> 00:08:10,480
我肯定可以做一些

252
00:08:10,480 --> 00:08:12,200
对系统级的优化

253
00:08:12,880 --> 00:08:13,680
所以这里面

254
00:08:13,920 --> 00:08:16,680
就像我们之前提到的LVM那样

255
00:08:16,680 --> 00:08:18,160
有非常多的parts

256
00:08:18,160 --> 00:08:21,040
然后中间通过一个IR进行一个优化的

257
00:08:21,280 --> 00:08:22,160
我们自动微分

258
00:08:22,320 --> 00:08:23,640
这个在MineSport里面

259
00:08:23,760 --> 00:08:26,480
也是通过一个编译来去实现的

260
00:08:27,440 --> 00:08:29,440
因此对于AI编译器来说

261
00:08:29,640 --> 00:08:31,840
我们可以将神经网络中间表达

262
00:08:32,200 --> 00:08:33,160
或者我们的IR

263
00:08:33,280 --> 00:08:35,480
变成不同的硬件的代码

264
00:08:35,480 --> 00:08:37,200
就直接怼到我们的硬件上面

265
00:08:37,280 --> 00:08:39,440
然后可以直接快速的部署起来

266
00:08:39,440 --> 00:08:40,960
提供高效的服务

267
00:08:41,720 --> 00:08:42,080
当然了

268
00:08:42,080 --> 00:08:43,040
上面我们提到的

269
00:08:43,040 --> 00:08:45,560
都是比较抽象的概念

270
00:08:45,560 --> 00:08:47,280
实际上我们对到每一层

271
00:08:47,600 --> 00:08:49,560
我们都是通过不同的优化

272
00:08:49,560 --> 00:08:51,520
不同的parts去执行的

273
00:08:51,520 --> 00:08:52,640
例如对计算图

274
00:08:52,640 --> 00:08:55,080
我们有计算图的特殊的优化

275
00:08:55,080 --> 00:08:56,360
在运行时的时候

276
00:08:56,520 --> 00:08:58,320
我们有运行时的优化

277
00:08:58,320 --> 00:08:59,800
在我们的算子执行的时候

278
00:08:59,800 --> 00:09:01,960
我们有算子执行特殊的优化

279
00:09:01,960 --> 00:09:03,960
所以后面把它结合出来

280
00:09:03,960 --> 00:09:06,080
我们其实对于不同层

281
00:09:06,160 --> 00:09:08,280
都可以做不同的parts的优化

282
00:09:08,280 --> 00:09:10,200
这对我们整个AI系统权

283
00:09:10,200 --> 00:09:12,480
在来说是非常重要的

284
00:09:12,480 --> 00:09:15,280
这也是为什么现在我比较喜欢

285
00:09:15,280 --> 00:09:16,720
PyTorch 2.0推出的

286
00:09:16,720 --> 00:09:18,080
Dynamo这个特性

287
00:09:20,080 --> 00:09:20,960
在结束之前

288
00:09:21,080 --> 00:09:24,360
我们看一下静态图加AI编译器的

289
00:09:24,360 --> 00:09:25,320
一些问题

290
00:09:25,440 --> 00:09:26,400
就是它的Const

291
00:09:26,400 --> 00:09:27,600
对我一个算法人来说

292
00:09:27,720 --> 00:09:30,560
其实我觉得PyTorch的动态图

293
00:09:30,560 --> 00:09:31,720
确实做得非常好

294
00:09:31,720 --> 00:09:33,080
我为什么需要编译器

295
00:09:34,000 --> 00:09:35,800
我使用其他AI框架的时候

296
00:09:35,800 --> 00:09:37,080
大部分都会带有一些

297
00:09:37,080 --> 00:09:38,240
AI编译器的性能

298
00:09:38,440 --> 00:09:40,480
这个时候我要去学它的前端

299
00:09:40,480 --> 00:09:42,200
不能够很好灵活的表达

300
00:09:42,200 --> 00:09:44,080
这个是对一些初学者

301
00:09:44,080 --> 00:09:45,040
或者开发者来说

302
00:09:45,280 --> 00:09:46,520
是不太友好的

303
00:09:46,800 --> 00:09:47,800
第二点就是

304
00:09:48,400 --> 00:09:50,400
经过优化后的计算图

305
00:09:50,480 --> 00:09:51,880
其实已经不是我们原来

306
00:09:51,880 --> 00:09:53,320
所表达的代码了

307
00:09:53,320 --> 00:09:54,960
就导致代码有一些错误

308
00:09:55,200 --> 00:09:56,440
很难去表达

309
00:09:56,440 --> 00:09:58,320
利用我做了一些算子的消除

310
00:09:58,320 --> 00:10:01,160
我原来算子消除的那段代码写错了

311
00:10:01,160 --> 00:10:03,240
这个时候很难去定位

312
00:10:04,240 --> 00:10:06,480
第三点还是调试的问题

313
00:10:06,480 --> 00:10:07,880
假设我们改了代码

314
00:10:07,880 --> 00:10:08,960
需要重新编译

315
00:10:08,960 --> 00:10:09,800
而重新编译

316
00:10:10,240 --> 00:10:12,840
又导致我们的执行效率的变低

317
00:10:14,840 --> 00:10:18,160
最后就是引发大家一个的思考

318
00:10:18,160 --> 00:10:19,520
像Torch Dynamo

319
00:10:19,760 --> 00:10:21,320
PyTorch 2.0的特性

320
00:10:21,360 --> 00:10:23,680
真的能解决99%的场景吗

321
00:10:23,720 --> 00:10:26,160
它能解决多少场景的问题

322
00:10:26,160 --> 00:10:27,880
这个是一个问号

323
00:10:27,880 --> 00:10:30,480
我们希望它能够解决的越多越好

324
00:10:30,560 --> 00:10:32,280
然后第二点就是Midas Ball

325
00:10:32,400 --> 00:10:33,200
它的优化

326
00:10:33,200 --> 00:10:36,000
主要是针对静态图加AI编译器的

327
00:10:36,040 --> 00:10:38,760
未来在动态图转静态图

328
00:10:38,760 --> 00:10:40,520
然后使用AI编译器

329
00:10:40,760 --> 00:10:43,480
大家有没有更好的方案呢

330
00:10:43,600 --> 00:10:45,080
其实我这里面很希望

331
00:10:45,080 --> 00:10:47,640
大家不要太多的去沉迷于

332
00:10:47,640 --> 00:10:49,400
用PyTorch这个框架

333
00:10:49,400 --> 00:10:51,760
而是更多的去回头来看看

334
00:10:51,760 --> 00:10:53,800
我们对于自己国产的框架

335
00:10:53,800 --> 00:10:55,080
有什么优化的点

336
00:10:55,080 --> 00:10:56,360
有什么好的思路

337
00:10:56,360 --> 00:10:59,120
去贡献到我们国产的AI框架里面

338
00:10:59,400 --> 00:10:59,960
好了

339
00:10:59,960 --> 00:11:00,760
谢谢各位

340
00:11:01,720 --> 00:11:02,520
卷的不行了

341
00:11:02,520 --> 00:11:03,360
卷的不行了

342
00:11:03,360 --> 00:11:04,800
记得一键三连加关注

343
00:11:05,200 --> 00:11:06,560
所有的内容都会开源

344
00:11:06,560 --> 00:11:08,360
在下面这条链接里面

345
00:11:08,800 --> 00:11:09,680
拜了个拜

