1
00:00:00,000 --> 00:00:07,400
哈喽大家好,我是周米

2
00:00:07,400 --> 00:00:13,000
今天我给大家去讲讲PyTorch里面一个不算太新,但是也不算太旧

3
00:00:13,000 --> 00:00:17,400
可是这个特性非常重要的就是Dispatch的机制

4
00:00:17,400 --> 00:00:19,100
那为什么会讲这个机制呢?

5
00:00:19,100 --> 00:00:22,600
是因为我们在讲到PyTorch 2.0新特性的时候

6
00:00:22,600 --> 00:00:24,600
会有一个AoT Off-Gate

7
00:00:24,600 --> 00:00:27,500
那AoT就是Ahead-of-Time Auto-Gate

8
00:00:27,500 --> 00:00:29,300
就自动为分这个功能

9
00:00:29,300 --> 00:00:31,300
而这个功能的具体实现呢

10
00:00:31,300 --> 00:00:33,100
我们在上一节分享里面呢

11
00:00:33,100 --> 00:00:36,200
其实给大家已经安利过

12
00:00:36,200 --> 00:00:36,700
只是呢

13
00:00:36,700 --> 00:00:40,300
它会严重的去依赖于Torch Dispatch这个机制

14
00:00:40,300 --> 00:00:43,200
所以今天我们来看看Torch Dispatch机制的原理

15
00:00:44,500 --> 00:00:47,800
那在正式进入到Torch Dispatch机制这个原理呢

16
00:00:47,800 --> 00:00:49,700
我们会分开几个内容去介绍

17
00:00:49,700 --> 00:00:51,900
首先什么是Dispatch

18
00:00:51,900 --> 00:00:53,800
Dispatch到底有什么不同

19
00:00:53,800 --> 00:00:54,400
那接着呢

20
00:00:54,400 --> 00:00:57,000
我们去看看为什么需要Dispatch

21
00:00:57,000 --> 00:00:58,100
Dispatch的中文呢

22
00:00:58,100 --> 00:00:59,300
我们等一下会讲

23
00:00:59,300 --> 00:01:01,400
那为什么需要Dispatch之后呢

24
00:01:01,400 --> 00:01:04,800
我们就会真正的去了解到了Dispatch的注册

25
00:01:04,800 --> 00:01:07,000
和分发的一个具体的内容

26
00:01:07,000 --> 00:01:08,700
或者它的一个Concept

27
00:01:08,700 --> 00:01:09,600
有了这个之后呢

28
00:01:09,600 --> 00:01:14,800
我们去看看PyTorch Dispatch里面的一个Key的表示和计算

29
00:01:14,800 --> 00:01:18,200
最后的我们去了解一下PyTorch Dispatch Table

30
00:01:18,200 --> 00:01:21,400
怎么去对我们一些新的算子进行注册

31
00:01:21,400 --> 00:01:23,800
或者新的功能进行注册的

32
00:01:23,800 --> 00:01:26,000
了解完PyTorch Dispatch机制之后呢

33
00:01:26,000 --> 00:01:29,300
我们就回头去看看Torch AOT Auto Gui

34
00:01:29,300 --> 00:01:31,800
这个特性的具体的实现原理的时候呢

35
00:01:31,800 --> 00:01:34,600
可能就会有一个更加清晰的了解了

36
00:01:36,100 --> 00:01:39,100
现在我们来了解一下什么是Dispatch

37
00:01:39,100 --> 00:01:40,400
那Dispatch的中文呢

38
00:01:40,400 --> 00:01:42,300
主要是派遣分发的意思

39
00:01:42,300 --> 00:01:45,900
我们简单的去把它当做分发的机制就好了

40
00:01:47,000 --> 00:01:47,500
假设呢

41
00:01:47,500 --> 00:01:48,900
我们现在有一个团队

42
00:01:48,900 --> 00:01:49,500
这个团队呢

43
00:01:49,500 --> 00:01:50,700
有四个人去组成

44
00:01:50,700 --> 00:01:52,300
一个是我们的PM

45
00:01:52,300 --> 00:01:55,700
另外的话是我们三个很惨的程序员

46
00:01:55,700 --> 00:01:56,400
那这个时候呢

47
00:01:56,400 --> 00:01:57,600
我们的甲方的爸爸

48
00:01:57,600 --> 00:01:59,400
不断的去给我们这个项目

49
00:01:59,400 --> 00:02:02,100
这四个人组成的项目提需求

50
00:02:02,100 --> 00:02:03,500
我们对这个甲方呢

51
00:02:03,500 --> 00:02:04,600
叫做Krisi甲方

52
00:02:04,600 --> 00:02:07,400
针对Krisi甲方给我们的这个项目团队

53
00:02:07,400 --> 00:02:09,500
提出各种各样的需求

54
00:02:09,500 --> 00:02:10,400
这个时候呢

55
00:02:10,400 --> 00:02:13,400
我们的项目经理就会根据Krisi甲方的需求

56
00:02:13,400 --> 00:02:14,400
进行拆分

57
00:02:14,400 --> 00:02:17,200
匹配到每个程序员适合

58
00:02:17,200 --> 00:02:19,000
擅长他们做的事情

59
00:02:19,000 --> 00:02:20,200
那这个项目经理呢

60
00:02:20,200 --> 00:02:21,600
我们叫做Dispatch

61
00:02:21,600 --> 00:02:25,600
他所做的工作就是一个简单的工作的分发

62
00:02:26,600 --> 00:02:28,000
那通过这个概念呢

63
00:02:28,000 --> 00:02:29,500
我们简单的去了解了

64
00:02:29,500 --> 00:02:31,100
什么是Dispatch

65
00:02:31,100 --> 00:02:31,800
那接着呢

66
00:02:31,800 --> 00:02:34,800
我们去看看为什么需要Dispatch

67
00:02:36,800 --> 00:02:38,600
从刚才的一个例子来看呢

68
00:02:38,600 --> 00:02:39,500
其实Dispatch呢

69
00:02:39,500 --> 00:02:41,400
更多的是一个if-else的工作

70
00:02:41,400 --> 00:02:42,800
如果你适合干这个活

71
00:02:42,800 --> 00:02:44,400
那我就把这个活分给你

72
00:02:44,400 --> 00:02:47,500
就是如果没有一个很好的Dispatch分发器的话

73
00:02:47,500 --> 00:02:49,600
我们会写很多if-else的代码

74
00:02:49,600 --> 00:02:51,600
如果input的contest等于GPU

75
00:02:51,600 --> 00:02:53,500
如果input的cast等于CPU

76
00:02:53,500 --> 00:02:55,100
或者等于不同的硬件的时候

77
00:02:55,100 --> 00:02:56,400
我们就会怎么做

78
00:02:56,400 --> 00:02:57,200
那这个时候呢

79
00:02:57,200 --> 00:02:57,900
没有Dispatch

80
00:02:57,900 --> 00:03:00,100
我们会写大量的if-else

81
00:03:00,100 --> 00:03:00,900
而Dispatch呢

82
00:03:00,900 --> 00:03:04,400
可以很好的帮我们去管理一些分发的工作

83
00:03:04,400 --> 00:03:05,500
那我们可以看一下

84
00:03:05,500 --> 00:03:07,000
其实关于上下文

85
00:03:07,000 --> 00:03:09,500
或者关于我们整个AI编辑器里面呢

86
00:03:09,500 --> 00:03:10,300
关于Tensor

87
00:03:10,300 --> 00:03:13,600
我们就有非常多不同的内容

88
00:03:13,600 --> 00:03:14,200
那第一个呢

89
00:03:14,200 --> 00:03:15,200
就是Devices

90
00:03:15,200 --> 00:03:16,800
我们针对一个具体的算子

91
00:03:16,800 --> 00:03:19,500
或者针对一个具体的Tensor的操作

92
00:03:19,500 --> 00:03:21,900
我们有非常多不同的设备

93
00:03:22,000 --> 00:03:23,500
有CPU、GPU、NPU、TPU

94
00:03:23,500 --> 00:03:26,400
还有FPGA等不同的硬件

95
00:03:26,400 --> 00:03:27,100
那这个时候呢

96
00:03:27,100 --> 00:03:29,300
我需要根据上下文去决定

97
00:03:29,300 --> 00:03:31,600
我这个算子跑在哪个硬件上面

98
00:03:31,600 --> 00:03:32,200
这里面呢

99
00:03:32,200 --> 00:03:34,100
我们就有了一个分发的机制

100
00:03:34,100 --> 00:03:35,700
分发的工作

101
00:03:35,700 --> 00:03:38,500
如果没有了这个Dispatch的分发的机制之后呢

102
00:03:38,500 --> 00:03:41,100
我们会写大量的代码去解决这些问题

103
00:03:41,100 --> 00:03:41,700
那代码呢

104
00:03:41,700 --> 00:03:43,300
就会非常的勇于

105
00:03:43,300 --> 00:03:45,600
而且维护起来也非常困难

106
00:03:45,600 --> 00:03:46,700
针对Tensor

107
00:03:46,700 --> 00:03:48,400
我们还有非常多的内容

108
00:03:48,400 --> 00:03:50,100
就Tensor它有很多的layout

109
00:03:50,100 --> 00:03:52,300
有很多不同的形式和结构

110
00:03:52,300 --> 00:03:53,900
那我们可以有普通的脏量

111
00:03:53,900 --> 00:03:55,100
有稀疏的脏量

112
00:03:55,100 --> 00:03:56,600
而且不同的脏量

113
00:03:56,600 --> 00:03:57,700
有不同的布局

114
00:03:57,700 --> 00:04:00,700
有NHWC、有NCHW

115
00:04:00,700 --> 00:04:01,300
另外的话

116
00:04:01,300 --> 00:04:02,900
我们举第三个例子

117
00:04:02,900 --> 00:04:04,700
就是Data Type

118
00:04:04,700 --> 00:04:06,800
脏量的数据类型

119
00:04:06,800 --> 00:04:08,500
我们平时在Tabularly上面

120
00:04:08,500 --> 00:04:10,700
去用的一些数据类型

121
00:04:10,700 --> 00:04:11,600
已经比较固定了

122
00:04:11,600 --> 00:04:13,400
有普通的Float、Long Float

123
00:04:13,400 --> 00:04:14,300
还有Short Float

124
00:04:14,300 --> 00:04:15,300
还有Longed In

125
00:04:15,300 --> 00:04:16,400
还有Shorted In

126
00:04:16,400 --> 00:04:18,000
很多不同的类型

127
00:04:18,100 --> 00:04:20,000
而AI深度学习诞生之后

128
00:04:20,000 --> 00:04:21,700
我们会出现的更多的

129
00:04:21,700 --> 00:04:23,000
不同的数据类型

130
00:04:23,000 --> 00:04:24,900
有BF16、HF32

131
00:04:24,900 --> 00:04:26,900
跟不同的类型

132
00:04:26,900 --> 00:04:28,500
如果我要去写大量的

133
00:04:28,500 --> 00:04:29,800
If Else的内容

134
00:04:29,800 --> 00:04:31,300
或者Switch Case的内容

135
00:04:31,300 --> 00:04:33,000
我们就会写非常大量

136
00:04:33,000 --> 00:04:34,500
勇于的代码

137
00:04:34,500 --> 00:04:35,800
那这个时候

138
00:04:35,800 --> 00:04:38,400
我们就确实需要一个Dispatcher

139
00:04:38,400 --> 00:04:40,900
让它统一帮我们去调度

140
00:04:40,900 --> 00:04:42,600
管理分配的工作

141
00:04:44,400 --> 00:04:45,800
在Pytorch里面

142
00:04:45,900 --> 00:04:47,300
主要是采用一个

143
00:04:47,300 --> 00:04:49,000
比较常见的架构

144
00:04:49,000 --> 00:04:51,600
那我们会做一个注册和分发

145
00:04:51,600 --> 00:04:53,300
但是对于我们这些

146
00:04:53,300 --> 00:04:55,200
苦逼的程序员来说

147
00:04:55,200 --> 00:04:56,700
我们就需要考虑到

148
00:04:56,700 --> 00:04:58,200
具体的设计模式

149
00:04:58,200 --> 00:04:59,700
用哪一种方式

150
00:04:59,700 --> 00:05:01,800
那实际上注册分发这种机制

151
00:05:01,800 --> 00:05:03,300
我们在设计模式里面

152
00:05:03,300 --> 00:05:05,500
会使用到注册器的模式

153
00:05:05,500 --> 00:05:07,000
还有工厂的模式

154
00:05:07,000 --> 00:05:09,600
去具体的实现这个功能

155
00:05:10,600 --> 00:05:12,700
下面我们对着具体的代码

156
00:05:12,700 --> 00:05:14,800
来看看什么是具体的

157
00:05:14,800 --> 00:05:16,600
Dispatcher的注册和分发

158
00:05:16,600 --> 00:05:18,800
还有这样的下方

159
00:05:18,800 --> 00:05:19,900
那下面我们也add

160
00:05:19,900 --> 00:05:21,100
这个算子作为例子

161
00:05:21,100 --> 00:05:22,500
那我们在上层

162
00:05:22,500 --> 00:05:25,000
或者在我们的Pytorch的API层

163
00:05:25,000 --> 00:05:26,600
大部分都是Python的代码

164
00:05:26,600 --> 00:05:29,100
那我们传进去的是两个Tensor

165
00:05:29,100 --> 00:05:31,900
然后进行一个累加的操作

166
00:05:31,900 --> 00:05:33,800
我们关于加的复数的表示

167
00:05:33,800 --> 00:05:35,700
其实有两种操作

168
00:05:35,700 --> 00:05:38,000
一种是实部和虚部的表示

169
00:05:38,000 --> 00:05:39,200
Rectangular

170
00:05:39,200 --> 00:05:41,900
一种就是模和浮角的表示

171
00:05:41,900 --> 00:05:43,300
我们叫做Polar

172
00:05:43,300 --> 00:05:45,200
如果我们要实现一个系统

173
00:05:45,200 --> 00:05:46,300
或者实现一个算子

174
00:05:46,300 --> 00:05:49,400
同时支持这两种形式的加法的运算

175
00:05:49,400 --> 00:05:50,900
那这个时候应该怎么做呢

176
00:05:50,900 --> 00:05:52,700
那首先我们由这一段代码

177
00:05:52,700 --> 00:05:56,300
我们会把一个接口实现定义好

178
00:05:56,300 --> 00:05:57,800
一个叫做Rectangular

179
00:05:57,800 --> 00:05:59,200
一个叫做Polar

180
00:05:59,200 --> 00:06:01,400
然后我们去通过if else

181
00:06:01,400 --> 00:06:04,500
去判断我们输进去的Tensor的一个类型

182
00:06:04,500 --> 00:06:05,800
它到底是哪种

183
00:06:05,800 --> 00:06:09,500
选择具体的它对应的实现的方式

184
00:06:09,500 --> 00:06:11,400
或者它实现的方法

185
00:06:11,400 --> 00:06:13,500
而采用了注册分发的机制

186
00:06:13,500 --> 00:06:16,200
实际上我们会保存一张表

187
00:06:16,200 --> 00:06:18,600
这张表我们叫做Vtable

188
00:06:18,600 --> 00:06:21,600
这个跟C++里面的一个虚拟表

189
00:06:21,600 --> 00:06:23,500
是类似相同的概念

190
00:06:23,500 --> 00:06:25,200
那这个时候我们会有一个key

191
00:06:25,200 --> 00:06:26,100
有个value

192
00:06:26,100 --> 00:06:27,700
那么可以看到key里面

193
00:06:27,700 --> 00:06:29,100
我们刚才的add操作

194
00:06:29,100 --> 00:06:30,900
有Rectangular有Polar

195
00:06:30,900 --> 00:06:32,700
然后我们具体的value

196
00:06:32,700 --> 00:06:34,100
就是对应的函数

197
00:06:34,100 --> 00:06:35,100
拿到具体的key

198
00:06:35,100 --> 00:06:38,400
就可以调用具体的一个函数的value

199
00:06:38,400 --> 00:06:40,600
有两个对应的具体的函数的实现

200
00:06:40,600 --> 00:06:42,300
实际上存的不是一个函数

201
00:06:42,300 --> 00:06:44,000
而实际上存的是地址

202
00:06:44,000 --> 00:06:45,600
每次有新方法的时候

203
00:06:45,600 --> 00:06:47,200
我们就通过regest

204
00:06:47,200 --> 00:06:49,200
去注册到刚才的那个表

205
00:06:49,200 --> 00:06:51,000
然后具体的接口的时候

206
00:06:51,000 --> 00:06:52,100
就会通过get

207
00:06:52,100 --> 00:06:55,100
来去获取对应的实现函数的地址

208
00:06:55,100 --> 00:06:57,600
我们有一个add的算子的操作

209
00:06:57,600 --> 00:07:00,600
数同样是z1跟z2

210
00:07:00,600 --> 00:07:03,200
最重要的是第18行代码

211
00:07:03,200 --> 00:07:04,800
我们通过get z1的tag

212
00:07:04,800 --> 00:07:07,300
而z1的tag就是对应的key

213
00:07:07,300 --> 00:07:08,600
通过get的方式

214
00:07:08,600 --> 00:07:11,700
去获取我们对应的要运行的函数

215
00:07:12,900 --> 00:07:13,900
那这种方式

216
00:07:13,900 --> 00:07:16,000
就是实际上注册和分发

217
00:07:16,000 --> 00:07:18,900
具体的实现的原理和过程了

218
00:07:18,900 --> 00:07:20,700
更多的我们会模仿

219
00:07:20,700 --> 00:07:23,200
C++里面的Virtual Table

220
00:07:23,200 --> 00:07:24,600
就是它的虚拟表

221
00:07:24,600 --> 00:07:26,500
PyTorch里面的Vtable

222
00:07:26,500 --> 00:07:28,100
首先我们具体的看看

223
00:07:28,100 --> 00:07:29,800
就是C++的Vtable

224
00:07:29,800 --> 00:07:32,300
它是每一个类都有一个Vtable

225
00:07:32,300 --> 00:07:33,800
而且只有dist

226
00:07:33,800 --> 00:07:35,800
指针指向我们的Vtable

227
00:07:35,800 --> 00:07:37,600
而PyTorch里面的Vtable

228
00:07:37,600 --> 00:07:39,800
就是每一个算子

229
00:07:39,800 --> 00:07:42,200
都会维护一个自己的Vtable

230
00:07:42,200 --> 00:07:44,300
而且我们不仅仅要考虑到

231
00:07:44,300 --> 00:07:45,800
Tensor相关的信息

232
00:07:45,800 --> 00:07:48,000
还要考虑到很多的上下文

233
00:07:48,000 --> 00:07:50,200
就我们刚才提到的data type的信息

234
00:07:50,200 --> 00:07:52,100
还有我们不同硬件的信息

235
00:07:52,100 --> 00:07:54,500
而且在PyTorch的一个Vtable

236
00:07:54,500 --> 00:07:56,700
基本上我们只会扩展

237
00:07:56,700 --> 00:07:59,300
我们对应的算子的操作

238
00:07:59,300 --> 00:08:00,800
而不会像C++这样

239
00:08:00,800 --> 00:08:04,300
根据每个类去提供对应的Vtable

240
00:08:04,300 --> 00:08:05,300
所以这里面很重要

241
00:08:05,300 --> 00:08:07,400
因为在我们的AI框架里面

242
00:08:07,400 --> 00:08:09,300
更关注的是一个计算

243
00:08:09,300 --> 00:08:11,700
而计算的逻辑是用户提供的

244
00:08:11,700 --> 00:08:13,200
就是用户的脚本告诉我

245
00:08:13,200 --> 00:08:15,900
我应该怎么去算这个深度学习的模型

246
00:08:15,900 --> 00:08:17,300
而PyTorch的Vtable

247
00:08:17,300 --> 00:08:19,300
或者PyTorch的Dispatch机制

248
00:08:19,300 --> 00:08:22,100
更多的是做一个具体的分发的工作

249
00:08:23,600 --> 00:08:25,100
那我们现在来看看

250
00:08:25,100 --> 00:08:28,100
实际的Dispatch的key是怎么操作的

251
00:08:28,100 --> 00:08:30,200
假设我们现在去执行

252
00:08:30,200 --> 00:08:33,600
一个Torch Add的一个算子的操作的时候

253
00:08:33,600 --> 00:08:36,100
就执行简单一个加法的时候

254
00:08:36,200 --> 00:08:38,600
Dispatch首先会找到这个算子

255
00:08:38,600 --> 00:08:41,300
就是我们这个加对应的Dispatch Key

256
00:08:41,300 --> 00:08:43,600
就我们刚才的那个Vtable

257
00:08:43,600 --> 00:08:46,100
然后根据这个Dispatch的key

258
00:08:46,100 --> 00:08:48,900
去找到对应的kernel的函数

259
00:08:48,900 --> 00:08:51,400
就对应实现真正实现的函数

260
00:08:51,400 --> 00:08:53,100
而在PyTorch里面

261
00:08:53,100 --> 00:08:54,600
这个对应的kernel的函数

262
00:08:54,600 --> 00:08:56,200
是我们的Primp IR

263
00:08:56,200 --> 00:08:57,600
或者我们的Atom IR

264
00:08:57,600 --> 00:08:59,200
对应的算子的实现了

265
00:09:02,400 --> 00:09:03,800
那在这里面

266
00:09:04,200 --> 00:09:07,100
非常推荐大家去看一下

267
00:09:07,100 --> 00:09:09,100
这一个网站就是

268
00:09:09,100 --> 00:09:12,200
easyyang的一个box

269
00:09:12,200 --> 00:09:14,400
它里面就分享了非常多

270
00:09:14,400 --> 00:09:16,100
关于PyTorch Dispatch

271
00:09:16,100 --> 00:09:19,700
还有PyTorch原生的一些具体的原理

272
00:09:19,700 --> 00:09:20,600
那在这里面

273
00:09:20,600 --> 00:09:22,600
我对它截了一张图

274
00:09:22,600 --> 00:09:24,200
右边的这个就是

275
00:09:24,200 --> 00:09:26,800
C++的一个Vtable的具体的实现

276
00:09:26,800 --> 00:09:28,400
而Vtable里面的key

277
00:09:28,400 --> 00:09:30,900
就对应它的一个Disk的指针

278
00:09:30,900 --> 00:09:32,500
PyTorch这里面的实现

279
00:09:32,500 --> 00:09:35,200
更多的是对我们的Tensor的执行

280
00:09:35,200 --> 00:09:36,600
去做一个Dispatch的

281
00:09:36,600 --> 00:09:39,100
所以它大部分针对的是一个Tensor

282
00:09:39,100 --> 00:09:39,900
那可以看到

283
00:09:39,900 --> 00:09:41,100
Dispatch的key

284
00:09:41,100 --> 00:09:43,500
主要是由一系列的byte set来做

285
00:09:43,500 --> 00:09:44,300
而这个byte

286
00:09:44,300 --> 00:09:45,100
一般来说

287
00:09:45,100 --> 00:09:47,700
它里面设置了成64位

288
00:09:47,700 --> 00:09:49,800
然后每一个标志位

289
00:09:49,800 --> 00:09:52,600
代表它具体的一个不同的一个内容

290
00:09:52,600 --> 00:09:54,900
这里面有几个内容来去组成的

291
00:09:54,900 --> 00:09:57,500
第一大内容就是Tensor的input

292
00:09:57,500 --> 00:10:00,100
那包括我们的一个CPU CUDA

293
00:10:00,100 --> 00:10:01,800
还有不同的后端

294
00:10:01,800 --> 00:10:04,500
第二个内容就是local include

295
00:10:04,500 --> 00:10:06,600
GPyTorch里面的一些local的功能

296
00:10:06,600 --> 00:10:08,600
当然了它有一些global的功能

297
00:10:08,600 --> 00:10:10,600
包括我们的backend的selection

298
00:10:10,600 --> 00:10:12,000
还有一些autograde

299
00:10:12,000 --> 00:10:13,600
当然了后来autograde

300
00:10:13,600 --> 00:10:16,700
已经移到我们的Tensor的内容里面了

301
00:10:17,600 --> 00:10:19,800
然后把不同的输入输进来之后

302
00:10:19,800 --> 00:10:21,900
通过我们的byte set进行一个concat

303
00:10:21,900 --> 00:10:25,300
然后把它变成具体的一个byte set里面

304
00:10:25,300 --> 00:10:27,500
当然了我们会做一个local exclude

305
00:10:27,500 --> 00:10:29,700
就把相关的内容把它去掉

306
00:10:29,800 --> 00:10:32,800
那最后真正的到我们的后端执行的时候

307
00:10:32,800 --> 00:10:35,100
我们就会去执行这个dispatch key

308
00:10:35,100 --> 00:10:37,400
能够留下的一些内容

309
00:10:38,900 --> 00:10:43,200
下面我们简单的来去看一些相关的概念

310
00:10:43,200 --> 00:10:47,900
首先dispatch并不只是针对我们的后端来去实现调度的

311
00:10:47,900 --> 00:10:51,400
也就是说dispatch它不是一个具体的实现

312
00:10:51,400 --> 00:10:53,900
也不是针对我们仅仅的硬件

313
00:10:53,900 --> 00:10:56,200
它更多的是对应一个抽象

314
00:10:56,200 --> 00:10:59,500
包括我们的一些PyTorch后端的代码

315
00:10:59,500 --> 00:11:02,000
包括它的tracing、JIT还有autogrid

316
00:11:02,000 --> 00:11:03,600
这些函数的功能

317
00:11:04,600 --> 00:11:07,000
第二个就是dispatch的key的计算

318
00:11:07,000 --> 00:11:10,900
刚才我们讲了它是由一个具体的数据结构来去实现的

319
00:11:10,900 --> 00:11:14,600
我们简单的理解它为一个64bit的一个数字

320
00:11:14,600 --> 00:11:17,500
每一个bit都代表一个dispatch的key

321
00:11:17,500 --> 00:11:20,600
所以我们从左到右是有个具体的优先级的

322
00:11:20,600 --> 00:11:24,900
同一个算子可能会有针对不同的dispatch的key的实现

323
00:11:24,900 --> 00:11:27,500
最后在执行或者调度的时候

324
00:11:27,500 --> 00:11:31,600
我们就会根据最高优先级的dispatch的key对应的kernel

325
00:11:31,600 --> 00:11:33,500
然后去调度执行

326
00:11:33,500 --> 00:11:36,500
这个就是dispatchkey的具体的原理

327
00:11:36,500 --> 00:11:38,100
当然我们可以理解一下

328
00:11:38,100 --> 00:11:41,600
其实PyTorch它不仅仅只有上层的API

329
00:11:41,600 --> 00:11:44,300
还有底层的kernel对应的算子的实现

330
00:11:44,300 --> 00:11:46,900
实际上它有非常多不同的功能

331
00:11:46,900 --> 00:11:49,400
例如它有autocast

332
00:11:49,400 --> 00:11:51,700
超入一些转块的算子

333
00:11:51,700 --> 00:11:54,700
当然针对不同的后端还有SLA CUDA CPU

334
00:11:54,700 --> 00:11:56,000
有不同的backend

335
00:11:56,000 --> 00:11:59,800
而backend只是占了其中的一小部分

336
00:11:59,800 --> 00:12:01,800
所以我们说dispatch的机制

337
00:12:01,800 --> 00:12:05,700
不仅仅是对后端的硬件进行一个分发调度

338
00:12:05,700 --> 00:12:09,800
它还会对它内部的一些功能函数进行调度

339
00:12:12,600 --> 00:12:16,100
跟Vegeta API的交互的方式有三种

340
00:12:16,100 --> 00:12:18,700
第一种就是定义具体的screenmark

341
00:12:18,700 --> 00:12:20,700
第二个就是实现Vegeta

342
00:12:20,700 --> 00:12:22,700
就是实现具体的初始的功能

343
00:12:22,700 --> 00:12:24,700
第三个就是fallback

344
00:12:24,700 --> 00:12:26,700
我们现在分开三个的方式

345
00:12:26,700 --> 00:12:29,700
看一下具体是怎么做注册的

346
00:12:29,700 --> 00:12:33,200
我们这里面有我们的算子作为例子

347
00:12:33,200 --> 00:12:35,700
就怎么去注册一个具体的算子

348
00:12:35,700 --> 00:12:37,700
到我们的Vegeta table里面

349
00:12:39,400 --> 00:12:42,500
那么可以看到具体的某个算子的注册

350
00:12:42,500 --> 00:12:44,300
我们就可以用Torch library

351
00:12:44,300 --> 00:12:45,700
impl

352
00:12:45,700 --> 00:12:48,700
然后去声明我们用的是哪个算子的IR

353
00:12:48,700 --> 00:12:50,700
然后用的是哪个后端

354
00:12:50,700 --> 00:12:53,900
接着我们去用amp-implement

355
00:12:53,900 --> 00:12:56,900
然后声明我们具体需要用到的算子

356
00:12:56,900 --> 00:12:58,900
或者注册的算子叫什么名字

357
00:12:58,900 --> 00:13:00,900
跑在哪个后端的函数里面

358
00:13:00,900 --> 00:13:03,900
刚才我们注册了一个atom的mod

359
00:13:03,900 --> 00:13:05,900
跑在CPU里面

360
00:13:05,900 --> 00:13:08,900
这个就是对单个算子注册在我们的

361
00:13:08,900 --> 00:13:11,900
Dispatcher里面的一个分发器里面

362
00:13:11,900 --> 00:13:13,900
实际上我们只是一个注册

363
00:13:13,900 --> 00:13:14,900
它还没有去运行的

364
00:13:14,900 --> 00:13:17,900
真正运行的时候是通过我们的Pattern

365
00:13:17,900 --> 00:13:18,900
执行的时候跑的时候

366
00:13:18,900 --> 00:13:21,900
才去真正的去调到我们具体的后端

367
00:13:23,900 --> 00:13:24,900
现在我们来看看

368
00:13:24,900 --> 00:13:25,900
amp-define

369
00:13:25,900 --> 00:13:26,900
然后mod-add

370
00:13:26,900 --> 00:13:28,900
这种方式就是定义

371
00:13:28,900 --> 00:13:30,900
具体的算子的一个screen

372
00:13:30,900 --> 00:13:34,900
我们通过刚才的Vtable来看一下

373
00:13:34,900 --> 00:13:36,900
我们通过Cache2这个操作

374
00:13:36,900 --> 00:13:38,900
就是把我们的kernel注册到

375
00:13:38,900 --> 00:13:39,900
所有的DispatchKey里

376
00:13:39,900 --> 00:13:42,900
或者通过amp-format这个接口

377
00:13:42,900 --> 00:13:44,900
为所有的算子和kernel

378
00:13:44,900 --> 00:13:46,900
提供一个Dispatch的key

379
00:13:48,900 --> 00:13:49,900
当然了我们刚才讲到的

380
00:13:49,900 --> 00:13:51,900
我们有三种的方式

381
00:13:51,900 --> 00:13:53,900
去注册到对应的Dispatch的key

382
00:13:53,900 --> 00:13:55,900
对应注册到我们的Vtable里面

383
00:13:55,900 --> 00:13:57,900
但是这三种方式

384
00:13:57,900 --> 00:13:59,900
还是有一个优先级的

385
00:13:59,900 --> 00:14:00,900
Top1的一个优先级

386
00:14:00,900 --> 00:14:02,900
就是针对一个特定的kernel

387
00:14:02,900 --> 00:14:04,900
或者特定的screener的一个实现

388
00:14:04,900 --> 00:14:06,900
那第二种就是我们的Cache2

389
00:14:06,900 --> 00:14:09,900
第三种才是我们的Fallback

390
00:14:12,900 --> 00:14:13,900
作弊老师你好

391
00:14:13,900 --> 00:14:15,900
你讲了关于很多

392
00:14:15,900 --> 00:14:17,900
Dispatch的一些原理

393
00:14:17,900 --> 00:14:19,900
和Dispatch怎么去注册

394
00:14:19,900 --> 00:14:20,900
Dispatch这个机制

395
00:14:20,900 --> 00:14:22,900
除了让我们去选择

396
00:14:22,900 --> 00:14:25,900
一些不同的后端和函数之外

397
00:14:25,900 --> 00:14:26,900
它有哪些功能吗

398
00:14:26,900 --> 00:14:28,900
或者具体的实现的功能

399
00:14:28,900 --> 00:14:29,900
有哪些吗

400
00:14:30,900 --> 00:14:32,900
这位小新同学

401
00:14:32,900 --> 00:14:33,900
你问的问题非常好

402
00:14:33,900 --> 00:14:35,900
那下面的这个表格

403
00:14:35,900 --> 00:14:36,900
或者下面的内容

404
00:14:36,900 --> 00:14:37,900
就是PyTorch

405
00:14:37,900 --> 00:14:39,900
Develop社区的网站

406
00:14:39,900 --> 00:14:42,900
给我们提供的一个具体的例子

407
00:14:42,900 --> 00:14:43,900
我们可以看到

408
00:14:43,900 --> 00:14:45,900
其实我们可以有很多的内容

409
00:14:45,900 --> 00:14:46,900
例如我们会做一些

410
00:14:46,900 --> 00:14:48,900
8bit的量化

411
00:14:48,900 --> 00:14:51,900
我们可以做很多的AOTO的柜

412
00:14:51,900 --> 00:14:53,900
而通过统一的一个调度接口

413
00:14:53,900 --> 00:14:55,900
就是我们Dispatch的调度器

414
00:14:55,900 --> 00:14:57,900
去做具体的实现

415
00:14:57,900 --> 00:14:58,900
我举一个最大的例子

416
00:14:58,900 --> 00:14:59,900
就是声腾

417
00:14:59,900 --> 00:15:01,900
我们作为一个第三方的后端

418
00:15:01,900 --> 00:15:03,900
我们想对接到PyTorch里面

419
00:15:03,900 --> 00:15:04,900
其实更多的是

420
00:15:04,900 --> 00:15:06,900
用刚才小小讲到的

421
00:15:06,900 --> 00:15:07,900
一个Dispatch的机制

422
00:15:07,900 --> 00:15:09,900
去提供一个新的后端

423
00:15:09,900 --> 00:15:11,900
让PyTorch去执行

424
00:15:11,900 --> 00:15:13,900
我们这个新的后端的

425
00:15:13,900 --> 00:15:14,900
而PyTorch也是通过

426
00:15:14,900 --> 00:15:15,900
Dispatch的机制

427
00:15:15,900 --> 00:15:16,900
去蓝向的对接到

428
00:15:16,900 --> 00:15:19,900
很多不同的硬件厂商里面

429
00:15:19,900 --> 00:15:21,900
而我们之前上一节讲到的

430
00:15:21,900 --> 00:15:22,900
AOTO的柜

431
00:15:22,900 --> 00:15:24,900
它作为一个具体的

432
00:15:24,900 --> 00:15:26,900
一个后端的C++的功能

433
00:15:26,900 --> 00:15:28,900
也是通过Dispatch的机制

434
00:15:28,900 --> 00:15:30,900
去做一个调度和分发

435
00:15:33,900 --> 00:15:34,900
好了

436
00:15:34,900 --> 00:15:36,900
今天的内容就到这里为止

437
00:15:36,900 --> 00:15:37,900
谢谢各位

438
00:15:37,900 --> 00:15:38,900
拜了个拜

439
00:15:39,900 --> 00:15:40,900
卷的不行了

440
00:15:40,900 --> 00:15:41,900
卷的不行了

441
00:15:41,900 --> 00:15:42,900
记得一键三连加关注哦

442
00:15:42,900 --> 00:15:44,900
所有的内容都会开源

443
00:15:44,900 --> 00:15:46,900
在下面这条链接里面

444
00:15:46,900 --> 00:15:47,900
拜了个拜

