1
00:00:00,000 --> 00:00:06,600
Hello 大家好

2
00:00:06,600 --> 00:00:10,200
我们在分布式系列里面又挖了一个新的坑了

3
00:00:10,200 --> 00:00:12,360
分布式的坑实在是太多了

4
00:00:12,360 --> 00:00:16,400
今天我们来到分布式并行策略的一个具体的大坑里面

5
00:00:16,400 --> 00:00:18,120
来讲讲基本的介绍

6
00:00:18,120 --> 00:00:21,200
就是接下来我们要讲哪些内容

7
00:00:21,200 --> 00:00:23,400
那我们回顾一下在之前的系列

8
00:00:23,400 --> 00:00:24,640
或者在之前的坑里面

9
00:00:24,640 --> 00:00:29,400
我们了解了分布式加AI继续那些关键的内容

10
00:00:29,400 --> 00:00:33,520
从服务器到机群到通讯到软件到AI框架

11
00:00:33,520 --> 00:00:35,240
它应该具备哪些功能

12
00:00:35,240 --> 00:00:39,360
那第二个就是我们来看了一下大模型的总体的算法

13
00:00:39,360 --> 00:00:41,360
从大模型遇到的一些挑战

14
00:00:41,360 --> 00:00:43,360
到两个最重要的算法结构

15
00:00:43,360 --> 00:00:47,240
最后引用了一些最经典的或者最收藏的大模型

16
00:00:47,240 --> 00:00:49,200
今天我们要分享的内容

17
00:00:49,200 --> 00:00:52,400
或者接下来我们要分享的内容有四个部分

18
00:00:52,400 --> 00:00:54,840
第一个就是数据并行

19
00:00:54,840 --> 00:00:57,680
数据并行就会有非常多的数据并行

20
00:00:57,720 --> 00:00:59,920
大家不要觉得数据并行很简单

21
00:00:59,920 --> 00:01:02,080
其实数据并行也可以做得很复杂

22
00:01:02,080 --> 00:01:05,280
就有DP,DDP还有FSDP

23
00:01:05,280 --> 00:01:08,000
不同的模式有不同的并行的策略

24
00:01:08,000 --> 00:01:11,000
接着我们来看看模型并行

25
00:01:11,000 --> 00:01:12,680
其实现在有很多误区

26
00:01:12,680 --> 00:01:15,840
就是张量并行和流水线并行是一个独立的

27
00:01:15,840 --> 00:01:19,800
其实这些并行都是并在我们模型并行里面

28
00:01:19,800 --> 00:01:21,760
我们模型并行又叫MP

29
00:01:21,760 --> 00:01:26,320
MP里面就分为张量并行TP和流水线并行PP

30
00:01:26,360 --> 00:01:28,400
Pipe,Pull,Night,Poll,Lessom

31
00:01:28,400 --> 00:01:30,800
接着我们来去学习一下

32
00:01:30,800 --> 00:01:34,960
我们现在MindSpore推出最新的一个自动并行的策略

33
00:01:34,960 --> 00:01:38,280
这里面我们只会讲MindSpore的张量自动并行

34
00:01:38,280 --> 00:01:40,840
其实MindSpore可以做得非常多的并行的策略

35
00:01:40,840 --> 00:01:43,120
特别是自动的多维混合并行

36
00:01:43,120 --> 00:01:44,600
聊到多维混合并行

37
00:01:44,600 --> 00:01:48,720
我们首先来去看看一个Inpending的混合并行

38
00:01:48,720 --> 00:01:52,560
接着去看看MPDP就是数据并行加模型并行

39
00:01:52,560 --> 00:01:56,200
就是把上面四五种并行的方式混合在一起用

40
00:01:56,240 --> 00:01:57,680
一起去训练

41
00:01:57,680 --> 00:01:58,880
好了,时不宜迟

42
00:01:58,880 --> 00:02:01,280
我们现在来继续往下看一看

43
00:02:01,280 --> 00:02:03,880
现在其实我们现在的大模型这个图

44
00:02:03,880 --> 00:02:05,160
我们看了好几回了

45
00:02:05,160 --> 00:02:06,240
已经脚闷了

46
00:02:06,640 --> 00:02:07,800
大模型越来越大

47
00:02:07,800 --> 00:02:10,240
然后大模型能够解决我们自监督的问题

48
00:02:10,240 --> 00:02:12,600
能够让我们的参数量变大

49
00:02:12,600 --> 00:02:15,320
然后突破我们的模型精度

50
00:02:15,320 --> 00:02:18,720
另外我们还可以解决模型碎片化的问题

51
00:02:18,720 --> 00:02:21,480
但是参数量越大

52
00:02:21,480 --> 00:02:23,840
我们训练的时间就越长

53
00:02:23,840 --> 00:02:26,000
为了解决我们训练时长的问题

54
00:02:26,040 --> 00:02:29,120
我们希望能够提升我们的计算数率

55
00:02:29,120 --> 00:02:31,600
而提升计算数率很重要的就是

56
00:02:31,920 --> 00:02:34,560
需要提升我们单4倍的运算数率

57
00:02:34,560 --> 00:02:37,080
那这个大部分是靠我们的模型率

58
00:02:37,080 --> 00:02:38,160
靠我们的制程的

59
00:02:38,480 --> 00:02:41,040
在另外一方面更加可控的可变因素

60
00:02:41,040 --> 00:02:42,360
就有4倍的数量

61
00:02:42,360 --> 00:02:43,880
就我们堆设备就行了

62
00:02:43,880 --> 00:02:47,360
第二个就是加速我们4倍之间的一个并行效率

63
00:02:47,360 --> 00:02:50,760
那这个就是我们今天的重点和主角

64
00:02:51,800 --> 00:02:54,080
现在我们来看看单4倍的数率

65
00:02:54,080 --> 00:02:55,800
其实有很多一些算法

66
00:02:55,800 --> 00:02:58,760
但这些算法还是只能说引证止渴

67
00:02:59,200 --> 00:03:01,720
真正能够解决的还是我们的制程

68
00:03:01,720 --> 00:03:04,400
那是被数我们之前的上一个系列里面

69
00:03:04,400 --> 00:03:06,080
已经详细的介绍过

70
00:03:06,080 --> 00:03:08,400
今天我们回到我们最重要的内容

71
00:03:08,400 --> 00:03:09,760
就是并行策略

72
00:03:09,760 --> 00:03:11,120
会讲一些数据并行

73
00:03:11,120 --> 00:03:11,800
流水并行

74
00:03:11,800 --> 00:03:12,480
模型并行

75
00:03:12,480 --> 00:03:13,440
张量并行

76
00:03:13,440 --> 00:03:15,280
还有周围混合并行

77
00:03:15,880 --> 00:03:16,280
好了

78
00:03:16,280 --> 00:03:17,080
时不宜迟

79
00:03:17,080 --> 00:03:18,840
让我们期待接下来的内容

80
00:03:19,240 --> 00:03:20,000
谢谢各位

81
00:03:20,000 --> 00:03:20,480
拜拜了

82
00:03:20,480 --> 00:03:21,080
拜拜

83
00:03:25,800 --> 00:03:28,760
所有的内容都会开源在下面这条链接里面

84
00:03:29,280 --> 00:03:29,560
拜了

85
00:03:29,560 --> 00:03:30,040
拜拜

