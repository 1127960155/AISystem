1
00:00:00,000 --> 00:00:05,200
Baba Baba

2
00:00:05,200 --> 00:00:06,400
Hello 大家好

3
00:00:06,400 --> 00:00:07,400
我是中米

4
00:00:07,400 --> 00:00:10,120
这一节的内容还是张亮并行

5
00:00:10,120 --> 00:00:15,320
不同的是我们去讲讲张亮并行里面的张亮重排

6
00:00:15,320 --> 00:00:17,920
然后再去拓展一下MindSpore

7
00:00:17,920 --> 00:00:22,800
如何去对我们的张亮做自动重排的一个具体的算法

8
00:00:25,240 --> 00:00:27,000
现在我们来到最后一个内容

9
00:00:27,000 --> 00:00:28,840
也就是MindSpore很重要的一个特性

10
00:00:28,840 --> 00:00:30,120
张亮自动并行

11
00:00:30,120 --> 00:00:32,880
我们来先前看看具体的数学原理吧

12
00:00:33,720 --> 00:00:35,840
首先我们回顾一下一个张亮

13
00:00:35,840 --> 00:00:38,000
现在的一个2x2的张亮

14
00:00:38,000 --> 00:00:40,040
把它切换到两台不同的机器

15
00:00:40,040 --> 00:00:41,720
可能我们有两种切换方式

16
00:00:41,720 --> 00:00:43,160
一种是行的切分

17
00:00:43,160 --> 00:00:44,440
一种是列的切分

18
00:00:44,440 --> 00:00:46,760
另外一种就是直接复制

19
00:00:46,760 --> 00:00:48,200
假设我复杂一点

20
00:00:48,200 --> 00:00:49,840
我的机器多了

21
00:00:49,840 --> 00:00:51,800
我同样是一个2x2的机器

22
00:00:51,800 --> 00:00:53,640
我现在有4台4倍

23
00:00:53,640 --> 00:00:56,280
我可能会进行一个行列的切分

24
00:00:56,320 --> 00:00:58,640
把每一个元素切换到不同的机器

25
00:00:58,640 --> 00:01:01,240
我也可能只进行一个行的切分

26
00:01:01,240 --> 00:01:03,280
或者只进行一个行的切分

27
00:01:03,280 --> 00:01:04,320
那我有4台机器

28
00:01:04,320 --> 00:01:05,960
行切分只会分成两半

29
00:01:05,960 --> 00:01:08,480
所以另外两半我们会做一个复制

30
00:01:08,480 --> 00:01:12,960
这个Devices1跟Devices3的数据是相同的

31
00:01:12,960 --> 00:01:15,280
第三种就是进行列的切分

32
00:01:15,280 --> 00:01:19,120
同样列的切分只会切分成两组数据

33
00:01:19,120 --> 00:01:21,360
我还是需要进行一个复制

34
00:01:21,360 --> 00:01:24,320
把Devices1的数据复制成Devices3

35
00:01:24,320 --> 00:01:27,200
我才可以保证4台机器都有数据

36
00:01:27,200 --> 00:01:29,560
最后一种方式就是全复制

37
00:01:29,560 --> 00:01:32,680
把一个矩阵复制到所有的机器

38
00:01:32,680 --> 00:01:35,560
既然我们有各种的切分方式

39
00:01:35,560 --> 00:01:39,360
就会涉及到各种的通讯方式了

40
00:01:41,200 --> 00:01:42,040
提到通讯方式

41
00:01:42,040 --> 00:01:45,400
大家可以看一下我之前分享的一个内容

42
00:01:45,400 --> 00:01:46,800
就是我们的通讯原理

43
00:01:46,800 --> 00:01:47,720
不是

44
00:01:47,720 --> 00:01:49,520
是通信原理

45
00:01:50,240 --> 00:01:53,280
其实刚才讲的各种的切分方式

46
00:01:53,280 --> 00:01:54,760
可以互相转换的

47
00:01:54,760 --> 00:01:58,120
可以通过Slits、Orget、Or2Or

48
00:01:58,120 --> 00:02:00,320
不同的方式进行切换

49
00:02:00,320 --> 00:02:02,040
同样我有4台4倍

50
00:02:02,040 --> 00:02:05,520
刚才的几种方式也可以通过Orget、OrReduce

51
00:02:05,520 --> 00:02:08,880
还有Slits、Or2Or这几种切分方式

52
00:02:08,880 --> 00:02:10,880
进行互相转化的

53
00:02:12,080 --> 00:02:13,600
讲这个有什么用呢

54
00:02:13,600 --> 00:02:16,240
是因为在整个神经网络模型里面

55
00:02:16,240 --> 00:02:19,680
我们会大量的去用到这些内容

56
00:02:20,680 --> 00:02:24,240
假设现在我引入了一个新的概念

57
00:02:24,240 --> 00:02:25,920
叫做张量重排

58
00:02:25,920 --> 00:02:28,720
Tensor with Distribution

59
00:02:28,720 --> 00:02:30,800
现在我们举一个简单的例子

60
00:02:30,800 --> 00:02:32,880
假设我现在有两个计算

61
00:02:32,880 --> 00:02:34,880
一个X乘以A等于Y

62
00:02:34,880 --> 00:02:37,120
第二个是我把Y作为输入

63
00:02:37,120 --> 00:02:38,840
Y乘以B等于J

64
00:02:38,840 --> 00:02:43,120
有点像我们刚才Transformer的MLP层

65
00:02:43,120 --> 00:02:45,120
在我们的网络模型里面

66
00:02:45,120 --> 00:02:47,920
我的X的输入其实已经切分了4半

67
00:02:47,920 --> 00:02:49,240
有X1234

68
00:02:49,240 --> 00:02:52,120
而我的权重A还是只有一份

69
00:02:52,120 --> 00:02:55,480
那我得到的就是一个Y1Y2Y3Y4

70
00:02:55,480 --> 00:02:59,960
下一层的网络模型只接受一个Y的输

71
00:02:59,960 --> 00:03:03,400
那我就需要对不同的设备的Y做一个Orget

72
00:03:03,400 --> 00:03:06,200
就把张量进行重新排列

73
00:03:06,200 --> 00:03:07,800
得到一个新的张量

74
00:03:07,800 --> 00:03:09,320
然后再进行计算的

75
00:03:09,320 --> 00:03:12,320
这个时候我的B已经按照列的方式切换好了

76
00:03:12,320 --> 00:03:15,360
Y1乘以B1最后得到我的J1234

77
00:03:15,360 --> 00:03:18,840
那中间的这个过程我们叫做张量重排

78
00:03:19,040 --> 00:03:21,280
我们再来看看另外一个概念

79
00:03:22,040 --> 00:03:24,000
假设我的计算公式还是一模一样的

80
00:03:24,000 --> 00:03:25,880
X乘以A等于Y

81
00:03:25,880 --> 00:03:28,240
那Y作为我们的J的输入

82
00:03:28,240 --> 00:03:30,080
Y乘以B等于J

83
00:03:31,120 --> 00:03:34,520
上一层网络模型传给我们的数据

84
00:03:34,520 --> 00:03:37,440
就不是X每一个进行切分

85
00:03:37,440 --> 00:03:39,680
而是X进行行切分

86
00:03:39,680 --> 00:03:41,240
A进行列切分

87
00:03:41,240 --> 00:03:43,000
所以Devices1是X1

88
00:03:43,000 --> 00:03:44,680
Devices2还是X1

89
00:03:44,680 --> 00:03:46,840
Devices3是X2

90
00:03:46,840 --> 00:03:48,000
而A呢

91
00:03:48,000 --> 00:03:49,680
Devices1是A1

92
00:03:49,680 --> 00:03:51,560
Devices2是A2

93
00:03:51,560 --> 00:03:55,040
那这个时候我的计算模型就不一样了

94
00:03:55,040 --> 00:03:58,600
中间这时候就不需要一个all get的方式

95
00:03:58,600 --> 00:04:00,320
把所有的Y进行聚合

96
00:04:00,320 --> 00:04:02,360
因为Y需不需要聚合

97
00:04:02,360 --> 00:04:04,720
取决于我们后面的计算

98
00:04:04,720 --> 00:04:08,360
那后面的B我是按照行进行切分的

99
00:04:08,360 --> 00:04:11,400
我按照行进行切分到不同的机器进行复制

100
00:04:11,400 --> 00:04:13,000
最后再进行计算

101
00:04:13,000 --> 00:04:16,200
那我期望得到的是J1J2

102
00:04:16,240 --> 00:04:17,400
Y成隐蔽之后

103
00:04:17,400 --> 00:04:19,440
需要做一个all reduce的操作

104
00:04:19,440 --> 00:04:22,280
然后聚合得到我的J1

105
00:04:22,280 --> 00:04:26,640
同理这个Y进行all reduce操作得到我的J2

106
00:04:26,640 --> 00:04:29,560
这种操作也作为我们张亮重排的

107
00:04:29,560 --> 00:04:31,520
其中一种特殊的形态

108
00:04:31,520 --> 00:04:33,120
这么做有什么好处呢

109
00:04:34,680 --> 00:04:37,360
张亮重排其实是一个很复杂的工程

110
00:04:37,360 --> 00:04:40,400
我需要知道很多种不同的排列方式

111
00:04:40,400 --> 00:04:44,240
然后为系统找到一种最优的执行效率

112
00:04:44,280 --> 00:04:46,200
所以MindSpot AI框架

113
00:04:46,200 --> 00:04:49,000
就发明了一个张亮切片的一个策略

114
00:04:49,000 --> 00:04:51,920
就是利用刚才张亮重排的一个原理

115
00:04:51,920 --> 00:04:55,120
那可能里面算法分为四部分

116
00:04:55,120 --> 00:04:58,360
第一步就是拿到网络模型定义的脚本

117
00:04:58,360 --> 00:05:00,840
通过圆码转换得到我们的计算图

118
00:05:00,840 --> 00:05:04,640
第二步就是对每一个算子

119
00:05:04,640 --> 00:05:07,560
去每举它可能的切分方式

120
00:05:07,560 --> 00:05:10,920
假设VidLun有很多种不同的切分方式

121
00:05:10,920 --> 00:05:11,880
有按行切分

122
00:05:11,880 --> 00:05:13,520
有按列切分

123
00:05:13,520 --> 00:05:16,760
假设是VidLun它有按行的第八行进行切分

124
00:05:16,760 --> 00:05:18,680
它有按第四行进行切分

125
00:05:18,680 --> 00:05:20,280
也有按第四列进行切分

126
00:05:20,280 --> 00:05:21,880
或者第八列进行切分

127
00:05:21,880 --> 00:05:23,400
切分的策略非常多

128
00:05:23,400 --> 00:05:25,240
会进行一个每举

129
00:05:25,240 --> 00:05:28,520
第三步系统就会去每举我们计算图里面

130
00:05:28,520 --> 00:05:32,480
每一条边经过张亮重排之后的具体的策略

131
00:05:32,480 --> 00:05:34,480
还有相对应的代价

132
00:05:34,480 --> 00:05:37,280
那这个我们叫做Cost代价函数

133
00:05:37,280 --> 00:05:41,080
第四步就是通过突优化或者动态规划的方法

134
00:05:41,120 --> 00:05:43,800
去求解最优的代价函数

135
00:05:43,800 --> 00:05:45,480
就是最优的Cost函数

136
00:05:46,360 --> 00:05:49,840
到最后一步就是把刚才求得到的一个策略

137
00:05:49,840 --> 00:05:51,320
从算子进行出发

138
00:05:51,320 --> 00:05:53,120
传播到整个网络

139
00:05:53,120 --> 00:05:54,720
然后去进行运算

140
00:05:56,320 --> 00:05:57,920
今天的内容稍微多了一点

141
00:05:57,920 --> 00:05:58,880
我们来总结一下

142
00:05:58,880 --> 00:06:01,800
我们还了解了MindSpot张亮自动并行的

143
00:06:01,800 --> 00:06:03,000
具体的策略原理

144
00:06:03,000 --> 00:06:04,880
卷的不行

145
00:06:04,880 --> 00:06:06,680
记得一键三连加关注

146
00:06:06,680 --> 00:06:09,880
所有的内容都会开源在下面这条链接里面

147
00:06:09,880 --> 00:06:11,280
拜拜了 拜拜

