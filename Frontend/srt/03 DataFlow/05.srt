1
00:00:00,000 --> 00:00:02,000
哈喽大家好,我是钟咪

2
00:00:02,000 --> 00:00:04,000
昨天录的太晚

3
00:00:04,000 --> 00:00:06,000
所以今天上班的时候

4
00:00:06,000 --> 00:00:08,000
经常在摸鱼

5
00:00:10,000 --> 00:00:11,000
废话不多说了

6
00:00:11,000 --> 00:00:13,000
我们来看看今天一个很重要的内容

7
00:00:13,000 --> 00:00:15,000
也是我觉得计算图里面

8
00:00:15,000 --> 00:00:17,000
除了自动微分之外

9
00:00:17,000 --> 00:00:19,000
第二个最重要的内容了

10
00:00:19,000 --> 00:00:21,000
就是我们的控制流

11
00:00:22,000 --> 00:00:23,000
那控制流里面

12
00:00:23,000 --> 00:00:25,000
我们今天主要是讲几个概念

13
00:00:25,000 --> 00:00:27,000
第一个就是我们的控制流

14
00:00:27,000 --> 00:00:29,000
第二个就是我们的控制流

15
00:00:29,000 --> 00:00:31,000
我们今天主要是讲几个概念

16
00:00:31,000 --> 00:00:33,000
第一个去看看什么是控制流

17
00:00:33,000 --> 00:00:35,000
控制流跟计算图是怎么表示的

18
00:00:35,000 --> 00:00:37,000
还有它们之间的关系

19
00:00:37,000 --> 00:00:39,000
接着去讲讲动态图

20
00:00:39,000 --> 00:00:41,000
引起的控制流的问题

21
00:00:41,000 --> 00:00:43,000
还有静态图跟控制流的关系

22
00:00:43,000 --> 00:00:45,000
最后我们看看

23
00:00:45,000 --> 00:00:47,000
现在我们经常去讲

24
00:00:47,000 --> 00:00:49,000
TensorFu也好,Pytorch也好

25
00:00:49,000 --> 00:00:51,000
都会做一些动静统一的结合和技术

26
00:00:51,000 --> 00:00:53,000
它到底是个什么样子的

27
00:00:53,000 --> 00:00:56,000
其实深度学习它是一个可编程的系统

28
00:00:56,000 --> 00:00:58,000
或者叫做可编程的框架

29
00:00:58,000 --> 00:01:00,000
这个框架在设计的时候

30
00:01:00,000 --> 00:01:04,000
首先第一个就是希望能够让前端用户

31
00:01:04,000 --> 00:01:07,000
能够独立于后面的芯片使能

32
00:01:07,000 --> 00:01:09,000
让前端的用户不用感知

33
00:01:09,000 --> 00:01:11,000
底层的硬件的实现的细节

34
00:01:11,000 --> 00:01:15,000
然后用更贴近于神经网络的方式

35
00:01:15,000 --> 00:01:17,000
去实现他们想要的算法和任务

36
00:01:17,000 --> 00:01:19,000
然后用更贴近于神经网络的方式

37
00:01:19,000 --> 00:01:21,000
去实现他们想要的算法和任务

38
00:01:21,000 --> 00:01:23,000
为了解决这个问题

39
00:01:23,000 --> 00:01:26,000
AI框架子里面就提出了一个统一的表示

40
00:01:26,000 --> 00:01:28,000
我们叫做计算图

41
00:01:28,000 --> 00:01:30,000
通过这个统一的描述

42
00:01:30,000 --> 00:01:32,000
可以帮助前端的用户

43
00:01:32,000 --> 00:01:36,000
在编程的时候更加灵活的去编写它的算法

44
00:01:36,000 --> 00:01:40,000
这个计算图也影响了后面的优化的方式

45
00:01:40,000 --> 00:01:42,000
还有整个系统如何进行扩展

46
00:01:42,000 --> 00:01:45,000
都是将神经网络的计算抽象成为一个

47
00:01:45,000 --> 00:01:48,000
由基本言语构成的有相无环图

48
00:01:48,000 --> 00:01:50,000
也就是这个计算图

49
00:01:50,000 --> 00:01:53,000
相无环图也就是叫做我们的DAG图

50
00:01:53,000 --> 00:01:56,000
不过呢,随着深度学习网络的研究的发展

51
00:01:56,000 --> 00:01:59,000
特别是这几年呈现紧盼式的发展

52
00:01:59,000 --> 00:02:02,000
我们迎来了INNLSTM的结构之后

53
00:02:02,000 --> 00:02:04,000
又迎来了Transformer

54
00:02:04,000 --> 00:02:08,000
甚至最近的还有GanttDiffusion这种网络模型

55
00:02:08,000 --> 00:02:10,000
出现这些网络模型

56
00:02:10,000 --> 00:02:13,000
就对AI框架引起了更大的挑战

57
00:02:13,000 --> 00:02:17,000
下面这段代码就是我从Hungerface里面去摘取的

58
00:02:17,000 --> 00:02:22,000
一个Decision Transformer里面的其中关于Transformer的一个结构

59
00:02:22,000 --> 00:02:25,000
我们可以看到Transformer里面的一个结构

60
00:02:25,000 --> 00:02:28,000
在Fuller的阶段它有一个If Else

61
00:02:28,000 --> 00:02:30,000
然后还有一个If

62
00:02:30,000 --> 00:02:34,000
这一些If Else While都是我们动态的一个控制流

63
00:02:34,000 --> 00:02:38,000
另外的话,在对Transformer进行堆叠的时候

64
00:02:38,000 --> 00:02:40,000
又引入了大量的Full循环

65
00:02:40,000 --> 00:02:44,000
这个时候就对我们的系统提出了非常大的挑战

66
00:02:44,000 --> 00:02:47,000
怎么样去更好地支持我们的

67
00:02:47,000 --> 00:02:50,000
这个时候对我们的AI框架和AI系统

68
00:02:50,000 --> 00:02:52,000
就提出了比较大的一个挑战

69
00:02:52,000 --> 00:02:56,000
怎么样去支持这些动态的控制流语句

70
00:02:58,000 --> 00:03:01,000
AI框架为了更好地支持这些

71
00:03:01,000 --> 00:03:04,000
天生就含有控制流语句的神经网络模型

72
00:03:04,000 --> 00:03:08,000
于是就会不约而同的去对动态控制流

73
00:03:08,000 --> 00:03:11,000
引入了新的语言结构的支持

74
00:03:11,000 --> 00:03:14,000
现在在控制流的解决方案里面

75
00:03:14,000 --> 00:03:17,000
好几个框架其实都有自己的一套解决方案

76
00:03:17,000 --> 00:03:20,000
我们来看看现在主流的三种解决方案

77
00:03:20,000 --> 00:03:22,000
虽然现在的AI框架很多

78
00:03:22,000 --> 00:03:24,000
但是主要是集中这三种

79
00:03:24,000 --> 00:03:30,000
首先第一种就是后端对控制流语句进行原生的支持

80
00:03:30,000 --> 00:03:33,000
也就是支持控制流原生的算子和原语

81
00:03:33,000 --> 00:03:36,000
然后允许在计算图里面

82
00:03:36,000 --> 00:03:39,000
去有一些控制流或者数据流进行混合

83
00:03:39,000 --> 00:03:43,000
这种方式最典型的代表就是Tensor Flow

84
00:03:43,000 --> 00:03:46,000
第二种就是附用前端语言的控制流语句

85
00:03:46,000 --> 00:03:50,000
也就是我直接附用Python的控制流语句

86
00:03:50,000 --> 00:03:54,000
然后通过Python的语言去驱动后端的数据流图的执行

87
00:03:54,000 --> 00:03:57,000
这种最典型的方式就是PyTorch

88
00:03:57,000 --> 00:04:00,000
另外第三种就是Mattersport

89
00:04:00,000 --> 00:04:05,000
第三种就是后端对控制流的语言结构进行解析

90
00:04:05,000 --> 00:04:07,000
变成一个子图

91
00:04:07,000 --> 00:04:11,000
也就是通过圆码表示的方式变成一个计算图

92
00:04:11,000 --> 00:04:14,000
这个最典型的代表就是Mattersport

93
00:04:14,000 --> 00:04:19,000
然后PyTorch和Tensor Flow最新的版本也开始慢慢的引入

94
00:04:25,000 --> 00:04:27,000
下面我们来打开看看第一种方式

95
00:04:27,000 --> 00:04:29,000
也就是典型的Tensor Flow的方式

96
00:04:29,000 --> 00:04:34,000
它主要是向数据流图中添加一个控制流原语

97
00:04:34,000 --> 00:04:37,000
控制流原语主要是在这一层

98
00:04:37,000 --> 00:04:41,000
然后里面去提供一些底层的控制流原语

99
00:04:41,000 --> 00:04:47,000
Enter, Switch, Exist, Merge, Next, Iterator一共是五个

100
00:04:47,000 --> 00:04:50,000
这种方式我们来看看它的特点

101
00:04:50,000 --> 00:04:52,000
我们先看完特点再解析那个图

102
00:04:52,000 --> 00:04:58,000
这种方式主要是采用商名式的编程去获得一个计算图

103
00:04:58,000 --> 00:05:02,000
在编译阶段对整个计算图进行全局的优化

104
00:05:02,000 --> 00:05:06,000
第二种它执行的时候就不需要在前端语言就是Python

105
00:05:06,000 --> 00:05:10,000
还有后端的OneTime的时候反复的切换

106
00:05:10,000 --> 00:05:13,000
这个时候就可以有更高的执行效率

107
00:05:13,000 --> 00:05:16,000
把整个图都央到OneTime去执行

108
00:05:16,000 --> 00:05:20,000
这种方式就是控制流原语提供一个控制流原语

109
00:05:20,000 --> 00:05:25,000
把控制流原语作为语言的第一特性然后去执行的

110
00:05:25,000 --> 00:05:28,000
我们现在来看看下面的这个图

111
00:05:28,000 --> 00:05:30,000
首先我从上往下看

112
00:05:30,000 --> 00:05:33,000
上面就是计算图的API

113
00:05:33,000 --> 00:05:35,000
也就是Tensor4的一些API

114
00:05:35,000 --> 00:05:39,000
Tensor4最基础的提供了TF-VialLoop

115
00:05:39,000 --> 00:05:41,000
还有TF-Condition或COMD

116
00:05:41,000 --> 00:05:44,000
这两个操作VialLoop就是Fall循环

117
00:05:44,000 --> 00:05:46,000
Condition就是if else这种方式

118
00:05:46,000 --> 00:05:51,000
Tensor4发现这种方式可能用的不太好用

119
00:05:51,000 --> 00:05:54,000
于是它又提供了高层次的API

120
00:05:54,000 --> 00:05:57,000
TF-MAP, FN, TF-CUST

121
00:05:57,000 --> 00:05:58,000
这两种方式

122
00:05:58,000 --> 00:06:02,000
但是TF出了名就是难用就是不好用

123
00:06:02,000 --> 00:06:04,000
谷歌为了解决这个问题

124
00:06:04,000 --> 00:06:08,000
然后又推出了另外一个更高级的API

125
00:06:08,000 --> 00:06:11,000
这个API就是叫做autograph

126
00:06:11,000 --> 00:06:16,000
通过Python控制流原码转换为一个最基本的控制流API

127
00:06:16,000 --> 00:06:19,000
也就是通过刚才说的第三种方式

128
00:06:19,000 --> 00:06:21,000
原码转换的方式

129
00:06:21,000 --> 00:06:24,000
把它变成TF-VialLoop和TF-Condition

130
00:06:24,000 --> 00:06:27,000
就是在里面自己写了些模板

131
00:06:27,000 --> 00:06:29,000
然后把这些模板套上来

132
00:06:29,000 --> 00:06:31,000
就是这么简单的一个工作

133
00:06:31,000 --> 00:06:33,000
它其实只是做了一个转换

134
00:06:33,000 --> 00:06:35,000
我们再往下层看一看

135
00:06:35,000 --> 00:06:37,000
刚才我们讲了

136
00:06:37,000 --> 00:06:41,000
计算图原语在Tensor4里面就提供了几种原语

137
00:06:41,000 --> 00:06:45,000
这几种原语就是去组成TF-VialLoop和TF-Condition的

138
00:06:45,000 --> 00:06:48,000
就是把这几个简单的组合

139
00:06:48,000 --> 00:06:51,000
再往下就是图并优化层了

140
00:06:51,000 --> 00:06:55,000
对上面使用底层控制流语句构建好的图进行一些编译优化

141
00:06:55,000 --> 00:07:00,000
那图优化能看到的其实更多的是底层的一个控制流语句

142
00:07:00,000 --> 00:07:01,000
因为在做转换的时候

143
00:07:01,000 --> 00:07:04,000
它已经一步步的变成这个图了

144
00:07:07,000 --> 00:07:09,000
下面就是举一个简单的例子

145
00:07:09,000 --> 00:07:12,000
看一下Tensor4里面具体是怎么实现的

146
00:07:12,000 --> 00:07:14,000
首先我们有一个例子

147
00:07:14,000 --> 00:07:18,000
就是两个嵌套循环的4,4i等于0

148
00:07:18,000 --> 00:07:19,000
然后叠代到10

149
00:07:19,000 --> 00:07:20,000
然后不断的去叠加

150
00:07:20,000 --> 00:07:23,000
那中间的某个计算我们就不展示出来了

151
00:07:23,000 --> 00:07:25,000
在Tensor4 2.0里面

152
00:07:25,000 --> 00:07:28,000
它的使用方式其实是比较头痛的

153
00:07:28,000 --> 00:07:31,000
最后调用VialLoop就两个4

154
00:07:31,000 --> 00:07:35,000
把ABCY存起来就两个4嵌套循环

155
00:07:36,000 --> 00:07:38,000
上层的表达就是这样的

156
00:07:38,000 --> 00:07:42,000
但是底层怎么去记录怎么去实现呢

157
00:07:42,000 --> 00:07:46,000
首先在Tensor4里面有一个叫做执行增

158
00:07:46,000 --> 00:07:47,000
Execution Firm

159
00:07:47,000 --> 00:07:52,000
这个执行增具有全局唯一的名字作为标识符

160
00:07:52,000 --> 00:07:56,000
我们可以把它作为一个御或者Scope一个方式

161
00:07:56,000 --> 00:07:59,000
然后下面就有很多key和value

162
00:07:59,000 --> 00:08:01,000
就有一些字典的方式

163
00:08:01,000 --> 00:08:05,000
字典存的就是算子还有算子对应的上下文

164
00:08:05,000 --> 00:08:07,000
包括它的输入数据的地址

165
00:08:07,000 --> 00:08:09,000
输出数据的地址

166
00:08:09,000 --> 00:08:10,000
算子的属性

167
00:08:10,000 --> 00:08:13,000
然后我们下面嵌套4的时候怎么办呢

168
00:08:13,000 --> 00:08:15,000
再嵌套一个执行增

169
00:08:15,000 --> 00:08:18,000
为的就是并发的时候可以利用这些记录的工作

170
00:08:18,000 --> 00:08:20,000
或者执行增的这个Scope

171
00:08:20,000 --> 00:08:22,000
然后进行一些并发的计算

172
00:08:22,000 --> 00:08:26,000
那这个就是Tensor4在底层去执行的一个方式

173
00:08:26,000 --> 00:08:30,000
现在我们来看一下Tensor4比较特别的

174
00:08:30,000 --> 00:08:33,000
它其实在一个condition语句里面

175
00:08:33,000 --> 00:08:37,000
就是if else里面用的是两个原语进行组合的

176
00:08:37,000 --> 00:08:39,000
那第一个原语就是switch

177
00:08:39,000 --> 00:08:41,000
第二个原语就是merge

178
00:08:41,000 --> 00:08:44,000
通过switch和merge不断的组合

179
00:08:44,000 --> 00:08:46,000
然后变成这么一条表达式

180
00:08:46,000 --> 00:08:48,000
那可能第一个就是判断

181
00:08:48,000 --> 00:08:50,000
然后第二个就是能不能打执行

182
00:08:50,000 --> 00:08:54,000
可以看到直接用Tensor4的condition这个API

183
00:08:54,000 --> 00:08:56,000
其实是很难去理解

184
00:08:56,000 --> 00:08:59,000
或者非常不方便我们去写代码的

185
00:08:59,000 --> 00:09:00,000
不过没关系

186
00:09:00,000 --> 00:09:01,000
我们继续往下看一看

187
00:09:01,000 --> 00:09:04,000
更复杂的一个操作就是wild loop

188
00:09:04,000 --> 00:09:05,000
写一个for

189
00:09:05,000 --> 00:09:06,000
写一个for的时候

190
00:09:06,000 --> 00:09:08,000
计算图更加复杂了

191
00:09:08,000 --> 00:09:11,000
右边下面的这个是实际上Tensor4

192
00:09:11,000 --> 00:09:14,000
这个AI框架去执行的计算图

193
00:09:14,000 --> 00:09:17,000
用户用的是wild loop这个API

194
00:09:17,000 --> 00:09:22,000
这时候Tensor4就把五个控制流的原语

195
00:09:22,000 --> 00:09:24,000
进行一个组装拼合

196
00:09:24,000 --> 00:09:26,000
所以它用起来也是让我比较头痛的

197
00:09:26,000 --> 00:09:28,000
那我们现在来看看

198
00:09:28,000 --> 00:09:30,000
像Tensor4这种方式

199
00:09:30,000 --> 00:09:31,000
就是提供控制流原语

200
00:09:31,000 --> 00:09:33,000
它有什么优缺点

201
00:09:33,000 --> 00:09:35,000
我们先来聊聊缺点

202
00:09:35,000 --> 00:09:37,000
因为缺点实在是太明显了

203
00:09:37,000 --> 00:09:39,000
就是它的控制流语句

204
00:09:39,000 --> 00:09:41,000
首先是服务它的运行时的

205
00:09:41,000 --> 00:09:43,000
就是为了在它的系统

206
00:09:43,000 --> 00:09:45,000
能够更好的去执行并发

207
00:09:45,000 --> 00:09:49,000
所以它设计了一套这种控制流原语

208
00:09:49,000 --> 00:09:50,000
有一个比较大的问题就是

209
00:09:50,000 --> 00:09:53,000
它跟深度学习的概念差异非常大

210
00:09:53,000 --> 00:09:55,000
我要重新的去学习一套

211
00:09:55,000 --> 00:09:57,000
它的API是怎么做的

212
00:09:57,000 --> 00:09:59,000
因为它的用户是用户

213
00:09:59,000 --> 00:10:01,000
第二个问题就是

214
00:10:01,000 --> 00:10:03,000
它对控制流原语进行再次封装

215
00:10:03,000 --> 00:10:05,000
那控制流的API的方式

216
00:10:05,000 --> 00:10:07,000
是提供给用户使用的

217
00:10:07,000 --> 00:10:09,000
导致我的计算图很复杂

218
00:10:09,000 --> 00:10:11,000
说白了就是用户看的是

219
00:10:11,000 --> 00:10:13,000
TF-VIO-LOOP,TF-Condition

220
00:10:13,000 --> 00:10:15,000
实际上计算机执行的是

221
00:10:15,000 --> 00:10:17,000
这么复杂的一个计算图

222
00:10:17,000 --> 00:10:19,000
这个计算图你让我看真不好看

223
00:10:19,000 --> 00:10:21,000
假设它FORNATION

224
00:10:21,000 --> 00:10:23,000
是用户的计算图

225
00:10:23,000 --> 00:10:25,000
那么它是用户的计算图

226
00:10:25,000 --> 00:10:27,000
那么它是用户的计算图

227
00:10:27,000 --> 00:10:29,000
这个计算图真的看真不好看

228
00:10:29,000 --> 00:10:31,000
假设它FORNATION里面再嵌套一个IF ELSE VIO

229
00:10:31,000 --> 00:10:33,000
IF ELSE VIO又嵌套一个FORNATION

230
00:10:33,000 --> 00:10:37,000
这个时候计算图真的没法看了

231
00:10:41,000 --> 00:10:43,000
那优点就是

232
00:10:43,000 --> 00:10:45,000
像计算图里面引入控制流原语

233
00:10:45,000 --> 00:10:47,000
非常方便编译期间

234
00:10:47,000 --> 00:10:49,000
挖掘运行时的效率

235
00:10:49,000 --> 00:10:51,000
也就是集字的性能

236
00:10:51,000 --> 00:10:53,000
第二个就是

237
00:10:53,000 --> 00:10:55,000
解有数字语言和执行过程

238
00:10:55,000 --> 00:10:57,000
加速整个运行时

239
00:10:57,000 --> 00:10:59,000
第二点可能跟第一点不一样

240
00:10:59,000 --> 00:11:01,000
就是我们把前端语言表达

241
00:11:01,000 --> 00:11:03,000
跟后端执行

242
00:11:03,000 --> 00:11:05,000
隔离开来

243
00:11:05,000 --> 00:11:07,000
不用反复的去利用宿主的IF ELSE VIO

244
00:11:07,000 --> 00:11:09,000
Pytosh使用的是动态图

245
00:11:09,000 --> 00:11:11,000
它主要是

246
00:11:11,000 --> 00:11:13,000
附用宿主语言的控制流

247
00:11:13,000 --> 00:11:15,000
所谓的宿主语言

248
00:11:15,000 --> 00:11:17,000
就是高级语言

249
00:11:17,000 --> 00:11:19,000
用户用到写API的语言

250
00:11:19,000 --> 00:11:21,000
这里面简单的一个计算图

251
00:11:21,000 --> 00:11:23,000
假设这个是神经网络的图

252
00:11:23,000 --> 00:11:25,000
AI框架在Pytosh里面

253
00:11:25,000 --> 00:11:27,000
就不再维护一个计算图

254
00:11:27,000 --> 00:11:29,000
计算图只是其中一个

255
00:11:29,000 --> 00:11:31,000
方便用户理解的概念

256
00:11:31,000 --> 00:11:33,000
接着我们使用Pytosh

257
00:11:33,000 --> 00:11:35,000
就好像使用Python代码一样

258
00:11:35,000 --> 00:11:37,000
模型记代码

259
00:11:37,000 --> 00:11:39,000
我们写一个网络模型出来

260
00:11:39,000 --> 00:11:41,000
就表示神经网络

261
00:11:41,000 --> 00:11:43,000
接着后端就直接以酷的形式

262
00:11:43,000 --> 00:11:45,000
去执行我们WinDNA

263
00:11:45,000 --> 00:11:47,000
CUDA,OpenCL

264
00:11:47,000 --> 00:11:49,000
还有CAN,像这种

265
00:11:49,000 --> 00:11:51,000
就直接执行里面的语句

266
00:11:51,000 --> 00:11:53,000
但是一旦设计到控制流的时候

267
00:11:53,000 --> 00:11:55,000
就在我们的CPU或者在我们上层

268
00:11:55,000 --> 00:11:57,000
宿主语言,就是我们的Python里面

269
00:11:57,000 --> 00:11:59,000
去执行

270
00:11:59,000 --> 00:12:01,000
这样附用宿主语言控制流的动态图方式

271
00:12:01,000 --> 00:12:03,000
有两个最大的好处

272
00:12:03,000 --> 00:12:05,000
第一个就是用户

273
00:12:05,000 --> 00:12:07,000
能够灵活的使用

274
00:12:07,000 --> 00:12:09,000
前端宿主语言进行表达控制流

275
00:12:09,000 --> 00:12:11,000
就直接使用Python的

276
00:12:11,000 --> 00:12:13,000
If else while for这些

277
00:12:13,000 --> 00:12:15,000
去表达我们的控制流

278
00:12:15,000 --> 00:12:17,000
马上就输出张量的计算求解结果

279
00:12:17,000 --> 00:12:19,000
也就是我写完这个代码之后

280
00:12:19,000 --> 00:12:21,000
我一执行S等于X加Y

281
00:12:21,000 --> 00:12:23,000
马上就输出结果

282
00:12:23,000 --> 00:12:25,000
另外一个好处就是

283
00:12:25,000 --> 00:12:27,000
大家都说PyTorch非常好用

284
00:12:27,000 --> 00:12:29,000
所以它定义神经网络

285
00:12:29,000 --> 00:12:31,000
就像编写真正的程序一样

286
00:12:31,000 --> 00:12:33,000
让开发者更加容易接受

287
00:12:33,000 --> 00:12:35,000
但是问题也很严重

288
00:12:35,000 --> 00:12:37,000
用户很容易

289
00:12:37,000 --> 00:12:39,000
难用前端的语言特性

290
00:12:39,000 --> 00:12:41,000
带来非常复杂的性能问题

291
00:12:41,000 --> 00:12:43,000
也就是你要做PyTorch的性能优化

292
00:12:43,000 --> 00:12:45,000
其实是有很多问题的

293
00:12:45,000 --> 00:12:47,000
第二个就是执行流

294
00:12:47,000 --> 00:12:49,000
第二个就是执行流会在语言的边界来跳转

295
00:12:49,000 --> 00:12:51,000
带来严重的

296
00:12:51,000 --> 00:12:53,000
one time的开销

297
00:12:53,000 --> 00:12:55,000
这个就是代表

298
00:12:55,000 --> 00:12:57,000
我可能语句在Python

299
00:12:57,000 --> 00:12:59,000
在CPU里面去执行

300
00:12:59,000 --> 00:13:01,000
我的后面张量的计算

301
00:13:01,000 --> 00:13:03,000
我在我的NPU、GPU上面去执行

302
00:13:03,000 --> 00:13:05,000
一个在NPU执行

303
00:13:05,000 --> 00:13:07,000
一个在CPU执行

304
00:13:07,000 --> 00:13:09,000
中间就涉及到GPU跟CPU之间的通讯

305
00:13:09,000 --> 00:13:11,000
第三个就是控制流

306
00:13:11,000 --> 00:13:13,000
和数据流隔离在前端

307
00:13:13,000 --> 00:13:15,000
控制流我在前端

308
00:13:15,000 --> 00:13:17,000
控制流大部分都是用Python代码

309
00:13:17,000 --> 00:13:19,000
数据流可能执行的是机器码

310
00:13:19,000 --> 00:13:21,000
这个时候

311
00:13:21,000 --> 00:13:23,000
跨语言的优化是很痛苦的

312
00:13:31,000 --> 00:13:33,000
第三种方式

313
00:13:33,000 --> 00:13:35,000
就是MindSport的一种方式

314
00:13:35,000 --> 00:13:37,000
对Python的原码进行解析

315
00:13:37,000 --> 00:13:39,000
然后变成一个计算图

316
00:13:39,000 --> 00:13:41,000
这个计算图是已经展开的计算图

317
00:13:41,000 --> 00:13:43,000
或者已经展开了

318
00:13:43,000 --> 00:13:45,000
或者已经展开作为子图的

319
00:13:45,000 --> 00:13:47,000
那它里面有两种方式

320
00:13:47,000 --> 00:13:49,000
第一种就是

321
00:13:49,000 --> 00:13:51,000
计算图能够直接表达的

322
00:13:51,000 --> 00:13:53,000
那就直接把它表达出来了

323
00:13:53,000 --> 00:13:55,000
例如FOR循环里面

324
00:13:55,000 --> 00:13:57,000
它直接把它变成一个串型的计算图

325
00:13:57,000 --> 00:13:59,000
例如我FOR两次

326
00:13:59,000 --> 00:14:01,000
那我可能把FOR两次里面的计算子

327
00:14:01,000 --> 00:14:03,000
直接列出来

328
00:14:03,000 --> 00:14:05,000
然后去变成我们的计算图

329
00:14:05,000 --> 00:14:07,000
那第二个

330
00:14:07,000 --> 00:14:09,000
像IF ELSE这种

331
00:14:09,000 --> 00:14:11,000
它可能就会把它变成两个子图

332
00:14:11,000 --> 00:14:13,000
IF里面的一个子图

333
00:14:13,000 --> 00:14:15,000
ELSE里面的又另外一个子图

334
00:14:15,000 --> 00:14:17,000
然后运行的时候

335
00:14:17,000 --> 00:14:19,000
动态的去选择两个子图

336
00:14:19,000 --> 00:14:21,000
进行运算

337
00:14:21,000 --> 00:14:23,000
那优点就是用户

338
00:14:23,000 --> 00:14:25,000
能够得到一定程度自由的

339
00:14:25,000 --> 00:14:27,000
去使用前端数字语言的控制流

340
00:14:27,000 --> 00:14:29,000
也就是用户

341
00:14:29,000 --> 00:14:31,000
可以使用简单的

342
00:14:31,000 --> 00:14:33,000
Python的代码

343
00:14:33,000 --> 00:14:35,000
去写一些控制流

344
00:14:35,000 --> 00:14:37,000
另外一个优点就是

345
00:14:37,000 --> 00:14:39,000
接有了数字语言和执行过程

346
00:14:39,000 --> 00:14:41,000
可以得到一定的效率的提升

347
00:14:41,000 --> 00:14:43,000
第三个就是

348
00:14:43,000 --> 00:14:45,000
我会有一个统一的计算图

349
00:14:45,000 --> 00:14:47,000
能够去做一些性能的优化

350
00:14:47,000 --> 00:14:49,000
看上去一切都很美好

351
00:14:49,000 --> 00:14:51,000
但是

352
00:14:51,000 --> 00:14:53,000
如果硬件不支持我的

353
00:14:53,000 --> 00:14:55,000
这种算子的选择

354
00:14:55,000 --> 00:14:57,000
程序依然会在语言的

355
00:14:57,000 --> 00:14:59,000
边界进行跳转

356
00:14:59,000 --> 00:15:01,000
仍然会有one time的开销

357
00:15:01,000 --> 00:15:03,000
部分Python的控制流的

358
00:15:03,000 --> 00:15:05,000
代码不能够表示有一定的

359
00:15:05,000 --> 00:15:07,000
约束性

360
00:15:07,000 --> 00:15:09,000
谈到它会有一定程度自由的使用

361
00:15:09,000 --> 00:15:11,000
而不是完全自由的

362
00:15:11,000 --> 00:15:13,000
去使用

363
00:15:13,000 --> 00:15:15,000
卷的不行

364
00:15:15,000 --> 00:15:17,000
记得一键三连加关注

365
00:15:17,000 --> 00:15:19,000
所有的内容都会开源在下面这条链接里面

366
00:15:19,000 --> 00:15:21,000
拜了个拜

