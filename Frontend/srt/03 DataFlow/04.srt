1
00:00:00,000 --> 00:00:10,125
哈喽大家晚上好,现在已经12点半了,其实我本来想躺床上然后刷刷抖音就睡了

2
00:00:10,125 --> 00:00:15,000
想想还是不要刷抖音了,录一期吧

3
00:00:15,000 --> 00:00:20,000
今天晚上主要是来讲讲计算图的优化和执行

4
00:00:20,000 --> 00:00:32,000
对计算图的优化主要是编译优化,编译优化的很多概念会留在后面来讲

5
00:00:32,000 --> 00:00:37,000
今天的重点主要是来讲讲计算图的调度和执行

6
00:00:37,000 --> 00:00:44,000
谈到图优化作用第一个概念,看看右边的AI计算框架的这么一个组件图

7
00:00:44,000 --> 00:00:53,000
计算图的出现其实可以允许整个AI框架或者AI系统 能够看到深度学习或者神经网络的全局定义

8
00:00:53,000 --> 00:00:57,400
也就是这个计算图其实是作为高层的AI一个表现

9
00:00:57,400 --> 00:01:02,000
把前端的具体的实现跟下层的优化把它隔绝起来

10
00:01:02,000 --> 00:01:06,000
所以这里面用不同的颜色把它区分下来

11
00:01:06,000 --> 00:01:10,175
实际上计算图的优化这一层是通过编译器去做的

12
00:01:10,175 --> 00:01:15,000
让看一下编译层或者图优化这个层具体做了哪些工作

13
00:01:15,000 --> 00:01:20,575
粉红色的这一层就是编译层或者图优化层

14
00:01:20,575 --> 00:01:26,000
上面的输入是计算图,输出也是一个计算图

15
00:01:26,000 --> 00:01:32,000
区别就在于上面输入的这个计算图是 没有经过优化的用户原始写出来的表达

16
00:01:32,000 --> 00:01:39,000
下面这个图呢,经过图优化层然后去优化过的,里面可能消除了一些部分节点

17
00:01:39,000 --> 00:01:46,000
中间的这些工作了,会在编译优化系列给大家去讲讲 这个编译优化层具体怎么实现的

18
00:01:46,000 --> 00:01:49,000
这里面呢,只是简单的提几个概念

19
00:01:49,000 --> 00:01:53,000
第一个就是常量折叠,就是把一些常量把它合在一起

20
00:01:53,000 --> 00:01:59,000
例如1加1等于2的这些,没有必要在计算的时候执行的时候才去算

21
00:01:59,000 --> 00:02:03,000
而是在编译的过程当中就把它算出来了

22
00:02:03,000 --> 00:02:10,000
第二个就是常量传播,那常量传播可能会跟常量折叠经常混合在一起

23
00:02:10,000 --> 00:02:14,000
还有一些算子融合,把一些小的算子合成一些大算子

24
00:02:14,000 --> 00:02:20,000
那另外呢,针对表达式呢,还有一些表达式的转换表达式的替换

25
00:02:20,000 --> 00:02:26,000
例如X乘以X乘以X,可能直接表示成X的三次方

26
00:02:26,000 --> 00:02:30,000
最后呢,可能还会有一些公共表达式的消除

27
00:02:30,000 --> 00:02:36,000
那这个呢,就是代码层面的,这个是算子层面的,那这些呢,就是图层面的

28
00:02:36,000 --> 00:02:41,000
所以呢,图优化图编译层,会在不同的内容方面去进行优化

29
00:02:41,000 --> 00:02:47,000
下面呢,回到今天的一个主要的内容,就是计算图的调度和执行

30
00:02:47,000 --> 00:02:52,000
公式,还是那条公式,这个呢,就是计算图

31
00:02:52,000 --> 00:02:59,000
然后呢,AI框架呢,会根据计算图的依赖关系,依次去调度将要运行的一些代码

32
00:02:59,000 --> 00:03:03,000
例如我首先执行一个Log,然后执行Mul,然后Sin,Add,Sub

33
00:03:03,000 --> 00:03:06,000
接着呢,再执行一些反向的操作

34
00:03:06,000 --> 00:03:09,000
那执行之前呢,不是直接执行的

35
00:03:09,000 --> 00:03:15,000
通过分析计算图的依赖关系,然后丢到一个算子的执行列表里面

36
00:03:15,000 --> 00:03:22,000
然后呢,NPU或者GPU呢,就会根据算子列表,然后足够的去执行,给出结果

37
00:03:22,000 --> 00:03:26,000
那这个呢,就是最简单的,最原始的调度执行

38
00:03:26,000 --> 00:03:31,000
那这个呢,就是刚才那条公式,万年不变的一条公式的时间走图

39
00:03:31,000 --> 00:03:36,000
首先去执行一个程,然后Log,Sin,加减,接着呢,去执行反向的

40
00:03:36,000 --> 00:03:42,000
那可能反向求完导之后就不一定是这个呀,Sin的反向可能是Cos

41
00:03:42,000 --> 00:03:50,000
那在AI框架的是被调度里面呢,虽然是单算子调度或者单机器调度, 但是呢,也没有这么简单

42
00:03:50,000 --> 00:03:53,000
会去分析算子之间的依赖关系

43
00:03:53,000 --> 00:03:58,000
首先AI框架呢,会去分析算子之间的一个依赖关系

44
00:03:58,000 --> 00:04:02,000
根据数据流图,找到一些独立的算子的节点

45
00:04:02,000 --> 00:04:06,000
要是它独立,例如X1跟S2,其实它们两个算子是独立的

46
00:04:06,000 --> 00:04:08,000
S1可以先算,S2可以后算

47
00:04:08,000 --> 00:04:13,000
如果两者之间没有关系,它们可能就会进入到并发执行的对列

48
00:04:13,000 --> 00:04:18,000
然后呢,机器就会根据这个对列,然后放在不同的现成词里面去执行

49
00:04:18,000 --> 00:04:21,000
这个时候就很好的提高并行效率

50
00:04:21,000 --> 00:04:26,475
因为都知道GPU,NPU其实不仅仅有一个核

51
00:04:26,475 --> 00:04:31,000
而是有很多个计算单元,很多个计算核来去组成的

52
00:04:31,000 --> 00:04:38,000
单单简单的按照最原始的方式,一个一个算子排列,这种调度方式是很慢的

53
00:04:38,000 --> 00:04:45,275
所以有了计算图之后呢,就会对图层进行优化分析

54
00:04:45,275 --> 00:04:48,000
让AI框架执行的更快,让训练更快

55
00:04:51,000 --> 00:04:55,175
假设现在有很多华为昇腾Atlas的设备

56
00:04:55,175 --> 00:05:00,000
这个时候就需要对计算图进行切分,还有多设备执行

57
00:05:00,000 --> 00:05:03,000
可是这么去执行就变得非常复杂了

58
00:05:03,000 --> 00:05:11,100
首先可能会考虑对计算图进行切分,就是会把一个大的网络模型切分成一些小图

59
00:05:11,100 --> 00:05:14,000
然后放在不同的设备上面去执行

60
00:05:14,000 --> 00:05:18,000
每一个设备都有计算图的一部分

61
00:05:18,000 --> 00:05:24,625
既然把计算图进行切分了,那计算图跟计算图之间就需要通讯

62
00:05:24,625 --> 00:05:27,000
需要对数据进行聚合

63
00:05:28,000 --> 00:05:33,050
这个时候就涉及到化是被化指图的一个数据传输

64
00:05:33,050 --> 00:05:38,000
可能数据传输的效率就会是制约整个计算的性能

65
00:05:38,000 --> 00:05:44,000
那为了解决这些问题,可能又会引起了多种的调度和执行的策略

66
00:05:44,000 --> 00:05:48,000
左边的这个图就是GoogleNet Inception这个网络模型

67
00:05:48,000 --> 00:05:53,700
假设我现在有四台Atlas的设备,或者叫做4张卡

68
00:05:53,700 --> 00:06:01,000
4张NPU或者GPU,那可能第一个1x1的卷积会放在这一个设备去执行

69
00:06:01,000 --> 00:06:07,000
第二个3x3的卷积会同步的放在第二个设备执行

70
00:06:07,000 --> 00:06:13,000
同样的后面5x5的卷积还有3x3的卷积都放在不同的设备执行

71
00:06:13,000 --> 00:06:16,875
这个只是最简单的放在不同的设备执行

72
00:06:16,875 --> 00:06:22,000
但是一旦放在不同的设备就会涉及到一个多种的调度模式

73
00:06:22,000 --> 00:06:29,000
这个就是三种调度模式。简单的来讲讲有哪几种,通常肯定是越贪心越好的

74
00:06:29,000 --> 00:06:34,725
最简单的就是我首先虽然有很多种设备,但是我在一个设备上面运行

75
00:06:34,725 --> 00:06:40,000
这个卷积在另外一个设备运行,这个卷积又在另外一个设备运行

76
00:06:40,000 --> 00:06:45,000
这种就是最原始的串型,现在没有人这么傻会这么去串型去做的

77
00:06:45,000 --> 00:06:54,000
如果真的是设计出这种傻逼的操作之后, 像我这样的工程师肯定第一时间被老板炒

78
00:06:54,000 --> 00:06:58,900
那第二个就是并行调度。我第一个卷积在设备1上面去执行

79
00:06:58,900 --> 00:07:04,000
第二个卷积在设备2上面去执行,那我的时间可能是差不多的。  

80
00:07:04,000 --> 00:07:12,900
最后把在不同设备上面去运行的结果concat到一起,最终输出

81
00:07:12,900 --> 00:07:17,000
那这种方式会比第一种方式更优,但肯定希望三种设备所有的都同时开启

82
00:07:17,000 --> 00:07:24,000
那这个时候就可能设计到通讯的等待、通讯的市集,这个就是贪心调度

83
00:07:24,000 --> 00:07:28,275
所以一般来说,涉及到跨图跨设备,那就变得非常复杂

84
00:07:28,275 --> 00:07:37,000
这个会在后面的大规模分布式并行里面去讲讲 具体MindSpore、TensorFlow和PyTorch是怎么实现

85
00:07:37,000 --> 00:07:40,775
那下面来看看具体的一个简单的例子

86
00:07:40,775 --> 00:07:50,000
这个Inception模块就有三个输入到不同的卷积, 最后汇集起来concat到一起,然后给输出的

87
00:07:50,000 --> 00:08:00,000
现在分在两个不同的设备,一个叫做华为Atlas 0, 第二个叫做华为Atlas 1。我又在卖广告了

88
00:08:03,000 --> 00:08:12,000
其实这个视频跟公司没有关系,是我私人的时间去录制的。 现在的时间接近凌晨一点钟

89
00:08:12,000 --> 00:08:19,200
接着来看看数据是怎么切分的。从刚才的Inception图里面可以看到

90
00:08:19,200 --> 00:08:25,000
假设我这么去切分,我可能去把两个卷积放在第一台设备上面去执行

91
00:08:25,000 --> 00:08:29,375
另外两个卷积放在另外一台设备上面去执行

92
00:08:29,375 --> 00:08:34,225
中间我可能会有两个通讯的原语或者通讯的算子

93
00:08:34,225 --> 00:08:43,000
一个是发送的,一个是接收的,最后再concat到其中一台服务器上面去做聚合

94
00:08:43,000 --> 00:08:50,150
这种方式可能会用Send, Reserve这些算子去代替数据传输

95
00:08:50,150 --> 00:08:57,000
也可能直接通过HCCL或者NCCL这种通讯原语或者通讯算子进行一个数据传输

96
00:08:57,000 --> 00:09:02,100
但实际上一旦涉及到夸4倍的通讯就会引起大量的问题

97
00:09:02,100 --> 00:09:07,900
实际上要做好计算图的切分,并且把这些子图映射到多个设备里面

98
00:09:07,900 --> 00:09:11,000
是一个非常复杂的组合优化问题

99
00:09:11,000 --> 00:09:18,100
需要在代价模型里面去找到跨设备通讯消耗时间最短的每个计算单元

100
00:09:18,100 --> 00:09:23,000
然后看一下怎么随着输入输出的大小的变化而变化

101
00:09:23,000 --> 00:09:27,075
最后以数据流依赖作为约束,均衡并行执行

102
00:09:27,075 --> 00:09:33,000
还有数据通信两者之间的关系去找到一个最好的balance。 

103
00:09:33,000 --> 00:09:38,175
这个时候我就需要考虑到我的计算图是怎么切分的

104
00:09:38,175 --> 00:09:43,000
应该怎么切才能够使得我这个组合优化问题效率更高

105
00:09:44,000 --> 00:09:54,000
好了,今天的内容比较简单,主要了解了对于计算图做了 一些编译优化的手段才能使得图执行的更快

106
00:09:54,000 --> 00:09:59,000
这个编译优化手段会在编译体系的系列里面去详细的展开

107
00:09:59,000 --> 00:10:03,200
第二个就是了解了计算图最基础的调度执行模式

108
00:10:03,200 --> 00:10:08,000
也就是单算子的调度模式,还有优化后的端线程的调度模式

109
00:10:08,000 --> 00:10:13,350
最后了解了计算图在多设备上进行图切分和多设备执行, 

110
00:10:13,350 --> 00:10:19,000
这一个的详细展开也会在大规模分布式并行里面去详细的展开

111
00:10:19,000 --> 00:10:22,000
那个内容可能会更有意思

112
00:10:24,000 --> 00:10:26,000
好了,谢谢各位,拜拜

