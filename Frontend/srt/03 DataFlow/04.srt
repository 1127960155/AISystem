1
00:00:00,000 --> 00:00:15,000
哈喽大家晚上好,现在已经12点半了,其实我本来想躺床上然后刷刷抖音就睡了,想想还是不要刷抖音了,我们录一期吧。

2
00:00:15,000 --> 00:00:20,000
今天晚上我们主要是来讲讲计算图的优化和执行。

3
00:00:20,000 --> 00:00:32,000
对计算图的优化主要是编译优化,编译优化的很多概念我们会留在后面来讲。

4
00:00:32,000 --> 00:00:37,000
今天的重点主要是来讲讲计算图的调度和执行。

5
00:00:37,000 --> 00:00:44,000
谈到图优化作用我们第一个概念,我们看看右边的AI计算框架的这么一个组件图。

6
00:00:44,000 --> 00:00:53,000
计算图的出现其实可以允许我们整个AI框架或者AI系统能够看到深度学习或者神经网络的全局定义。

7
00:00:53,000 --> 00:01:02,000
也就是这个计算图其实是作为高层的IR一个表现,把我们的前端的具体的实现跟下层的优化把它隔绝起来。

8
00:01:02,000 --> 00:01:06,000
所以这里面我们用不同的颜色把它区分下来。

9
00:01:06,000 --> 00:01:15,000
实际上计算图的优化这一层是通过编译器去做的,让我们看一下编译层或者图优化这个层具体做了哪些工作。

10
00:01:15,000 --> 00:01:26,000
粉红色的这一层就是我们的编译层或者图优化层,上面的输入是我们的计算图,输出也是一个计算图。

11
00:01:26,000 --> 00:01:32,000
区别就在于上面输入的这个计算图是没有经过优化的用户原始写出来的表达。

12
00:01:32,000 --> 00:01:39,000
下面这个图呢,经过图优化层然后去优化过的,里面可能消除了一些部分节点。

13
00:01:39,000 --> 00:01:46,000
中间的这些工作了,我们会在编译优化系列给大家去讲讲这个编译优化层具体怎么实现的。

14
00:01:46,000 --> 00:01:49,000
这里面呢,只是简单的提几个概念。

15
00:01:49,000 --> 00:01:53,000
第一个就是常量折叠,就是把一些常量把它合在一起。

16
00:01:53,000 --> 00:01:59,000
例如1加1等于2的这些,没有必要在计算的时候执行的时候才去算。

17
00:01:59,000 --> 00:02:03,000
而是在编译的过程当中就把它算出来了。

18
00:02:03,000 --> 00:02:10,000
第二个就是常量传播,那常量传播可能会跟常量折叠经常混合在一起。

19
00:02:10,000 --> 00:02:14,000
还有一些算子融合,把一些小的算子合成一些大算子。

20
00:02:14,000 --> 00:02:20,000
那另外呢,针对表达式呢,我们还有一些表达式的转换表达式的替换。

21
00:02:20,000 --> 00:02:26,000
例如X乘以X乘以X,我们可能直接表示成X的三次方。

22
00:02:26,000 --> 00:02:30,000
最后呢,可能还会有一些公共表达式的消除。

23
00:02:30,000 --> 00:02:36,000
那这个呢,就是代码层面的,这个是算子层面的,那这些呢,就是图层面的。

24
00:02:36,000 --> 00:02:41,000
所以呢,图优化图编译层,我们会在不同的内容方面去进行优化。

25
00:02:41,000 --> 00:02:47,000
下面呢,我们回到今天的一个主要的内容,就是计算图的调度和执行。

26
00:02:47,000 --> 00:02:52,000
公式,还是那条公式,这个呢,就是我们的计算图。

27
00:02:52,000 --> 00:02:59,000
然后呢,AI框架呢,会根据计算图的依赖关系,依次去调度将要运行的一些代码。

28
00:02:59,000 --> 00:03:03,000
例如我首先执行一个Log,然后执行MODE,然后Science,Add,Sub。

29
00:03:03,000 --> 00:03:06,000
接着呢,再执行一些反向的操作。

30
00:03:06,000 --> 00:03:09,000
那执行之前呢,不是直接执行的。

31
00:03:09,000 --> 00:03:15,000
通过分析计算图的依赖关系,然后丢到一个算子的执行列表里面。

32
00:03:15,000 --> 00:03:22,000
然后呢,NPU或者GPU呢,就会根据我们的算子列表,然后足够的去执行,给出结果。

33
00:03:22,000 --> 00:03:26,000
那这个呢,就是最简单的,最原始的调度执行。

34
00:03:26,000 --> 00:03:31,000
那这个呢,就是我们刚才那条公式,万年不变的一条公式的时间走图。

35
00:03:31,000 --> 00:03:36,000
首先去执行一个程,然后Log,Science,加减,接着呢,去执行反向的。

36
00:03:36,000 --> 00:03:42,000
那可能反向切完倒之后就不一定是这个呀,Science的反向可能是Coscience。

37
00:03:42,000 --> 00:03:50,000
那在AI框架的是被调度里面呢,虽然是单算子调度或者单机器调度,但是呢,也没有这么简单。

38
00:03:50,000 --> 00:03:53,000
我们会去分析算子之间的依赖关系。

39
00:03:53,000 --> 00:03:58,000
首先AI框架呢,会去分析算子之间的一个依赖关系。

40
00:03:58,000 --> 00:04:02,000
根据数据流图,找到一些独立的算子的节点。

41
00:04:02,000 --> 00:04:06,000
要是它独立,例如X1跟S2,其实它们两个算子是独立的。

42
00:04:06,000 --> 00:04:08,000
S1可以先算,S2可以后算。

43
00:04:08,000 --> 00:04:13,000
如果两者之间没有关系,它们可能就会进入到并发执行的对列。

44
00:04:13,000 --> 00:04:18,000
然后呢,机器就会根据这个对列,然后放在不同的现成词里面去执行。

45
00:04:18,000 --> 00:04:21,000
这个时候就很好的提高我们的并行效率。

46
00:04:21,000 --> 00:04:31,000
因为我们都知道我们的GPU,NPU其实不仅仅有一个核,而是有很多个计算单元,很多个计算核来去组成的。

47
00:04:31,000 --> 00:04:38,000
单单简单的按照我们最原始的方式,一个一个算子排列,这种调度方式是很慢的。

48
00:04:38,000 --> 00:04:48,000
所以有了计算图之后呢,就会对图层进行优化分析,让我们的AI框架执行的更快,让我们的训练更快。

49
00:04:51,000 --> 00:05:00,000
假设我们现在有很多华为生腾Atlas的设备,这个时候我们就需要对计算图进行切分,还有多设备执行。

50
00:05:00,000 --> 00:05:03,000
可是这么去执行就变得非常复杂了。

51
00:05:03,000 --> 00:05:14,000
首先我们可能会考虑对计算图进行切分,就是我们会把一个大的网络模型切分成一些小图,然后放在不同的设备上面去执行。

52
00:05:14,000 --> 00:05:18,000
每一个设备都有计算图的一部分。

53
00:05:18,000 --> 00:05:27,000
既然我们把计算图进行切分了,那我们计算图跟计算图之间就需要通讯,我们需要对数据进行聚合。

54
00:05:28,000 --> 00:05:38,000
这个时候我们就涉及到化是被化指图的一个数据传输,可能数据传输的效率就会是制约我们整个计算的性能。

55
00:05:38,000 --> 00:05:44,000
那为了解决这些问题,可能又会引起了多种的调度和执行的策略。

56
00:05:44,000 --> 00:05:48,000
左边的这个图就是GoogleNet Inception这个网络模型。

57
00:05:48,000 --> 00:06:01,000
假设我现在有四台Atlas的设备,或者我们叫做4张卡,4张NPU或者GPU,那可能第一个1x1的卷机我们会放在这一个设备去执行。

58
00:06:01,000 --> 00:06:07,000
第二个3x3的卷机我们会同步的放在第二个设备执行。

59
00:06:07,000 --> 00:06:13,000
同样的后面5x5的卷机还有3x3的卷机我们都放在不同的设备执行。

60
00:06:13,000 --> 00:06:22,000
这个只是最简单的放在不同的设备执行,但是一旦放在不同的设备就会涉及到一个多种的调度模式。

61
00:06:22,000 --> 00:06:29,000
这个就是我们三种调度模式。我们简单的来讲讲有哪几种,通常我们肯定是越贪心越好的。

62
00:06:29,000 --> 00:06:40,000
最简单的就是我首先虽然有很多种设备,但是我在一个设备上面运行,这个卷机在另外一个设备运行,这个卷机又在另外一个设备运行。

63
00:06:40,000 --> 00:06:45,000
这种就是最原始的串型,现在没有人这么傻会这么去串型去做的。

64
00:06:45,000 --> 00:06:54,000
如果真的是设计出这种傻逼的操作之后,像我这样的工程师肯定第一时间被老板吵。

65
00:06:54,000 --> 00:07:04,000
那第二个就是并行调度。我第一个卷机在设备1上面去执行,第二个卷机在设备2上面去执行,那我的时间可能是差不多的。

66
00:07:04,000 --> 00:07:17,000
最后我们把在不同设备上面去运行的结果conquer到一起,最终输出。那这种方式会比第一种方式更优,但肯定我们希望三种设备所有的都同时开启。

67
00:07:17,000 --> 00:07:24,000
那这个时候我们就可能设计到通讯的等待、空讯的市集,这个就是我们的贪心调度。

68
00:07:24,000 --> 00:07:37,000
所以一般来说,设计到夸图夸事辈,那就变得非常复杂。这个我们会在后面的大规模分布式并行里面去讲讲具体MindSpot、Tensor4和PyTorch是怎么实现。

69
00:07:37,000 --> 00:07:50,000
那下面我们来看看具体的一个简单的例子。这个Inception模块就有三个输入到不同的卷机,最后汇集起来conquer到一起,然后给输出的。

70
00:07:50,000 --> 00:08:00,000
现在我们分在两个不同的设备,一个叫做华为Atlas 0,第二个叫做华为Atlas 1。我又在卖广告了。

71
00:08:03,000 --> 00:08:12,000
其实这个视频跟公司没有关系,是我私人的时间去录制的。现在的时间接近凌晨一点钟。

72
00:08:12,000 --> 00:08:25,000
接着我们来看看数据是怎么切分的。我们从刚才的Inception图里面可以看到,假设我这么去切分,我可能去把两个卷机放在第一台设备上面去执行。

73
00:08:25,000 --> 00:08:43,000
另外两个卷机放在另外一台设备上面去执行。中间我可能会有两个通讯的原语或者通讯的算子。一个是发送的,一个是接收的,最后再conquer到其中一台服务器上面去做聚合。

74
00:08:43,000 --> 00:08:57,000
这种方式我们可能会用Send, Reserve这些算子去代替我们的数据传输,也可能直接通过HCCL或者NCCL这种通讯原语或者通讯算子进行一个数据传输。

75
00:08:57,000 --> 00:09:11,000
但实际上一旦涉及到夸4倍的通讯就会引起大量的问题。实际上要做好计算图的切分,并且把这些指图映射到多个设备里面,是一个非常复杂的组合优化问题。

76
00:09:11,000 --> 00:09:23,000
我们需要在代价模型里面去找到夸4倍通讯消耗时间最短的每个计算单元,然后看一下怎么随着输入输出的大小的变化而变化。

77
00:09:23,000 --> 00:09:33,000
最后以数据流依赖作为约束,均衡并行执行,还有数据通信两者之间的关系去找到一个最好的balance。

78
00:09:33,000 --> 00:09:43,000
这个时候我就需要考虑到我的计算图是怎么切分的,应该怎么切才能够使得我这个组合优化问题效率更高。

79
00:09:44,000 --> 00:09:54,000
好了,今天的内容比较简单,我们主要了解了对于计算图做了一些编译优化的手段才能使得我们的图执行的更快。

80
00:09:54,000 --> 00:09:59,000
这个编译优化手段我们会在编译体系的信念里面去详细的展开。

81
00:09:59,000 --> 00:10:08,000
第二个就是了解了计算图最基础的调度执行模式,也就是单算子的调度模式,还有优化后的端线程的调度模式。

82
00:10:08,000 --> 00:10:19,000
最后我们了解了计算图在多4倍上进行图切分和多4倍执行,这一个的详细展开我们也会在大规模分布式并行里面去详细的展开。

83
00:10:19,000 --> 00:10:22,000
那个内容可能会更有意思。

84
00:10:24,000 --> 00:10:26,000
好了,谢谢各位,拜拜。

