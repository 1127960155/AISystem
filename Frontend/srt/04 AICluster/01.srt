1
00:00:00,000 --> 00:00:13,760
哈喽大家好,我是中米。今天我们来到一个新的内容,就是分布式集群系列。

2
00:00:13,760 --> 00:00:17,360
我呢也叫它作为分布式训练一个系列。

3
00:00:17,360 --> 00:00:23,520
今天我们来到一个基本的介绍,了解一下分布式训练我们到底讲些啥学些啥。

4
00:00:23,520 --> 00:00:26,480
大家不要觉得分布式很难或者很遥远,

5
00:00:26,640 --> 00:00:31,200
现在我们不管是训练模型也好,基本上都会用到AI集群。

6
00:00:31,200 --> 00:00:42,400
现在最近特别火的就是大模型,有了大模型之后,我们就引入了一个分布式训练,让我们的模型真正的能在集群里面跑起来。

7
00:00:42,400 --> 00:00:48,400
后面我们主要分开三大内容去介绍的,第一个就是分布式集群。

8
00:00:48,400 --> 00:00:55,200
先来看看我们的硬件,我们的集群,我们的通讯,接着我们去看看分布式的大模型算法。

9
00:00:55,440 --> 00:01:00,960
最后我们看一下一些并行的策略,我们分为三大部分去介绍。

10
00:01:00,960 --> 00:01:07,520
接着我们打开一下我们最近的将要介绍的一个系列,就是分布式AI集群。

11
00:01:07,520 --> 00:01:14,480
我们首先会去看看AI集群的服务器的架构,有这么多的服务器,我们就要有一个架构统一的去做管理。

12
00:01:14,480 --> 00:01:25,120
另外我们要去处理同步和异步的并行,另外我们讲一个环同步的算法,让我们的网络模型在我们的AI集群里面真正的跑起来。

13
00:01:25,280 --> 00:01:29,600
接着我们就会去讲讲AI集群里面的软硬件通讯。

14
00:01:29,600 --> 00:01:37,200
首先肯定是软件和硬件怎么去互相通讯的,接着我们实现了软硬件的通讯。

15
00:01:37,200 --> 00:01:43,680
真正通讯的时候,我们会讲到我们通讯的原语,具体是用什么方式去通讯的。

16
00:01:43,680 --> 00:01:51,680
讲完一个集群的内容之后,我们就看看一个比较跟我们贴近的,就是AI框架的分布式的能力。

17
00:01:51,840 --> 00:02:02,080
也就是我们这个AI框架,不管是Math, Ball, PyTorch, TensorFlow也好,它也必须要具备分布式训练的能力,才能够把我们的集群调度起来。

18
00:02:02,080 --> 00:02:10,400
在后面的内容,我们就会介绍大模型算法和分布式并行的一些策略,这些我们留在后面再给大家详细的展开。

19
00:02:11,520 --> 00:02:17,600
现在我们回到分布式训练或者分布式AI集群里面,可以看到,从1950年开始,

20
00:02:17,600 --> 00:02:31,360
研究智能第一次提出到了1980年或者90年代的时候,机器学习是非常火的,直到2010年的时候,深度学习真正的可以落地了,然后也越来越火。

21
00:02:31,360 --> 00:02:42,560
现在发文章你不用深度学习,都感觉效果不如人意,但是自从2020年之后,我们迎来了一个叫做Foundation Model,也就是我们的大模型。

22
00:02:42,960 --> 00:02:50,240
现在谷歌和Facebook还有微软比拼的都是一些大模型,因为大模型的性能确实好很多。

23
00:02:50,240 --> 00:03:03,680
那我们再从另外一个角度来看看,现在我们的网络模型的训练也是模型的参数量越来越大,随着模型参数量越来越大,我们的accuracy就是精度也是越来越高的。

24
00:03:03,680 --> 00:03:13,840
所以说现在有这么多的模型,有这么多的精度,我们训练的就需要从串型到并型,然后从并型再到大规模的集群。

25
00:03:13,840 --> 00:03:24,000
不过这里面的模型的参数量其实还不够大,我们往另外一个图看看,刚才提到的网络模型,它的参数规模大概到这个位置为止。

26
00:03:24,000 --> 00:03:32,000
但是从16年,AFAGO出来之后到20年,特别是20年,这里面我们的大模型就集堆式的爆发了。

27
00:03:32,000 --> 00:03:40,880
我们的大模型可以看到,就一个语言大模型GDP-3使用8张V100的话,训练时长要到36年。

28
00:03:40,880 --> 00:03:43,360
我猴年马月才能训练起来啊。

29
00:03:43,520 --> 00:03:51,840
OpenAI就用了512张V100训练了接近7个月,然后就对外宣布我们的GDP-3终于诞生了。

30
00:03:51,840 --> 00:03:58,080
这个时候我们可以看到GDP-3的效果还是非常好的,它解决了我们的自监督的方法。

31
00:03:58,080 --> 00:04:04,080
而且模型的参数量突破了千亿的规模,还解决了模型碎片化的难题。

32
00:04:04,160 --> 00:04:14,480
但是一方面,有很多人就开始提出质疑了,一味的让模型参数量变大,参数量爆炸式的增长,就真正的是智能了吗?

33
00:04:14,480 --> 00:04:16,960
这是通向智能的一条真正道路吗?

34
00:04:16,960 --> 00:04:29,680
虽然很多人去质疑这个问题,但是现在来看,即确实模型参数量变大确实是通向通用智能的其中一种方式,但它不一定代表真正的智能。

35
00:04:29,840 --> 00:04:35,840
很多这些时候的判断我们要留给后面再做判断,先不要判断的太早。

36
00:04:35,840 --> 00:04:42,640
为了让我们的大模型真正训练起来,其实我们很重要的,就是解决我们的训练耗时的问题。

37
00:04:42,640 --> 00:04:46,880
而训练耗时主要是由三个参数量来决定的。

38
00:04:46,880 --> 00:04:51,280
第一个就是训练的数据规模,数据规模肯定是越大越好的。

39
00:04:51,280 --> 00:04:58,320
另外一个是单部的计算量,单部计算量也是跟我们的网络模型相关的,因为现在的模型量越大,

40
00:04:58,400 --> 00:05:01,360
它单部的计算的时间肯定是越长的。

41
00:05:01,360 --> 00:05:08,880
另外一个就是计算的数率,那计算数率越快,我们总体的耗时肯定也是越快的。

42
00:05:08,880 --> 00:05:17,040
计算数率是一个可变的因素,于是我们现在最重要的目的就是解决我们计算数率的问题。

43
00:05:17,040 --> 00:05:23,920
我们希望这个计算数率越大越好,那计算数率我们又分开三个变量。

44
00:05:24,000 --> 00:05:26,400
那不要着急,我们还是组一个的来看一下。

45
00:05:26,400 --> 00:05:33,120
首先第一个就是单4倍的计算数率,就是每一台4倍或者每一张NPU或者GPU的卡,

46
00:05:33,120 --> 00:05:35,760
制程越高,肯定的数率就越快。

47
00:05:35,760 --> 00:05:41,360
那第二个就是4倍数,4倍数越多,计算数越多,可能训练的越快。

48
00:05:41,360 --> 00:05:50,240
第三个就是4倍的并行效率,我们称的加速比越高,越快越大,那我们整体的计算数率也会提升。

49
00:05:50,320 --> 00:05:56,640
而在这个系列里面,我们围绕的更是4倍数的增加的时候,我们4倍数增加了,

50
00:05:56,640 --> 00:05:59,520
慢慢的多起来了,就变成一个集群了。

51
00:05:59,520 --> 00:06:05,280
有了集群,我们就要去解决服务器的架构问题,我们要去解决通讯TOP的问题,

52
00:06:05,280 --> 00:06:12,800
我们要解决软硬件通讯的问题,我们还要解决AI框架能在这个集群里面去跑的问题。

53
00:06:12,800 --> 00:06:18,240
在这个时候华为就推出了Atlas 900这个AI集群。

54
00:06:18,240 --> 00:06:24,640
这个AI集群其实我们现在在全国有22个地方去布局了,包括西安的AI集群中心,

55
00:06:24,640 --> 00:06:32,560
南昌的员工智能中心,南京的人工智能中心,杭州的员工智能中心都布局了我们Atlas服务器。

56
00:06:32,560 --> 00:06:42,080
后面我们将会去介绍怎么去提高我们的加速比,提高加速比很重要的就是我们要了解机器跟机器之间是怎么通讯的,

57
00:06:42,080 --> 00:06:45,760
机器内部加速卡跟加速卡之间是怎么通讯的。

58
00:06:45,920 --> 00:06:51,440
有了硬件之后,我们就要真正的去看看软件是怎么进行一个集合通讯的。

59
00:06:51,440 --> 00:07:00,400
可以通讯之后,我们现在就要看一个问题,什么东西,用什么东西可以控制我这些通讯呢?肯定是AI框架嘛。

60
00:07:00,400 --> 00:07:04,800
所以在最后一小节里面,我们将会去介绍分布式训练系统,

61
00:07:04,800 --> 00:07:12,000
就是我们的AI框架怎么去控制我们的这些集群,怎么控制我们的通讯源与软硬件进行一个通讯的。

62
00:07:12,080 --> 00:07:16,160
那这个时候我们就会引入了一个分布式的并行架构,

63
00:07:16,160 --> 00:07:20,880
而这个怎么架构呢?其实在我们的AI框架里面已经做好了,

64
00:07:20,880 --> 00:07:23,680
我们只需要去调用,至少要去用就行了。

65
00:07:23,680 --> 00:07:28,320
好吧,时不宜迟,让我们开展我们下一个内容。

66
00:07:28,320 --> 00:07:30,080
谢谢各位,掰了个掰。

