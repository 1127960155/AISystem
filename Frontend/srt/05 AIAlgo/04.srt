1
00:00:00,000 --> 00:00:06,000
嗨大家好

2
00:00:06,000 --> 00:00:10,600
这里是大魔星与分步式训练系列里面的第5节内容

3
00:00:10,600 --> 00:00:12,480
在开始这一节内容之前

4
00:00:12,480 --> 00:00:17,520
我今天下午跟我们公司教练组的刘博去聊

5
00:00:17,520 --> 00:00:20,800
他说我的视频看起来太难太深了

6
00:00:20,800 --> 00:00:23,760
所以他建议我在每一节开始之前

7
00:00:23,760 --> 00:00:26,920
加一些背景知识之后再开始

8
00:00:26,920 --> 00:00:28,880
所以在后面的每一章节里面

9
00:00:28,880 --> 00:00:31,960
我都会简单的去介绍一下背景的知识

10
00:00:31,960 --> 00:00:34,560
上一节课我们讲了通讯的软硬件

11
00:00:34,560 --> 00:00:36,600
还有通讯的具体的实现方式

12
00:00:36,600 --> 00:00:39,280
那这一节我们会讲讲通讯的原语

13
00:00:39,280 --> 00:00:41,600
什么叫做通讯原语吗

14
00:00:41,600 --> 00:00:43,920
在我们分步式训练系统里面

15
00:00:43,920 --> 00:00:46,960
由于我们的网络模型现在越来越大了

16
00:00:46,960 --> 00:00:50,080
大到我们一张卡或者一台服务器已经塞不下了

17
00:00:50,080 --> 00:00:52,880
于是我们会对这个网络模型进行切分

18
00:00:52,880 --> 00:00:56,240
切分完之后可能会放在不同的机器里面

19
00:00:56,640 --> 00:00:57,720
想象一下

20
00:00:57,720 --> 00:01:01,840
当我们的模型大到要切分到非常多的服务器里面

21
00:01:01,840 --> 00:01:05,520
假设我们现在把一个模型切分到五个服务器

22
00:01:05,520 --> 00:01:08,840
每个服务器之间又需要相互通讯

23
00:01:08,840 --> 00:01:13,320
我们把一个大的网络模型切分成很多小的网络模型

24
00:01:13,320 --> 00:01:16,720
每个小的网络模型之间是有相互的依赖的

25
00:01:16,720 --> 00:01:20,880
所以我们就需要跨节点对数据进行同步

26
00:01:20,880 --> 00:01:22,440
既然是一道同步

27
00:01:22,440 --> 00:01:25,200
中间的过程就需要进行通讯

28
00:01:25,200 --> 00:01:26,480
跨节点的通讯

29
00:01:26,480 --> 00:01:27,800
跨网络的通讯

30
00:01:27,800 --> 00:01:29,080
跨卡的通讯

31
00:01:29,080 --> 00:01:30,840
各种通讯的方式不同

32
00:01:30,840 --> 00:01:32,960
就取决于我们的系统

33
00:01:32,960 --> 00:01:36,400
或者我们的网络TOP是怎么样组成的

34
00:01:36,400 --> 00:01:38,480
下面有个简单的例子

35
00:01:38,480 --> 00:01:40,120
就是我们的PyTorch的代码

36
00:01:40,120 --> 00:01:42,480
这里面我训练了一个网络模型

37
00:01:42,480 --> 00:01:44,880
这里面是网络模型的训练过程

38
00:01:44,880 --> 00:01:46,800
我先定义了一个优化器

39
00:01:46,800 --> 00:01:48,320
定义了一个网络模型

40
00:01:48,320 --> 00:01:50,760
接着我迭代十次

41
00:01:50,760 --> 00:01:53,000
每一次迭代在训练反向的时候

42
00:01:53,000 --> 00:01:55,160
我需要对T度进行聚合

43
00:01:55,320 --> 00:01:57,120
在T度进行聚合的时候

44
00:01:57,120 --> 00:01:59,720
是通过AlwaysDue通讯的操作

45
00:01:59,720 --> 00:02:01,400
对数据进行聚合的

46
00:02:02,200 --> 00:02:05,200
AlwaysDue或者数据的操作方式

47
00:02:05,200 --> 00:02:07,360
我们又叫做通讯原语

48
00:02:07,360 --> 00:02:10,760
通讯原语我们叫通讯的Permitive

49
00:02:10,760 --> 00:02:13,600
通讯的原语主要有三种类型

50
00:02:13,600 --> 00:02:14,800
一种是一对多

51
00:02:14,800 --> 00:02:16,080
一种是多对一

52
00:02:16,080 --> 00:02:17,960
另外一种是多对多

53
00:02:17,960 --> 00:02:20,440
下面我们分开来去讲解

54
00:02:20,440 --> 00:02:22,960
这些通讯方式有哪些不一样

55
00:02:23,960 --> 00:02:26,840
首先我们看一下一对多的通讯方式

56
00:02:26,840 --> 00:02:28,280
我们叫做Broadcast

57
00:02:28,280 --> 00:02:30,680
就是我有一台服务器0

58
00:02:30,680 --> 00:02:33,600
服务器0把它自己的一些数据

59
00:02:33,600 --> 00:02:35,520
同步到不同的机器

60
00:02:35,520 --> 00:02:37,040
就是把我这个绿色的框

61
00:02:37,040 --> 00:02:40,440
绿色的数据块同步给另外三台服务器

62
00:02:40,440 --> 00:02:41,640
1 2 3

63
00:02:41,640 --> 00:02:45,160
这个时候我们叫做Broadcast 广播

64
00:02:45,160 --> 00:02:46,760
广播的这种方式

65
00:02:46,760 --> 00:02:50,560
最常用于就是我们的网络模型参数的初始化

66
00:02:50,640 --> 00:02:53,240
下面这个图就是广播的方式

67
00:02:53,240 --> 00:02:55,280
我在NPU里面有A数据

68
00:02:55,280 --> 00:02:56,440
然后我通过广播

69
00:02:56,440 --> 00:03:00,480
使得所有的NPU都具备我A的这份数据

70
00:03:02,000 --> 00:03:05,280
另外一种一对多的方式就是Sketch

71
00:03:05,280 --> 00:03:08,200
假设我零号卡里面现在有四份数据

72
00:03:08,200 --> 00:03:09,920
分别用不同的颜色代表

73
00:03:09,920 --> 00:03:11,600
我需要按照一定的策略

74
00:03:11,600 --> 00:03:15,320
去把这四份数据分发到不同的硬件上面

75
00:03:15,320 --> 00:03:18,800
这个时候我可能零号卡只保留我自己的绿色的数据

76
00:03:18,840 --> 00:03:22,960
把不同的数据每一份都分发到不同的机器上面

77
00:03:22,960 --> 00:03:25,000
这个就是Sketch

78
00:03:25,000 --> 00:03:27,360
下面这个图也是Sketch的一种方式

79
00:03:27,360 --> 00:03:29,000
我现在有一个零号机器

80
00:03:29,000 --> 00:03:31,800
分别有ABCDE

81
00:03:31,800 --> 00:03:33,280
我通过Sketch的操作

82
00:03:33,280 --> 00:03:37,720
让每一块NPU都有自己的一份独立的数据

83
00:03:37,720 --> 00:03:39,240
接着就是多对一

84
00:03:39,240 --> 00:03:43,200
多对一我们更多的称它为聚合的方式

85
00:03:43,200 --> 00:03:45,560
聚合的操作又叫做归约

86
00:03:45,560 --> 00:03:48,040
归约的操作又可以做加减乘除

87
00:03:48,040 --> 00:03:50,280
最大值求最小值

88
00:03:50,280 --> 00:03:52,440
这里面我们以加为例子

89
00:03:52,440 --> 00:03:57,320
现在假设我每款GPU都有一个项量51237842

90
00:03:57,320 --> 00:03:59,600
每款GPU都有自己的独立的数据

91
00:03:59,600 --> 00:04:03,600
我通过ReduceSum把所有GPU的数据都汇集起来

92
00:04:03,600 --> 00:04:05,960
然后进行一个累加的操作

93
00:04:05,960 --> 00:04:09,960
这个就是ReduceSum原语的一个具体的操作方式

94
00:04:09,960 --> 00:04:13,640
假设我每款NPU都有自己的一个数据

95
00:04:13,680 --> 00:04:16,440
最后我通过ReduceSum把所有数据

96
00:04:16,440 --> 00:04:19,520
都汇集到一个NPU上面去进行操作

97
00:04:19,520 --> 00:04:22,160
多对一还有一个叫Gather的操作

98
00:04:22,160 --> 00:04:26,120
Gather的操作我们看上面的这个图就很明确了

99
00:04:26,120 --> 00:04:28,040
我们现在有四个节点

100
00:04:28,040 --> 00:04:30,440
每个节点都有不同的数据

101
00:04:30,440 --> 00:04:33,840
通过Gather的方式就把所有节点的数据

102
00:04:33,840 --> 00:04:36,040
都汇集在一个卡里面

103
00:04:36,040 --> 00:04:38,160
我们现在看看下面的图

104
00:04:38,160 --> 00:04:41,720
每一款NPU都有自己的数据ABCD

105
00:04:41,760 --> 00:04:42,960
通过Gather的操作

106
00:04:42,960 --> 00:04:46,240
所有的数据都汇集到一个卡上面

107
00:04:46,240 --> 00:04:49,160
但是这里面只是做一个汇集的操作

108
00:04:49,160 --> 00:04:51,320
并不进行任何计算

109
00:04:51,320 --> 00:04:53,640
在我们分布式并行的算法里面

110
00:04:53,640 --> 00:04:56,320
经常会用到做排序和搜索

111
00:04:56,320 --> 00:05:00,040
我把所有的NPU上面的数据都汇集到一起

112
00:05:00,040 --> 00:05:02,520
进行个排序和搜索的操作之后

113
00:05:02,520 --> 00:05:05,560
再广播给其他的NPU

114
00:05:05,560 --> 00:05:09,040
下面我来看一下多对多的通讯方式

115
00:05:09,040 --> 00:05:10,960
多对多的通讯方式里面

116
00:05:10,960 --> 00:05:14,160
最简单快最常用的方式就是All Reduced

117
00:05:14,160 --> 00:05:16,160
All Reduced我们以加的为例子

118
00:05:16,160 --> 00:05:17,560
就是All Reduced Sum

119
00:05:17,560 --> 00:05:19,480
上面我们有四个节点

120
00:05:19,480 --> 00:05:21,360
每个节点都有一个向量

121
00:05:21,360 --> 00:05:22,600
通过All Reduced Sum

122
00:05:22,600 --> 00:05:25,640
我们就去把所有的数据累加起来

123
00:05:25,640 --> 00:05:28,080
然后再广播给各个节点

124
00:05:28,080 --> 00:05:30,360
下面这个图可能会更清楚

125
00:05:30,360 --> 00:05:31,760
我们有四个NPU

126
00:05:31,760 --> 00:05:34,440
每块NPU都有自己的独立的数据

127
00:05:34,440 --> 00:05:36,040
通过All Reduced Sum之后

128
00:05:36,040 --> 00:05:39,120
每一款GPU都有四个GPU汇集的数据

129
00:05:41,000 --> 00:05:42,120
在多对多里面

130
00:05:42,120 --> 00:05:43,560
我们还有All Get

131
00:05:43,560 --> 00:05:46,480
假设我们现在有四个节点

132
00:05:46,480 --> 00:05:49,480
每个节点都有自己一份独立的数据

133
00:05:49,480 --> 00:05:50,840
我们通过All Get

134
00:05:50,840 --> 00:05:55,120
把这几分数据都同步到所有的机器上面

135
00:05:55,120 --> 00:05:56,240
All Get的方式

136
00:05:56,240 --> 00:05:58,040
在我们做多环通讯的时候

137
00:05:58,040 --> 00:05:59,440
经常会用到的

138
00:06:01,120 --> 00:06:03,560
另外还有一个Reduced Scatter

139
00:06:03,560 --> 00:06:05,840
Reduced Scatter很有意思

140
00:06:05,840 --> 00:06:07,280
Reduced Scatter的一个操作

141
00:06:07,280 --> 00:06:09,760
我们首先会进行一个Reduced操作

142
00:06:09,760 --> 00:06:12,280
然后再进行一个Scatter的操作

143
00:06:12,280 --> 00:06:15,680
假设我们现在每个节点都有一款数据

144
00:06:15,680 --> 00:06:18,560
我们首先会执行Reduced操作

145
00:06:18,560 --> 00:06:21,120
然后把所有的数据都汇集起来

146
00:06:21,120 --> 00:06:23,040
然后再进行Scatter的切分

147
00:06:24,400 --> 00:06:26,440
看下面这个图就会更加明白

148
00:06:26,440 --> 00:06:29,120
假设我们现在有四款NPU

149
00:06:29,120 --> 00:06:31,880
每款NPU的数据都是相同的

150
00:06:31,880 --> 00:06:33,360
我们Reduced操作

151
00:06:33,360 --> 00:06:37,000
就把四个NPU里面的A的数据进行累加

152
00:06:37,000 --> 00:06:39,480
然后放在我们NPU1里面

153
00:06:39,520 --> 00:06:40,320
然后B呢

154
00:06:40,320 --> 00:06:42,960
我们把所有B的数据进行累加

155
00:06:42,960 --> 00:06:45,280
放在我们第二个NPU上面

156
00:06:45,280 --> 00:06:46,600
以此类推

157
00:06:46,600 --> 00:06:50,240
使得每款NPU都有一个Reduced后的数据

158
00:06:51,480 --> 00:06:53,720
最后就是All to All

159
00:06:53,720 --> 00:06:55,600
假设我们现在有四个节点

160
00:06:55,600 --> 00:06:58,600
我们希望把每个节点里面想要的数据

161
00:06:58,600 --> 00:07:01,360
都汇集到第二个节点上面

162
00:07:01,360 --> 00:07:04,560
那下面我们来看看具体的一个NPU的例子

163
00:07:04,560 --> 00:07:08,560
假设现在每款NPU上面都有一个A的数据

164
00:07:08,560 --> 00:07:10,800
那这个A的数据在进行计算完之后

165
00:07:10,800 --> 00:07:12,520
我们希望进行通讯

166
00:07:12,520 --> 00:07:14,680
都变成一块卡的数据

167
00:07:14,680 --> 00:07:16,760
然后再进行一个剧类处理的

168
00:07:17,560 --> 00:07:19,080
刚才我们已经讲了

169
00:07:19,080 --> 00:07:20,800
1对多,Scatter,Boccus

170
00:07:20,800 --> 00:07:23,360
还有多对1,Gather,Reduce的方式

171
00:07:23,360 --> 00:07:25,000
另外我们还讲了All to All

172
00:07:25,000 --> 00:07:29,120
还有All to All的这种多对多的通讯的方式

173
00:07:29,120 --> 00:07:31,680
具体其实多对多的方式

174
00:07:31,680 --> 00:07:35,360
可以由1对多或者多对1的方式来组成的

175
00:07:35,400 --> 00:07:38,880
我们在后面多维度并行数据并行的时候

176
00:07:38,880 --> 00:07:41,720
就会充分的用到这种通讯的方式

177
00:07:41,720 --> 00:07:43,440
通过不同的通讯方式

178
00:07:43,440 --> 00:07:46,640
去加速我们整个的通讯比

179
00:07:46,640 --> 00:07:48,280
下面以Always Dues为例

180
00:07:48,280 --> 00:07:51,760
Always Dues假设我们的NPU里面有四份数据

181
00:07:51,760 --> 00:07:54,200
每份NPU都有自己独立的数据

182
00:07:54,200 --> 00:07:55,760
我经过Always Dues之后

183
00:07:55,760 --> 00:07:59,080
就把四份数据都进行了一个累加

184
00:07:59,080 --> 00:08:00,960
然后每个卡上面都能得到

185
00:08:00,960 --> 00:08:03,600
上面四块GPU的数据的汇集

186
00:08:03,640 --> 00:08:06,480
我们这个操作其实是等于Vidius Get

187
00:08:06,480 --> 00:08:07,720
再加All Vidius

188
00:08:07,720 --> 00:08:10,000
Vidius Get我们刚才已经讲过了

189
00:08:10,000 --> 00:08:12,840
我们现在NPU里面有各份的数据

190
00:08:12,840 --> 00:08:15,720
Vidius Get就把上面每一款GPU的数据

191
00:08:15,720 --> 00:08:17,720
都汇集到某个地址

192
00:08:17,720 --> 00:08:20,520
第二个块的数据都汇集到第二个卡

193
00:08:20,520 --> 00:08:24,040
把第三块的数据都汇集到第三个卡

194
00:08:24,040 --> 00:08:26,080
最后再加上All Get的方式

195
00:08:26,080 --> 00:08:28,520
All Get的方式就是进行一个广播

196
00:08:28,520 --> 00:08:30,840
这一块的数据广播给其他

197
00:08:30,840 --> 00:08:33,120
把第二块的数据广播给其他

198
00:08:33,120 --> 00:08:35,880
GPU上面相同位置的数据

199
00:08:35,880 --> 00:08:38,640
Vidius Get再加上All Get的操作之后

200
00:08:38,640 --> 00:08:40,760
就等于All Vidius的这种方式了

201
00:08:42,480 --> 00:08:45,520
所以说在分布式训练系统里面

202
00:08:45,520 --> 00:08:49,000
通讯的方式对我们来说是非常重要的

203
00:08:49,000 --> 00:08:50,400
我们需要控制节点

204
00:08:50,400 --> 00:08:52,080
什么时候进行通讯

205
00:08:52,080 --> 00:08:54,040
用什么样的方式通讯

206
00:08:54,040 --> 00:08:57,920
才能更好地利用我们整个系统的性能

207
00:08:57,920 --> 00:09:00,680
让我们的模型训练的越快越好

208
00:09:01,680 --> 00:09:04,120
今天的内容比较简单

209
00:09:04,120 --> 00:09:07,680
我们了解了集合通讯的三种不同的方式

210
00:09:07,680 --> 00:09:10,760
还了解了一对多的主要有Sketter和Boccus

211
00:09:10,760 --> 00:09:11,920
广播的方式

212
00:09:11,920 --> 00:09:15,400
多对一有聚合Geta和Vidius的方式

213
00:09:15,400 --> 00:09:18,600
另外我们还有多对多的集合通讯的方式

214
00:09:18,600 --> 00:09:21,040
最后我们了解了多对多

215
00:09:21,040 --> 00:09:23,800
其实可以由一对多和多对一的组合方式

216
00:09:23,800 --> 00:09:26,000
例如All Vidius就等于Vidius Get

217
00:09:26,000 --> 00:09:28,120
再加上All Get的方式

218
00:09:28,120 --> 00:09:30,240
在这么类绝的环境下

219
00:09:30,240 --> 00:09:32,720
做到经常更新时速不易

220
00:09:32,720 --> 00:09:35,320
非常欢迎大家对我一键三连

221
00:09:35,320 --> 00:09:36,120
谢谢各位

222
00:09:36,120 --> 00:09:37,040
百乐哥 掰

