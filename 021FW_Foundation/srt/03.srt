1
00:00:00,000 --> 00:00:02,000
哈喽大家好

2
00:00:02,000 --> 00:00:04,480
这又是一节没什么人来观看

3
00:00:04,480 --> 00:00:08,000
但是我依然在坚持的AI系列的课程的课里面

4
00:00:08,000 --> 00:00:11,520
今天我想给大家一起去分享一下框架之争

5
00:00:11,520 --> 00:00:14,960
就是现在有很多AI框架出现了

6
00:00:14,960 --> 00:00:18,160
不管它叫做第一代第二代第三代多好

7
00:00:18,160 --> 00:00:22,560
其实我们用户关心的就是现在我有哪些AI框架可以用

8
00:00:24,560 --> 00:00:28,160
我记得在我第一代第二代第三代的课上

9
00:00:28,960 --> 00:00:30,960
我记得在很久之前

10
00:00:30,960 --> 00:00:35,200
应该是16年到18年我刚开始用AI框架的时候

11
00:00:35,200 --> 00:00:38,400
Tensor 4和Pytorch两个非常火

12
00:00:38,400 --> 00:00:41,040
那个时候很多人去问一个问题

13
00:00:41,040 --> 00:00:44,720
我到底是用A框架好呢还是用B框架好呢

14
00:00:44,720 --> 00:00:47,360
然后到18年到19年的时候

15
00:00:47,360 --> 00:00:49,920
很多人就会去争取一个标题

16
00:00:49,920 --> 00:00:52,640
Pytorch超越了Tensor 4了没有呢

17
00:00:52,640 --> 00:00:55,360
到2020年的时候或者去年

18
00:00:55,360 --> 00:00:59,520
Pytorch和Tensor 4各自又发表了一些官方的文章

19
00:00:59,520 --> 00:01:03,680
里面就去澄清Tensor 4依然占据着主流的位置

20
00:01:03,680 --> 00:01:06,240
Pytorch的上升趋势非常大

21
00:01:06,240 --> 00:01:10,080
框架之争这个概念是随着AI这个市场

22
00:01:10,080 --> 00:01:12,400
或者AI规模化越来越大

23
00:01:12,400 --> 00:01:16,160
所以大家都想倡夺类似于操作系统的地位

24
00:01:16,160 --> 00:01:19,440
垄断最底层的AI的核心技术

25
00:01:19,440 --> 00:01:23,040
那今天我想给大家一起去分享一下

26
00:01:23,040 --> 00:01:26,880
关于我对AI框架之争的一些看法和想法

27
00:01:26,880 --> 00:01:28,720
还有一些总结的心得体会

28
00:01:29,760 --> 00:01:33,760
那我们可以看到其实在2010年之前

29
00:01:33,760 --> 00:01:36,240
AI框架那个时候还没有形成

30
00:01:36,240 --> 00:01:38,480
也没有东西叫做AI框架

31
00:01:38,480 --> 00:01:41,680
右边用的更多的是Lumpines,SciencePY

32
00:01:41,680 --> 00:01:42,960
还有的Metalab

33
00:01:42,960 --> 00:01:46,640
注意千万不要忽略Metalab这个里面

34
00:01:46,640 --> 00:01:49,360
会提供一些神经网络的接口

35
00:01:49,360 --> 00:01:52,880
因为最近应该是两个月前

36
00:01:52,880 --> 00:01:56,720
我去西南中央大学去拜访的时候

37
00:01:56,720 --> 00:01:59,200
他们有一个要学智能学院

38
00:01:59,200 --> 00:02:03,360
里面的老师现在的教学还是用Metalab进行教学

39
00:02:03,360 --> 00:02:05,920
因为他们觉得Metalab有给他们提供一个

40
00:02:05,920 --> 00:02:08,240
比较简单的神经网络的系统

41
00:02:08,240 --> 00:02:11,280
他们的课程也有十几年没有更新过了

42
00:02:11,280 --> 00:02:14,960
里面还是用Metalab做一些心电数据的分析

43
00:02:14,960 --> 00:02:18,000
那这个分析的内容还是用神经网络

44
00:02:18,000 --> 00:02:20,320
那时候很早之前已经有神经网络的

45
00:02:20,320 --> 00:02:22,480
只是没有大规模的铺开

46
00:02:22,480 --> 00:02:24,400
所以不要觉得Metalab很low

47
00:02:24,400 --> 00:02:26,800
其实Metalab现在还有很多人来用的

48
00:02:26,800 --> 00:02:29,040
只是随着美国对中国的打压

49
00:02:29,040 --> 00:02:32,080
现在很多国内的高校和科研机构

50
00:02:32,080 --> 00:02:33,600
已经不能使用Metalab了

51
00:02:37,920 --> 00:02:39,760
在2010年之前

52
00:02:39,760 --> 00:02:41,680
那个时候还没有AI框架

53
00:02:41,680 --> 00:02:44,960
机器学习缺乏一些领域的专用库

54
00:02:44,960 --> 00:02:47,920
然后只能提供一些神经网络

55
00:02:47,920 --> 00:02:50,480
能够简单表示的一些接口

56
00:02:50,640 --> 00:02:53,360
那个时候右边的这些库

57
00:02:53,360 --> 00:02:55,360
最重要的特点就是提供一些

58
00:02:55,360 --> 00:02:56,720
脚本式的编程

59
00:02:56,720 --> 00:02:57,920
简单的编程

60
00:02:57,920 --> 00:03:00,880
或者通过像Metalab通过一些简单的配置

61
00:03:00,880 --> 00:03:03,120
形成一些神经网络的接口

62
00:03:03,600 --> 00:03:06,080
优点就是在当时的情况下

63
00:03:06,080 --> 00:03:09,680
AI或者神经网络深度学习还没有起来的时候

64
00:03:09,680 --> 00:03:12,560
提供了一定程度的可编程性

65
00:03:12,560 --> 00:03:14,560
而Metalab还有Lumpi

66
00:03:14,560 --> 00:03:17,440
就提供了关于CPU的计算加速

67
00:03:17,440 --> 00:03:19,600
那个时候或者那个时期

68
00:03:19,600 --> 00:03:22,800
能够有这些库出现还是很不容易的

69
00:03:22,800 --> 00:03:24,880
也是非常具有前瞻性的

70
00:03:24,880 --> 00:03:29,840
其实在2010年之前或者在到AI正式起来之前

71
00:03:29,840 --> 00:03:32,400
我们还有另外一个过渡时期

72
00:03:32,400 --> 00:03:34,960
那个时候以Cafe作为著名的代表

73
00:03:34,960 --> 00:03:36,640
里面就以CNN

74
00:03:36,640 --> 00:03:40,880
因为卷机神经网络或者视觉方面的一个AI

75
00:03:40,880 --> 00:03:42,400
火得非常坏

76
00:03:42,400 --> 00:03:45,600
然后经常用一些Layer去做一个组成的

77
00:03:45,600 --> 00:03:48,320
所以它比较著名的特点就是Layer-based

78
00:03:48,400 --> 00:03:52,160
就是基于网络层数来定义的一层超一层

79
00:03:52,160 --> 00:03:54,720
右边这个图我们可以看到Layer1

80
00:03:54,720 --> 00:03:57,920
然后Layer2通过不断的层数的添加

81
00:03:57,920 --> 00:04:01,680
然后表示我们右边的图不断的一层一层

82
00:04:01,680 --> 00:04:05,280
当时应该是5年前的10年前的神经网络

83
00:04:05,280 --> 00:04:06,640
还是比较简单

84
00:04:06,640 --> 00:04:10,480
只是一层一层网络模型不断的去堆叠下来

85
00:04:10,480 --> 00:04:13,680
现在的神经网络Bert、Transform那种

86
00:04:13,680 --> 00:04:16,080
虽然大的结构上还是一层一层

87
00:04:16,240 --> 00:04:19,360
但实际上它们已经演变了非常多的不同

88
00:04:19,360 --> 00:04:21,040
灵活组合的方式

89
00:04:21,040 --> 00:04:24,400
那个时候另外一个特点就是支持CPU和GPU的

90
00:04:24,400 --> 00:04:26,000
高效的计算

91
00:04:26,000 --> 00:04:29,840
也就是慢慢的引入了GPU支持GPU的加速

92
00:04:29,840 --> 00:04:31,680
这个就是它的一个优点

93
00:04:31,680 --> 00:04:35,440
另外一个优点就提供了一定程度的可编程性

94
00:04:35,440 --> 00:04:36,960
就是像右边的这个图

95
00:04:36,960 --> 00:04:39,760
我可以一定程度的通过一些配置

96
00:04:39,760 --> 00:04:42,320
把整个神经网络运作起来

97
00:04:42,320 --> 00:04:47,440
当然这一系列的神经网络或者这一系列的酷AI框架

98
00:04:47,440 --> 00:04:51,520
它受制于当时时代的发展有自身的局限性

99
00:04:51,520 --> 00:04:55,040
那第一个局限性我们叫做Limitation 1

100
00:04:55,040 --> 00:04:57,520
限制了整个AI框架的灵活性

101
00:04:57,520 --> 00:05:01,360
不能够很好的满足深度学习的快速发展

102
00:05:01,360 --> 00:05:04,960
那我们可以看到深度学习的快速发展有四点

103
00:05:04,960 --> 00:05:06,320
我所总结的四点

104
00:05:06,320 --> 00:05:09,200
第一点就是网络模型层出不从

105
00:05:09,280 --> 00:05:13,280
从我们的INN LSTM再到Transformer

106
00:05:13,280 --> 00:05:15,840
网络模型结构非常夸张

107
00:05:15,840 --> 00:05:20,080
然后新的层就会引入新的前向和后向的计算

108
00:05:20,080 --> 00:05:22,640
如果只是给我们提供了一个层

109
00:05:22,640 --> 00:05:23,920
让我们去改参数

110
00:05:23,920 --> 00:05:26,560
可能满足不了我们自定义的一些操作

111
00:05:26,560 --> 00:05:29,520
还有像Cafe它提供了一些非高级语言

112
00:05:29,520 --> 00:05:30,800
就是非Python

113
00:05:30,800 --> 00:05:33,840
还是集中在C++或者C这种方式

114
00:05:33,840 --> 00:05:36,080
那另外新的优化器

115
00:05:36,080 --> 00:05:39,680
我们的对T度的计算和参数的运算会更加复杂

116
00:05:39,680 --> 00:05:42,640
不仅仅是通过Python来控制我们的网络模型

117
00:05:42,640 --> 00:05:45,920
我们还是希望控制整个运算的过程

118
00:05:46,640 --> 00:05:49,600
第二个约束就是现在神经网络

119
00:05:49,600 --> 00:05:54,480
它除了简单的LSTM Transformer这些网络模型结构的更新之外

120
00:05:54,480 --> 00:05:56,880
它还有新的训练的方式的更新

121
00:05:56,880 --> 00:05:59,440
例如LSTM IN循环

122
00:05:59,440 --> 00:06:02,480
还有GAN这种左右两个网络互相博弈的

123
00:06:02,480 --> 00:06:05,520
像强化学习这种通过多轮迭代

124
00:06:05,520 --> 00:06:09,680
还有最新的Diffusion Model这些新的训练方式

125
00:06:09,680 --> 00:06:11,680
已经很难满足了

126
00:06:12,960 --> 00:06:15,360
于是后面在第二个阶段

127
00:06:15,360 --> 00:06:19,280
应该是2015年之后或者2016年之后

128
00:06:19,280 --> 00:06:23,840
就出现了基于数据流图的计算框架的出现了

129
00:06:23,840 --> 00:06:25,760
就是我们叫做Base DAG

130
00:06:25,760 --> 00:06:27,840
DAG就是数据流图

131
00:06:27,840 --> 00:06:31,600
正是因为基于数据流图的AI计算框架起来

132
00:06:31,600 --> 00:06:34,960
所以会出现刚才前面我们所讲的那一幕

133
00:06:35,040 --> 00:06:38,800
很多人还在讨论用哪个AI框架更简单

134
00:06:38,800 --> 00:06:42,480
我们来看看基于数据流图的计算框架

135
00:06:42,480 --> 00:06:44,320
AI框架有什么不一样

136
00:06:44,320 --> 00:06:46,400
首先第一个它是很重要的

137
00:06:46,400 --> 00:06:49,360
有一个基本的数据结构叫做张亮

138
00:06:49,360 --> 00:06:51,920
TensorFloat谷歌的TensorFloat

139
00:06:51,920 --> 00:06:56,800
很重要的名字叫做TensorFloat张亮流

140
00:06:56,800 --> 00:06:58,960
它里面的AI框架就叫做张亮流

141
00:06:58,960 --> 00:07:02,320
所以张亮这个数据结构是非常重要的

142
00:07:02,400 --> 00:07:05,600
里面张亮可以代表非常多的不同的数据类型

143
00:07:05,600 --> 00:07:06,720
数据格式

144
00:07:06,720 --> 00:07:09,280
第二个就是基本的运算单元

145
00:07:09,280 --> 00:07:12,960
我们叫做operator或者PrimitiveOperator

146
00:07:12,960 --> 00:07:14,720
最原始的计算单位

147
00:07:14,720 --> 00:07:17,440
然后它有很多代数的算子组成

148
00:07:17,440 --> 00:07:20,720
例如我们经常用到的加减乘除求开号

149
00:07:20,720 --> 00:07:23,840
SineCodeSine这些都是基本的运算算子

150
00:07:25,120 --> 00:07:28,640
有了这些运算算子和基本的张亮之后

151
00:07:28,640 --> 00:07:32,240
我们就可以把整个图构建起来了

152
00:07:32,320 --> 00:07:34,640
这个图里面有一个非常重要的概念

153
00:07:34,640 --> 00:07:37,840
就是它是DAG有向无框图

154
00:07:37,840 --> 00:07:40,640
就是我图里面是有一个方向性的

155
00:07:40,640 --> 00:07:42,240
但是它没有回框

156
00:07:42,240 --> 00:07:44,880
就是我的图每一次都是有个方向的

157
00:07:44,880 --> 00:07:46,720
然后指向最终的输出

158
00:07:46,720 --> 00:07:50,000
如果我有回框的时候就会影响一个问题

159
00:07:50,000 --> 00:07:52,480
我的参数到底是如何更新的

160
00:07:52,480 --> 00:07:54,800
所以我们都叫做DAG图

161
00:07:54,800 --> 00:07:57,520
DAG图里面有一个比较特殊的操作

162
00:07:57,520 --> 00:07:58,800
就是控制流

163
00:07:58,800 --> 00:08:02,080
控制流我们会在后面去单独的去了解一下的

164
00:08:02,480 --> 00:08:05,200
基于DAG的主要两个AI框架

165
00:08:05,200 --> 00:08:07,200
一个是谷歌的TensorFloat

166
00:08:07,200 --> 00:08:08,800
一个是Facebook的Pytouch

167
00:08:08,800 --> 00:08:13,360
它们代表了深度学习里面的两种截然不同的事迹的路径

168
00:08:13,360 --> 00:08:18,240
一个TensorFloat是非常注重于性能比灵活性更加优先

169
00:08:18,240 --> 00:08:23,040
那Pytouch更加注重于灵活性、应用性比性能更加优先

170
00:08:23,040 --> 00:08:27,520
我们看看下面市场或者我们学术界整个的选择

171
00:08:27,520 --> 00:08:30,240
层次的这个就是代表TensorFloat

172
00:08:31,200 --> 00:08:34,320
然后我们可以看到TensorFloat的市场份额

173
00:08:34,320 --> 00:08:37,760
或者它整体的学术的研究使用的越来越少

174
00:08:37,760 --> 00:08:40,800
而Pytouch它从一开始比TensorFloat少的

175
00:08:40,800 --> 00:08:42,240
然后越来越多

176
00:08:42,240 --> 00:08:46,720
就是因为灵活性、应用性对大家来说实在是太重要了

177
00:08:46,720 --> 00:08:50,480
在不是说性能损耗的非常严重的情况下

178
00:08:50,480 --> 00:08:54,560
大家更倾向于使用一些能够简单易学的AI框架

179
00:08:54,560 --> 00:08:58,720
至少AI框架我们还是朝着未来的方向去演进的

180
00:08:58,720 --> 00:09:01,440
这里面有一个比较重要的概念

181
00:09:01,440 --> 00:09:03,760
叫做特定领域语言

182
00:09:03,760 --> 00:09:06,480
我们叫做Domain Specific Language

183
00:09:06,480 --> 00:09:08,960
那面向于特定领域语言

184
00:09:08,960 --> 00:09:11,360
就是我们AI或者深度学习

185
00:09:11,360 --> 00:09:14,320
作为一种特殊的领域或者特殊的应用

186
00:09:14,320 --> 00:09:16,720
它就衍生了自己的领域语言

187
00:09:16,720 --> 00:09:20,160
像Pytouch、JIT、MindSpot、JAL、SenseCode

188
00:09:20,240 --> 00:09:22,240
这种新的框架的出现

189
00:09:22,240 --> 00:09:25,280
为了解决某些特定领域的需求

190
00:09:25,280 --> 00:09:29,120
例如MindSpot在科学计算里面是非常好用的

191
00:09:29,120 --> 00:09:31,920
因为它可以灵活的做一些分布式并行

192
00:09:31,920 --> 00:09:33,200
高节微分

193
00:09:33,200 --> 00:09:36,640
而JAX它利用TensorFood XLA

194
00:09:36,640 --> 00:09:38,080
然后加上Lumpet

195
00:09:38,080 --> 00:09:41,920
可以非常灵活的去表达一些科学计算的问题

196
00:09:41,920 --> 00:09:45,120
像泰奇它能够表达一些非常有效的技术

197
00:09:45,120 --> 00:09:48,320
比如说它能够表达一些非常有效的技术

198
00:09:48,800 --> 00:09:52,800
像泰奇它能够很方便的做一些GPU的渲染

199
00:09:52,800 --> 00:09:54,640
还有物理仿真的能力

200
00:09:54,640 --> 00:09:58,640
这些就是特定领域语言所使用的框架

201
00:09:58,640 --> 00:10:01,280
也是整个学术界大家都叫做

202
00:10:01,280 --> 00:10:04,240
第三代AI框架的一个趋势

203
00:10:04,240 --> 00:10:05,680
这里面的这个趋势

204
00:10:05,680 --> 00:10:08,640
我们做一个简单的总结或者讨论

205
00:10:08,640 --> 00:10:11,440
就是它兼顾了整个编程的灵活性

206
00:10:11,440 --> 00:10:13,360
还有计算的高效性

207
00:10:13,360 --> 00:10:16,480
能够非常好好的去表达神经网络

208
00:10:16,480 --> 00:10:19,040
同时它又通过编译优化的手段

209
00:10:19,040 --> 00:10:23,520
来改善像Pytosh一开始可能性能不太优的阶段

210
00:10:23,520 --> 00:10:28,240
右边的这个图就是现在或者现代第三代AI框架

211
00:10:28,240 --> 00:10:31,680
基本上就是熟图同规的一种方式

212
00:10:38,560 --> 00:10:40,640
我们可以看看右边的这个图

213
00:10:40,640 --> 00:10:43,840
首先往上层的就是前端的编程语言

214
00:10:43,920 --> 00:10:46,640
有了前端的编程语言或者高级语言之后

215
00:10:46,640 --> 00:10:49,760
我们就需要最核心的机制自动求导

216
00:10:49,760 --> 00:10:51,680
自动求导也叫做自动微分

217
00:10:51,680 --> 00:10:54,720
我们在之前的那个系列已经详细的讲过了

218
00:10:54,720 --> 00:10:56,560
有了这个前端的表示之后

219
00:10:56,560 --> 00:11:00,160
我们会把所有的一切变成一个统一的表示

220
00:11:00,160 --> 00:11:02,880
统一的表示在我们第二代AI框架里面

221
00:11:02,880 --> 00:11:04,640
最著名的就是DAG

222
00:11:04,640 --> 00:11:07,280
现在很多也会去使用DAG图

223
00:11:07,280 --> 00:11:10,080
去对计算机的一些指令流进行表示

224
00:11:10,080 --> 00:11:12,400
表示完之后有了一个统一表示

225
00:11:12,480 --> 00:11:16,000
我们肯定需要一个对统一表示进行优化和调度

226
00:11:16,000 --> 00:11:19,600
于是就出现了图的优化和调度的编译之行

227
00:11:19,600 --> 00:11:20,560
有了这一层

228
00:11:20,560 --> 00:11:23,520
我们还停留在编译层的上面

229
00:11:23,520 --> 00:11:24,960
实际上我们代码之行

230
00:11:24,960 --> 00:11:28,080
我们还需要进行内核代码的优化和编译

231
00:11:28,080 --> 00:11:29,760
最终编译层及其指令

232
00:11:29,760 --> 00:11:33,520
让我们的计算机的不同的硬件去执行

233
00:11:33,520 --> 00:11:39,520
这个就是现代AI框架基本上都会去采用的这种分层结构

234
00:11:39,600 --> 00:11:42,800
可能每一层结构里面的细节会有点不一样

235
00:11:42,800 --> 00:11:43,760
例如MindSpore

236
00:11:43,760 --> 00:11:47,600
它可能就会把自动球岛和这一坨放在一起

237
00:11:47,600 --> 00:11:52,400
而PyTorch可能就少了图的优化和图的执行调度这一个模块

238
00:11:52,400 --> 00:11:54,160
或者少了编译模块

239
00:11:54,160 --> 00:11:57,040
或者它的编译模块非常轻量

240
00:11:57,040 --> 00:11:59,040
我们从左右两边可以看到

241
00:11:59,040 --> 00:12:01,600
一个是追求极致的性能

242
00:12:01,600 --> 00:12:04,080
一个是追求极致的应用性

243
00:12:04,080 --> 00:12:05,440
像应用性方面

244
00:12:05,440 --> 00:12:08,560
我们可以像一个基于Python原生的语言

245
00:12:08,640 --> 00:12:11,120
有Lumpi和SciencePy这两种

246
00:12:11,120 --> 00:12:14,960
这也是我们所谓的第一代AI框架所解决的问题

247
00:12:14,960 --> 00:12:18,880
研究学者想基于AI框架去写一些神经网络的时候

248
00:12:18,880 --> 00:12:21,200
只能基于这些酷来去实现

249
00:12:21,200 --> 00:12:24,960
后来应该也是第一代跟第二代过渡之间

250
00:12:24,960 --> 00:12:26,960
我们有了Cafe这个框架

251
00:12:26,960 --> 00:12:28,800
它主要是基于layer-based

252
00:12:28,800 --> 00:12:31,360
就是非常方便AI做部署

253
00:12:31,360 --> 00:12:34,960
那个时候的AI其实形态没有太多要化

254
00:12:34,960 --> 00:12:38,080
在15年、16年到14年之间

255
00:12:38,080 --> 00:12:40,640
能够满足我们AI的时代的发展

256
00:12:40,640 --> 00:12:42,560
然后通过简单的配置

257
00:12:42,560 --> 00:12:44,720
就可以把整个AI跑起来了

258
00:12:44,720 --> 00:12:49,600
这也是我当时候在研究室里面买的1080

259
00:12:49,600 --> 00:12:53,200
然后跑Cafe就觉得原来搞AI这么简单

260
00:12:53,200 --> 00:12:56,800
但是后来网络模型越来越多越来越复杂

261
00:12:56,800 --> 00:12:58,320
我们出现了干网络

262
00:12:58,320 --> 00:13:00,240
用Cafe就很难去表示了

263
00:13:00,240 --> 00:13:02,080
要自己写很多C++的代码

264
00:13:02,080 --> 00:13:04,640
这个时候Tensor4出现了

265
00:13:04,640 --> 00:13:07,200
或者基于数据流图、静态图

266
00:13:07,200 --> 00:13:08,720
那个时候还叫静态图

267
00:13:08,720 --> 00:13:11,360
的一种Tensor4的编程方式出现了

268
00:13:11,360 --> 00:13:14,800
Tensor4当时出现给我的一种感觉就是惊艳

269
00:13:14,800 --> 00:13:17,280
Tensor4至上产生的KeyRust

270
00:13:17,280 --> 00:13:20,160
我觉得真的是神一般的框架存在

271
00:13:20,160 --> 00:13:24,240
那个时候就觉得Tensor4解决了开发效率的问题

272
00:13:24,240 --> 00:13:28,240
18年的时候我的好哥们就给我推荐的Pytosh

273
00:13:28,240 --> 00:13:30,720
他说Pytosh去写NLP的一些

274
00:13:30,720 --> 00:13:33,760
他说Pytosh这种基于命令式编程

275
00:13:33,760 --> 00:13:36,480
或者动态图的方式非常方便

276
00:13:36,480 --> 00:13:39,040
他去解决NLP的任务

277
00:13:39,040 --> 00:13:41,440
这个时候我用上了Pytosh之后

278
00:13:41,440 --> 00:13:44,320
发现一个很惊艳、更加惊艳的问题

279
00:13:44,320 --> 00:13:46,240
其实应用性跟效率

280
00:13:46,240 --> 00:13:48,800
你如果说Tensor4很重要

281
00:13:48,800 --> 00:13:50,560
解决了用户开发效率

282
00:13:50,560 --> 00:13:54,160
那Pytosh解决了用户好不好用的问题

283
00:13:54,160 --> 00:13:58,720
面向特殊语言的一些新的任务需求

284
00:13:58,720 --> 00:14:01,360
这个时候又出现了新的AI框架

285
00:14:01,360 --> 00:14:03,840
他们融合了第二代里面数据流图

286
00:14:03,920 --> 00:14:06,880
Tensor4和Pytosh之间的一些优缺点

287
00:14:06,880 --> 00:14:09,600
也结合了领域的一些特殊性

288
00:14:09,600 --> 00:14:10,880
然后做了一些优化

289
00:14:10,880 --> 00:14:12,480
上了新的AI框架

290
00:14:12,480 --> 00:14:14,640
这就是未来的发展趋势

291
00:14:14,640 --> 00:14:18,640
下面我们可能从更加宏观的一个角度

292
00:14:18,640 --> 00:14:21,680
然后刚才我们只是讲了Framework这一个层次

293
00:14:21,680 --> 00:14:23,120
我们看看Hardware

294
00:14:23,120 --> 00:14:27,280
因为每一个时代它对应的一些硬件是不一样的

295
00:14:27,280 --> 00:14:28,960
随着我们软件的更新

296
00:14:28,960 --> 00:14:30,960
我们的硬件也在快速的迭代

297
00:14:30,960 --> 00:14:32,480
在第一代的时候

298
00:14:32,480 --> 00:14:36,400
其实那个时候并没有出现太多的特殊的硬件

299
00:14:36,400 --> 00:14:38,800
例如我们的Lempy或者SensePy

300
00:14:38,800 --> 00:14:41,120
主要是解决我们CPU的问题

301
00:14:41,120 --> 00:14:43,840
后来出现了Cafe或者Final这些框架

302
00:14:43,840 --> 00:14:47,200
把GPU的能力应用在深度学习里面

303
00:14:47,200 --> 00:14:50,000
在第二代里面出现了Tensor4和Pytosh

304
00:14:50,000 --> 00:14:52,640
像Tensor4谷歌就主打了一个TPU

305
00:14:52,640 --> 00:14:55,600
他们针对神经网络设计了特殊的硬件

306
00:14:55,600 --> 00:14:59,520
在第三代就是面向于我们特殊的领域语言

307
00:14:59,680 --> 00:15:03,280
这个时候我们可能从SIMD、MIMD的一个过渡

308
00:15:03,280 --> 00:15:06,480
或者我们会引入一些更加吸收性的需求

309
00:15:06,480 --> 00:15:07,520
还有控制流

310
00:15:07,520 --> 00:15:09,760
在计算机体系结构里面做一些

311
00:15:09,760 --> 00:15:12,400
纯算一体的特殊的优化

312
00:15:12,400 --> 00:15:14,720
所以面向我们的硬件的发展

313
00:15:14,720 --> 00:15:17,280
也是伴随软件AI框架的发展

314
00:15:17,280 --> 00:15:19,760
我们不能割裂软件去看硬件

315
00:15:19,760 --> 00:15:22,000
也不能割裂硬件去看软件

316
00:15:22,000 --> 00:15:24,960
最后又到了大家喜闻乐见的环节

317
00:15:24,960 --> 00:15:26,320
那这个课程里面

318
00:15:26,320 --> 00:15:29,440
我们整体回顾了AI框架的发展趋势

319
00:15:29,440 --> 00:15:33,760
从第一代AI框架去解决了深度学习可编程的问题

320
00:15:33,760 --> 00:15:38,640
到第二代AI框架去加速整个科研和产业的落地

321
00:15:38,640 --> 00:15:43,600
现在我们应该是刚迈进第三代AI框架的发展历程当中

322
00:15:43,600 --> 00:15:46,720
里面就结合了特定领域语言或者任务

323
00:15:46,720 --> 00:15:48,000
正在快速发展

324
00:15:48,000 --> 00:15:52,320
但是这个领域或者第三代没有完全收敛

325
00:15:52,320 --> 00:15:53,840
之后我们还一起了解了

326
00:15:53,840 --> 00:15:56,080
AI框架或者AI这个产业

327
00:15:56,080 --> 00:15:59,600
是伴随着软硬件的发展升级共同发展的

328
00:15:59,600 --> 00:16:01,200
我们不能割裂软件

329
00:16:01,200 --> 00:16:03,040
看硬件也不能割裂硬件

330
00:16:03,040 --> 00:16:04,080
看软件

331
00:16:04,080 --> 00:16:04,720
好了

332
00:16:04,720 --> 00:16:05,520
谢谢各位

333
00:16:05,520 --> 00:16:06,560
拜了个拜

