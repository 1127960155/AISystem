# 算子的计算与调度

## 计算与调度的含义

有一个耳熟能详的高斯得出求和公式的故事，当时，老师让学生计算1到100的和，本来需要逐个相加，但是高斯很快就找到了一个简便的方法。他观察到，如果将这些数字按照顺序两两配对，比如1和100、2和99、3和98，以此类推，每对数字的和都是101。而总共有50对这样的数字组合，所以他通过50乘以101来得到1到100的和，即5050。

对于计算机运算来说，也存在这样的”捷径“。一个计算，可以简单的按照最原始的模式一个一个执行，也可以利用各种特殊硬件如专门的存储或者计算组件来加速这个过程。这是一个一对多的映射，这个计算本身可以有多种不同的实现方式，这些实现方式在不同场景、不同输入、不同机器、不同参数上各有千秋，没有一个最佳的覆盖所有面的实现。在这个背景下，分离出了计算和调度两个概念：

+   计算：描述算法的逻辑，而不关心具体实现。
+   调度：对计算进行优化和控制的过程。通过调度，可以指定计算的执行顺序、内存布局、并行策略等参数，以实现对计算性能的优化。

这两个概念在Halide中被发扬光大。Halide是用C++作为宿主语言的一个图像处理相关的DSL(Domain Specified Language)语言。主要的作用为在软硬层面上(与算法本身的设计无关)实现对算法的底层加速。在Halide中计算定义了如何生成输出图像像素的方式，可以包括简单的像素级操作、复杂的算法表达式以及各种变换和滤波操作。并且Halide提供了丰富的调度器来帮助用户优化他们的计算图，包括并行化、向量化、内存布局优化等技术，使得用户可以更灵活地控制计算的执行方式。Halide将计算与其实现解耦合，可以更加高效的设计算法的具体执行过程，使得用户可以专注于底层加速。

在神经网络中，深度学习算法由一个个计算单元组成，我们称这些计算单元为算子（Operator，简称Op）。算子是一个函数空间到函数空间上的映射O：X→Y；从广义上讲，对任何函数进行某一项操作都可以认为是一个算子。于AI 框架而言，所开发的算子是网络模型中涉及到的计算函数。

在神经网络中矩阵乘法是最常见的算子，矩阵乘法的公式为：$  C_{ij} = \sum_{k=1}^{n} A_{ik} \cdot B_{kj}  $ ，其最朴实的实现如下代码：

```C++
void matrixMultiplication(int A[][128], int B[][128], int result[][128], int size) {
    for (int i = 0; i < size; ++i) {
        for (int j = 0; j < size; ++j) {
            result[i][j] = 0;
            for (int k = 0; k < size; ++k) {
                result[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}
```

使用循环分块对其进行优化：

```c++
void matrixMultiplicationTiled(int A[][128], int B[][128], int result[][128], int size, int tileSize) {
    for (int i = 0; i < size; i += tileSize) {
        for (int j = 0; j < size; j += tileSize) {
            for (int k = 0; k < size; k += tileSize) {
                for (int ii = i; ii < i + tileSize; ++ii) {
                    for (int jj = j; jj < j + tileSize; ++jj) {
                        int sum = 0;
                        for (int kk = k; kk < k + tileSize; ++kk) {
                            sum += A[ii][kk] * B[kk][jj];
                        }
                        result[ii][jj] += sum;
                    }
                }
            }
        }
    }
}

```

抑或是使用向量化对其优化：

```C++
#include <immintrin.h>

void matrixMultiplicationVectorized(int A[][128], int B[][128], int result[][128], int size) {
    for (int i = 0; i < size; ++i) {
        for (int j = 0; j < size; j += 4) {
            __m128i row = _mm_set1_epi32(A[i][j]);
            for (int k = 0; k < size; ++k) {
                __m128i b = _mm_loadu_si128((__m128i*)&B[k][j]);
                __m128i product = _mm_mullo_epi32(row, b);
                __m128i currentResult = _mm_loadu_si128((__m128i*)&result[i][j]);
                __m128i updatedResult = _mm_add_epi32(currentResult, product);
                _mm_storeu_si128((__m128i*)&result[i][j], updatedResult);
            }
        }
    }
}

```

我们还可以使用更多的优化方式来实现矩阵乘法，或是将它们组合起来。上面三种操作的算法功能是一样的，但是速度是有差异的。这种差异是和硬件设计强相关的，计算机为加快运算做了许多特殊设计，如存储层次、向量加速器、多个核心等，当我们充分这些硬件特性，可以极大地提升程序执行的速度，优化后的运行效率是原始程序效率的几十倍甚至几百倍。

算子调度具体执行的所有可能的调度方式称为调度空间。AI 编译器优化的目的在于通过对算子进行最佳调度，使得算子在特定硬件上的运行时间达到最优水平。这种优化涉及到对算子调度空间的全面搜索和分析，以确定最适合当前硬件架构的最佳调度方案。这样的优化过程旨在最大程度地利用硬件资源，提高算子的执行效率，并最终实现整体计算任务的高性能执行。

## 调度树

在构建一个算子的调度空间时，首先要确定我们能使用哪些优化手段。在Halide中，可以使用的优化有Reorder(交换)、Split(拆分)、Fuse(融合)、Tile(平铺)、Vector(向量化)、展开(Unrolling)、并行(Parallelizing)等，以Halide思想为指导的AI编译器TVM继承了这些优化方式：

+   **Reorder（交换）**：重新排列计算的顺序，可以改变计算的依赖关系，有助于提高缓存命中率，降低内存访问延迟，从而提高性能。
+   **Split（拆分）**：将一个维度的计算拆分成多个较小的维度，可以帮助并行化和向量化，并优化内存访问模式。
+   **Fuse（融合）**：合并多个计算，减少内存访问和数据传输的开销，提高计算的局部性，以及减少调度开销。
+   **Tile（平铺）**：将计算划分成小的块，有利于并行化和向量化，并且可以提高缓存的命中率。
+   **Vector（向量化）**：通过将多个数据元素打包成矢量操作，充分利用 SIMD 指令集，提高计算密集型任务的效率。
+   **展开（Unrolling）**：循环展开，减少循环的开销，减少分支预测失败的可能性，提高指令级并行性。
+   **并行（Parallelizing）**：将计算任务分解成多个并行执行的子任务，充分利用多核处理器或者并行处理单元，提高整体计算速度。

对于神经网络中的算子来说，其计算形式一般比较规则，是多层嵌套的循环，也很少有复杂的控制流，并且输入主要是多维张量。分析完计算的特点后，我们来分析下调度的要素。对于一个计算，其首先要进行存储的分配以容纳输入，之后在多层循环下进行计算，得出最终结果后再存储回结果位置。

```C++
// in为输入原始图像 blury为输出模糊后的图像
void box_filter_3x3(const Mat &in, Mat &blury)
{
    Mat blurx(in.size(), in.type());  // 存储

    for(int x = 1; x < in.cols-1; x ++)
        for(int y = 0 ; y < in.rows; y ++)   //循环
            blurx.at<uint8_t >(y, x) = static_cast<uint8_t>(
                    (in.at<uint8_t >(y, x-1) + in.at<uint8_t >(y, x) + in.at<uint8_t >(y, x+1)) / 3);  //计算

    for(int x = 0; x < in.cols; x ++)
        for(int y = 1 ; y < in.rows-1; y ++) //循环
            blury.at<uint8_t >(y, x) = static_cast<uint8_t>(
                    (blurx.at<uint8_t >(y-1, x) + blurx.at<uint8_t >(y, x) + blurx.at<uint8_t >(y+1, x)) / 3);  //计算

}
```



根据调度的要素，可以将其抽象为一个树结构，称为调度树：

+   循环节点：表示函数如何沿着给定维度进行遍历计算。循环节点与一个函数和一个变量（维度）相关联。循环节点还包含循环是按顺序运行、并行运行还是矢量化运行等信息。
+   存储节点：表示存储待使用的中间结果。
+   计算节点：调度树的叶子，表示正在执行的计算。计算节点可以有其他计算节点作为子节点，以表示内联函数而不是从中间存储加载。

对于任意的算子，可以定义其默认调度。其以行主序的形式遍历所有输出，并且内联所有函数调用，如下图所示：

![默认调度](../images/034CM_Backend/default.png)

我们将调度树与原有的程序进行对应：

![调度树与程序](../images/034CM_Backend/config_code.png)

在给定一个调度树后，可以通过深度优先搜索的方式进行遍历，然后转换成对应的程序代码。这里就体现计算与调度分离的好处，对于一个计算，可以有多个调度树生成不同性能的程序，只要调度树是合法的，就可以在结果正确的前提下提升程序的性能。

## 调度转换

在调度中可以使用许多优化手段，这些方式可以通过变换调度树来体现。

例如对于Fuse：将树中同一函数的两个相邻循环节点合并为一个循环节点

![融合](../images/034CM_Backend/fuse.png)

Parallel：改变循环类型为并行化

![并行化](../images/034CM_Backend/parallel.png)

Reorder：重新排序与给定函数关联的循环节点

![重排序](../images/034CM_Backend/reorder.png)

除了这些，其他的优化类型也可以对调度树进行相应的变换。

而不同调度树对应了不同的程序实现，具有不同的性能，我们如何能获得一个最优的调度树呢？

最简单的方法就是通过静态分析来获得最优调度树。一旦循环大小确定，我们就有足够的信息来确定调度树的重要执行特征，例如它将分配多少内存和执行多少操作。计调度的成本就是这些数据点的加权总和。

![调度成本](../images/034CM_Backend/cost.png)

然而这个方法过于简单和天真了，首先我们无法确定每个操作的成本，只可能有一个大概的预估。其次这些操作是相互影响的，并不独立，也就是成本是动态变化的。成本的总和也并不是简单的线性叠加。总之寻找一个最优调度树是非常复杂的过程，目前主流的方法如TVM中采用的是自动调优法。即根据可利用的优化手段，将它们组合，生成一个十分庞大的调度空间，然后利用一些探索器如启发式算法或者机器学习算法，对这个调度空间进行遍历，去实际运行或者用模型预测其性能，根据实际性能反馈对调度空间的探索，最终在一定时间内选择一个相对最优的调度。

![调度搜索](../images/034CM_Backend/search_tuner.png)

## 本节视频

<html>
<iframe src="https://player.bilibili.com/player.html?bvid=BV1K84y1x7Be&as_wide=1&high_quality=1&danmaku=0&t=30&autoplay=0" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</html>
