1
00:00:00,000 --> 00:00:04,800
【字幕生成: 奔崩 字幕校对: 奔崩】
（进~片~头）

2
00:00:04,800 --> 00:00:07,000
Hello，大家好，我是ZOMI

3
00:00:07,000 --> 00:00:09,400
刚才12点多刚开完会

4
00:00:09,400 --> 00:00:11,400
然后现在我过来去录一门课

5
00:00:11,400 --> 00:00:13,300
然后给大家分享一个知识点

6
00:00:13,300 --> 00:00:15,200
就是大模型和分布式训练的

7
00:00:15,200 --> 00:00:16,800
这里调侃一下

8
00:00:16,800 --> 00:00:18,800
我对生活说生活太苦了

9
00:00:18,800 --> 00:00:21,200
生活反倒给我说我给你加点糖啊

10
00:00:21,200 --> 00:00:23,200
我反倒问了是什么糖啊

11
00:00:23,200 --> 00:00:25,625
生活说加点荒糖

12
00:00:25,684 --> 00:00:27,237
（好冷啊 我去加件衣服）

13
00:00:28,277 --> 00:00:30,400
好了,今天要分享的内容

14
00:00:30,400 --> 00:00:33,500
就是通信实现和通信原语

15
00:00:33,500 --> 00:00:36,600
那首先会讲讲通信要实现

16
00:00:36,600 --> 00:00:39,400
那需要软硬件具备哪些能力

17
00:00:39,400 --> 00:00:42,700
接着会讲讲通信具体的一种实现方式

18
00:00:42,700 --> 00:00:46,400
那最后会去看一下通信的原语

19
00:00:46,400 --> 00:00:48,300
到底是什么一个概念

20
00:00:48,300 --> 00:00:50,800
因为一提到原语可能很多人不理解

21
00:00:50,800 --> 00:00:52,800
What is 语言是吧

22
00:00:52,800 --> 00:00:54,400
所以现在来打开一下

23
00:00:54,500 --> 00:00:56,600
实现大模型分布式并行的时候

24
00:00:56,600 --> 00:00:57,800
肯定离不开通信

25
00:00:57,800 --> 00:01:00,800
所以通信这一节对来说非常的重要

26
00:01:02,000 --> 00:01:03,400
下面来唠一唠

27
00:01:03,400 --> 00:01:05,700
正常的计算机网络里面通信

28
00:01:05,700 --> 00:01:07,900
两个非常重要的评价指标

29
00:01:07,900 --> 00:01:09,400
第一个就是带宽

30
00:01:09,400 --> 00:01:10,800
第二个就是延迟

31
00:01:10,800 --> 00:01:14,200
带宽意味着我每一秒能够通信多少数据

32
00:01:14,200 --> 00:01:17,600
而延迟就是我通信的快还是慢

33
00:01:17,600 --> 00:01:19,600
由于大规模分布式训练里面

34
00:01:19,600 --> 00:01:22,400
需要传输大量的网络模型的参数

35
00:01:22,400 --> 00:01:24,400
就是模型参数

36
00:01:24,400 --> 00:01:26,500
需要大量的同步的操作

37
00:01:26,500 --> 00:01:29,900
所以带宽和延迟同样对分布式训练

38
00:01:29,900 --> 00:01:31,700
是非常的重要

39
00:01:31,700 --> 00:01:35,900
现在来看看通信的具体的两种实现方式

40
00:01:35,900 --> 00:01:38,700
通信的实现方式分两个类型

41
00:01:38,700 --> 00:01:41,100
第一个类型就是机器内的一个通信

42
00:01:41,100 --> 00:01:43,700
第二个类型就是机器间的通信

43
00:01:43,700 --> 00:01:45,900
首先看看机器内的通信

44
00:01:45,900 --> 00:01:48,500
现在这个灰色的虚框里面就代表

45
00:01:48,500 --> 00:01:51,400
这是一台机器

46
00:01:51,400 --> 00:01:54,900
机器内部可能会通过共享内存进行通信

47
00:01:54,900 --> 00:01:57,200
另外的话还可以通过PCI的插槽

48
00:01:57,200 --> 00:02:00,700
或者NVLink的这个方式进行一种通信

49
00:02:00,700 --> 00:02:03,800
另外一种就是机器跟机器之间的通信

50
00:02:03,800 --> 00:02:06,100
那机器跟机器之间的可能更多的

51
00:02:06,100 --> 00:02:07,719
会通过TCP/IP这种

52
00:02:07,719 --> 00:02:09,500
Socket的网络模型

53
00:02:09,500 --> 00:02:12,400
或者RDMA方式的网卡进行通信

54
00:02:12,400 --> 00:02:14,500
主要有这两种实现方式

55
00:02:14,500 --> 00:02:16,735
那具体怎么去实现这些

56
00:02:16,735 --> 00:02:18,300
机器跟机器之间

57
00:02:18,300 --> 00:02:19,700
机器内部的通信

58
00:02:19,700 --> 00:02:21,500
往下继续看

59
00:02:21,500 --> 00:02:22,700
那机器内的通信

60
00:02:22,700 --> 00:02:24,100
刚才讲了有两种

61
00:02:24,100 --> 00:02:26,000
第一种就是共享内存

62
00:02:26,000 --> 00:02:28,200
假设我这里面有一款CPU

63
00:02:28,200 --> 00:02:30,100
这里面有另外一款CPU

64
00:02:30,100 --> 00:02:31,700
那CPU跟CPU之间

65
00:02:31,700 --> 00:02:34,200
我可能会共享同一块内存

66
00:02:34,200 --> 00:02:35,800
或者多核处理器的时候

67
00:02:35,800 --> 00:02:38,700
可能会共享相同的内存

68
00:02:38,700 --> 00:02:40,000
这个共享内存

69
00:02:40,000 --> 00:02:42,600
在手机里面是最明显的

70
00:02:42,600 --> 00:02:44,800
就是我手机有很多不同的IC

71
00:02:44,800 --> 00:02:45,600
我有CPU

72
00:02:45,600 --> 00:02:46,300
我有GPU

73
00:02:46,300 --> 00:02:47,800
我可能还会有ISP

74
00:02:47,800 --> 00:02:51,700
可能都会共享同一款手机里面的内存

75
00:02:51,700 --> 00:02:55,500
那第二个就是PCIe这种方式

76
00:02:55,500 --> 00:02:57,450
PCIe最明显的方式就是

77
00:02:57,450 --> 00:02:59,400
GPU跟CPU之间的通信

78
00:02:59,400 --> 00:03:02,500
大部分都是通过PCIe的插槽进行通信的

79
00:03:02,500 --> 00:03:04,200
而NVLink这种方式

80
00:03:04,200 --> 00:03:08,400
更多的是GPU跟GPU之间进行互联互通

81
00:03:08,400 --> 00:03:11,500
下面来看看机器间的一个通信

82
00:03:11,500 --> 00:03:13,700
那下面左边的这个框

83
00:03:13,700 --> 00:03:14,900
就是一台机器

84
00:03:14,900 --> 00:03:17,300
中间这个框又是另外一台机器

85
00:03:17,300 --> 00:03:20,200
机器跟机器之间是会进行通信的

86
00:03:20,200 --> 00:03:21,600
那更多的通信方式

87
00:03:21,600 --> 00:03:24,500
是通过网络的方式来进行通信的

88
00:03:24,500 --> 00:03:26,100
也就是上面这条蓝色（的线）

89
00:03:26,100 --> 00:03:29,200
更多的通过网线进行连接

90
00:03:29,200 --> 00:03:31,200
另外在AI集群里面

91
00:03:31,200 --> 00:03:34,700
可能更多的会用到RDMA的一种网络方式

92
00:03:34,700 --> 00:03:37,800
那在AI计算中心或者AI集群里面

93
00:03:37,800 --> 00:03:40,000
实际上更多的会采用

94
00:03:40,000 --> 00:03:42,200
RDMA的网络模型通信

95
00:03:42,200 --> 00:03:45,000
下面来看看具体的这些有什么区别

96
00:03:45,000 --> 00:03:47,000
或者再解释一下这些概念

97
00:03:48,500 --> 00:03:50,700
下面正式的来到一个硬件篇

98
00:03:50,700 --> 00:03:52,800
来看看这个硬件架构图

99
00:03:52,800 --> 00:03:55,200
这个图就是OpenPOWER

100
00:03:55,200 --> 00:03:57,400
IBMG英伟达Tesla P100

101
00:03:57,400 --> 00:03:59,300
出了一款GPU集群

102
00:03:59,300 --> 00:04:01,400
那这里面GPU跟GPU之间

103
00:04:01,400 --> 00:04:04,000
是通过NVLink进行一个通信的

104
00:04:04,000 --> 00:04:05,200
就看到了

105
00:04:05,200 --> 00:04:06,900
可以看到下面绿色的这个

106
00:04:06,900 --> 00:04:08,000
就是NVLink

107
00:04:08,000 --> 00:04:09,400
然后GPU跟CPU之间

108
00:04:09,400 --> 00:04:11,600
也是通过NVLink进行通信的

109
00:04:11,600 --> 00:04:14,300
但是CPU跟CPU之间

110
00:04:14,300 --> 00:04:17,100
反倒是通过总线去共享内存的方式

111
00:04:17,100 --> 00:04:18,300
进行通信的

112
00:04:18,300 --> 00:04:20,000
服务器跟服务器之间

113
00:04:20,000 --> 00:04:22,800
是通过RDMA网卡进行通信的

114
00:04:22,800 --> 00:04:24,700
而什么是PCI-E插槽

115
00:04:24,700 --> 00:04:27,100
现在来看看Wiki的定义

116
00:04:27,100 --> 00:04:28,500
维基百科里面说了

117
00:04:28,500 --> 00:04:29,300
PCI-E

118
00:04:29,300 --> 00:04:31,300
其实那个E是Express的意思

119
00:04:31,300 --> 00:04:34,200
是计算机总线的一个重要的分支

120
00:04:34,200 --> 00:04:37,700
沿用了原来的PCI编程的概念

121
00:04:37,700 --> 00:04:39,100
和信号的标准

122
00:04:39,100 --> 00:04:40,600
构建了更加高速的

123
00:04:40,600 --> 00:04:42,600
串行通信的系统标准

124
00:04:42,600 --> 00:04:43,900
那简单的来说

125
00:04:43,900 --> 00:04:46,100
它就是一个通信的标准

126
00:04:46,100 --> 00:04:48,600
在以前PCI-E出现之前

127
00:04:48,600 --> 00:04:49,900
在计算机里面

128
00:04:49,900 --> 00:04:52,100
或者组装计算机的时候

129
00:04:52,100 --> 00:04:54,700
通常都会有一个南桥北桥

130
00:04:54,700 --> 00:04:56,600
那现在通过PCI-E的插槽

131
00:04:56,600 --> 00:04:59,100
解决了南北桥的问题

132
00:04:59,100 --> 00:05:01,200
直接通过PCI-E总线

133
00:05:01,200 --> 00:05:02,600
进行一个通信

134
00:05:02,600 --> 00:05:03,600
下面这个图

135
00:05:03,600 --> 00:05:05,500
不管是长的短的

136
00:05:05,500 --> 00:05:08,200
这种都是PCI-E的一个插槽

137
00:05:08,200 --> 00:05:10,700
而现在PCI-E通信协议

138
00:05:10,700 --> 00:05:13,300
从1.1已经发展到5.0

139
00:05:13,300 --> 00:05:15,600
而现在正在迈入6.0的时代

140
00:05:16,600 --> 00:05:18,800
PCI-E的传输速率

141
00:05:18,800 --> 00:05:20,500
其实还不够高

142
00:05:20,500 --> 00:05:21,900
英伟达就发明了

143
00:05:21,900 --> 00:05:24,000
NVLink这种传输方式

144
00:05:24,000 --> 00:05:26,200
NVLink最主要的特征

145
00:05:26,200 --> 00:05:27,700
就是非常的高速

146
00:05:27,700 --> 00:05:30,200
而且有非常多的通道

147
00:05:30,200 --> 00:05:32,000
通过插分库的双向链路

148
00:05:32,000 --> 00:05:33,300
来去实现的

149
00:05:33,300 --> 00:05:34,300
左边这个图

150
00:05:34,300 --> 00:05:36,100
GPU跟CPU之间

151
00:05:36,100 --> 00:05:37,700
可以通过NVLink的方式

152
00:05:37,700 --> 00:05:38,700
进行连接

153
00:05:38,700 --> 00:05:40,400
但是这种方式就要求

154
00:05:40,400 --> 00:05:43,100
CPU是支持NVLink这个协议

155
00:05:43,100 --> 00:05:44,400
右边的这个图

156
00:05:44,400 --> 00:05:45,900
更多是现在常用的

157
00:05:45,900 --> 00:05:48,000
就是GPU跟GPU之间互联

158
00:05:48,000 --> 00:05:51,400
更多的是使用NVLink进行传输的

159
00:05:51,400 --> 00:05:52,300
现在来看看

160
00:05:52,300 --> 00:05:54,400
一般的NVLink是怎么工作的

161
00:05:54,400 --> 00:05:56,600
首先CPU会发起一个test

162
00:05:56,600 --> 00:05:58,500
或者一个任务

163
00:05:58,500 --> 00:06:00,000
这个任务现在还是通过

164
00:06:00,000 --> 00:06:02,000
PCI-E来进行一个连接的

165
00:06:02,000 --> 00:06:03,300
接着还会保留

166
00:06:03,300 --> 00:06:05,200
PCI-E的编程接口

167
00:06:05,200 --> 00:06:06,500
同时可以触发

168
00:06:06,500 --> 00:06:08,900
GPU跟CPU之间互联

169
00:06:08,900 --> 00:06:10,700
在上一节里面讲到

170
00:06:10,700 --> 00:06:12,300
其实这个互联方式

171
00:06:12,300 --> 00:06:15,800
实际上是通过NVLink进行连接的

172
00:06:15,800 --> 00:06:16,900
这里面就会对

173
00:06:16,900 --> 00:06:19,400
GPU跟GPU之间组成一个环

174
00:06:19,400 --> 00:06:21,700
更方便做集合通信

175
00:06:21,700 --> 00:06:22,800
现在看看

176
00:06:22,800 --> 00:06:24,200
另外一个很重要的概念

177
00:06:24,200 --> 00:06:25,500
就是RDMA

178
00:06:25,500 --> 00:06:28,200
Remote Direct Memory Assessed

179
00:06:28,200 --> 00:06:30,500
直接听名字可能觉得很陌生

180
00:06:30,500 --> 00:06:32,200
但是一看它的英文详写

181
00:06:32,200 --> 00:06:33,700
可能就非常直接了

182
00:06:33,700 --> 00:06:34,900
简单的说就是

183
00:06:34,900 --> 00:06:36,400
远程内存直连

184
00:06:36,400 --> 00:06:38,200
它有三个重要的特性

185
00:06:38,200 --> 00:06:40,300
这三个特性实在太重要了

186
00:06:40,300 --> 00:06:42,300
这第一个就是CPU Offload

187
00:06:42,300 --> 00:06:44,200
就不需要CPU进行干预

188
00:06:44,200 --> 00:06:46,300
我可以直连内存

189
00:06:46,300 --> 00:06:48,500
第二个就是Kernel Bypass

190
00:06:48,500 --> 00:06:49,600
这里面通信

191
00:06:49,600 --> 00:06:51,000
不需要Kernel程序执行

192
00:06:51,000 --> 00:06:52,300
可以在用户态进行

193
00:06:52,300 --> 00:06:53,900
执行数据的传输

194
00:06:53,900 --> 00:06:56,600
那第三个特性就是Zero Copy

195
00:06:56,600 --> 00:06:57,800
用户的应用程序

196
00:06:57,800 --> 00:07:00,400
直接可以访问集群里面的虚拟内存

197
00:07:00,400 --> 00:07:02,200
这三个特性非常重要

198
00:07:02,200 --> 00:07:04,300
来看看下面的这个图

199
00:07:04,300 --> 00:07:06,200
左边就是传统的网络通信

200
00:07:06,200 --> 00:07:07,200
右边的这个就是

201
00:07:07,200 --> 00:07:09,000
RDMA的一个通信方式

202
00:07:09,000 --> 00:07:10,300
传统的网络通信

203
00:07:10,300 --> 00:07:12,800
采用的是TCP/IP的网络通信

204
00:07:12,800 --> 00:07:14,000
那以前主要是以

205
00:07:14,000 --> 00:07:15,700
发送一些很小的数据

206
00:07:15,700 --> 00:07:17,600
或者很小的消息为主

207
00:07:17,600 --> 00:07:18,900
所以那时候聚焦的点

208
00:07:18,900 --> 00:07:20,500
就是处理延迟

209
00:07:20,500 --> 00:07:21,800
通信的延迟

210
00:07:21,800 --> 00:07:23,000
这是提升整个

211
00:07:23,000 --> 00:07:25,500
网络性能的一个关键的点

212
00:07:25,500 --> 00:07:26,800
从左边的那个图

213
00:07:26,800 --> 00:07:28,200
好几个蓝色的方块

214
00:07:28,200 --> 00:07:29,800
可以看到里面有Socket

215
00:07:29,800 --> 00:07:30,900
TCP IP

216
00:07:30,900 --> 00:07:32,500
还有Network Device

217
00:07:32,500 --> 00:07:34,000
这个过程就需要经历

218
00:07:34,000 --> 00:07:36,300
非常多的用户的内存拷贝

219
00:07:36,300 --> 00:07:37,400
所以它执行起来

220
00:07:37,400 --> 00:07:39,000
可能会非常的缓慢

221
00:07:39,000 --> 00:07:41,000
而数据量越大的时候

222
00:07:41,000 --> 00:07:42,200
这个延迟对来说

223
00:07:42,200 --> 00:07:44,500
是很难去接受的

224
00:07:44,500 --> 00:07:46,200
而RDMA新的协议

225
00:07:46,200 --> 00:07:47,700
就是用户跳开Kernel层

226
00:07:47,700 --> 00:07:48,800
就Kernel Bypass

227
00:07:48,800 --> 00:07:51,500
直接传到远端的服务器

228
00:07:51,500 --> 00:07:53,200
数据绕过CPU

229
00:07:53,200 --> 00:07:55,100
直接通过RDMA设备

230
00:07:55,100 --> 00:07:56,300
对远端的虚拟内存

231
00:07:56,300 --> 00:07:58,500
直接进行访问读和写

232
00:07:58,500 --> 00:07:59,800
通过简单的介绍

233
00:07:59,800 --> 00:08:01,400
刚才的几个硬件设备

234
00:08:01,400 --> 00:08:02,300
包括PCIe

235
00:08:02,300 --> 00:08:03,200
还有NVLink

236
00:08:03,200 --> 00:08:05,100
还有Infiniband

237
00:08:05,100 --> 00:08:06,600
RDMA几种方式

238
00:08:06,700 --> 00:08:08,000
了解到了

239
00:08:08,000 --> 00:08:09,400
机器内的通信

240
00:08:09,400 --> 00:08:11,200
CPU跟CPU之间

241
00:08:11,200 --> 00:08:12,900
可能更多的通过总线

242
00:08:12,900 --> 00:08:14,000
来共享内存

243
00:08:14,000 --> 00:08:14,700
那第二个

244
00:08:14,700 --> 00:08:16,000
CPU跟GPU之间

245
00:08:16,000 --> 00:08:17,900
可能会通过PCIe这个插槽

246
00:08:17,900 --> 00:08:19,400
进行连接

247
00:08:19,400 --> 00:08:20,700
GPU跟GPU之间

248
00:08:20,700 --> 00:08:22,800
更多会通过NVLink的方式

249
00:08:22,800 --> 00:08:24,000
进行通信

250
00:08:24,000 --> 00:08:26,000
而跨机器之间的通信

251
00:08:26,000 --> 00:08:27,500
更多通过网络

252
00:08:27,500 --> 00:08:28,600
AI集群里面

253
00:08:28,600 --> 00:08:29,500
更多的是使用

254
00:08:29,500 --> 00:08:31,300
RDMA这种网络协议的方式

255
00:08:31,300 --> 00:08:32,139
进行通信

256
00:08:33,200 --> 00:08:34,400
下面来看以下

257
00:08:34,400 --> 00:08:36,200
一个互联的拓扑

258
00:08:36,200 --> 00:08:38,600
那只是只有PCI的时候

259
00:08:38,600 --> 00:08:40,400
一般下面有八个卡

260
00:08:40,400 --> 00:08:41,600
八个卡之间

261
00:08:41,600 --> 00:08:43,700
一般是通过PCI插槽

262
00:08:43,700 --> 00:08:46,200
跟X86 CPU进行通信

263
00:08:46,200 --> 00:08:49,200
那在英伟达的DGX第一代里面

264
00:08:49,200 --> 00:08:51,000
中间的这些绿色的线

265
00:08:51,000 --> 00:08:53,100
就是通过NVLink进行互联

266
00:08:53,100 --> 00:08:54,500
然后形成一个环

267
00:08:54,500 --> 00:08:56,300
最后通过PCI插槽

268
00:08:56,300 --> 00:08:59,700
跟X86进行一个连接

269
00:08:59,700 --> 00:09:01,700
后来DGX第二代的时候

270
00:09:01,700 --> 00:09:03,200
英伟达就对NVLink

271
00:09:03,200 --> 00:09:04,300
进行一个组合

272
00:09:04,300 --> 00:09:06,400
变成一个NVSwitch的这种

273
00:09:06,400 --> 00:09:09,400
网络通信路由的方式

274
00:09:09,400 --> 00:09:12,400
连接更多的GPU的芯片

275
00:09:12,400 --> 00:09:14,000
最后就是刚才讲的

276
00:09:14,000 --> 00:09:16,600
机器跟机器之间的一个通信

277
00:09:16,600 --> 00:09:18,200
就是通过网线

278
00:09:18,200 --> 00:09:19,800
或者RDMA的方式

279
00:09:19,800 --> 00:09:20,814
进行通信的

280
00:09:22,400 --> 00:09:23,300
了解完硬件

281
00:09:23,300 --> 00:09:24,800
看看软件篇

282
00:09:24,800 --> 00:09:26,300
软件篇其实很好理解

283
00:09:26,300 --> 00:09:27,600
概念也比较简单

284
00:09:27,600 --> 00:09:29,000
第一个就是MPI

285
00:09:29,000 --> 00:09:30,400
第二个就是NCCL

286
00:09:30,400 --> 00:09:32,200
NCCL就是英伟达的

287
00:09:32,200 --> 00:09:33,400
网络通信协议

288
00:09:33,400 --> 00:09:35,300
那HCCL就是华为的

289
00:09:35,300 --> 00:09:36,400
网络通信协议

290
00:09:36,400 --> 00:09:37,700
还有Facebook发明的

291
00:09:37,700 --> 00:09:39,400
Gloo三种

292
00:09:40,100 --> 00:09:41,500
第一种MPI

293
00:09:41,500 --> 00:09:43,000
就是定义了非常多的

294
00:09:43,000 --> 00:09:44,400
原语的接收方式

295
00:09:44,400 --> 00:09:45,300
那一开始

296
00:09:45,300 --> 00:09:47,700
它主要是对点对点通信的

297
00:09:47,700 --> 00:09:49,600
就是点跟点之间通信

298
00:09:49,600 --> 00:09:51,100
我一个数据发送

299
00:09:51,100 --> 00:09:53,100
我一个数据做接收

300
00:09:53,100 --> 00:09:53,900
这种方式

301
00:09:53,900 --> 00:09:56,300
后来MPI推出了集合通信

302
00:09:56,300 --> 00:09:57,300
但是集合通信

303
00:09:57,300 --> 00:09:58,900
还是建立在点对点的

304
00:09:58,900 --> 00:10:00,000
通信方式的基础

305
00:10:00,000 --> 00:10:02,600
进行一个拓展

306
00:10:02,700 --> 00:10:05,300
NCCL以英伟达作为例子

307
00:10:05,300 --> 00:10:06,900
首先它的工作方式

308
00:10:06,900 --> 00:10:08,400
我需要对网络的拓扑

309
00:10:08,400 --> 00:10:09,300
进行一个感知

310
00:10:09,300 --> 00:10:10,600
知道我的网络拓扑

311
00:10:10,600 --> 00:10:11,800
到底长什么样子的

312
00:10:11,800 --> 00:10:12,800
我的回环

313
00:10:12,800 --> 00:10:14,900
到底是如何的组织方式

314
00:10:14,900 --> 00:10:16,700
接着我可能会去做一个

315
00:10:16,700 --> 00:10:17,700
Graph的Search

316
00:10:17,700 --> 00:10:19,100
就是对网络拓扑

317
00:10:19,100 --> 00:10:20,000
进行搜索

318
00:10:20,000 --> 00:10:22,600
找到一个最好的通信的策略

319
00:10:22,600 --> 00:10:24,200
最后就使用CUDA的Kernel

320
00:10:24,200 --> 00:10:26,300
对数据进行通信

321
00:10:26,300 --> 00:10:27,800
下面中间的这个图

322
00:10:27,800 --> 00:10:29,800
是我截取PyTorch

323
00:10:29,800 --> 00:10:32,900
对GLOO MPI和NCCL的一个支持情况

324
00:10:32,900 --> 00:10:34,700
可以看到MPI大部分都是

325
00:10:34,700 --> 00:10:36,500
在CPU上面去执行的

326
00:10:36,500 --> 00:10:39,200
而NCCL主要是支持GPU

327
00:10:39,200 --> 00:10:41,100
GPU支持的模式非常多

328
00:10:41,100 --> 00:10:44,200
而Gloo 有点一言难尽

329
00:10:44,200 --> 00:10:45,900
但是大部分是支持CPU

330
00:10:45,900 --> 00:10:48,000
然后GPU也有部分的支持

331
00:10:48,000 --> 00:10:49,700
可能还不是说非常完善

332
00:10:49,700 --> 00:10:52,700
所以大家参考着来使用

333
00:10:52,700 --> 00:10:54,200
聊到通信的实现方式

334
00:10:54,200 --> 00:10:56,400
其实刚才在讲MPI的时候

335
00:10:56,400 --> 00:10:57,700
已经简单的提到了

336
00:10:57,700 --> 00:10:59,700
有点对点的通信

337
00:10:59,700 --> 00:11:01,300
一个是接受一个是发送

338
00:11:01,300 --> 00:11:02,700
就Send和Receive

339
00:11:02,700 --> 00:11:04,500
然后集合通信就是

340
00:11:04,500 --> 00:11:07,300
All-Reduce这种方式

341
00:11:07,300 --> 00:11:09,700
点对点的通信还是比较粗暴的

342
00:11:09,700 --> 00:11:11,100
就是我服务器0

343
00:11:11,100 --> 00:11:14,900
把我的数据传送到服务器3

344
00:11:14,900 --> 00:11:16,100
这里面的PyTorch

345
00:11:16,100 --> 00:11:17,700
支持点对点的通信

346
00:11:17,700 --> 00:11:18,700
直接去声明

347
00:11:18,700 --> 00:11:19,900
我的一个数据是Send

348
00:11:19,900 --> 00:11:21,100
一个数据是Receive

349
00:11:21,100 --> 00:11:22,600
就可以了

350
00:11:22,600 --> 00:11:23,600
集合通信

351
00:11:23,600 --> 00:11:25,100
会在接下来的内容里面

352
00:11:25,100 --> 00:11:26,800
去详细的展开

353
00:11:26,800 --> 00:11:28,200
PyTorch可以直接调

354
00:11:28,200 --> 00:11:29,400
集合通信的方式

355
00:11:29,400 --> 00:11:30,700
直接在代码里面

356
00:11:30,700 --> 00:11:32,800
声明All-Reduce

357
00:11:32,800 --> 00:11:34,400
今天的内容比较简单

358
00:11:34,400 --> 00:11:34,900
下一节

359
00:11:34,900 --> 00:11:36,500
将会详细的去展开

360
00:11:36,500 --> 00:11:38,300
集合通信的具体的方式

361
00:11:38,300 --> 00:11:39,500
今天就了解了

362
00:11:39,500 --> 00:11:40,100
机器内部

363
00:11:40,100 --> 00:11:41,100
还有机器之间的

364
00:11:41,100 --> 00:11:43,200
具体的通信方式

365
00:11:43,200 --> 00:11:43,700
另外的话

366
00:11:43,700 --> 00:11:44,400
还了解了

367
00:11:44,400 --> 00:11:46,400
硬件会通过PCIe NVLink

368
00:11:46,400 --> 00:11:47,600
还有RDMA的方式

369
00:11:47,600 --> 00:11:48,900
针对不同的场景

370
00:11:48,900 --> 00:11:50,900
或者不同的机器的组合方式

371
00:11:50,900 --> 00:11:53,100
来去实现硬件通信的

372
00:11:53,100 --> 00:11:54,400
而在软件层面

373
00:11:54,400 --> 00:11:56,200
会通过MPI Gloo

374
00:11:56,200 --> 00:11:58,700
还有XCCL的实现方式

375
00:11:58,700 --> 00:12:01,000
另外还简单的了解了

376
00:12:01,000 --> 00:12:03,300
点对点通信和集合通信的

377
00:12:03,300 --> 00:12:04,300
具体的差异

378
00:12:05,600 --> 00:12:07,200
在这么内卷的环境下

379
00:12:07,200 --> 00:12:08,500
做到经常更新

380
00:12:08,500 --> 00:12:09,600
实属不易

381
00:12:09,600 --> 00:12:12,200
非常欢迎大家对我一键三连

382
00:12:12,200 --> 00:12:13,000
谢谢各位

383
00:12:13,000 --> 00:12:13,800
摆了个拜