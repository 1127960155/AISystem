1
00:00:00,000 --> 00:00:11,600
哈喽大家好,我是zomie,今天呢我们还是在AI芯片的基础

2
00:00:11,600 --> 00:00:15,400
不过呢我们来到了AI芯片里面基础的最后一个内容

3
00:00:15,400 --> 00:00:18,400
计算体系架构的黄金十年

4
00:00:18,400 --> 00:00:21,400
我们其实从CPU到GPU到NPU

5
00:00:21,400 --> 00:00:23,600
可能呢DPU不在我们的范围内

6
00:00:23,600 --> 00:00:26,400
那么多不同的架构的芯片呢组合在一起呢

7
00:00:26,400 --> 00:00:29,600
其实我们真正的来到了整个计算体系架构的

8
00:00:29,600 --> 00:00:31,800
真正的革命和演变的时代

9
00:00:31,800 --> 00:00:33,500
而为什么我可以这么说呢

10
00:00:33,500 --> 00:00:35,000
这个结论的不是我说的

11
00:00:35,000 --> 00:00:41,400
而是特林的得奖者David在计算机架构的黄金十年里面

12
00:00:41,400 --> 00:00:43,300
去讲到的一个概念

13
00:00:43,300 --> 00:00:44,800
而一年之后呢

14
00:00:44,800 --> 00:00:47,900
LLVM之父Chris呢发表了一篇报告

15
00:00:47,900 --> 00:00:50,300
叫做编译器的黄金十年

16
00:00:50,300 --> 00:00:53,000
非常欢迎大家去看看这两个视频

17
00:00:53,000 --> 00:00:54,100
那这两个视频呢

18
00:00:54,100 --> 00:00:57,200
在我们的YouTube上面都可以去看的

19
00:00:57,200 --> 00:00:59,300
接下来我们回到今天的重点

20
00:00:59,300 --> 00:01:01,100
AI芯片的发展

21
00:01:02,600 --> 00:01:04,800
芯片呢经历过三个阶段

22
00:01:04,800 --> 00:01:06,600
那我们简单的去过一过

23
00:01:06,600 --> 00:01:07,400
第一个阶段呢

24
00:01:07,400 --> 00:01:09,400
一段呢就是AI芯片算力不足

25
00:01:09,400 --> 00:01:12,200
神级网络呢没有很好的被受到重视

26
00:01:12,200 --> 00:01:12,800
那个时候呢

27
00:01:12,800 --> 00:01:15,300
应该是1970年到1980年

28
00:01:15,300 --> 00:01:17,900
CPU呢还没有正式的或者出现

29
00:01:17,900 --> 00:01:19,200
而在第二个阶段呢

30
00:01:19,200 --> 00:01:22,700
就是CPU的算力大幅的提升

31
00:01:22,700 --> 00:01:24,300
应该在千禧年左右

32
00:01:24,300 --> 00:01:25,600
但是那个时候呢

33
00:01:25,600 --> 00:01:28,500
已经开始慢慢出现了一些AI的框架

34
00:01:28,500 --> 00:01:31,300
例如PyTorch的全身Torch

35
00:01:31,300 --> 00:01:33,400
不过那个时候那个阶段的最大的问题

36
00:01:33,400 --> 00:01:35,900
就是CPU的算力虽然大幅的提升了

37
00:01:35,900 --> 00:01:38,200
但是没有办法去满足神经网络

38
00:01:38,200 --> 00:01:40,700
或者深度学习算力的增长需求

39
00:01:40,700 --> 00:01:42,000
到第三个阶段呢

40
00:01:42,000 --> 00:01:45,400
就是我们现在来到的一个AI产业的阶段

41
00:01:45,400 --> 00:01:47,300
GPU和AI的芯片呢

42
00:01:47,300 --> 00:01:49,700
整体的新的架构体系的出现

43
00:01:49,700 --> 00:01:52,800
推动了整个人工智能的快速落地

44
00:01:52,800 --> 00:01:55,300
现在呢我们的算力越来越多

45
00:01:55,300 --> 00:01:58,000
能够从小模型演变到大模型

46
00:01:58,000 --> 00:02:01,200
到现在的基础模型了

47
00:02:01,200 --> 00:02:02,200
模型参数量呢

48
00:02:02,200 --> 00:02:05,400
动辄就已经上百亿千亿万亿的这种规模

49
00:02:05,400 --> 00:02:08,200
也是非常的惊人和夸张的

50
00:02:08,200 --> 00:02:10,600
接着呢我们讲完一些基础的内容

51
00:02:10,600 --> 00:02:12,800
我们来看看什么叫做异构

52
00:02:12,800 --> 00:02:15,200
我们今天的主角就是我们的异构场景

53
00:02:15,200 --> 00:02:16,700
和具体的异构芯片

54
00:02:16,700 --> 00:02:18,400
那下面呢以一个具体的例子

55
00:02:18,400 --> 00:02:20,200
来去看看这个问题

56
00:02:20,200 --> 00:02:23,100
我们以特斯拉这款芯片呢作为例子

57
00:02:23,100 --> 00:02:25,100
那特斯拉可以看到一款车啊

58
00:02:25,100 --> 00:02:27,600
我在车里面要做很多相关的工作

59
00:02:27,600 --> 00:02:28,500
我要感知雷达呢

60
00:02:28,500 --> 00:02:29,400
我要做GPS呢

61
00:02:29,400 --> 00:02:30,800
我要做地图的建模呢

62
00:02:30,800 --> 00:02:33,300
我可能还会对IMU的数据进行处理

63
00:02:33,300 --> 00:02:36,200
所以说它的功能是非常非常的多样化的

64
00:02:36,200 --> 00:02:40,500
面对这些功能的特斯拉HW3FSD芯片呢

65
00:02:40,500 --> 00:02:42,900
就推出了它不仅有自己的CPU

66
00:02:42,900 --> 00:02:44,600
GPU还有NPU

67
00:02:44,600 --> 00:02:46,100
可能里面还会有ISP

68
00:02:46,100 --> 00:02:48,000
还有Security Process Unit

69
00:02:48,000 --> 00:02:51,300
里面的功能单元非常非常的多

70
00:02:51,300 --> 00:02:52,500
下面这个图呢

71
00:02:52,500 --> 00:02:54,900
就是NPU的一个Data Flow的架构

72
00:02:54,900 --> 00:02:57,400
面对这么在一款芯片里面呢

73
00:02:57,400 --> 00:02:59,300
拥有这么多不同的IP

74
00:02:59,300 --> 00:03:00,500
我们叫这款IP呢

75
00:03:00,500 --> 00:03:01,400
或者这款芯片呢

76
00:03:01,400 --> 00:03:03,400
叫做异构的SoC

77
00:03:03,400 --> 00:03:07,600
这款芯片有非常多不同的IP进行组合

78
00:03:07,600 --> 00:03:10,800
进行配合才能够正常的工作起来

79
00:03:10,800 --> 00:03:13,300
那这种情况呢我们叫做异构

80
00:03:13,300 --> 00:03:15,600
整个计算的体系

81
00:03:15,600 --> 00:03:17,500
因为我们的应用场景越来越丰富

82
00:03:17,500 --> 00:03:19,400
因为我们的计算的需求越来越多

83
00:03:19,400 --> 00:03:22,800
于是呢我们现在迎来了整个异构的体系

84
00:03:22,800 --> 00:03:25,600
异构的时代

85
00:03:25,600 --> 00:03:28,600
我们来看一下整个异构芯片的出现呢

86
00:03:28,600 --> 00:03:31,000
其实现在我们大部分的CPU呢

87
00:03:31,000 --> 00:03:33,000
都是采用冯洛依曼的架构

88
00:03:33,000 --> 00:03:34,000
那冯依曼的架构呢

89
00:03:34,000 --> 00:03:37,200
基本上就是我按指令顺序的去执行

90
00:03:37,200 --> 00:03:39,700
虽然这种方式呢确实有点低效

91
00:03:39,700 --> 00:03:41,600
于是呢就出现了Docker的处理器

92
00:03:41,600 --> 00:03:43,600
或者变成了一个集群的计算

93
00:03:43,600 --> 00:03:46,200
引入了并行计算这个概念

94
00:03:46,200 --> 00:03:47,600
那并行计算这个概念呢

95
00:03:47,600 --> 00:03:50,500
其实一开始呢是出现在我们的GPU

96
00:03:50,500 --> 00:03:52,300
但是GPU呢它其实自己

97
00:03:52,300 --> 00:03:53,900
是没有办法单独的工作的

98
00:03:53,900 --> 00:03:56,600
而是要跟CPU进行一个配合

99
00:03:56,600 --> 00:03:57,100
哎

100
00:03:57,100 --> 00:03:59,900
既然两种不同的架构在一起配合工作

101
00:03:59,900 --> 00:04:02,100
于是呢我们就迎来了第一种

102
00:04:02,100 --> 00:04:04,800
异构的芯片异构的工作流程

103
00:04:04,800 --> 00:04:06,100
下面我们来打开看一下

104
00:04:06,100 --> 00:04:08,100
它整体的GPU跟CPU的异构呢

105
00:04:08,100 --> 00:04:09,900
是怎么去

106
00:04:09,900 --> 00:04:11,800
首先呢

107
00:04:11,800 --> 00:04:13,900
CPU要处理一些工作的时候呢

108
00:04:13,900 --> 00:04:16,600
它会把一些数据存在里面的DWAM

109
00:04:16,600 --> 00:04:17,300
在第一步呢

110
00:04:17,300 --> 00:04:20,400
就会把DWAM的数据呢搬运到HBM

111
00:04:20,400 --> 00:04:22,300
也就是我们的显存

112
00:04:22,300 --> 00:04:24,800
GPU的显示内存里面

113
00:04:24,800 --> 00:04:25,600
接着呢

114
00:04:25,600 --> 00:04:26,900
在第二步的时候呢

115
00:04:26,900 --> 00:04:30,400
CPU就会发射一些相对应的指令

116
00:04:30,400 --> 00:04:31,900
给到GPU的CUDA Core

117
00:04:31,900 --> 00:04:33,700
或者GPU的

118
00:04:33,700 --> 00:04:35,500
真正的去执行计算

119
00:04:35,500 --> 00:04:36,500
那计算完之后呢

120
00:04:36,500 --> 00:04:38,500
GPU就会把相关的结果

121
00:04:38,500 --> 00:04:40,800
返回存储到HBM里面

122
00:04:40,800 --> 00:04:42,500
最后一步也就是step4

123
00:04:42,500 --> 00:04:45,000
step4会把一些GPU计算完的结果

124
00:04:45,000 --> 00:04:46,900
返回给我们的CPU

125
00:04:46,900 --> 00:04:47,900
那这个时候呢

126
00:04:47,900 --> 00:04:50,500
GPU计算的是一些特殊的加速

127
00:04:50,500 --> 00:04:53,900
或者特殊的需要进行并行的一些计算的功能

128
00:04:53,900 --> 00:04:56,800
这个时候CPU跟GPU之间的异构

129
00:04:56,800 --> 00:04:58,800
就非常之明显了

130
00:04:58,800 --> 00:05:01,600
CPU主要是用来处理一些

131
00:05:01,600 --> 00:05:03,600
应用逻辑程序

132
00:05:03,600 --> 00:05:04,500
而GPU呢

133
00:05:04,500 --> 00:05:06,000
在一开始出现的时候呢

134
00:05:06,000 --> 00:05:08,800
主要是来处理一些图形图像

135
00:05:08,800 --> 00:05:12,000
渲染的一些工作

136
00:05:12,000 --> 00:05:13,000
这五年呢

137
00:05:13,000 --> 00:05:14,800
我们又有非常多的芯片

138
00:05:14,800 --> 00:05:16,300
例如SIC的芯片呢

139
00:05:16,300 --> 00:05:18,600
就迎来了一个真正能够帮助

140
00:05:18,600 --> 00:05:20,000
AI应用做加速的

141
00:05:20,000 --> 00:05:21,200
像谷歌的TPU呢

142
00:05:21,200 --> 00:05:23,300
就从第一代V1 V2 V3 V4

143
00:05:23,300 --> 00:05:24,400
到现在的V4

144
00:05:24,400 --> 00:05:27,400
确实已经有很多专门为AI

145
00:05:27,400 --> 00:05:29,300
这个应用做加速的芯片

146
00:05:29,300 --> 00:05:30,200
而这些芯片呢

147
00:05:30,200 --> 00:05:31,800
除了通用的IO之外呢

148
00:05:31,800 --> 00:05:33,900
它最重要的一个核心模块就是

149
00:05:33,900 --> 00:05:36,800
针对AI的一个专用处理引擎

150
00:05:36,800 --> 00:05:37,800
我们的

151
00:05:39,700 --> 00:05:41,100
什么是异构之后呢

152
00:05:41,100 --> 00:05:42,800
我们现在来看看

153
00:05:42,800 --> 00:05:44,700
何为超异构

154
00:05:44,700 --> 00:05:46,600
里面有一个最重要的字眼

155
00:05:46,600 --> 00:05:48,600
就是一个超字了

156
00:05:48,600 --> 00:05:49,400
那下面这个图呢

157
00:05:49,400 --> 00:05:50,900
我们可以看到超异构的

158
00:05:50,900 --> 00:05:52,900
整体的一个关系

159
00:05:52,900 --> 00:05:54,200
我们除了有CPU

160
00:05:54,200 --> 00:05:55,400
有协处理器

161
00:05:55,400 --> 00:05:56,600
后来有了GPU

162
00:05:56,600 --> 00:05:58,000
到现在的NPU

163
00:05:58,000 --> 00:05:59,700
但后面还有一些DPU

164
00:05:59,700 --> 00:06:01,200
越来越多的芯片

165
00:06:01,200 --> 00:06:03,400
而越来越多的特殊的芯片呢

166
00:06:03,400 --> 00:06:06,100
主要是提供一些特殊的性能加速

167
00:06:06,100 --> 00:06:09,400
还有特殊的硬件的专用的处理

168
00:06:09,400 --> 00:06:11,900
针对某些应用场景

169
00:06:11,900 --> 00:06:13,800
走的这些芯片呢

170
00:06:13,800 --> 00:06:16,500
基本上就会越会针对某些应用

171
00:06:16,500 --> 00:06:18,000
或者某些计算场景

172
00:06:18,000 --> 00:06:20,300
做一些专用的硬件的提供

173
00:06:20,300 --> 00:06:21,100
它的性能呢

174
00:06:21,100 --> 00:06:23,600
也会更加的比一些通用的要高

175
00:06:23,600 --> 00:06:24,300
这个时候呢

176
00:06:24,300 --> 00:06:26,500
我们就迎来了一个最大的问题

177
00:06:26,500 --> 00:06:28,200
处理器的架构越来越多

178
00:06:28,200 --> 00:06:29,100
架构多了

179
00:06:29,100 --> 00:06:30,900
整个碎片化程度就会多

180
00:06:30,900 --> 00:06:34,100
构建整个生态的难度也会越来越大

181
00:06:37,100 --> 00:06:39,000
异构计算的发展历史

182
00:06:39,000 --> 00:06:41,200
我们从CPU简单的IO

183
00:06:41,200 --> 00:06:41,700
这种呢

184
00:06:41,700 --> 00:06:43,300
我们叫做同构

185
00:06:43,300 --> 00:06:45,900
或者直接说是串行计算就行了

186
00:06:45,900 --> 00:06:47,400
它连构都不是

187
00:06:47,400 --> 00:06:47,900
接着呢

188
00:06:47,900 --> 00:06:51,400
我们迎来了GPU跟CPU协同合作

189
00:06:51,400 --> 00:06:52,100
那这种呢

190
00:06:52,100 --> 00:06:54,700
慢慢的迎来了我们的异构

191
00:06:54,700 --> 00:06:55,200
当然呢

192
00:06:55,200 --> 00:06:59,900
我们现在更多的是CPU跟MPU进行协作的

193
00:06:59,900 --> 00:07:01,600
这种也是属于异构

194
00:07:01,600 --> 00:07:05,500
CPU同时也可以跟GPU进行一个协作处理

195
00:07:05,500 --> 00:07:08,700
那这种方式其实也属于一个异构的场景

196
00:07:08,700 --> 00:07:11,600
到未来或者未来接近的现在

197
00:07:11,600 --> 00:07:13,400
我们出现了超异构的架构

198
00:07:13,400 --> 00:07:15,800
中间连接的可能就已经不是CPU

199
00:07:15,800 --> 00:07:18,500
而是我们的DPU数据处理单元

200
00:07:18,500 --> 00:07:19,400
数据处理单元呢

201
00:07:19,400 --> 00:07:22,800
可以跟GPU、MPU还有我们的IO、CPU之间

202
00:07:22,800 --> 00:07:24,200
互相的协作

203
00:07:24,200 --> 00:07:24,800
而CPU呢

204
00:07:24,800 --> 00:07:27,400
又可以跟我们的GPU进行互相的协作

205
00:07:27,400 --> 00:07:29,800
当然可能CPU会跟我们的MPU

206
00:07:29,800 --> 00:07:31,400
或者MPU跟我们的GPU呢

207
00:07:31,400 --> 00:07:32,600
进行互相的协作

208
00:07:32,600 --> 00:07:34,600
我们举一个非常简单的例子

209
00:07:34,600 --> 00:07:35,100
现在呢

210
00:07:35,100 --> 00:07:36,100
我有一个场景

211
00:07:36,100 --> 00:07:38,200
例如我们三维的场景

212
00:07:38,200 --> 00:07:39,100
我们的Nerf

213
00:07:39,100 --> 00:07:39,600
Nerf呢

214
00:07:39,600 --> 00:07:42,900
现在可以用MPU进行一些三维的加速

215
00:07:42,900 --> 00:07:43,800
加速完之后呢

216
00:07:43,800 --> 00:07:45,100
我要显示的时候

217
00:07:45,100 --> 00:07:47,300
交给GPU进行处理

218
00:07:47,300 --> 00:07:48,800
GPU处理完之后呢

219
00:07:48,800 --> 00:07:49,700
最终显示

220
00:07:49,700 --> 00:07:51,500
返回给用户显示的应用呢

221
00:07:51,500 --> 00:07:54,300
由我们的GPU进行调度

222
00:07:54,300 --> 00:07:55,400
那这种场景呢

223
00:07:55,400 --> 00:07:59,200
就是我们超异构架构所会使用到的

224
00:08:00,300 --> 00:08:00,800
因此呢

225
00:08:00,800 --> 00:08:02,300
我们从刚才那个图呢

226
00:08:02,300 --> 00:08:03,500
我们可以看到计算呢

227
00:08:03,500 --> 00:08:07,100
我们从异构并行走向了超异构并行

228
00:08:07,900 --> 00:08:10,100
简单的两层CPU加GPU

229
00:08:10,100 --> 00:08:11,500
或者CPU加NPU

230
00:08:11,500 --> 00:08:12,900
到现在的三层

231
00:08:12,900 --> 00:08:15,400
甚至更高层的CPU加GPU

232
00:08:15,400 --> 00:08:16,900
同时加上XPU

233
00:08:16,900 --> 00:08:19,300
就我们的NPU TPU或者DPU

234
00:08:19,300 --> 00:08:21,000
同时协同的工作

235
00:08:21,000 --> 00:08:21,600
这个时候呢

236
00:08:21,600 --> 00:08:24,700
我们就真正的迈进了超异构并行架构里面了

237
00:08:26,100 --> 00:08:27,200
超异构计算里面呢

238
00:08:27,200 --> 00:08:30,900
其实这里面并不是简单的对一些芯片

239
00:08:30,900 --> 00:08:33,500
或者我们的整个系统进行简单的集成

240
00:08:33,500 --> 00:08:36,900
而是把更多的异构计算重整起来

241
00:08:37,000 --> 00:08:39,100
变成一个新的架构体系

242
00:08:39,100 --> 00:08:40,700
各种各样的处理器呢

243
00:08:40,700 --> 00:08:43,000
非常之良好的配合的工作

244
00:08:43,000 --> 00:08:45,600
形成了整一个超异构计算的体系

245
00:08:45,600 --> 00:08:47,800
我们为什么要去强调计算体系呢

246
00:08:47,800 --> 00:08:50,400
因为它是一个整体的解决方案

247
00:08:50,400 --> 00:08:54,300
而不仅是把架构服务器堆叠起来

248
00:08:56,600 --> 00:08:57,200
内容里面呢

249
00:08:57,200 --> 00:08:59,100
其实我们讲了很多不同的概念

250
00:08:59,100 --> 00:08:59,600
这里面呢

251
00:08:59,600 --> 00:09:01,700
我们简单的做一个汇总

252
00:09:01,700 --> 00:09:02,700
那在第一个阶段呢

253
00:09:02,700 --> 00:09:06,600
就是由单引擎串行的我们的单核的CPU

254
00:09:06,600 --> 00:09:07,900
到在第二个阶段呢

255
00:09:07,900 --> 00:09:09,800
就是我们的同构并行

256
00:09:09,800 --> 00:09:10,700
所谓的同构呢

257
00:09:10,700 --> 00:09:12,400
可能就是多核的CPU

258
00:09:12,400 --> 00:09:15,000
或者多核的GPU独立的工作

259
00:09:15,000 --> 00:09:16,100
到第三个阶段

260
00:09:16,100 --> 00:09:19,000
也就是我们现在所处的阶段

261
00:09:19,000 --> 00:09:22,200
是主要是两层的两种的类型的并行

262
00:09:22,200 --> 00:09:23,700
例如CPU加GPU

263
00:09:23,700 --> 00:09:26,600
或者CPU加NPU这种方式

264
00:09:26,600 --> 00:09:28,200
到未来我们在未来呢

265
00:09:28,200 --> 00:09:31,100
或者现在我们正在处于的一个变革时代

266
00:09:31,100 --> 00:09:32,600
就是三种以上的

267
00:09:32,600 --> 00:09:35,500
三层以上的类型不同的处理器

268
00:09:35,600 --> 00:09:37,500
我们叫做超异构并行

269
00:09:37,500 --> 00:09:38,800
从CPU加GPU

270
00:09:38,800 --> 00:09:40,300
再NPU再DPU

271
00:09:40,300 --> 00:09:41,900
互相的配合工作

272
00:09:41,900 --> 00:09:43,900
就变成了我们超异构并行的架构

273
00:09:46,000 --> 00:09:47,600
这种超异构并行的架构呢

274
00:09:47,600 --> 00:09:49,000
有两个主要的特点

275
00:09:49,000 --> 00:09:49,700
第一个特点呢

276
00:09:49,700 --> 00:09:52,500
就是超大规模的计算集群

277
00:09:53,400 --> 00:09:54,100
第二个特点呢

278
00:09:54,100 --> 00:09:56,900
就是计算系统非常的复杂

279
00:09:56,900 --> 00:09:59,500
分块分层去组成的

280
00:09:59,500 --> 00:10:00,400
可能应用层呢

281
00:10:00,400 --> 00:10:01,700
我们会使用CPU

282
00:10:01,700 --> 00:10:02,800
特殊的应用加速呢

283
00:10:02,800 --> 00:10:03,700
我们会使用GPU

284
00:10:03,700 --> 00:10:05,600
ASIC还有DPU或者NPU

285
00:10:05,600 --> 00:10:06,700
各种各样的

286
00:10:06,700 --> 00:10:08,500
而基础的网络设施啊

287
00:10:08,500 --> 00:10:10,600
我们又会有独特的

288
00:10:10,600 --> 00:10:13,300
特殊的一些PU进行给我们处理

289
00:10:13,300 --> 00:10:15,700
所以它形成了一个超大规模的集群

290
00:10:18,200 --> 00:10:21,100
不过我们来到了一个超异构的并行架构了

291
00:10:21,100 --> 00:10:23,300
确实也遇到很多问题

292
00:10:23,300 --> 00:10:24,300
最大的一个问题呢

293
00:10:24,300 --> 00:10:26,200
钟敏觉得就是单处理器

294
00:10:26,200 --> 00:10:29,100
我们现在有非常多不同形态的架构

295
00:10:29,100 --> 00:10:30,900
这些架构之间怎么去兼容

296
00:10:30,900 --> 00:10:32,000
怎么去配合

297
00:10:32,000 --> 00:10:33,900
怎么去灵活的使用

298
00:10:33,900 --> 00:10:35,500
这是一个最大的问题

299
00:10:35,500 --> 00:10:36,000
于是呢

300
00:10:36,000 --> 00:10:39,900
就引入了我们最后一个内容

301
00:10:39,900 --> 00:10:42,100
超异构架构的挑战

302
00:10:42,100 --> 00:10:44,300
和关于超异构架构的思考

303
00:10:45,400 --> 00:10:46,900
一个很直观的问题就是

304
00:10:46,900 --> 00:10:49,800
面对如此复杂的超异构的架构

305
00:10:49,800 --> 00:10:52,600
我们应该如何很好的去驾驭

306
00:10:52,600 --> 00:10:53,800
这个超异构间呢

307
00:10:53,800 --> 00:10:56,500
钟敏结合了非常多的idea

308
00:10:56,500 --> 00:10:57,500
然后呢

309
00:10:57,500 --> 00:10:58,600
做了一个总结

310
00:10:58,600 --> 00:11:00,500
首先我们看看软件层

311
00:11:00,500 --> 00:11:03,000
软件层我们肯定是跨平台的

312
00:11:03,000 --> 00:11:03,800
跨不同处理器

313
00:11:03,800 --> 00:11:04,600
跨厂商

314
00:11:04,600 --> 00:11:05,300
跨不同位置

315
00:11:05,300 --> 00:11:06,800
跨不同的设备

316
00:11:06,800 --> 00:11:09,100
所以我们的软件架构的复杂性

317
00:11:09,100 --> 00:11:10,700
会急剧的增长

318
00:11:10,700 --> 00:11:12,700
成为一个最大的挑战

319
00:11:12,700 --> 00:11:14,000
也就是我们的软件

320
00:11:14,000 --> 00:11:16,100
面对这些软件的挑战呢

321
00:11:16,100 --> 00:11:19,600
我们应该更多的是开放整个生态

322
00:11:19,600 --> 00:11:20,900
介入整个社区

323
00:11:20,900 --> 00:11:21,400
这里面呢

324
00:11:21,400 --> 00:11:24,800
像英伟达的CUDA就做得非常非常的好

325
00:11:24,800 --> 00:11:27,900
它开放了自己的整个编程的体系

326
00:11:27,900 --> 00:11:29,400
虽然CUDA它这个语言呢

327
00:11:29,400 --> 00:11:31,000
是没有去开源的

328
00:11:31,000 --> 00:11:32,800
里面的编译层也没有开源

329
00:11:32,800 --> 00:11:35,600
但是它整套编译体系是开放出来了

330
00:11:35,600 --> 00:11:37,200
让更多的人去介入

331
00:11:37,200 --> 00:11:40,800
也形成了现在GPU的一个非常之良好的生态

332
00:11:40,800 --> 00:11:41,500
那第二种呢

333
00:11:41,500 --> 00:11:43,900
就是我们的软件需要兼容

334
00:11:43,900 --> 00:11:45,500
更好的去AI芯片

335
00:11:45,500 --> 00:11:48,000
我觉得很多厂商也在做

336
00:11:48,000 --> 00:11:49,700
但是在软件兼容方面呢

337
00:11:49,700 --> 00:11:51,000
确实也挺困难的

338
00:11:51,000 --> 00:11:53,000
怎么形成一个软件兼容方面

339
00:11:53,000 --> 00:11:55,100
是做得非常之头痛的

340
00:11:55,100 --> 00:11:57,100
未来Pytorch 2.0呢

341
00:11:57,100 --> 00:11:58,300
确实有这种趋势

342
00:11:58,300 --> 00:12:01,600
慢慢的去做一些软件的篮下的兼容

343
00:12:01,600 --> 00:12:03,400
那第三就是开放接口

344
00:12:03,400 --> 00:12:04,700
或者开放架构

345
00:12:04,700 --> 00:12:06,400
还有开放的生态

346
00:12:06,400 --> 00:12:08,400
形成整体的标准

347
00:12:08,400 --> 00:12:10,600
那开放这个事情很重要

348
00:12:10,600 --> 00:12:13,500
那这是上面硬件体系能够做的

349
00:12:13,500 --> 00:12:17,400
再往下来就是开放整体的硬件的架构

350
00:12:17,400 --> 00:12:18,700
像现在的WiFi呢

351
00:12:18,700 --> 00:12:20,800
就是一个非常之开放的硬件架构

352
00:12:20,800 --> 00:12:22,500
这也是我们现

353
00:12:22,500 --> 00:12:23,700
第二个问题就是

354
00:12:23,700 --> 00:12:25,700
到底是硬件定义软件呢

355
00:12:25,700 --> 00:12:27,800
还是软件定义硬件呢

356
00:12:27,800 --> 00:12:30,200
在这么一个超异构架构平台里面

357
00:12:30,200 --> 00:12:33,400
我到底应该怎么去定义我们的产品

358
00:12:33,400 --> 00:12:35,600
怎么定义我们的解决方案呢

359
00:12:35,600 --> 00:12:36,300
那这个时候呢

360
00:12:36,300 --> 00:12:38,600
我们看一下所谓的软件定义硬件

361
00:12:38,600 --> 00:12:41,000
和硬件定义软件到底有什么区别

362
00:12:41,000 --> 00:12:42,700
那硬件定义软件的这种

363
00:12:42,700 --> 00:12:43,700
其实是很明确的

364
00:12:43,700 --> 00:12:47,400
像CPU或者我们的GPU就很明确

365
00:12:47,400 --> 00:12:48,600
我们的硬件架构

366
00:12:48,600 --> 00:12:50,800
我们的硬件的体系就这么定了

367
00:12:50,800 --> 00:12:51,800
你的软件

368
00:12:51,800 --> 00:12:54,000
你必须要去适配我的硬件

369
00:12:54,000 --> 00:12:55,700
你必须要去学

370
00:12:55,700 --> 00:12:57,100
CUDA是怎么写的

371
00:12:57,100 --> 00:12:59,500
你必须要学C++是怎么写的

372
00:12:59,500 --> 00:13:01,700
你才能够把他们的软件

373
00:13:01,700 --> 00:13:03,600
跑在具体的硬件上面

374
00:13:03,600 --> 00:13:05,200
而软件定硬件

375
00:13:05,200 --> 00:13:07,100
其实这个也很好理解

376
00:13:07,100 --> 00:13:09,500
我们现在AI应用的大部分开发者

377
00:13:09,500 --> 00:13:11,600
都是基于PyTorch或者Python

378
00:13:11,600 --> 00:13:13,500
来去写他们的一些语言

379
00:13:13,500 --> 00:13:14,300
而这个时候

380
00:13:14,300 --> 00:13:16,000
他们并不是很关心

381
00:13:16,000 --> 00:13:17,200
我写完的Python

382
00:13:17,200 --> 00:13:19,000
到底是执行在GPU

383
00:13:19,000 --> 00:13:20,900
NPU还是TPU里面

384
00:13:20,900 --> 00:13:22,000
里面只要是要改了

385
00:13:22,000 --> 00:13:24,100
Torch.NPUTorch.Devices

386
00:13:24,100 --> 00:13:26,300
就可以执行在不同的硬件上面

387
00:13:26,300 --> 00:13:30,200
那这种就是软件定义硬件的一些Demo

388
00:13:30,200 --> 00:13:31,800
或者我们的一个例子

389
00:13:31,800 --> 00:13:34,600
最后一种就是软硬件协同定义

390
00:13:34,600 --> 00:13:36,200
那这种其实现在来看

391
00:13:36,200 --> 00:13:38,200
没有太多相关的内容

392
00:13:38,200 --> 00:13:39,300
或者太多的Demo

393
00:13:39,300 --> 00:13:41,500
这也是我们在不断的演进当中

394
00:13:41,500 --> 00:13:44,700
确实衍生了越来越多的新的

395
00:13:47,000 --> 00:13:48,300
硬件定义软件也好

396
00:13:48,300 --> 00:13:49,800
还是软件定义也好

397
00:13:49,800 --> 00:13:52,800
其实这个是跟我们的整体系统复杂度

398
00:13:52,800 --> 00:13:53,800
是相关的

399
00:13:53,900 --> 00:13:57,300
CPU和GPU它有非常大的区别

400
00:13:57,300 --> 00:14:00,700
CPU就是我大部分都是比较擅长于

401
00:14:00,700 --> 00:14:02,400
还有一些操作系统的承载

402
00:14:02,400 --> 00:14:05,000
而GPU更多的是对图形图像

403
00:14:05,000 --> 00:14:07,900
或者并行计算的进行一些加速

404
00:14:07,900 --> 00:14:09,400
那其实整体来说

405
00:14:09,400 --> 00:14:10,600
不管是软件定义硬件

406
00:14:10,600 --> 00:14:12,800
还是硬件定义软件

407
00:14:12,800 --> 00:14:14,600
问题就是我们这个系统

408
00:14:14,600 --> 00:14:16,400
应该怎么去定义

409
00:14:16,400 --> 00:14:18,800
其实这个问题非常非常的抽象

410
00:14:18,800 --> 00:14:20,700
也非常非常的难回答

411
00:14:20,700 --> 00:14:22,000
而我们现在回顾一下

412
00:14:22,000 --> 00:14:25,000
整个计算的体系和编译的体系

413
00:14:25,000 --> 00:14:26,400
虽然我们的计算系统

414
00:14:26,400 --> 00:14:28,300
或者我们的超异构系统很难定义

415
00:14:28,300 --> 00:14:30,600
但很多时候我们更多的是依靠于

416
00:14:30,600 --> 00:14:33,900
我们的去承载的具体的计算

417
00:14:33,900 --> 00:14:36,000
是由我们的编译去决定的

418
00:14:36,000 --> 00:14:38,400
我们很多时候各类各样的应用

419
00:14:38,400 --> 00:14:41,300
大部分怎么跑在不同的芯片上面

420
00:14:41,300 --> 00:14:43,200
靠的就是我们的编译体系

421
00:14:43,200 --> 00:14:45,500
而计算体系其实基本上都是定型的

422
00:14:45,500 --> 00:14:48,700
根据我们的计算的原则来去定义

423
00:14:48,700 --> 00:14:50,300
有了这计算的原则之后

424
00:14:50,300 --> 00:14:52,600
就需要去定义我们的编译体系

425
00:14:52,600 --> 00:14:55,100
就需要反向的去对我们的编译体系

426
00:14:55,100 --> 00:14:57,000
提出各种各样的需求

427
00:14:57,000 --> 00:14:59,000
那最后我们来到最后一个内容

428
00:14:59,000 --> 00:15:01,500
就是在整体整个系统来看

429
00:15:01,500 --> 00:15:04,100
我觉得一点就是计算的资源

430
00:15:04,100 --> 00:15:05,600
必须要中心化

431
00:15:05,600 --> 00:15:07,700
把不同的计算的孤岛连接起来

432
00:15:07,700 --> 00:15:08,700
把GPU连接起来

433
00:15:08,700 --> 00:15:10,000
把CPU连接起来

434
00:15:10,000 --> 00:15:11,500
把NPU连接起来

435
00:15:11,500 --> 00:15:13,400
实现整个资源的词化

436
00:15:13,400 --> 00:15:15,400
特别是计算资源的词化

437
00:15:15,400 --> 00:15:18,300
提升整体系统的算力用率

438
00:15:18,300 --> 00:15:21,200
而不是单块芯片的算力利用率

439
00:15:21,200 --> 00:15:24,600
是整个系统的算力利用率

440
00:15:24,600 --> 00:15:27,000
那这个时候我们回顾一下

441
00:15:27,000 --> 00:15:29,600
刚才所讲的两个内容

442
00:15:29,600 --> 00:15:33,000
第一个就是跨平台统一整个计算架构

443
00:15:33,000 --> 00:15:36,800
把一些孤岛的计算资源连接起来

444
00:15:36,800 --> 00:15:39,200
第二个就是超异构时代

445
00:15:39,200 --> 00:15:41,900
我们要形成一个整体的开放的程序

446
00:15:41,900 --> 00:15:43,000
开放的生态

447
00:15:43,000 --> 00:15:44,600
让更多的计算资源

448
00:15:44,600 --> 00:15:47,200
连接到我们整个中心里面

449
00:15:47,200 --> 00:15:51,500
满足我们对更多的计算的渴求

450
00:15:51,500 --> 00:15:52,800
有了上面点之后

451
00:15:52,800 --> 00:15:54,700
就来到了我们的软硬件

452
00:15:54,700 --> 00:15:56,200
需要共同的去定义

453
00:15:56,200 --> 00:15:57,300
而不像以前

454
00:15:57,300 --> 00:15:59,100
可能某个软件定义硬件

455
00:15:59,100 --> 00:16:00,700
或者有硬件定义软件

456
00:16:00,700 --> 00:16:02,500
而是相互组成

457
00:16:02,500 --> 00:16:04,300
整个超异构生态开放

458
00:16:04,300 --> 00:16:09,000
去迎接我们未来新的应用场景

459
00:16:09,000 --> 00:16:12,000
针对未来计算体系的黄金十年

460
00:16:12,000 --> 00:16:14,000
我们总结了三个内容

461
00:16:14,000 --> 00:16:16,100
第一个内容就是超异构的计算架构

462
00:16:16,100 --> 00:16:18,900
我们确实已经开始慢慢到来了

463
00:16:18,900 --> 00:16:20,800
从CPU GPU FHA到DSA

464
00:16:20,800 --> 00:16:23,500
到各种PU的融合

465
00:16:23,500 --> 00:16:25,300
第二个就是我们需要平台化

466
00:16:25,300 --> 00:16:26,700
可编程化

467
00:16:26,700 --> 00:16:28,200
第三个就是我们需要建立

468
00:16:28,200 --> 00:16:29,600
整个标准的体系

469
00:16:29,600 --> 00:16:31,400
还有开放整个生态的接口

470
00:16:31,400 --> 00:16:34,400
我们才能够让整个超异构的计算架构

471
00:16:34,400 --> 00:16:37,200
更好的发挥它的计算的算力

472
00:16:37,200 --> 00:16:40,200
更好的利用好每一个算力程序

473
00:16:40,200 --> 00:16:42,500
今天的内容就到这里为止

474
00:16:42,500 --> 00:16:44,100
虽然讲的有点虚

475
00:16:44,200 --> 00:16:45,000
谢谢各位

476
00:16:45,000 --> 00:16:45,800
摆了个拜

