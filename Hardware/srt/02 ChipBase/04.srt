1
00:00:00,000 --> 00:00:05,840
Hello 大家好

2
00:00:05,840 --> 00:00:06,840
我是周密

3
00:00:06,840 --> 00:00:10,120
我发现环境真的会影响人类的身体健康的

4
00:00:10,120 --> 00:00:14,440
我在办公室的时候经常头疼腰疼屁股疼

5
00:00:14,440 --> 00:00:17,800
回到家之后我发现哪都不疼了

6
00:00:17,800 --> 00:00:21,840
那今天我们还是在AI芯片基础这一个大系列里面

7
00:00:21,840 --> 00:00:25,280
今天我要给大家去分享的就是计算的诗言

8
00:00:25,280 --> 00:00:26,680
Latent

9
00:00:26,680 --> 00:00:29,200
我们来看看计算诗言有什么不一样

10
00:00:29,200 --> 00:00:33,160
今天我们主要还是在从数据看CPU计算

11
00:00:33,160 --> 00:00:35,400
这一个小内容里面

12
00:00:35,400 --> 00:00:40,480
还记得CPU里面的数据的读取速度是200GB的每second

13
00:00:40,480 --> 00:00:45,000
而CPU的Flops计算能力是2000G Flops

14
00:00:45,000 --> 00:00:47,120
对应的单位都是Fp16

15
00:00:47,120 --> 00:00:51,280
这个时候计算的强度就等于Flops除以我们的Data Rate

16
00:00:51,280 --> 00:00:54,880
就是数据的传输速率得到我们的一个80的值

17
00:00:54,880 --> 00:00:58,200
这个80的值就意味着我们对每一个数据

18
00:00:58,240 --> 00:01:00,560
都要进行80次操作

19
00:01:00,560 --> 00:01:04,720
才能够达到一种计算跟数据传输速率的平衡

20
00:01:04,720 --> 00:01:06,560
不过像这种前一节课里面

21
00:01:06,560 --> 00:01:09,400
周敏介给大家汇报了CPU里面

22
00:01:09,400 --> 00:01:11,720
实际上Flops不是说最重要的

23
00:01:11,720 --> 00:01:14,160
更重要的是我们的数据传输的速率

24
00:01:14,160 --> 00:01:16,760
我们的数据应该怎么去算

25
00:01:16,760 --> 00:01:17,640
而我们其实

26
00:01:19,000 --> 00:01:23,320
现在我们继续回到AS加B这个例子

27
00:01:23,320 --> 00:01:24,840
去看看整体的Demo

28
00:01:24,880 --> 00:01:28,760
那下面就是我们ASRB的一个C++的代码

29
00:01:28,760 --> 00:01:31,120
里面就有两个运算

30
00:01:31,120 --> 00:01:32,640
那一个就是加法

31
00:01:32,640 --> 00:01:34,600
一个就是乘法

32
00:01:34,600 --> 00:01:37,360
而这里面有两个内存的读取

33
00:01:37,360 --> 00:01:39,920
内存的读取第一个就是XI

34
00:01:39,920 --> 00:01:41,280
第二个就是YI

35
00:01:41,280 --> 00:01:43,080
都是足元数的去读取的

36
00:01:43,080 --> 00:01:44,760
这一条公式展开

37
00:01:44,960 --> 00:01:48,600
就变成Y等于AS加B这种方式了

38
00:01:48,600 --> 00:01:51,640
而这里面有一个独特的操作

39
00:01:51,640 --> 00:01:54,840
就是我们可以用一个指令来去代替

40
00:01:54,840 --> 00:01:58,040
例如FMA Fuse Multiply and Add

41
00:01:58,040 --> 00:02:00,760
就是把乘法和加法融合成一个指令

42
00:02:00,760 --> 00:02:02,560
当然了我们在之前也讲过

43
00:02:02,560 --> 00:02:04,160
可以叫做MAC

44
00:02:04,160 --> 00:02:05,560
通过这么一个简单的例子

45
00:02:05,680 --> 00:02:08,760
我们去看看整体的食盐是怎么产生的

46
00:02:09,200 --> 00:02:11,480
下面我们以这个图

47
00:02:11,480 --> 00:02:13,840
这个图就是我们的指令的流水

48
00:02:13,840 --> 00:02:16,040
我们叫做Instruction Pipeline

49
00:02:16,040 --> 00:02:17,320
指令流水

50
00:02:17,320 --> 00:02:20,120
下面我们打开看看这个指令流水

51
00:02:20,120 --> 00:02:22,560
首先我们需要从内存里面

52
00:02:22,560 --> 00:02:25,440
去读取我们的一个元素X0

53
00:02:25,440 --> 00:02:29,080
接着我们同时去读取另外一个元素Y0

54
00:02:29,080 --> 00:02:31,640
因为X0和Y0之间没有依赖关系

55
00:02:31,640 --> 00:02:35,280
所以我们可以同时的从D1里面去读取

56
00:02:35,280 --> 00:02:36,680
读取的过程当中

57
00:02:36,680 --> 00:02:39,040
就会产生一个memory的latency

58
00:02:39,040 --> 00:02:41,240
就是我们的内存的食盐

59
00:02:41,240 --> 00:02:43,440
这个就是我们今天所关注的内容

60
00:02:43,440 --> 00:02:46,120
读完之后我就可以read from cache

61
00:02:46,120 --> 00:02:48,120
就是写到我们的cache里面

62
00:02:48,160 --> 00:02:50,080
接着我们的控制器

63
00:02:50,200 --> 00:02:51,880
就会从我们的cache里面

64
00:02:51,880 --> 00:02:53,600
或者从我们的计算器里面

65
00:02:53,600 --> 00:02:55,560
去读取我们的X0

66
00:02:55,560 --> 00:02:58,440
同时我们也可以去读取Y0

67
00:02:58,680 --> 00:03:00,400
我们先去读取X0

68
00:03:00,400 --> 00:03:03,760
然后执行Ax的操作

69
00:03:04,080 --> 00:03:06,240
A我们同样也是一个元素

70
00:03:06,400 --> 00:03:08,360
类似里面cache里面的一个元素

71
00:03:08,360 --> 00:03:09,440
我们需要读取

72
00:03:09,440 --> 00:03:10,520
然后层的操作

73
00:03:10,680 --> 00:03:13,200
其实我们的复计算的非常的快

74
00:03:13,200 --> 00:03:15,800
只占了中间的这么一小撮时间

75
00:03:15,800 --> 00:03:17,360
接着就写回结果

76
00:03:17,360 --> 00:03:18,200
写回结果之后

77
00:03:18,520 --> 00:03:19,720
我的Y0得到了

78
00:03:19,720 --> 00:03:21,960
我的Ax的结果得到了

79
00:03:21,960 --> 00:03:24,560
接着做一个加Y的操作

80
00:03:24,560 --> 00:03:26,080
然后加的操作

81
00:03:26,080 --> 00:03:28,400
同样也需要点时间

82
00:03:28,400 --> 00:03:30,640
最后计算完As加B之后

83
00:03:30,960 --> 00:03:32,640
就写回结果

84
00:03:32,640 --> 00:03:34,120
写回到我们的cache里面

85
00:03:34,120 --> 00:03:35,600
至于后面要不要写回内存

86
00:03:35,600 --> 00:03:37,120
就是另外一个事情了

87
00:03:37,120 --> 00:03:39,760
可以看到在整体的计算过程

88
00:03:39,760 --> 00:03:41,640
在我们的instruction pipeline

89
00:03:41,640 --> 00:03:43,160
指令流水过程中

90
00:03:43,160 --> 00:03:45,480
最耗时的是我们的memory

91
00:03:46,360 --> 00:03:48,280
我们的内存的时延

92
00:03:49,560 --> 00:03:52,960
现在我们看几个物理上的一个意义和概念

93
00:03:52,960 --> 00:03:54,920
就是光和电的传播速度

94
00:03:54,920 --> 00:03:58,000
可以看到光的传播速度

95
00:03:58,000 --> 00:04:01,080
是30万公里每秒

96
00:04:01,080 --> 00:04:02,480
非常非常的快

97
00:04:02,480 --> 00:04:05,320
大家都知道光的传播速度是更快的

98
00:04:05,320 --> 00:04:07,680
但是我们有一个非常夸张的数据

99
00:04:07,680 --> 00:04:10,000
就是计算机的频率

100
00:04:10,000 --> 00:04:10,960
时钟周期

101
00:04:10,960 --> 00:04:11,840
计算机的频率

102
00:04:11,920 --> 00:04:14,000
我们可以克制每秒

103
00:04:14,480 --> 00:04:16,200
这个是我们在一个时钟周期内

104
00:04:16,400 --> 00:04:18,040
光的传播速度是

105
00:04:18,320 --> 00:04:19,120
10厘米

106
00:04:19,120 --> 00:04:20,720
也就是100毫秒

107
00:04:21,080 --> 00:04:22,840
下面我们看第2个数据

108
00:04:22,840 --> 00:04:25,120
我们的电流的传播速度

109
00:04:25,360 --> 00:04:28,320
电流主要是指在我们的硅芯片里面的

110
00:04:28,320 --> 00:04:29,040
传播速度

111
00:04:29,040 --> 00:04:31,880
只是光的1 3分之1

112
00:04:32,400 --> 00:04:33,920
公里每秒

113
00:04:34,120 --> 00:04:37,520
这个时候我们就得出一个比较有意思的规律

114
00:04:37,520 --> 00:04:38,800
就是一个时钟周期内

115
00:04:39,240 --> 00:04:41,480
电流的传播速度

116
00:04:41,520 --> 00:04:43,960
是20毫秒

117
00:04:44,800 --> 00:04:46,640
我们现在有一款芯片

118
00:04:46,640 --> 00:04:47,400
或者有一个系统

119
00:04:47,400 --> 00:04:48,120
我们有CPU

120
00:04:48,120 --> 00:04:48,920
还有DWAM

121
00:04:48,920 --> 00:04:52,720
我们只是简单的从CPU传到我们的DWAM里面

122
00:04:52,720 --> 00:04:55,640
它的一个距离大概是5到10毫秒

123
00:04:55,640 --> 00:04:59,120
也就是使用了我们5 6个时钟周期了

124
00:04:59,120 --> 00:05:00,480
5 6个时钟周期

125
00:05:00,480 --> 00:05:02,720
这就是产生了我们的食盐

126
00:05:02,720 --> 00:05:04,960
而计算机里面一个时钟周期

127
00:05:04,960 --> 00:05:08,400
ALU可以执行非常多个FLOP的计算

128
00:05:08,400 --> 00:05:11,520
就每秒执行几亿万次的时钟周期计算

129
00:05:12,000 --> 00:05:15,480
这么多的生了我们的食盐的问题了

130
00:05:16,480 --> 00:05:18,560
还是站在一个整体系统的角度

131
00:05:18,560 --> 00:05:19,680
去看待问题的

132
00:05:19,680 --> 00:05:21,920
如果我们放在处理器内部

133
00:05:21,920 --> 00:05:23,720
我们放在晶体管内部

134
00:05:23,720 --> 00:05:26,160
实际上数据之间的搬运

135
00:05:26,160 --> 00:05:28,400
就是把一个晶体管里面的数据

136
00:05:28,400 --> 00:05:31,160
传输到另外一组晶体管

137
00:05:31,760 --> 00:05:33,720
刚才就用了晶体管里面的

138
00:05:33,720 --> 00:05:35,160
数据的传输速率

139
00:05:35,200 --> 00:05:37,000
去反弹我们系统里面

140
00:05:37,000 --> 00:05:39,000
跟我们数据之间的一个关系

141
00:05:39,000 --> 00:05:41,120
里面就引出了一个食盐

142
00:05:41,360 --> 00:05:43,800
现在我们还是以AS加Y

143
00:05:43,800 --> 00:05:45,480
这个demo作为例子

144
00:05:45,480 --> 00:05:47,800
现在我们左边有一款芯片

145
00:05:47,800 --> 00:05:49,960
假设是英特尔的一款芯片

146
00:05:49,960 --> 00:05:52,520
里面的有两个主要的指标单位

147
00:05:53,280 --> 00:05:54,680
是我们的内存带宽

148
00:05:54,680 --> 00:05:56,920
内存带宽有131GB

149
00:05:56,920 --> 00:05:59,120
每秒能够传输那么多数据

150
00:05:59,120 --> 00:06:01,920
第二个内容就是memory的latency

151
00:06:01,920 --> 00:06:05,280
我们的内存的食盐是89纳秒

152
00:06:05,280 --> 00:06:07,400
这就意味着在89纳秒以内

153
00:06:07,520 --> 00:06:12,400
能够传输11659个字节的内容

154
00:06:12,720 --> 00:06:14,480
这样的话我们在89纳秒以内

155
00:06:14,680 --> 00:06:20,240
最多可以传输11659个字节

156
00:06:20,240 --> 00:06:21,760
而我们刚才的demo

157
00:06:22,040 --> 00:06:23,560
是AS加Y这个demo

158
00:06:23,760 --> 00:06:25,760
然后传输了16个字节

159
00:06:25,760 --> 00:06:28,440
也就是X0和Y0

160
00:06:28,440 --> 00:06:30,240
在89纳秒以内

161
00:06:30,640 --> 00:06:32,600
这个时候我们16个字节

162
00:06:32,600 --> 00:06:35,160
对比11065个字节

163
00:06:35,160 --> 00:06:36,640
整个内存的利用率

164
00:06:36,640 --> 00:06:38,800
内存的效率只有0.14

165
00:06:38,800 --> 00:06:40,720
是非常低的

166
00:06:40,720 --> 00:06:42,800
反观我们看一看

167
00:06:42,800 --> 00:06:43,840
有个最大的问题

168
00:06:43,840 --> 00:06:47,120
就是现在我们虽然在Intel S

169
00:06:47,120 --> 00:06:48,000
这块芯片里面

170
00:06:48,000 --> 00:06:49,560
传输那么多数据

171
00:06:49,560 --> 00:06:51,120
但是0.14

172
00:06:51,120 --> 00:06:53,320
已经是整个AMD

173
00:06:53,320 --> 00:06:55,000
英特尔英伟达里面

174
00:06:55,000 --> 00:06:56,680
数据传输效率

175
00:06:56,680 --> 00:06:58,720
内存利用率最高的

176
00:06:58,720 --> 00:07:00,840
为什么会有这种情况发生

177
00:07:01,160 --> 00:07:02,520
为什么英伟达更低

178
00:07:03,080 --> 00:07:04,640
这个时候我们就很有意思

179
00:07:04,640 --> 00:07:06,280
这涉及到我们的计算

180
00:07:06,400 --> 00:07:07,360
我们的计算

181
00:07:07,360 --> 00:07:09,600
刚才只是搬运了少量的数据

182
00:07:09,600 --> 00:07:11,200
而英伟达A100

183
00:07:11,200 --> 00:07:12,200
或者我们的GPU

184
00:07:12,560 --> 00:07:14,640
大部分都是对我们大量的数据

185
00:07:14,640 --> 00:07:15,920
进行大量的计算

186
00:07:15,920 --> 00:07:18,680
同一组数据进行非常之夸张

187
00:07:18,680 --> 00:07:20,040
惊人的计算

188
00:07:20,040 --> 00:07:22,120
这个时候非常不擅长

189
00:07:22,120 --> 00:07:24,160
做一些小数据的计算

190
00:07:24,160 --> 00:07:26,560
而是对大数据进行大计算

191
00:07:27,960 --> 00:07:30,200
现在我们回到AS加B

192
00:07:30,480 --> 00:07:31,480
指令架构图里面

193
00:07:31,480 --> 00:07:33,240
可以看到大部分时间

194
00:07:33,360 --> 00:07:36,520
我们的内存都是在等待的时间

195
00:07:36,520 --> 00:07:38,200
都是在传输的时间

196
00:07:38,200 --> 00:07:39,960
而内存的时延

197
00:07:39,960 --> 00:07:43,080
就严重的阻碍了我们的计算时延

198
00:07:43,080 --> 00:07:45,760
我们现在的内存利用率都这么的低

199
00:07:45,760 --> 00:07:48,160
更不用说计算的利用率了

200
00:07:48,160 --> 00:07:49,880
可以看到整个计算里面了

201
00:07:49,880 --> 00:07:51,360
这整个时间周期里面

202
00:07:51,360 --> 00:07:52,840
整个程序的周期

203
00:07:52,840 --> 00:07:55,840
计算只有中间这两个点

204
00:07:55,840 --> 00:07:57,600
就是乘和加

205
00:07:57,600 --> 00:08:01,520
只占了可能里面非常少的一个时间

206
00:08:02,520 --> 00:08:05,400
因此我们等一下就是CPU的架构

207
00:08:05,400 --> 00:08:08,520
真的是主要是擅长逻辑控制

208
00:08:08,520 --> 00:08:11,720
而计算的利用率其实并不高

209
00:08:11,720 --> 00:08:13,320
我们如果要提CPU

210
00:08:13,320 --> 00:08:15,400
提它的flop数非常高

211
00:08:15,400 --> 00:08:16,840
其实这是不合理的

212
00:08:16,840 --> 00:08:19,280
我们提它的内存带宽的利用率很高

213
00:08:19,280 --> 00:08:20,480
也是不合理的

214
00:08:20,480 --> 00:08:22,880
更多的我们要提高计算的利用率

215
00:08:22,880 --> 00:08:25,000
可能不仅仅是依托于CPU

216
00:08:25,000 --> 00:08:27,360
而是依托于我们的超异构架构

217
00:08:27,960 --> 00:08:30,040
CPU加NPU组合起来

218
00:08:32,520 --> 00:08:34,280
我们总结一下

219
00:08:34,280 --> 00:08:36,360
从数据看CPU

220
00:08:36,360 --> 00:08:37,400
我们在上一节课里面

221
00:08:37,400 --> 00:08:40,000
给大家汇报了一个计算的强度

222
00:08:40,000 --> 00:08:40,880
在这一节里面

223
00:08:41,040 --> 00:08:42,480
我们数据的传输

224
00:08:42,480 --> 00:08:45,520
衍生了我们的内存传输的一个食言

225
00:08:45,520 --> 00:08:47,360
最后因为有了食言

226
00:08:47,360 --> 00:08:48,880
有了跟计算相关的

227
00:08:48,880 --> 00:08:50,440
于是就出现了下一节

228
00:08:50,440 --> 00:08:52,360
我们会去深入的介绍的

229
00:08:52,360 --> 00:08:53,920
通用图形处理器GPU

230
00:08:53,920 --> 00:08:56,160
还有我们的AI专用处理器NPU

231
00:08:56,160 --> 00:08:59,200
最后再到我们的超异构架构的未来

232
00:08:59,240 --> 00:09:01,480
或者现在正处于的黄金十年

233
00:09:02,120 --> 00:09:03,640
今天的内容就到这里

234
00:09:03,640 --> 00:09:04,480
谢谢各位

235
00:09:04,480 --> 00:09:05,680
拜了个拜

236
00:09:06,640 --> 00:09:08,240
卷的不行了

237
00:09:08,240 --> 00:09:09,640
记得一键三连加关注

238
00:09:10,160 --> 00:09:11,400
所有的内容都会开源

239
00:09:11,400 --> 00:09:13,120
在下面这条链接里面

240
00:09:13,720 --> 00:09:14,400
拜了个拜

