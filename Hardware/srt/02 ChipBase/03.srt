1
00:00:00,000 --> 00:00:05,560
哈喽大家好

2
00:00:05,560 --> 00:00:07,880
今天中米带来一节不一样的课

3
00:00:07,880 --> 00:00:10,400
我们虽然还在AI芯片的基础里面

4
00:00:10,400 --> 00:00:14,360
但是今天我们来通过CPU去看看计算的本质

5
00:00:14,360 --> 00:00:16,000
计算的工作原理

6
00:00:16,000 --> 00:00:18,640
这也是中米觉得最有意思的一节

7
00:00:18,640 --> 00:00:22,040
那我们现在处在的位置还是在AI芯片基础

8
00:00:22,040 --> 00:00:22,960
在上一节里面

9
00:00:23,080 --> 00:00:24,800
我们给大家去普及了一下

10
00:00:24,800 --> 00:00:27,240
通用处理器CPU的历史和发展

11
00:00:27,240 --> 00:00:29,120
最后看看他们的指定机架构

12
00:00:29,120 --> 00:00:33,080
接着我们今天来到了CPU里面非常重要的一节

13
00:00:33,080 --> 00:00:36,160
从数据看CPU的计算

14
00:00:36,160 --> 00:00:39,440
其实很多时候大家关注的是我们的计算

15
00:00:39,440 --> 00:00:41,200
我们的算力Furbs

16
00:00:41,200 --> 00:00:44,320
但是实际上当你如果深入到kernel

17
00:00:44,320 --> 00:00:46,640
当我们深入到整个计算的本质的时候

18
00:00:46,640 --> 00:00:48,680
非常点就会不一样了

19
00:00:48,680 --> 00:00:50,880
我们会更关注我们的数据在哪里

20
00:00:50,880 --> 00:00:53,720
我们的数据怎么跟我们的计算相交互

21
00:00:53,720 --> 00:00:56,200
我们的数据怎么充分的发挥我们的算力

22
00:00:56,200 --> 00:00:58,520
于是通过数据看CPU的计算

23
00:00:58,520 --> 00:01:00,120
我们了解了计算的本质之后

24
00:01:00,480 --> 00:01:03,440
就有了下一节通用图形处理器GPU

25
00:01:03,440 --> 00:01:06,000
还有我们的AI作用芯片NPU

26
00:01:06,000 --> 00:01:06,840
那接下来

27
00:01:08,120 --> 00:01:10,680
我们现在又回到了今年的图里面

28
00:01:10,880 --> 00:01:14,320
横桌坐标是代表我们的算力的敏感度

29
00:01:14,320 --> 00:01:16,040
能够执行多少的数据

30
00:01:16,040 --> 00:01:18,960
而纵坐标是我们的性能

31
00:01:18,960 --> 00:01:21,680
每一秒能够执行多少的操作

32
00:01:21,680 --> 00:01:23,840
那可以看到随着我们的P的增加

33
00:01:23,840 --> 00:01:24,880
P就是我们的计算单元

34
00:01:25,080 --> 00:01:26,000
P增加了之后

35
00:01:26,560 --> 00:01:29,640
整体的计算的峰值肯定是越高的

36
00:01:29,640 --> 00:01:32,280
当然我们单元不会无限制的增加

37
00:01:32,280 --> 00:01:34,480
肯定会有一个数量的限制

38
00:01:34,480 --> 00:01:37,280
所以当我们的P数量增加到一定程度的时候

39
00:01:37,280 --> 00:01:39,840
我们就会遇到了一个理论的峰值

40
00:01:39,840 --> 00:01:42,280
而左边的灰色的这个峰块

41
00:01:42,480 --> 00:01:46,600
就是我们的带宽Bandwidth的一个约束

42
00:01:46,600 --> 00:01:47,600
而右边的这个

43
00:01:47,720 --> 00:01:50,400
就是我们的计算的Band的计算的约束

44
00:01:50,400 --> 00:01:54,960
可以看到中间我们会有一条非常之明确的线段

45
00:01:54,960 --> 00:01:57,000
或者中间有一个转折点

46
00:01:57,000 --> 00:02:01,840
那这个就是我们带宽跟计算最好的一个中位数

47
00:02:01,840 --> 00:02:03,480
因为可能算单元的增加

48
00:02:03,480 --> 00:02:05,080
如果我们带宽跟不上

49
00:02:05,080 --> 00:02:08,160
那这个时候我们的计算的增加是没有效果的

50
00:02:08,160 --> 00:02:12,120
当然那是我们需要寻求一个从带宽到P

51
00:02:12,120 --> 00:02:13,680
到我们的计算单元之间

52
00:02:13,680 --> 00:02:15,320
一个最好的平衡点

53
00:02:15,320 --> 00:02:17,880
也就是中间的这一个转折点

54
00:02:17,880 --> 00:02:22,120
那现在我们看一下一些业界的最新的进展

55
00:02:22,120 --> 00:02:27,280
首先这个我是来自于AMD最新的一个演讲视频来去截取的

56
00:02:27,280 --> 00:02:29,880
我们可以看到服务器的整体性能的趋势

57
00:02:29,880 --> 00:02:33,240
基本上每2.4年就会翻一番

58
00:02:33,240 --> 00:02:37,120
整个服务器架构的性能是提升的非常的夸张

59
00:02:37,120 --> 00:02:40,040
这里面的性能主要提升的是指算力

60
00:02:40,040 --> 00:02:42,760
而这里面我们看看单个GPU的性能

61
00:02:42,760 --> 00:02:47,160
这个Float基本上每2.2年也是有一个翻一番的速率

62
00:02:47,160 --> 00:02:49,440
从2005年到2025年

63
00:02:49,480 --> 00:02:51,640
预计我们的计算的速率

64
00:02:51,640 --> 00:02:55,320
我们的计算的峰值会非常非常的高

65
00:02:56,400 --> 00:02:56,880
接着呢

66
00:02:56,880 --> 00:03:00,720
我们现在其实已经来到了整个计算架构的黄金十年

67
00:03:00,720 --> 00:03:02,520
因为我们刚才谈到我们的服务器

68
00:03:02,520 --> 00:03:03,000
我们的GPU

69
00:03:03,000 --> 00:03:05,120
我们的单算力都在不断的增长

70
00:03:05,120 --> 00:03:05,520
于是呢

71
00:03:05,520 --> 00:03:09,680
我们整体的计算的架构肯定会迎来新的黄金的十年

72
00:03:09,680 --> 00:03:11,760
而随着我们的计算的架构的增长

73
00:03:11,760 --> 00:03:13,320
我们的计算的速率的增长

74
00:03:13,320 --> 00:03:14,840
我们的计算的Float增长

75
00:03:14,840 --> 00:03:18,960
我们肯定也会迎来一个编译器的黄金的十年

76
00:03:18,960 --> 00:03:22,600
所以非常欢迎大家去看看这两个YouTube上面对应的视频

77
00:03:22,600 --> 00:03:25,320
去了解一下计算架构编译器的架构

78
00:03:25,320 --> 00:03:27,120
近期的一个发展情况

79
00:03:28,040 --> 00:03:28,760
接下来呢

80
00:03:28,760 --> 00:03:30,560
我们来看看一个更有意思的数据

81
00:03:30,560 --> 00:03:33,080
就是超算中心的性能

82
00:03:33,080 --> 00:03:36,040
超算中心就不仅仅是指我们的GPU

83
00:03:36,040 --> 00:03:37,280
进行我们的CPU

84
00:03:37,280 --> 00:03:39,400
更多的是指超异构的架构

85
00:03:39,400 --> 00:03:41,800
除了单单和GPU的算力的增长

86
00:03:41,800 --> 00:03:44,080
我们还有很多异构芯片的增长

87
00:03:44,080 --> 00:03:44,600
于是呢

88
00:03:44,600 --> 00:03:47,720
我们可以看到性能基本上是1.2年

89
00:03:47,760 --> 00:03:48,960
再进行翻一翻

90
00:03:48,960 --> 00:03:53,760
从95年到24年的整体预测是非常非常的夸张

91
00:03:53,760 --> 00:03:56,760
已经是到从A6 scale迈进C6 scale

92
00:03:57,640 --> 00:03:59,160
算力时代

93
00:03:59,160 --> 00:03:59,920
而这里面呢

94
00:03:59,920 --> 00:04:02,160
现在我们看一下大家都谈大模型

95
00:04:02,160 --> 00:04:06,280
训练大模型整体的时间是已经越来越长了

96
00:04:06,280 --> 00:04:09,600
从模型从10B到1000B

97
00:04:09,600 --> 00:04:12,280
从百亿到千亿到万亿

98
00:04:12,280 --> 00:04:15,080
随着我们增长的不仅仅是算力

99
00:04:15,080 --> 00:04:19,040
还有我们的内存和我们的数据都在跨越式的增长

100
00:04:19,040 --> 00:04:20,000
而这个时候呢

101
00:04:20,000 --> 00:04:23,000
我们又迎来了一个新的趋势的预言

102
00:04:23,000 --> 00:04:24,960
就是我们的逻辑电路的趋势

103
00:04:24,960 --> 00:04:26,560
可以看到从08年开始

104
00:04:26,560 --> 00:04:28,000
我们迈进了纳米的时代

105
00:04:28,000 --> 00:04:28,800
2010年呢

106
00:04:28,800 --> 00:04:30,160
是在我们445纳米

107
00:04:30,160 --> 00:04:34,520
直到我们现在所处的是5纳米到4纳米量产的阶段

108
00:04:34,520 --> 00:04:37,480
未来我们可能还会进一步突破

109
00:04:37,480 --> 00:04:38,800
接近两纳米

110
00:04:40,000 --> 00:04:42,040
随着我们的制程的提高

111
00:04:42,040 --> 00:04:45,040
整体的算力也会不断的增长

112
00:04:45,200 --> 00:04:48,000
但这个时候总比就有一个疑问呢

113
00:04:48,000 --> 00:04:50,160
谁会真正的在乎算力呢

114
00:04:50,160 --> 00:04:52,360
谁会真正在乎我们的flux呢

115
00:04:52,360 --> 00:04:54,360
虽然我在跟客户交流的时候呢

116
00:04:54,360 --> 00:04:55,800
非常多人都会问

117
00:04:55,800 --> 00:04:56,240
哎

118
00:04:56,240 --> 00:04:56,880
你的硬件

119
00:04:56,880 --> 00:04:58,720
你的生成的算力到底是多少

120
00:04:58,720 --> 00:05:01,280
对比起英伟达的算力到底有多少区别

121
00:05:01,280 --> 00:05:05,480
很多时候我只能说我们的算力算力会比英伟达的要高

122
00:05:05,480 --> 00:05:07,560
而海姆基亚海姆基必然百度啊

123
00:05:07,560 --> 00:05:08,000
昆仑啊

124
00:05:08,000 --> 00:05:11,040
这些都在强求自己的峰值算力啊

125
00:05:11,040 --> 00:05:11,680
这个时候呢

126
00:05:11,680 --> 00:05:12,640
就非常有趣了

127
00:05:12,640 --> 00:05:14,600
我引入了另外一个新的话题

128
00:05:14,600 --> 00:05:15,520
像第一chip呢

129
00:05:15,520 --> 00:05:17,240
是一部的一篇芯片

130
00:05:17,240 --> 00:05:19,480
它里面的一发布就强调了

131
00:05:19,480 --> 00:05:22,400
它有非常之夸张的算力的峰值

132
00:05:22,400 --> 00:05:24,200
362T-FLUX

133
00:05:24,200 --> 00:05:27,280
还有226T-FLUX的FP32

134
00:05:27,280 --> 00:05:31,080
可以看到F的峰值算力非常非常的夸张

135
00:05:31,080 --> 00:05:31,760
而这里面呢

136
00:05:31,760 --> 00:05:33,720
我们看一下Graphcore里面的IPU啊

137
00:05:33,720 --> 00:05:36,800
也是非常强调它的峰值算力

138
00:05:36,800 --> 00:05:38,600
5.6PTFLUX

139
00:05:38,600 --> 00:05:40,000
还有1.12PTFLUX

140
00:05:40,000 --> 00:05:42,200
到它的一个集群Port的集群

141
00:05:42,200 --> 00:05:45,480
已经有了358.4PTFLUX

142
00:05:45,480 --> 00:05:47,320
整体的算力越来越夸张

143
00:05:47,320 --> 00:05:48,280
越来越大

144
00:05:48,280 --> 00:05:49,320
而这个时候呢

145
00:05:49,320 --> 00:05:52,360
我们又反都会去跟英伟达对比

146
00:05:52,360 --> 00:05:54,880
到底在FP32的计算里面

147
00:05:54,880 --> 00:05:56,720
它有2PTFLUX的算力

148
00:05:56,720 --> 00:05:59,640
而它只有156T-FLUX的算力

149
00:05:59,640 --> 00:06:01,680
整体的算力是它的12倍

150
00:06:01,680 --> 00:06:02,800
而在AI里面呢

151
00:06:02,800 --> 00:06:04,680
英伟达有2.5PTFLUX

152
00:06:04,680 --> 00:06:05,920
而整个Graphcore呢

153
00:06:05,920 --> 00:06:07,920
它有8PTFLUX是它的三倍

154
00:06:07,920 --> 00:06:09,200
不管怎么样来看

155
00:06:09,200 --> 00:06:11,880
整体的峰值算力也是越来越高的

156
00:06:11,920 --> 00:06:14,320
大家都在强调峰值算力

157
00:06:14,320 --> 00:06:15,200
但是

158
00:06:15,200 --> 00:06:17,520
客户真正在乎的是算力吗

159
00:06:17,520 --> 00:06:19,280
客户真正在乎的是FLUX吗

160
00:06:19,280 --> 00:06:21,880
是每秒能够运行多少算力吗

161
00:06:21,880 --> 00:06:22,400
其实

162
00:06:25,440 --> 00:06:26,400
我觉得呀

163
00:06:26,400 --> 00:06:28,000
最重要的是我们的物理定律

164
00:06:28,000 --> 00:06:30,040
还有硬件本身很大程度决定了

165
00:06:30,040 --> 00:06:32,840
我们对机器的编程的方式

166
00:06:32,840 --> 00:06:35,040
而机器的编程的方式的不一样呢

167
00:06:35,040 --> 00:06:37,880
当我们深入到整个计算的本质的时候

168
00:06:37,880 --> 00:06:39,840
我们就会有一个更深的体会

169
00:06:39,840 --> 00:06:42,320
我的数据到底在哪里

170
00:06:42,320 --> 00:06:45,440
我们真正关心的可能是我们的数据搬运

171
00:06:45,440 --> 00:06:47,840
我算的非常的非常的快

172
00:06:47,840 --> 00:06:50,280
但是我的数据来得及提供吗

173
00:06:50,280 --> 00:06:52,120
我的数据来不及提供

174
00:06:52,120 --> 00:06:55,160
那我们可能永远都处于这个位置

175
00:06:55,160 --> 00:06:57,680
还达不到真正的峰值算力

176
00:06:57,680 --> 00:07:00,320
所以算力不一定是最重要的

177
00:07:00,320 --> 00:07:01,920
我们接下来往下

178
00:07:01,920 --> 00:07:02,400
所以呢

179
00:07:02,400 --> 00:07:05,680
下面我们来到一个真正非常具有争议性的话题

180
00:07:05,680 --> 00:07:08,440
我觉得没有人真的会在意FLUX

181
00:07:08,480 --> 00:07:11,200
就是每秒浮点运算的次数

182
00:07:11,200 --> 00:07:13,560
FLUX跟机器的算力非常相关的

183
00:07:13,560 --> 00:07:15,560
所以很多客户在买机器的时候呢

184
00:07:15,560 --> 00:07:18,040
希望能够了解它到底有多少算力

185
00:07:18,040 --> 00:07:19,000
有多少FLUX

186
00:07:19,000 --> 00:07:21,120
每秒能够执行的多快

187
00:07:21,120 --> 00:07:23,120
不过我真的是想告诉你

188
00:07:23,120 --> 00:07:25,800
这个不是我们真正应该关注的一点

189
00:07:25,800 --> 00:07:27,280
因为我们真正关注的点

190
00:07:27,280 --> 00:07:30,200
我们的重点不在这里面

191
00:07:30,200 --> 00:07:33,320
如果你认为没有太必要去关心FLUX呢

192
00:07:33,320 --> 00:07:35,360
有多少倍的MV的比例呢

193
00:07:35,360 --> 00:07:38,440
我们现在来看看CPU跟它的内存之间

194
00:07:38,440 --> 00:07:40,040
是什么样的一个关系

195
00:07:40,040 --> 00:07:40,600
首先呢

196
00:07:40,600 --> 00:07:41,920
内存会把它的数据呢

197
00:07:41,920 --> 00:07:43,640
传到我们的CPU上面

198
00:07:43,640 --> 00:07:48,400
每秒钟我们假设大概能够传输200G的字节

199
00:07:48,400 --> 00:07:50,360
每秒钟也就per second

200
00:07:50,360 --> 00:07:52,880
往上看一看CPU呢

201
00:07:52,880 --> 00:07:53,880
大概每秒钟呢

202
00:07:53,880 --> 00:07:56,920
能够进行两万一次的双精度

203
00:07:56,920 --> 00:07:59,320
也就是FLUX的运算

204
00:07:59,320 --> 00:08:00,040
那这个数呢

205
00:08:00,040 --> 00:08:02,560
我们看上去非常非常的夸张

206
00:08:02,560 --> 00:08:03,040
不过呢

207
00:08:03,040 --> 00:08:03,760
这个算量啊

208
00:08:03,760 --> 00:08:05,000
对于CPU来说

209
00:08:05,040 --> 00:08:07,440
它只是一个非常经典典型的数据

210
00:08:09,000 --> 00:08:10,920
我们知道每一个FP16呢

211
00:08:10,920 --> 00:08:11,960
是八个字节

212
00:08:11,960 --> 00:08:15,320
那内存每秒钟传输200G的字节

213
00:08:15,320 --> 00:08:19,480
每秒能够传输25GFP16的数值

214
00:08:19,480 --> 00:08:20,520
那这个数值呢

215
00:08:20,520 --> 00:08:26,040
对于内存来说就是每秒可以提供251个FP16的数据

216
00:08:26,040 --> 00:08:27,960
这是非常非常的多的

217
00:08:27,960 --> 00:08:33,960
但是CPU每秒确实能够处理两万一个FP16的数据

218
00:08:34,000 --> 00:08:37,680
那也对比就是我们左边的这条公式

219
00:08:37,680 --> 00:08:39,760
设备的计算强度

220
00:08:39,760 --> 00:08:41,880
required compute intensive

221
00:08:42,840 --> 00:08:43,760
这个例子呢

222
00:08:43,760 --> 00:08:48,480
我们就需要计算强度80来整体的计算平衡

223
00:08:48,480 --> 00:08:53,040
也就是说我们对每一个数据都要进行80次操作

224
00:08:53,040 --> 00:08:53,680
否则呢

225
00:08:53,680 --> 00:08:54,560
我们的PE

226
00:08:54,560 --> 00:08:55,320
我们的CPU

227
00:08:55,320 --> 00:08:58,640
我们的PU就会处于空闲的状态

228
00:08:58,640 --> 00:09:00,680
处于等待的状态

229
00:09:00,680 --> 00:09:01,560
如果我们达不到

230
00:09:01,560 --> 00:09:05,320
CPU不能够做到对每个数据进行80次操作

231
00:09:05,320 --> 00:09:07,680
那这个时候还不如买一个更便宜的CPU

232
00:09:07,680 --> 00:09:09,600
它的FLOP数没有那么高

233
00:09:09,600 --> 00:09:10,360
没有那么高

234
00:09:10,360 --> 00:09:14,000
每秒没有必要去计算那么多FLOP

235
00:09:14,000 --> 00:09:18,000
后来每一个数据都进行80次操作

236
00:09:18,000 --> 00:09:19,360
这真的有必要吗

237
00:09:19,360 --> 00:09:24,000
我们真的会有算法对每一个数据都执行这么多遍操作吗

238
00:09:24,000 --> 00:09:26,320
我个人觉得在通用CPU里面呢

239
00:09:26,320 --> 00:09:28,600
这种情况是非常非常少见的

240
00:09:28,600 --> 00:09:31,760
只有一种非常一种非常之特殊的情况

241
00:09:31,760 --> 00:09:33,200
我们的AI

242
00:09:33,200 --> 00:09:35,200
我们的图形图像

243
00:09:35,200 --> 00:09:37,040
也就是迎来了我们的GPU

244
00:09:37,040 --> 00:09:38,600
可能有这种情况

245
00:09:38,600 --> 00:09:40,760
我们的PU AI芯片

246
00:09:40,760 --> 00:09:43,440
针对矩阵程可能会有这种情况

247
00:09:44,720 --> 00:09:45,240
下面呢

248
00:09:45,240 --> 00:09:48,160
这里有一个不同处理器的速度的表格

249
00:09:48,160 --> 00:09:49,960
我从左边的这一部分呢

250
00:09:49,960 --> 00:09:51,960
是英特尔和AMD的

251
00:09:51,960 --> 00:09:53,040
右边那部分呢

252
00:09:53,040 --> 00:09:54,240
是英伟达的

253
00:09:54,240 --> 00:09:55,120
可以看到呢

254
00:09:55,120 --> 00:09:57,200
大家的计算强度或者计算比呢

255
00:09:57,240 --> 00:09:59,200
都是差不多的

256
00:09:59,200 --> 00:10:00,040
不同的芯片啊

257
00:10:00,040 --> 00:10:02,320
都有非常强大的Flux

258
00:10:02,320 --> 00:10:04,000
就是我们的计算能力

259
00:10:04,000 --> 00:10:05,600
也有非常大的内存带宽

260
00:10:05,600 --> 00:10:08,680
去平衡计算和带宽之间中间的一个gap

261
00:10:08,680 --> 00:10:09,840
那我们很多里面

262
00:10:09,840 --> 00:10:13,840
其实我们尽可能的希望能够降低整个计算的强度

263
00:10:13,840 --> 00:10:16,840
因为不可能有算法在每一次加载的时候

264
00:10:16,840 --> 00:10:20,240
都要执行接近100多次同样的计算

265
00:10:20,240 --> 00:10:21,720
针对同样的数据

266
00:10:21,720 --> 00:10:23,560
所以这是一个很奇怪的事情

267
00:10:24,480 --> 00:10:25,000
不不得

268
00:10:25,000 --> 00:10:25,920
你啥意思

269
00:10:25,920 --> 00:10:26,480
我告诉你

270
00:10:26,480 --> 00:10:27,320
刘腾我告诉你

271
00:10:27,320 --> 00:10:29,240
这个手你都背负

272
00:10:29,240 --> 00:10:31,320
不得计算的速度的增加

273
00:10:31,320 --> 00:10:33,760
比我们内存带宽速度增加更快的时候

274
00:10:33,760 --> 00:10:36,120
我们的计算强度就会去上升

275
00:10:36,120 --> 00:10:38,280
就好像左边英特尔这一款呢

276
00:10:38,280 --> 00:10:39,480
我们可以看到明显

277
00:10:39,480 --> 00:10:41,640
它的计算强度高了很多

278
00:10:41,640 --> 00:10:42,280
所以呢

279
00:10:42,280 --> 00:10:44,640
那我们就需要在程序算法上面

280
00:10:44,640 --> 00:10:46,360
不断的去做一些创新

281
00:10:46,360 --> 00:10:48,760
来保持我们尽可能的去塞满

282
00:10:48,760 --> 00:10:51,720
尽可能的去提升我们的算力的利用率

283
00:10:53,200 --> 00:10:54,840
回到这一个观点

284
00:10:54,880 --> 00:10:55,400
ZOMI呢

285
00:10:55,400 --> 00:10:58,600
其实并不是说非常的在哭FLOPS

286
00:10:58,600 --> 00:10:59,960
因为我们现在已经知道

287
00:10:59,960 --> 00:11:01,720
已经有足够多的FLOPS了

288
00:11:01,720 --> 00:11:02,440
我们的GPU

289
00:11:02,440 --> 00:11:03,080
我们的CPU

290
00:11:03,080 --> 00:11:04,600
我们的MPU

291
00:11:04,600 --> 00:11:07,080
已经有足够多的计算的能力

292
00:11:07,080 --> 00:11:10,200
我们要做的是提升我们的算力利用率

293
00:11:11,160 --> 00:11:13,280
如果不能够让CPU忙起来

294
00:11:13,280 --> 00:11:14,120
那情况呢

295
00:11:14,120 --> 00:11:16,040
就会变得非常的糟糕

296
00:11:16,040 --> 00:11:16,640
因此呢

297
00:11:16,640 --> 00:11:20,560
我觉得我们更应该去关注的是内存带宽

298
00:11:20,560 --> 00:11:21,560
还有时延

299
00:11:21,560 --> 00:11:24,520
尽可能的提升我们的算力的利用率

300
00:11:25,840 --> 00:11:26,840
小视频里面呢

301
00:11:26,840 --> 00:11:28,520
我会给大家去分享一下

302
00:11:28,520 --> 00:11:30,640
CPU里面的内存带宽时延

303
00:11:30,640 --> 00:11:31,440
跟我们的GPU

304
00:11:31,440 --> 00:11:33,440
我个人觉得更加有意思的一个

305
00:11:33,440 --> 00:11:34,440
简单的DEMO

306
00:11:34,440 --> 00:11:35,240
然后去看看

307
00:11:35,240 --> 00:11:37,600
我们什么时候才应该去满足

308
00:11:37,600 --> 00:11:39,520
内存和带宽时延的要求

309
00:11:39,520 --> 00:11:42,200
同时也可以提升我们的算力利用率

310
00:11:42,200 --> 00:11:42,640
好了

311
00:11:42,640 --> 00:11:43,960
今天的内容呢

312
00:11:43,960 --> 00:11:45,000
就到这里为止

313
00:11:45,000 --> 00:11:45,720
谢谢各位

314
00:11:45,720 --> 00:11:46,080
拜了

315
00:11:46,080 --> 00:11:46,800
拜拜

316
00:11:47,680 --> 00:11:48,480
卷的不行了

317
00:11:48,480 --> 00:11:49,360
卷的不行了

318
00:11:49,360 --> 00:11:51,160
记得一键三连加关注哦

319
00:11:51,160 --> 00:11:52,520
所有的内容都会开源

320
00:11:52,520 --> 00:11:54,280
在下面这条链接里面

321
00:11:54,880 --> 00:11:55,200
拜了

322
00:11:55,200 --> 00:11:55,680
拜拜

