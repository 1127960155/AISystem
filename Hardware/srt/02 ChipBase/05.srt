1
00:00:00,000 --> 00:00:07,560
Hello,大家好,我是Zoomi

2
00:00:07,560 --> 00:00:10,680
今天我们还是在AI芯片基础的一个内容

3
00:00:10,680 --> 00:00:14,520
不过我们今天迎来了一个新的简单的内容

4
00:00:14,520 --> 00:00:18,040
就是我们图形图像处理器GPU

5
00:00:18,040 --> 00:00:19,960
今天我们不会介绍太多的内容

6
00:00:19,960 --> 00:00:22,120
不过我们将会在下一个系列里面

7
00:00:22,120 --> 00:00:24,640
会有非常多GPU的深度的展开

8
00:00:24,640 --> 00:00:27,760
第一个我们会去看看整个GPU的硬件的基础

9
00:00:27,760 --> 00:00:28,840
就是它的工作原理

10
00:00:28,840 --> 00:00:31,080
还有一个编程的本子

11
00:00:31,080 --> 00:00:32,400
以英伟达作为例子

12
00:00:32,400 --> 00:00:34,120
看看GPU的整体的架构

13
00:00:34,120 --> 00:00:35,560
从菲米的架构到hopper

14
00:00:35,560 --> 00:00:37,320
现在的h100

15
00:00:37,320 --> 00:00:39,520
里面可能会有一个小的插曲

16
00:00:39,520 --> 00:00:41,640
就是现在用的非常多的tensor core

17
00:00:41,640 --> 00:00:42,800
还有NVLink

18
00:00:42,800 --> 00:00:46,000
最后我们回到GPU最开始的初衷

19
00:00:46,000 --> 00:00:49,640
它用来做一些图形图像的流水线的处理

20
00:00:49,640 --> 00:00:51,240
里面就会详细的去看

21
00:00:51,240 --> 00:00:54,280
你看GPU里面的图形流水线的基础

22
00:00:54,280 --> 00:00:55,800
还有它的逻辑模块划分

23
00:00:55,800 --> 00:00:58,440
最后再到图形图像处理的一些算法

24
00:00:58,440 --> 00:01:00,840
到硬件是怎么形成

25
00:01:00,840 --> 00:01:03,480
整个英伟达整个GPU的帝国的

26
00:01:03,480 --> 00:01:07,640
那现在我们还是回到通用图形图像处理器

27
00:01:07,640 --> 00:01:09,160
AI芯片的基础

28
00:01:09,160 --> 00:01:11,320
今天要给大家去分享的几个内容

29
00:01:11,320 --> 00:01:13,160
有4部分

30
00:01:13,160 --> 00:01:15,480
第一部分就是GPU的发展历史

31
00:01:15,480 --> 00:01:16,440
和它的组成

32
00:01:16,440 --> 00:01:18,200
跟我们的CPU其实是一样的

33
00:01:18,200 --> 00:01:20,400
接着我们简单的去看看

34
00:01:20,400 --> 00:01:23,560
GPU和CPU的一个具体的区别

35
00:01:23,560 --> 00:01:25,080
然后我们看看

36
00:01:25,080 --> 00:01:27,880
AI的发展为什么需要GPU

37
00:01:27,880 --> 00:01:32,200
最后就看看GPU的应用场景了

38
00:01:32,200 --> 00:01:33,240
那时不一次

39
00:01:33,240 --> 00:01:36,920
我们现在马上开始我们今天的主要内容

40
00:01:38,360 --> 00:01:41,000
第一个就是GPU的发展历史

41
00:01:41,000 --> 00:01:43,720
the history of the GPU

42
00:01:44,640 --> 00:01:46,280
我们看一下GPU发展

43
00:01:46,440 --> 00:01:48,320
其实经历了三个阶段

44
00:01:48,520 --> 00:01:51,720
第一个阶段主要是自初代的GPU

45
00:01:51,920 --> 00:01:53,480
这个时候GPU其实自身

46
00:01:53,640 --> 00:01:56,400
是不具备软件的编程能力的

47
00:01:56,440 --> 00:01:58,200
它没有软件自己的编程能力

48
00:01:58,200 --> 00:01:59,480
那时候CUDA还没有

49
00:01:59,480 --> 00:02:02,000
大家是不能够基于GPU来去做一些

50
00:02:02,000 --> 00:02:03,640
编程写自己的代码的

51
00:02:03,640 --> 00:02:05,920
它只是作为一个CPU的

52
00:02:05,920 --> 00:02:07,440
另外一个计算单元

53
00:02:07,440 --> 00:02:10,400
能够把部分的三维图像的功能

54
00:02:10,640 --> 00:02:12,800
从CPU里面剥离出来

55
00:02:12,800 --> 00:02:15,800
针对图形图像这些软件算法

56
00:02:15,800 --> 00:02:18,680
做一些独立的硬件的加速

57
00:02:18,880 --> 00:02:21,920
那个时候有一个最出名的一个引擎

58
00:02:21,920 --> 00:02:23,640
就是我们的几号处理引擎

59
00:02:23,680 --> 00:02:26,360
Geometric Engine作为整体的代表的

60
00:02:26,720 --> 00:02:30,280
下面我们看一下GPU发展的第二个阶段

61
00:02:30,480 --> 00:02:34,040
第二阶段就是从99年到2005年

62
00:02:34,040 --> 00:02:36,080
这个时候GPU机提供了

63
00:02:36,080 --> 00:02:38,320
更多的硬件的加速能力

64
00:02:38,320 --> 00:02:40,400
还有一些有限的编程性

65
00:02:40,400 --> 00:02:44,080
那时候的编程能力还是非常有限的

66
00:02:44,080 --> 00:02:47,840
那时候在第二代GPU里面的CUDA

67
00:02:47,960 --> 00:02:51,800
我们现在熟悉的CUDA还没有出现

68
00:02:51,840 --> 00:02:53,600
那我们看一下这个时间段

69
00:02:53,600 --> 00:02:55,680
其实有两个厂商在竞逐

70
00:02:55,680 --> 00:02:57,880
第一个就是英伟达

71
00:02:57,880 --> 00:03:00,160
第二个就是我们的ATI

72
00:03:00,160 --> 00:03:02,600
那后来ATI被AMD收购了

73
00:03:02,600 --> 00:03:04,920
我们叫做A卡和N卡

74
00:03:04,920 --> 00:03:07,360
而那个时候ZOMI去买显卡

75
00:03:07,560 --> 00:03:09,000
都是非常之纠结

76
00:03:09,000 --> 00:03:10,920
到底选A卡还是N卡

77
00:03:10,920 --> 00:03:13,040
下面我们来看一下具体的内容

78
00:03:13,880 --> 00:03:15,920
那时候英伟达就发布了

79
00:03:15,920 --> 00:03:18,200
GeForce Orion图形图像处理器

80
00:03:18,200 --> 00:03:21,760
那这个时候真正的去把一些图形图像

81
00:03:21,760 --> 00:03:23,680
的快速变换的显示的功能

82
00:03:23,680 --> 00:03:25,680
从CPU里面分离出来

83
00:03:25,680 --> 00:03:28,880
实现了第一个真正意义的GPU

84
00:03:28,880 --> 00:03:31,560
而在2000年到2005年的时候

85
00:03:31,720 --> 00:03:33,400
是属于一个GPU硬件

86
00:03:33,400 --> 00:03:35,920
硬件高速发展的阶段

87
00:03:35,920 --> 00:03:37,480
整体的运算的速率

88
00:03:37,600 --> 00:03:38,440
就是我们的Float数

89
00:03:38,680 --> 00:03:41,400
超过了我们的CPU非常非常的多

90
00:03:41,400 --> 00:03:44,520
而且超过的比例也是呈指数性的增长

91
00:03:45,240 --> 00:03:48,120
图形硬件流水线被定义为流处理器

92
00:03:48,400 --> 00:03:50,200
针对我图形硬件的流水线

93
00:03:50,400 --> 00:03:51,840
被称为流处理器

94
00:03:51,840 --> 00:03:53,160
在这些流处理器里面

95
00:03:53,440 --> 00:03:55,520
就出现了的顶点可编程

96
00:03:55,520 --> 00:03:56,600
3D的顶点可编程

97
00:03:56,600 --> 00:03:57,920
图像的顶点可编程

98
00:03:57,920 --> 00:04:01,160
还有像素级别的有限可编程

99
00:04:01,160 --> 00:04:03,240
但整体来说它的编程能力有限

100
00:04:03,240 --> 00:04:07,200
这个时间段更多的是聚焦于硬件的加速

101
00:04:07,320 --> 00:04:11,240
最后那就是英伟达和ATI的两块显卡

102
00:04:11,240 --> 00:04:13,280
左边就GeForce 6800

103
00:04:13,280 --> 00:04:16,120
右边就是ATI的分别的显卡

104
00:04:16,120 --> 00:04:18,200
而ATI不是被AMD收购了吗

105
00:04:18,200 --> 00:04:19,760
还是保持着红色

106
00:04:20,080 --> 00:04:23,280
接着我们来到GPU的发展第三个阶段

107
00:04:23,280 --> 00:04:25,440
从2006年到现在

108
00:04:25,440 --> 00:04:29,400
基本上主目标就是奔着软件可编程去发展的

109
00:04:30,280 --> 00:04:31,960
也是从2006年开始

110
00:04:32,120 --> 00:04:34,040
英伟达跟ATI就是我们的A卡

111
00:04:34,040 --> 00:04:35,160
或者AMD的显卡

112
00:04:35,440 --> 00:04:37,760
出现了一个比较大的分水岭

113
00:04:38,040 --> 00:04:41,200
2006年英伟达就推出了一个CUDA

114
00:04:41,560 --> 00:04:43,360
我们的CUDA

115
00:04:44,240 --> 00:04:46,760
而ATI推出了CTM

116
00:04:47,040 --> 00:04:48,920
两个都推出了编程环境

117
00:04:48,920 --> 00:04:52,600
使得整个打破了只能够对图形图像

118
00:04:52,600 --> 00:04:54,120
这些硬件进行加速

119
00:04:54,120 --> 00:04:57,080
而成为了真正并行的数据处理的加速器

120
00:04:57,080 --> 00:04:59,480
也要成为我们的GPU

121
00:04:59,480 --> 00:05:00,880
而2008年的时候

122
00:05:01,000 --> 00:05:04,360
Apple就推出了一个通用的并行计算平台

123
00:05:04,360 --> 00:05:05,880
我们的OpenCL

124
00:05:05,880 --> 00:05:09,280
就是苹果推出的一个协议和编程语言

125
00:05:09,280 --> 00:05:10,360
跟CPU一样

126
00:05:10,520 --> 00:05:12,120
CUDA只能支持英伟达

127
00:05:12,120 --> 00:05:13,320
现在我们遇到很多客户

128
00:05:13,480 --> 00:05:16,640
希望我们的NPU支持像CUDA这种编程方式

129
00:05:16,680 --> 00:05:19,000
但其实是不太可能或者不太现实的

130
00:05:19,000 --> 00:05:21,440
因为CUDA它只针对英伟达有效

131
00:05:21,440 --> 00:05:25,160
像OpenCL它这种就是跟具体的适配没有关系

132
00:05:25,680 --> 00:05:29,080
随着2008年苹果iPhone4的出现

133
00:05:29,520 --> 00:05:32,640
整个OpenCL已经成为移动端GPU的

134
00:05:32,640 --> 00:05:34,960
一个编程的业界标准

135
00:05:34,960 --> 00:05:37,480
这也是跟生态相关的

136
00:05:38,200 --> 00:05:40,760
简单的打开CUDA来去看看

137
00:05:40,760 --> 00:05:42,440
CUDA就是我们这一层

138
00:05:42,440 --> 00:05:44,920
居英伟达的硬件之上

139
00:05:45,120 --> 00:05:46,640
CUDA它有CUDA toolkit

140
00:05:47,000 --> 00:05:48,200
还有CUDA driver

141
00:05:48,400 --> 00:05:51,240
所以CUDA不仅仅是一个硬件的驱动

142
00:05:51,240 --> 00:05:54,440
它还是一个编程开发的软件工具

143
00:05:54,440 --> 00:05:56,640
在里面就有自己的编译器

144
00:05:56,800 --> 00:05:58,920
有自己的debug profiling的一些工具

145
00:05:58,920 --> 00:06:01,960
当然还有一些C++的API的接口

146
00:06:01,960 --> 00:06:04,080
网上提供给我们去编程的

147
00:06:04,080 --> 00:06:08,160
在网上就是CUDA之上建立的一些库了

148
00:06:08,160 --> 00:06:11,040
我们现在深度学习经常用到的各种加速库

149
00:06:11,040 --> 00:06:13,280
就是基于CUDA之上构建的

150
00:06:14,960 --> 00:06:16,880
下面我们了解完历史之后

151
00:06:17,000 --> 00:06:20,720
我们看看GPU跟CPU之间的一个差异

152
00:06:44,920 --> 00:06:45,920
Ladies and gentlemen

153
00:06:47,120 --> 00:06:48,320
Leonardo

154
00:06:50,320 --> 00:06:51,320
2.0

155
00:06:52,560 --> 00:06:55,200
When we hit this trigger on this thing

156
00:06:55,200 --> 00:06:58,040
2100 gallons of air

157
00:06:58,040 --> 00:06:59,880
goes through these accumulators

158
00:06:59,880 --> 00:07:00,840
out these valves

159
00:07:00,840 --> 00:07:03,560
into all 1100 of these tubes

160
00:07:03,560 --> 00:07:04,760
into these tubes

161
00:07:04,760 --> 00:07:06,880
in which the bottom of is a paintball

162
00:07:06,880 --> 00:07:09,600
Each of those paintballs will fly across 7 feet of space

163
00:07:09,600 --> 00:07:10,600
and in 8 minutes

164
00:07:10,600 --> 00:07:12,480
they will go through these accumulators

165
00:07:12,480 --> 00:07:14,120
and they will go through these tubes

166
00:07:14,120 --> 00:07:15,600
And they reach its target

167
00:07:15,600 --> 00:07:17,880
its target will be under similar Sonic wave of ampersand

168
00:07:17,880 --> 00:07:19,360
and then in 80 milliseconds

169
00:07:19,360 --> 00:07:20,640
reach its target

170
00:07:20,640 --> 00:07:21,640
hopefully

171
00:07:22,840 --> 00:07:23,920
when it is all set and done

172
00:07:23,920 --> 00:07:25,320
it's going to paint the Mona Lisa

173
00:07:25,320 --> 00:07:28,680
GPU painting demonstration

174
00:07:29,400 --> 00:07:30,820
and 10

175
00:07:31,520 --> 00:07:32,120
No

176
00:07:32,120 --> 00:07:33,160
9

177
00:07:33,160 --> 00:07:34,680
8

178
00:07:34,680 --> 00:07:35,720
7

179
00:07:35,720 --> 00:07:36,880
6

180
00:07:36,880 --> 00:07:38,320
5

181
00:07:38,320 --> 00:07:39,480
4

182
00:07:39,480 --> 00:07:40,560
3

183
00:07:40,560 --> 00:07:41,760
2

184
00:07:41,760 --> 00:07:42,760
1

185
00:07:44,120 --> 00:07:49,120
Ladies and gentlemen, science class is now over!

186
00:07:49,120 --> 00:07:51,120
Thank you!

187
00:07:55,120 --> 00:08:01,120
那通过刚才那个视频呢,我们看到了CPU跟GPU之间的一个具体的表现形式。

188
00:08:01,120 --> 00:08:04,120
我们现在来看看图形计算单元了。

189
00:08:04,120 --> 00:08:10,120
所谓的图形计算单元呢,GPU的一开始呢,其实它没有想过自己能够成为一个并行的处理器。

190
00:08:10,120 --> 00:08:14,120
它主要是接替CPU对图形进行渲染。

191
00:08:14,120 --> 00:08:20,120
因为我们的图形啊,非常多相同的元素,非常多相同的像素点。

192
00:08:20,120 --> 00:08:23,120
我们要对每个像素点呢,都进行相同的运算。

193
00:08:23,120 --> 00:08:28,120
于是呢,就衍生了我们的GPU去分担CPU的工作。

194
00:08:31,120 --> 00:08:35,120
那左边这个呢,就是我们之前多次给大家演示到的CPU的架构图。

195
00:08:35,120 --> 00:08:38,120
右边的这个呢,就是我们的GPU的架构图。

196
00:08:38,120 --> 00:08:42,120
可以看到自己的架构图,我们可以看到了GPU大部分都有绿色的这些ALU,

197
00:08:42,120 --> 00:08:48,120
是我们的计算单元去组成的,只有少量的控制单元和内存的存储单元。

198
00:08:48,120 --> 00:08:53,120
大部分我们左边的CPU呢,不仅仅被cache占用了大量的空间,

199
00:08:53,120 --> 00:08:58,120
而且有非常之复杂的控制逻辑电路,还有其他额外的电路。

200
00:08:58,120 --> 00:09:04,120
相比起来呢,计算能力,计算能力的提升只是CPU里面的很小的一部分。

201
00:09:05,120 --> 00:09:10,120
接着我们继续打开GPU的整体的架构,来看看GPU有什么不一样。

202
00:09:10,120 --> 00:09:15,120
首先呢,GPU一个呢,就是GPU的cache呢,是非常非常的少的。

203
00:09:15,120 --> 00:09:18,120
它有很少的控制单元。

204
00:09:18,120 --> 00:09:23,120
正常处理if else while for这种控制流语句。

205
00:09:23,120 --> 00:09:30,120
那第三个呢,就是有非常多的ALU,就是有非常多的ALU。

206
00:09:30,120 --> 00:09:33,120
ALU就是我们绿色的计算单元。

207
00:09:33,120 --> 00:09:36,120
ALU已经成矩阵的排列非常非常的多。

208
00:09:36,120 --> 00:09:41,120
很有意思的就是我们的cache非常的少,我们的dwam并不大。

209
00:09:41,120 --> 00:09:44,120
但是呢,里面却有非常多的计算单元。

210
00:09:44,120 --> 00:09:49,120
这意味着我们有非常之长的latency,但是呢会有一个很high的fullput。

211
00:09:49,120 --> 00:09:53,120
翻译过来就是食言呢,可能会稍微相对长一点,

212
00:09:53,120 --> 00:09:57,120
但是呢,吞吐率却是非常非常的大。

213
00:09:58,120 --> 00:10:04,120
那就非常多的线程,每个线程呢,去控制一个ALU或者控制多个ALU。

214
00:10:04,120 --> 00:10:08,120
通过大量的线程的并发,可以处理并行的内容。

215
00:10:10,120 --> 00:10:13,120
那我们提到GPU的cache呢,是非常少的。

216
00:10:13,120 --> 00:10:15,120
那为什么去里面的cache很多?

217
00:10:15,120 --> 00:10:18,120
是因为它能做很多大量的缓存。

218
00:10:18,120 --> 00:10:21,120
缓存起来了,提供后面的数据进行处理。

219
00:10:21,120 --> 00:10:25,120
但是GPU的cache呢,它的缓存并不是用来保存之后呢,

220
00:10:25,120 --> 00:10:29,120
跟后续进行访问的,而是为我们的线程提供服务的。

221
00:10:30,120 --> 00:10:34,120
我们其实简单的提到过呢,GPU它是一个SIMT的架构,

222
00:10:34,120 --> 00:10:36,120
那T呢就是我们的线程。

223
00:10:36,120 --> 00:10:40,120
很多时候线之后呢,大量的线程需要访问同一段数据,

224
00:10:40,120 --> 00:10:44,120
也就是我们一种我们可能一段数据呢,要执行非常多的计算。

225
00:10:44,120 --> 00:10:49,120
那这个时候呢,我们的缓存就会合并很多这种线程的访问,

226
00:10:49,120 --> 00:10:53,120
然后再去通过多极流水呢,去访问我们的DWAM,

227
00:10:53,120 --> 00:10:56,120
就下面的这个内存的单元,或者我们的内存,

228
00:10:56,120 --> 00:10:58,120
或者大家叫做显存也可以。

229
00:10:58,120 --> 00:11:03,120
获取数据之后呢,cache会统一分发到对应的线程上面,

230
00:11:03,120 --> 00:11:08,120
所以它的作用呢,不是为了保存后面要访问的数据,

231
00:11:08,120 --> 00:11:12,120
而是方便我们的线程进行合并读写。

232
00:11:13,120 --> 00:11:15,120
我们了解完GPU的几个重要的特性,

233
00:11:15,120 --> 00:11:19,120
我们现在来看看GPU适合处理哪些应用程序,

234
00:11:19,120 --> 00:11:22,120
那主要有两次密集型的计算程序。

235
00:11:22,120 --> 00:11:24,120
我们的程序上面有大量的计算,

236
00:11:24,120 --> 00:11:25,120
大量相同的计算,

237
00:11:25,120 --> 00:11:28,120
于是这个时候呢,我们就需要GPU进行处理。

238
00:11:28,120 --> 00:11:31,120
第二种呢,就是是易于并行的程序,

239
00:11:31,120 --> 00:11:33,120
我们可能有非常多的计算,

240
00:11:33,120 --> 00:11:36,120
非常多的数据都执行相同的计算,

241
00:11:36,120 --> 00:11:39,120
于是呢,我们可以使用现代的GPU进行处理了,

242
00:11:39,120 --> 00:11:41,120
但早期的GPU呢,是不具备这个能力的。

243
00:11:42,120 --> 00:11:46,120
最后呢,我们简单的看看现在AI整个规模化产业化发展的,

244
00:11:46,120 --> 00:11:48,120
其实是局需我们的GPU的,

245
00:11:48,120 --> 00:11:51,120
我们可以看到AI遇到GPU呢,

246
00:11:51,120 --> 00:11:53,120
主要有比较大的一个时间节点,

247
00:11:53,120 --> 00:11:54,120
就是在2012年,

248
00:11:54,120 --> 00:11:55,120
Alice跟Hita呢,

249
00:11:55,120 --> 00:11:57,120
设计了整个AlexNet,

250
00:11:57,120 --> 00:11:58,120
那AlexNet呢,

251
00:11:58,120 --> 00:12:00,120
在image的这个数据机里面呢,

252
00:12:00,120 --> 00:12:03,120
获得非常之夸张的一个冠军的水平,

253
00:12:03,120 --> 00:12:04,120
对比起其他办法呢,

254
00:12:04,120 --> 00:12:06,120
确实已经没有太多的优势了,

255
00:12:06,120 --> 00:12:07,120
而AlexNet呢,

256
00:12:07,120 --> 00:12:09,120
主要是用GPU进行加速训练两周,

257
00:12:09,120 --> 00:12:11,120
效果已经非常非常的好了。

258
00:12:11,120 --> 00:12:12,120
另外一个呢,

259
00:12:12,120 --> 00:12:15,120
就是谷歌使用1000台CPU服务器呢,

260
00:12:15,120 --> 00:12:18,120
去训练谷歌的YouTube里面的视频,

261
00:12:18,120 --> 00:12:20,120
做一个猫和狗的分别,

262
00:12:20,120 --> 00:12:24,120
那这个时候温达使用了三台GTS680GPU,

263
00:12:24,120 --> 00:12:26,120
就完成了相同的任务,

264
00:12:26,120 --> 00:12:28,120
我们就大家开始意识到,

265
00:12:28,120 --> 00:12:30,120
通过GPU加深度学习呢,

266
00:12:30,120 --> 00:12:33,120
我们可以取代很多CPU复杂的操作,

267
00:12:33,120 --> 00:12:34,120
节省很多的资源,

268
00:12:34,120 --> 00:12:37,120
而真正的整个AI的爆发期呢,

269
00:12:37,120 --> 00:12:39,120
是随着我们产业的发展的,

270
00:12:39,120 --> 00:12:40,120
那产业的发展呢,

271
00:12:40,120 --> 00:12:41,120
有两大方面,

272
00:12:41,120 --> 00:12:42,120
第一大方面呢,

273
00:12:42,120 --> 00:12:43,120
就是整个AI的分网,

274
00:12:43,120 --> 00:12:45,120
我们的AI框架越来越多,

275
00:12:45,120 --> 00:12:46,120
大部分的AI框架,

276
00:12:46,120 --> 00:12:48,120
慢慢的开始兼容我们的CPU,

277
00:12:48,120 --> 00:12:49,120
可能部分的AI框架,

278
00:12:49,120 --> 00:12:50,120
像飞龙啊,

279
00:12:50,120 --> 00:12:51,120
还有一开始的Torch,

280
00:12:51,120 --> 00:12:52,120
而不是PyTorch,

281
00:12:52,120 --> 00:12:54,120
都是支持CPU的,

282
00:12:54,120 --> 00:12:56,120
后来就越来越多的支持GPU了,

283
00:12:56,120 --> 00:12:57,120
那第二种呢,

284
00:12:57,120 --> 00:12:59,120
就是英伟达的AI Enterprise,

285
00:12:59,120 --> 00:13:02,120
它推出了一个系列的解决方案,

286
00:13:02,120 --> 00:13:05,120
通过GPU更好的去支持我们整个AI的发展,

287
00:13:05,120 --> 00:13:07,120
所以它是一个AI的爆发呢,

288
00:13:07,120 --> 00:13:09,120
跟GPU的爆发是相关联的,

289
00:13:09,120 --> 00:13:12,120
跟英伟达的努力也是相关联的,

290
00:13:12,120 --> 00:13:13,120
最后一点呢,

291
00:13:13,120 --> 00:13:15,120
就到这里为止,

292
00:13:15,120 --> 00:13:17,120
我们了解了通用图形处理器,

293
00:13:17,120 --> 00:13:19,120
GPU的整体的发展,

294
00:13:19,120 --> 00:13:21,120
然后看了一下GPU的架构,

295
00:13:21,120 --> 00:13:23,120
接下来我们会从硬件的基础,

296
00:13:23,120 --> 00:13:24,120
英伟达的CPU架构,

297
00:13:24,120 --> 00:13:26,120
还有GPU的图形处理,

298
00:13:26,120 --> 00:13:27,120
流水线,

299
00:13:27,120 --> 00:13:29,120
我们的流量的流处理器,

300
00:13:29,120 --> 00:13:31,120
去深入的看看GPU,

301
00:13:31,120 --> 00:13:32,120
那各位,

302
00:13:32,120 --> 00:13:33,120
拜了个拜!

303
00:13:42,120 --> 00:13:43,120
拜了个拜!

