1
00:00:00,000 --> 00:00:05,880
哈喽大家好

2
00:00:05,880 --> 00:00:07,680
我是小时候缺盖

3
00:00:07,680 --> 00:00:09,640
长大了缺发的周米

4
00:00:09,640 --> 00:00:14,080
来到一个新的内容

5
00:00:14,080 --> 00:00:15,400
GPU的详解

6
00:00:15,400 --> 00:00:17,360
这里面的GPU的GPU

7
00:00:18,800 --> 00:00:21,840
在整个英伟达的GPU架构系列里面

8
00:00:21,960 --> 00:00:23,640
我们来了解一下

9
00:00:23,640 --> 00:00:26,400
接下来我们会给大家展开哪些内容

10
00:00:26,400 --> 00:00:29,200
今天的主角GPU的基础概念

11
00:00:29,200 --> 00:00:33,160
有了对GPU的软硬件的基础概念之后

12
00:00:33,160 --> 00:00:36,440
接下来我们就会简单的去看一看

13
00:00:36,440 --> 00:00:38,640
从费米到Volta的架构

14
00:00:38,640 --> 00:00:41,320
从Turing到Hopper的架构

15
00:00:41,320 --> 00:00:44,040
最后看一下最近这几年

16
00:00:44,040 --> 00:00:47,280
针对AI而衍生出来的Tensor Core

17
00:00:47,280 --> 00:00:50,080
还有大带宽的NVLink

18
00:00:50,080 --> 00:00:50,880
然后去看看

19
00:00:51,760 --> 00:00:53,480
GPU基础概念里面

20
00:00:53,640 --> 00:00:56,840
主要分开三大块给大家去汇报的

21
00:00:56,840 --> 00:00:59,120
第一块就是GPU的基础概念

22
00:00:59,120 --> 00:01:00,960
包括是CUDA

23
00:01:00,960 --> 00:01:02,960
CUDA是一个并行的计算平台

24
00:01:02,960 --> 00:01:05,120
或者并行的编程体系也好

25
00:01:05,120 --> 00:01:05,800
第

26
00:01:05,800 --> 00:01:08,800
CUDA里面的GridBlockFlex

27
00:01:08,800 --> 00:01:12,120
线程网格块相关的结构

28
00:01:12,120 --> 00:01:13,000
最后我们看看

29
00:01:13,000 --> 00:01:16,120
看看英伟达的算力是怎么计算的

30
00:01:16,120 --> 00:01:17,160
有了这个算力之后

31
00:01:17,280 --> 00:01:18,160
我们在

32
00:01:18,520 --> 00:01:20,440
大电的时候就很好的去计算

33
00:01:20,440 --> 00:01:22,240
我们的算力峰值

34
00:01:22,240 --> 00:01:24,120
算一下我们的算力利用率

35
00:01:24,120 --> 00:01:25,440
到底是怎么样的

36
00:01:25,720 --> 00:01:27,600
接下来进入实际内容之前

37
00:01:27,720 --> 00:01:30,800
我们来回顾一下GPU跟CPU

38
00:01:30,800 --> 00:01:32,240
之间的一个关系

39
00:01:32,400 --> 00:01:33,800
从左边这下角的图

40
00:01:33,800 --> 00:01:34,560
我们可以看到

41
00:01:34,560 --> 00:01:36,120
其实CPU里面的AIO

42
00:01:36,120 --> 00:01:37,800
或者所谓的计算单元

43
00:01:37,800 --> 00:01:39,160
并不是那么多

44
00:01:39,160 --> 00:01:41,560
更重要的是讲究逻辑的控制

45
00:01:41,560 --> 00:01:44,400
所以层次的这块控制单元会比较大

46
00:01:44,400 --> 00:01:46,560
而且cache也会比较大

47
00:01:46,560 --> 00:01:49,000
右边的这个就是GPU的简单的架构

48
00:01:49,000 --> 00:01:50,560
绿色代表我们的计算单元

49
00:01:50,560 --> 00:01:51,400
从GPU的架构

50
00:01:51,400 --> 00:01:52,360
你们可以看到

51
00:01:52,360 --> 00:01:54,440
里面有大量的计算单元

52
00:01:54,440 --> 00:01:56,160
而真正的控制和cache

53
00:01:56,280 --> 00:01:57,920
其实是非常少的一部分

54
00:01:57,920 --> 00:01:58,320
当然了

55
00:01:58,320 --> 00:01:59,440
大家都有DWAM

56
00:01:59,440 --> 00:02:00,400
而在GPU里面

57
00:02:00,400 --> 00:02:01,440
实际上DWAM

58
00:02:01,480 --> 00:02:04,160
叫做HBM高气

59
00:02:05,240 --> 00:02:07,840
到第1个真正的内容

60
00:02:07,840 --> 00:02:11,920
就是英伟达的硬件的基本的概念

61
00:02:12,680 --> 00:02:14,360
像我们逐个的去看一下

62
00:02:14,360 --> 00:02:15,320
首先可以看到

63
00:02:15,320 --> 00:02:18,000
这里面有非常多的GPC

64
00:02:18,000 --> 00:02:20,480
有非常多的图像处理处

65
00:02:20,480 --> 00:02:22,720
就是我们的graph possessed cluster

66
00:02:22,720 --> 00:02:23,880
非常多的特

67
00:02:24,000 --> 00:02:26,040
那每一期我们可以看到

68
00:02:26,040 --> 00:02:29,160
里面又有非常多的TPC

69
00:02:29,160 --> 00:02:31,240
TPC是英伟达的

70
00:02:31,240 --> 00:02:33,000
texture possessed cluster

71
00:02:33,000 --> 00:02:34,680
纹理处理处

72
00:02:34,680 --> 00:02:36,240
每个纹理处理处里面

73
00:02:36,680 --> 00:02:39,080
又分为多个SM

74
00:02:39,080 --> 00:02:40,640
多个SM里面

75
00:02:40,640 --> 00:02:42,880
又分为很多block和thread

76
00:02:43,240 --> 00:02:45,760
我们现在来去综合的看一下

77
00:02:45,760 --> 00:02:47,080
这些主要的概念

78
00:02:47,080 --> 00:02:50,160
首先在整个最大的有一个GPC

79
00:02:50,160 --> 00:02:51,960
我们叫做图像处理处

80
00:02:51,960 --> 00:02:55,080
然后又有了TPC纹理处理处

81
00:02:55,080 --> 00:02:57,840
最小的单位有一个流处理处

82
00:02:57,840 --> 00:02:58,840
而另外的话

83
00:02:58,840 --> 00:03:00,120
在中间绿色的

84
00:03:00,120 --> 00:03:00,840
或者蓝色的

85
00:03:00,840 --> 00:03:01,560
刚才那个模块

86
00:03:01,880 --> 00:03:04,680
就是我们的HBM高带宽存储器

87
00:03:04,680 --> 00:03:05,840
整体的包含官室

88
00:03:06,040 --> 00:03:08,040
就是GPC大于TCP

89
00:03:08,040 --> 00:03:08,720
TSM

90
00:03:08,720 --> 00:03:09,640
而SM里面

91
00:03:09,760 --> 00:03:11,880
就有各种各样的CUDA Cortex core

92
00:03:11,880 --> 00:03:13,880
各种各样的TR core也好

93
00:03:13,880 --> 00:03:16,680
专门的针对我们的图形图像

94
00:03:16,680 --> 00:03:19,280
纹理或者AI张量

95
00:03:19,280 --> 00:03:21,240
进行处理的单元

96
00:03:21,280 --> 00:03:24,760
而这里面理解一个非常重要的概念

97
00:03:24,760 --> 00:03:26,120
叫做SM

98
00:03:30,800 --> 00:03:31,720
里面的SM

99
00:03:31,960 --> 00:03:34,160
并不是我们意义上理解的SM

100
00:03:34,360 --> 00:03:36,720
是多流式处理器

101
00:03:36,720 --> 00:03:38,680
Streaming Multiprocessor

102
00:03:38,680 --> 00:03:42,120
这个概念其实是从G80

103
00:03:42,120 --> 00:03:43,760
也就是2006年的时候

104
00:03:43,760 --> 00:03:44,880
去提出的

105
00:03:44,880 --> 00:03:46,520
整个的核心组件

106
00:03:46,520 --> 00:03:48,000
主要是有CUDA core

107
00:03:48,000 --> 00:03:50,000
就是我们的计算的核心

108
00:03:50,000 --> 00:03:51,600
另外还会有一些共享的类传

109
00:03:51,600 --> 00:03:52,600
还有集成器

110
00:03:52,600 --> 00:03:54,760
里面SM最核心的模块

111
00:03:54,880 --> 00:03:57,160
就是我们的现成的执行的单元

112
00:03:57,160 --> 00:03:58,600
所以我们叫做CUDA core

113
00:03:58,600 --> 00:03:59,560
这里面可以看到

114
00:03:59,560 --> 00:04:00,880
不管是int32

115
00:04:00,880 --> 00:04:01,640
FP32

116
00:04:01,640 --> 00:04:02,440
FP14

117
00:04:02,440 --> 00:04:03,760
还是Tensor core

118
00:04:03,760 --> 00:04:06,720
它最终都归根于我们的执行单元

119
00:04:06,720 --> 00:04:08,240
或者最小的执行单位

120
00:04:08,240 --> 00:04:09,440
这是因为我们说

121
00:04:09,440 --> 00:04:12,160
SM是英伟达的整个的核心

122
00:04:12,160 --> 00:04:14,600
里面SM有非常多的计算单元

123
00:04:14,600 --> 00:04:16,880
所有计算单元都藏在SM里面

124
00:04:17,840 --> 00:04:19,240
可以并发的执行

125
00:04:19,240 --> 00:04:21,040
数百个线程

126
00:04:21,040 --> 00:04:23,840
每一个线程都会执行对应的指令

127
00:04:23,840 --> 00:04:26,080
或者在我们对应的硬件数据上面

128
00:04:26,080 --> 00:04:27,200
去进行处理的

129
00:04:27,200 --> 00:04:29,280
而每一个都是硬件上的概念

130
00:04:29,280 --> 00:04:30,600
而从软件上面来看

131
00:04:30,880 --> 00:04:32,800
特别是从CUDA的角度来看

132
00:04:32,800 --> 00:04:34,960
我们可以通过SM并发的执行

133
00:04:34,960 --> 00:04:36,040
数百个线程

134
00:04:36,040 --> 00:04:36,960
数百个fret

135
00:04:36,960 --> 00:04:37,720
而每个fret

136
00:04:37,720 --> 00:04:39,400
刚才其实在上一个章节里面

137
00:04:39,400 --> 00:04:40,120
我们提到

138
00:04:40,120 --> 00:04:41,800
线程其实是有等级的

139
00:04:41,800 --> 00:04:43,000
它有快

140
00:04:43,600 --> 00:04:45,160
和最小的单位线程

141
00:04:45,160 --> 00:04:46,200
而每个快上快

142
00:04:46,360 --> 00:04:48,480
是放在同一个SM去执行

143
00:04:48,480 --> 00:04:49,480
而SM里面

144
00:04:49,720 --> 00:04:50,960
通过register

145
00:04:50,960 --> 00:04:51,920
或者我们的cache

146
00:04:52,200 --> 00:04:53,760
去约束每个快

147
00:04:53,760 --> 00:04:54,880
线程的大小

148
00:04:54,880 --> 00:04:56,640
因为数据就这么多了

149
00:04:56,640 --> 00:04:58,040
硬件单元就这么多了

150
00:04:58,040 --> 00:04:58,960
所以我们的线程

151
00:04:59,120 --> 00:05:00,800
不能无限制的扩充

152
00:05:01,080 --> 00:05:02,080
接下来我们来看一看

153
00:05:02,080 --> 00:05:03,880
其实SM刚才只是举了

154
00:05:03,880 --> 00:05:06,000
几个比较重要的模块

155
00:05:06,000 --> 00:05:08,200
实际上SM里面的模块非常多

156
00:05:08,200 --> 00:05:09,360
我们有CUDA core

157
00:05:09,360 --> 00:05:10,920
向量的运算单元

158
00:05:10,920 --> 00:05:12,080
还有Tensor core

159
00:05:12,080 --> 00:05:13,280
张量的运算单元

160
00:05:13,280 --> 00:05:15,720
专门针对AI进行加速的

161
00:05:15,720 --> 00:05:17,160
特别是矩阵层

162
00:05:17,160 --> 00:05:19,040
另外针对超越函数

163
00:05:19,040 --> 00:05:20,440
或者一些复杂的数学操作

164
00:05:20,760 --> 00:05:24,760
我们就会有SFU特殊的函数单元

165
00:05:24,760 --> 00:05:26,040
专门对我们的数学进行

166
00:05:26,040 --> 00:05:28,400
仿平凡跟正弦余弦的操作

167
00:05:28,680 --> 00:05:30,960
在二三主要是针对我们具体的

168
00:05:30,960 --> 00:05:33,400
计算执行来去看待的

169
00:05:33,400 --> 00:05:35,520
而我们下面看看第4个

170
00:05:35,520 --> 00:05:36,760
就是我们的web schedule

171
00:05:36,760 --> 00:05:38,040
还有dispatch schedule

172
00:05:38,040 --> 00:05:40,560
我们是线程数的一个调度器

173
00:05:40,560 --> 00:05:41,640
我们会把线程

174
00:05:41,640 --> 00:05:43,800
下发到具体的计算单元里面

175
00:05:43,800 --> 00:05:45,160
而针对线程

176
00:05:45,160 --> 00:05:46,600
它是个软件的概念

177
00:05:46,600 --> 00:05:47,400
实际上硬件

178
00:05:47,520 --> 00:05:49,280
我们是执行指令

179
00:05:49,280 --> 00:05:51,040
因此有了第5个单元

180
00:05:51,040 --> 00:05:52,040
dispatch unit

181
00:05:52,040 --> 00:05:54,000
专门针对指令进行分发

182
00:05:54,000 --> 00:05:54,840
分发到上面

183
00:05:54,840 --> 00:05:56,960
一二三的具体的执行单位

184
00:05:56,960 --> 00:05:57,680
另外的话

185
00:05:57,680 --> 00:05:59,600
这两层和iola

186
00:05:59,600 --> 00:06:00,520
就是we just file

187
00:06:00,520 --> 00:06:01,600
我们的寄存器堆

188
00:06:01,600 --> 00:06:02,920
还有我们的low store

189
00:06:02,920 --> 00:06:04,440
访问存一些单元

190
00:06:04,440 --> 00:06:06,680
专门针对我们的数据进行处理

191
00:06:08,320 --> 00:06:10,120
刚才只是简单的去看看

192
00:06:10,120 --> 00:06:11,720
一个比较大的概念

193
00:06:11,720 --> 00:06:13,720
或者单元叫做sm

194
00:06:13,720 --> 00:06:15,600
现在我们再打开sm里面

195
00:06:15,760 --> 00:06:17,880
其实刚才提到的很多

196
00:06:17,880 --> 00:06:18,520
CUDA core

197
00:06:18,840 --> 00:06:20,200
它的前身叫做

198
00:06:20,200 --> 00:06:21,880
sp流处理器

199
00:06:21,880 --> 00:06:24,360
里面最基本的处理的单元

200
00:06:25,120 --> 00:06:27,040
在后来的英伟达的架构眼镜

201
00:06:27,240 --> 00:06:29,640
慢慢的被CUDA core所替代掉了

202
00:06:29,640 --> 00:06:30,240
而CUDA core

203
00:06:30,240 --> 00:06:32,040
其实后面也慢慢的消亡了

204
00:06:32,040 --> 00:06:34,080
那现在我们进行并行的计算

205
00:06:34,080 --> 00:06:36,400
因此我们会有非常多的sm

206
00:06:36,400 --> 00:06:38,480
和非常多的sp

207
00:06:39,200 --> 00:06:40,160
你架构的提出

208
00:06:40,320 --> 00:06:42,920
sp就逐渐的被CUDA core

209
00:06:42,920 --> 00:06:44,320
所代替掉了

210
00:06:44,320 --> 00:06:46,000
这里面是新的架构的

211
00:06:46,000 --> 00:06:47,240
名字的命名

212
00:06:47,240 --> 00:06:48,400
在一个sm里面

213
00:06:48,560 --> 00:06:50,800
具有非常多的CUDA core

214
00:06:50,800 --> 00:06:52,880
而我们打开其中一个CUDA core

215
00:06:52,880 --> 00:06:53,400
来看看

216
00:06:53,840 --> 00:06:54,920
一个sm里面

217
00:06:55,000 --> 00:06:55,920
有两组

218
00:06:55,920 --> 00:06:57,640
各16个CUDA core

219
00:06:57,640 --> 00:06:58,680
而每个CUDA core

220
00:06:58,880 --> 00:07:00,800
就是我们右边的小模块

221
00:07:00,800 --> 00:07:02,680
包含一个浮点的运算单元

222
00:07:02,680 --> 00:07:03,520
还有一个

223
00:07:04,080 --> 00:07:05,360
运算单元

224
00:07:06,040 --> 00:07:06,880
它架构的时候

225
00:07:07,040 --> 00:07:08,720
CUDA core又慢慢的

226
00:07:08,720 --> 00:07:09,920
被取代掉了

227
00:07:09,920 --> 00:07:11,000
就没有了CUDA core

228
00:07:11,040 --> 00:07:12,960
反而变成int32的单元

229
00:07:12,960 --> 00:07:14,320
多个fp32单元

230
00:07:14,320 --> 00:07:16,520
可能还会出现出现的tensor core

231
00:07:16,520 --> 00:07:18,040
之所以这样去掉CUDA core

232
00:07:18,040 --> 00:07:18,520
这个概念

233
00:07:18,720 --> 00:07:20,400
是因为每个sm

234
00:07:20,520 --> 00:07:24,120
现在支持fp32和int32的并发执行

235
00:07:24,120 --> 00:07:27,160
更好的提升我们运算的吞吐量

236
00:07:27,160 --> 00:07:28,800
提升我们系统的利用率

237
00:07:29,760 --> 00:07:30,640
硬件架构里面

238
00:07:30,760 --> 00:07:33,200
我们漏掉了中间非常重要的

239
00:07:33,200 --> 00:07:34,920
黄黄的模块

240
00:07:34,920 --> 00:07:35,440
这个模块

241
00:07:35,440 --> 00:07:37,080
我们叫做web线程处

242
00:07:37,080 --> 00:07:38,080
从逻辑上来说

243
00:07:38,080 --> 00:07:39,000
所有的线程

244
00:07:39,000 --> 00:07:41,360
其实是并行或者并发的去执行的

245
00:07:41,360 --> 00:07:43,200
但是从硬件的角度来说

246
00:07:43,200 --> 00:07:44,600
不是所有的线程

247
00:07:44,600 --> 00:07:46,920
我们都能够在同一时刻

248
00:07:46,920 --> 00:07:47,840
去执行的

249
00:07:47,840 --> 00:07:48,880
也就是我们的并发

250
00:07:48,880 --> 00:07:50,680
就引用了web这个概念

251
00:07:50,680 --> 00:07:52,680
通过web去控制线程

252
00:07:53,360 --> 00:07:55,440
对我们的线程进行锁同步

253
00:07:55,440 --> 00:07:57,280
然后分发具体的指令

254
00:07:57,280 --> 00:07:59,560
给我们的计算单元去执行

255
00:08:01,920 --> 00:08:04,400
现在我们来到第二个内容的概念

256
00:08:04,400 --> 00:08:06,000
看一下什么是CUDA

257
00:08:06,000 --> 00:08:08,000
是在2006年11月份的时候

258
00:08:08,000 --> 00:08:09,400
英伟达就推出来了

259
00:08:09,400 --> 00:08:10,400
为要着CUDA

260
00:08:10,600 --> 00:08:13,120
英伟达其实做了非常多的工作

261
00:08:13,120 --> 00:08:16,640
利用了推出了非常多的奇奇怪怪的数学库

262
00:08:16,640 --> 00:08:20,120
还推出了很多那些针对CUDA的加速库

263
00:08:20,120 --> 00:08:22,960
当然在还可以支持OpenACC

264
00:08:22,960 --> 00:08:23,560
LVM

265
00:08:23,560 --> 00:08:24,000
Fortune

266
00:08:24,000 --> 00:08:26,080
Python等高级的语言

267
00:08:27,080 --> 00:08:29,400
来了解一下CUDA到底是什么

268
00:08:29,400 --> 00:08:32,080
首先我们可以非常方便的去控制

269
00:08:32,080 --> 00:08:35,360
GPU里面的各种并行的硬件

270
00:08:35,360 --> 00:08:35,840
而第二个

271
00:08:35,960 --> 00:08:38,280
它是觉得它是一个编程的模型

272
00:08:38,280 --> 00:08:39,480
所谓的编程模型

273
00:08:39,480 --> 00:08:40,600
更好的理解

274
00:08:40,760 --> 00:08:42,600
总比觉得它是一个编程的体系

275
00:08:42,600 --> 00:08:44,080
可以使用C或者C++

276
00:08:45,200 --> 00:08:46,560
的并行的语言

277
00:08:46,560 --> 00:08:47,480
而在底层

278
00:08:47,760 --> 00:08:51,320
CUDA它其实是通过一个LVM来去实现的

279
00:08:51,320 --> 00:08:52,640
一个CUDA的编辑

280
00:08:52,640 --> 00:08:53,760
非常方便开发者

281
00:08:53,760 --> 00:08:55,440
举C C++高级语言

282
00:08:55,680 --> 00:08:57,960
去进行开发CUDA的程序

283
00:08:57,960 --> 00:09:00,640
那第三个就是CUDA可以支持OpenCL

284
00:09:00,640 --> 00:09:01,120
Fortune

285
00:09:01,120 --> 00:09:02,560
还有DirectCompute

286
00:09:02,560 --> 00:09:04,840
这种第三个语言或者应用程序的接口

287
00:09:04,840 --> 00:09:08,320
从而更好地去服务于我们更上层的

288
00:09:08,320 --> 00:09:09,400
Application

289
00:09:10,080 --> 00:09:10,960
英伟达这一层

290
00:09:11,320 --> 00:09:12,680
英伟达的硬件

291
00:09:12,680 --> 00:09:14,400
就可以不断的去演进

292
00:09:14,400 --> 00:09:17,840
从而保持着软硬件的一个独立的结构

293
00:09:17,840 --> 00:09:20,160
更好地去实现一些硬件的发展

294
00:09:21,160 --> 00:09:22,680
那具体的打开一下CUDA

295
00:09:22,680 --> 00:09:24,560
相关的一个软件集成

296
00:09:24,560 --> 00:09:25,680
首先中间这一层

297
00:09:25,680 --> 00:09:26,680
我们叫做CUDA

298
00:09:26,680 --> 00:09:28,640
里面就包括了CUDA的Compiler

299
00:09:28,760 --> 00:09:31,120
还有CUDA C++的一个核心

300
00:09:31,120 --> 00:09:32,920
带有一些简单的工具

301
00:09:32,920 --> 00:09:35,040
在底下就是CUDA的Driver

302
00:09:35,040 --> 00:09:35,800
它的驱动

303
00:09:35,800 --> 00:09:37,640
因为很多人可以理解为CUDA

304
00:09:37,840 --> 00:09:41,040
它可以方便我们去驱动英伟达的GPU

305
00:09:41,040 --> 00:09:43,040
去实现多相关的API的库

306
00:09:43,200 --> 00:09:43,960
内存的管理

307
00:09:44,120 --> 00:09:46,040
还有我们的图形图像的一些

308
00:09:46,040 --> 00:09:47,360
API的接口

309
00:09:47,360 --> 00:09:49,640
在网上就是CUDAxLibrary了

310
00:09:49,640 --> 00:09:50,320
CUDAxLibrary

311
00:09:50,320 --> 00:09:53,480
其实在针对AI或者神经网络深度学习

312
00:09:53,480 --> 00:09:54,440
这一个领域里面

313
00:09:54,720 --> 00:09:57,320
就推出了非常多的加速库了

314
00:09:57,320 --> 00:09:58,200
训练加速库了

315
00:09:58,200 --> 00:09:58,920
推理加速库了

316
00:09:58,920 --> 00:10:00,080
还有基础加速库

317
00:10:00,080 --> 00:10:01,120
就非常的多了

318
00:10:01,120 --> 00:10:02,640
在网上就是去对接

319
00:10:02,640 --> 00:10:04,120
我们的一些AI框架了

320
00:10:04,120 --> 00:10:05,480
还有ONNX各种各样

321
00:10:05,480 --> 00:10:07,440
非常多的AI框架

322
00:10:07,440 --> 00:10:10,080
在网上就是我们真正的AI的一些功能了

323
00:10:10,320 --> 00:10:13,320
整个就是CUDA的软硬件生态站

324
00:10:14,160 --> 00:10:15,400
来到了第三个内容

325
00:10:15,400 --> 00:10:16,240
我们现在来看看

326
00:10:16,240 --> 00:10:17,520
CUDA的层次结构

327
00:10:17,520 --> 00:10:19,200
来到CUDA的层次结构里面

328
00:10:19,200 --> 00:10:20,320
很重要的一个概念

329
00:10:20,320 --> 00:10:21,360
我们之前讲到

330
00:10:21,360 --> 00:10:22,920
CUDA最重要一个自信单位

331
00:10:22,920 --> 00:10:26,160
就是线程里面的每个弯弯弯弯的

332
00:10:26,160 --> 00:10:27,960
都是我们的线程

333
00:10:27,960 --> 00:10:30,080
而线程最主要最重要的是

334
00:10:30,080 --> 00:10:30,760
我们的网格

335
00:10:30,760 --> 00:10:32,920
网格里面又分回很多的块

336
00:10:32,920 --> 00:10:34,760
块类又很多的线程

337
00:10:34,760 --> 00:10:35,880
这些块件的线程

338
00:10:36,000 --> 00:10:36,920
都是独立执行

339
00:10:36,920 --> 00:10:38,920
中间通过本地共享内存

340
00:10:38,920 --> 00:10:41,360
就local memory去交换数据

341
00:10:41,360 --> 00:10:43,320
而现在我们真正的理解一下

342
00:10:43,320 --> 00:10:45,640
线程类的一些层次的结构

343
00:10:45,640 --> 00:10:48,440
首先第一个概念就是所谓的kernel

344
00:10:48,600 --> 00:10:49,600
了解kernel之前

345
00:10:49,680 --> 00:10:51,120
我们看两个概念

346
00:10:51,120 --> 00:10:52,360
一个就是host

347
00:10:52,360 --> 00:10:53,880
host主要是指我们的CPU

348
00:10:53,880 --> 00:10:54,960
另外一个是devices

349
00:10:54,960 --> 00:10:57,040
devices主要是指我们的GPU

350
00:10:57,040 --> 00:10:59,880
host跟devices之间是交互去执行的

351
00:10:59,880 --> 00:11:02,240
而不管我们之间可以进行通讯

352
00:11:02,240 --> 00:11:02,640
这样的话

353
00:11:02,640 --> 00:11:04,160
我们就可以非常方便

354
00:11:04,160 --> 00:11:06,080
数据进行传出传入

355
00:11:06,080 --> 00:11:06,960
通过devices

356
00:11:06,960 --> 00:11:07,640
通过GPU

357
00:11:07,800 --> 00:11:09,080
做一些并行的操作

358
00:11:09,080 --> 00:11:10,080
并行操作完之后

359
00:11:10,200 --> 00:11:11,160
把数据的结果

360
00:11:11,160 --> 00:11:12,400
丢给我们的host CPU

361
00:11:12,400 --> 00:11:13,440
进行处理

362
00:11:13,440 --> 00:11:15,200
整体就是这么一个循环

363
00:11:15,200 --> 00:11:16,160
接下来我们看一下

364
00:11:16,160 --> 00:11:18,000
什么为之kernel

365
00:11:18,000 --> 00:11:18,920
kernel这些概念

366
00:11:19,080 --> 00:11:20,000
是在CUDA里面

367
00:11:20,000 --> 00:11:22,560
最核心的一个重要概念

368
00:11:23,320 --> 00:11:24,600
里面主要就是指

369
00:11:24,600 --> 00:11:26,920
调用我们的CUDA的核函数

370
00:11:26,920 --> 00:11:28,320
也就是我们的kernel函数

371
00:11:28,360 --> 00:11:30,440
来执行并行的计算

372
00:11:30,600 --> 00:11:33,120
这就是我们第一个讲到的概念

373
00:11:33,120 --> 00:11:34,400
而在第二个概念里面

374
00:11:34,480 --> 00:11:35,760
我们会等一下看到

375
00:11:36,080 --> 00:11:37,600
有很多host的代码

376
00:11:37,720 --> 00:11:39,880
实际上是在CPU上面去执行的

377
00:11:39,880 --> 00:11:41,640
但是当我们数据遇到一些

378
00:11:41,640 --> 00:11:43,560
要并发并行处理的任务

379
00:11:43,560 --> 00:11:44,880
我们就会使用CUDA

380
00:11:44,880 --> 00:11:46,960
或者CUDA进行编程

381
00:11:46,960 --> 00:11:47,680
在编译完之后

382
00:11:47,680 --> 00:11:48,440
执行的时候

383
00:11:48,720 --> 00:11:49,760
可能有部分代码

384
00:11:49,760 --> 00:11:50,440
是在host

385
00:11:50,440 --> 00:11:52,080
我们的主机端去执行

386
00:11:52,080 --> 00:11:52,840
有部分代码

387
00:11:52,960 --> 00:11:55,440
就会在devices上面去执行

388
00:11:55,440 --> 00:11:56,480
而这个程序

389
00:11:56,720 --> 00:11:58,480
只要是CUDA执行的部分

390
00:11:58,480 --> 00:12:00,640
我们统一都叫做kernel

391
00:12:01,320 --> 00:12:02,320
再来我们看两个

392
00:12:02,320 --> 00:12:03,840
真实的具体的代码的例子

393
00:12:04,000 --> 00:12:04,680
这个代码例子

394
00:12:04,800 --> 00:12:06,360
只是实现很简单的功能

395
00:12:06,360 --> 00:12:08,400
迭代很多次x加y

396
00:12:08,400 --> 00:12:10,400
然后把结果存到y里面

397
00:12:10,640 --> 00:12:12,960
这个时候在遵循冯洛依曼架构

398
00:12:12,960 --> 00:12:14,200
所以我们执行的时候

399
00:12:14,440 --> 00:12:16,080
都是线程级别的去执行

400
00:12:16,080 --> 00:12:17,560
一条一条指令的去执行

401
00:12:17,560 --> 00:12:18,840
所以我们在循环里面

402
00:12:18,840 --> 00:12:20,480
就会执行很多次迭代

403
00:12:20,480 --> 00:12:22,160
所以我们有个迭代for n

404
00:12:22,520 --> 00:12:23,440
接下来我们看一下

405
00:12:23,440 --> 00:12:25,560
程序的主线有个make

406
00:12:25,560 --> 00:12:26,720
然后定一个数据

407
00:12:26,720 --> 00:12:28,200
开辟一个内存空间

408
00:12:28,200 --> 00:12:30,960
接着去定义初始化的数据

409
00:12:30,960 --> 00:12:32,160
然后调用add

410
00:12:32,160 --> 00:12:33,400
刚才那个函数

411
00:12:33,520 --> 00:12:35,520
大量的想要的计算

412
00:12:35,520 --> 00:12:38,160
最后销毁我们的内存

413
00:12:38,240 --> 00:12:39,040
我们看一下

414
00:12:39,040 --> 00:12:40,560
CUDA它是怎么执行的

415
00:12:40,560 --> 00:12:41,320
首先CUDA执行

416
00:12:41,640 --> 00:12:43,720
在前面加了个global

417
00:12:43,720 --> 00:12:44,440
去声明

418
00:12:44,440 --> 00:12:47,200
会有一个变量声明辅典global

419
00:12:47,200 --> 00:12:48,480
然后就去执行

420
00:12:48,480 --> 00:12:50,160
我们具体的函数了

421
00:12:50,160 --> 00:12:51,200
这里面就是我们具体的

422
00:12:51,200 --> 00:12:52,560
函数的执行方式

423
00:12:52,560 --> 00:12:54,680
接着在内存开辟的时候

424
00:12:54,840 --> 00:12:55,880
就直接声明CUDA

425
00:12:55,880 --> 00:12:56,720
我们在CUDA里面

426
00:12:56,840 --> 00:12:57,880
开辟一个内存

427
00:12:57,880 --> 00:12:58,840
然后在CUDA里面

428
00:12:59,040 --> 00:13:02,000
对这个数据进行具体的复制

429
00:13:02,000 --> 00:13:03,160
接着调用add

430
00:13:03,160 --> 00:13:05,400
1 1 n x y

431
00:13:05,400 --> 00:13:06,360
把数据传进去

432
00:13:06,520 --> 00:13:07,920
就真正在执行的时候

433
00:13:07,920 --> 00:13:10,240
就会执行GPU里面的

434
00:13:10,240 --> 00:13:11,560
kernel的函数

435
00:13:11,760 --> 00:13:12,360
执行完之后

436
00:13:12,560 --> 00:13:14,840
就通过声明CUDA free

437
00:13:14,880 --> 00:13:16,440
去释放我们的内存

438
00:13:16,440 --> 00:13:17,280
里面值得

439
00:13:17,880 --> 00:13:19,600
里面去执行的是.cpp

440
00:13:19,600 --> 00:13:22,880
而在英伟达里面执行是.cu

441
00:13:22,880 --> 00:13:24,120
这里面看到

442
00:13:24,120 --> 00:13:24,960
其实有部分代码

443
00:13:25,080 --> 00:13:26,480
执行的是在CPU

444
00:13:26,480 --> 00:13:27,320
有部分代码

445
00:13:27,520 --> 00:13:29,720
就执行在我们的CUDA里面

446
00:13:31,080 --> 00:13:33,160
我们看看线程的层次结构

447
00:13:33,160 --> 00:13:35,520
线程最外面的一个概念是grid

448
00:13:35,520 --> 00:13:36,800
我们的网格

449
00:13:36,800 --> 00:13:38,440
kernel在我们的devices

450
00:13:38,440 --> 00:13:39,560
就GPU执行的时候

451
00:13:39,840 --> 00:13:42,960
实际上会启动非常多的线程

452
00:13:42,960 --> 00:13:45,280
就很多刚才一条条弯曲的曲线

453
00:13:45,280 --> 00:13:47,120
而一个kernel所启动的时候

454
00:13:47,400 --> 00:13:48,400
所有的线程

455
00:13:48,400 --> 00:13:50,520
都会封装在我们的一个grid里面

456
00:13:50,520 --> 00:13:51,640
同一个网格上面

457
00:13:51,800 --> 00:13:54,320
线程是共享全局内存的

458
00:13:54,320 --> 00:13:55,960
也是刚才我们声明的

459
00:13:55,960 --> 00:13:57,200
global的意思

460
00:13:57,200 --> 00:13:59,200
里面的数据都是共享的

461
00:13:59,200 --> 00:14:01,280
而grid是作为第一层

462
00:14:01,720 --> 00:14:04,000
接下来就是线程块

463
00:14:04,000 --> 00:14:05,440
我们的thread block

464
00:14:05,640 --> 00:14:07,320
实际上我们叫错叫block就行了

465
00:14:07,320 --> 00:14:09,360
刚才我们讲到了grid的网格

466
00:14:09,360 --> 00:14:11,480
网格里面的概念就是block

467
00:14:11,480 --> 00:14:15,160
一个block就可以包括非常多的线程

468
00:14:15,160 --> 00:14:16,840
可以看到我们block之间

469
00:14:17,160 --> 00:14:18,640
是并行的去执行的

470
00:14:18,640 --> 00:14:19,480
也就是block00

471
00:14:19,600 --> 00:14:22,240
跟block10可以同时的进行执行

472
00:14:22,440 --> 00:14:23,800
他们同时进行执行的时候

473
00:14:23,920 --> 00:14:25,920
我们就没有必要去让他们之间

474
00:14:25,920 --> 00:14:26,960
相互通讯

475
00:14:26,960 --> 00:14:28,400
而且也没有执行的顺序

476
00:14:28,400 --> 00:14:30,320
大家都并行的去执行

477
00:14:30,320 --> 00:14:31,480
我们这些block里面的

478
00:14:31,480 --> 00:14:32,680
各自的线程就好了

479
00:14:32,680 --> 00:14:35,000
而block我们就会说

480
00:14:35,000 --> 00:14:37,800
block里面的线程是可以同步的

481
00:14:37,800 --> 00:14:41,720
线程进行通讯和数据之间的传输

482
00:14:41,720 --> 00:14:44,600
而第三层就是我们来到了线程

483
00:14:44,600 --> 00:14:47,520
最小的一个逻辑计算单位

484
00:14:48,200 --> 00:14:49,640
整个所有的devices

485
00:14:49,640 --> 00:14:51,440
就是CUDA的整个程序里面

486
00:14:51,640 --> 00:14:53,000
我们真正执行的

487
00:14:53,000 --> 00:14:54,720
都是由最小的这些fret

488
00:14:54,720 --> 00:14:56,240
我们的线程来执行

489
00:14:56,240 --> 00:14:58,440
而多个线程组成我们的block

490
00:14:58,440 --> 00:15:00,600
多个block又组成我们的grid

491
00:15:00,600 --> 00:15:03,680
这种方式来去真正的对一下

492
00:15:03,680 --> 00:15:06,240
第一个我们在刚开始的概念里面

493
00:15:06,280 --> 00:15:08,120
就去讲了英伟达的硬件的结构

494
00:15:08,120 --> 00:15:10,120
还有硬件的一些兼容相关的概念

495
00:15:10,160 --> 00:15:12,080
接着我们去看了一下CUDA

496
00:15:12,280 --> 00:15:14,360
现在我们把CUDA跟英伟达之间的

497
00:15:14,360 --> 00:15:16,280
硬件架构把它联系起来

498
00:15:16,280 --> 00:15:19,320
从软件我们看到执行的是具体的线程

499
00:15:19,320 --> 00:15:21,560
线程又包成block又包成grid

500
00:15:21,560 --> 00:15:23,000
而在硬件上面去执行

501
00:15:23,160 --> 00:15:25,320
我们的线程实际上是执行

502
00:15:25,320 --> 00:15:26,760
在我们的CUDA core里面的

503
00:15:26,760 --> 00:15:29,200
每一个线程就对应的我们的CUDA core

504
00:15:29,200 --> 00:15:31,440
当然了线程的数量是超配的

505
00:15:31,440 --> 00:15:32,600
软件上我们超配

506
00:15:32,600 --> 00:15:34,920
硬件上面我们执行是有限的

507
00:15:34,920 --> 00:15:36,400
所以我们会通过刚才的wrap

508
00:15:36,400 --> 00:15:38,000
进行一个调度和同步

509
00:15:38,000 --> 00:15:39,320
然后我们看看第二个

510
00:15:39,320 --> 00:15:40,680
就是第二层的目录

511
00:15:40,680 --> 00:15:41,520
就是我们的fretboard

512
00:15:41,520 --> 00:15:42,240
我们的快

513
00:15:42,240 --> 00:15:44,880
快就是由sm去进行执行

514
00:15:44,920 --> 00:15:46,080
最后就是网格

515
00:15:46,080 --> 00:15:48,720
网格就是由大量的sm进行堆叠

516
00:15:48,720 --> 00:15:50,720
堆叠起来就变成我们的TPC

517
00:15:50,720 --> 00:15:52,160
还有我们的GPC了

518
00:15:53,280 --> 00:15:55,320
现在我们来到最后一个内容

519
00:15:55,320 --> 00:15:56,400
算力的计算

520
00:15:56,400 --> 00:15:58,120
特别是英伟达的算力

521
00:15:58,120 --> 00:15:59,520
是怎么去算出来的

522
00:15:59,520 --> 00:16:00,920
有了这个算力峰值之后

523
00:16:01,120 --> 00:16:02,120
就很好的去评量

524
00:16:02,120 --> 00:16:03,560
我们在训练大模型

525
00:16:03,560 --> 00:16:06,160
或者在执行大模型训练的过程当中

526
00:16:06,160 --> 00:16:09,320
怎么去评价我们的算力的利用率

527
00:16:09,440 --> 00:16:11,240
现在我们看一下GPU的算力

528
00:16:11,360 --> 00:16:14,520
其实跟三个因素有非常强烈的关系

529
00:16:14,720 --> 00:16:16,840
第一个就是我们的核心的个数

530
00:16:16,840 --> 00:16:19,400
特别是指我们的sm的数量

531
00:16:19,400 --> 00:16:21,440
第二个是指核心的频率

532
00:16:21,440 --> 00:16:23,600
第三个就是指每个core里面的

533
00:16:23,600 --> 00:16:25,960
单时钟周期类的一个算力

534
00:16:26,920 --> 00:16:28,440
就是由这三个数相乘

535
00:16:28,440 --> 00:16:32,360
而得到我们的peakflops的一个具体的值了

536
00:16:32,560 --> 00:16:34,560
现在我们看看一下具体的计算公式

537
00:16:34,560 --> 00:16:37,440
fclock就是指GPU时钟周期类的

538
00:16:37,440 --> 00:16:39,200
一个指令执行数量

539
00:16:39,200 --> 00:16:41,760
flops单位flops每cycle

540
00:16:41,800 --> 00:16:43,800
第二个就是nsm

541
00:16:43,800 --> 00:16:46,120
sm就是英伟达的stream

542
00:16:46,680 --> 00:16:48,080
里面的一个数量

543
00:16:48,080 --> 00:16:49,640
我们的sm的一个核数

544
00:16:49,640 --> 00:16:51,600
第三个ffrequency

545
00:16:51,600 --> 00:16:53,400
是指我们的运行的频率

546
00:16:53,400 --> 00:16:54,320
现在我们以AE

547
00:16:54,320 --> 00:16:55,680
今天的内容就这么多

548
00:16:55,680 --> 00:16:57,480
我们现在总结一下

549
00:16:57,480 --> 00:17:00,040
首先GPU里面有非常多的概念

550
00:17:00,040 --> 00:17:03,000
我们重点展开了sm还有core

551
00:17:03,000 --> 00:17:04,880
另外的话sm里面实际上

552
00:17:04,960 --> 00:17:07,920
还包含很多各种各样的一些核

553
00:17:07,920 --> 00:17:09,840
而CUDA core里面也包含了

554
00:17:09,840 --> 00:17:11,480
非常多相关的概念

555
00:17:11,480 --> 00:17:13,440
这些其实我们都没有展开

556
00:17:13,440 --> 00:17:16,320
只是具体的看一下大概念的一丝

557
00:17:17,080 --> 00:17:18,360
硬件的一个了解了

558
00:17:18,360 --> 00:17:20,240
从core sm到我们的driver

559
00:17:20,240 --> 00:17:22,000
最后我们了解了一下

560
00:17:22,000 --> 00:17:24,880
CUDA里面的一个现场分析的概念

561
00:17:24,880 --> 00:17:26,240
现场的分析flatbox

562
00:17:26,240 --> 00:17:27,040
还有grid

563
00:17:27,040 --> 00:17:29,120
就是我们的tie还有网格

564
00:17:29,120 --> 00:17:32,520
最后就把硬件跟软件之间的关系

565
00:17:32,520 --> 00:17:33,760
给大家去讲完

566
00:17:33,920 --> 00:17:35,680
今天的内容就到这里为止

567
00:17:35,680 --> 00:17:36,400
谢谢各位

568
00:17:36,400 --> 00:17:37,520
拜拜

569
00:17:38,520 --> 00:17:39,360
卷的不行了

570
00:17:39,360 --> 00:17:40,200
卷的不行了

571
00:17:40,200 --> 00:17:41,640
记得一键三连加关注

572
00:17:42,000 --> 00:17:43,400
所有的内容都会开源

573
00:17:43,400 --> 00:17:45,320
在下面这条链接里面

574
00:17:45,600 --> 00:17:46,640
拜拜

