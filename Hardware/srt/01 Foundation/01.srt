1
00:00:00,000 --> 00:00:05,840
Hello 大家好

2
00:00:05,840 --> 00:00:07,680
我室内憋屈了我的身体

3
00:00:07,680 --> 00:00:10,960
床铺埋葬了我的灵魂的ZOMI

4
00:00:10,960 --> 00:00:13,840
现在我们又来到了午夜更新

5
00:00:13,840 --> 00:00:15,320
不是午夜凶宁

6
00:00:15,320 --> 00:00:17,760
这一次我们来到一个全新的内容

7
00:00:17,760 --> 00:00:19,240
就是AI芯片

8
00:00:19,240 --> 00:00:22,120
这个内容可能很多人不会太关心

9
00:00:22,120 --> 00:00:24,040
但是在整个AI系统里面

10
00:00:24,040 --> 00:00:27,200
AI的芯片是所有的基础

11
00:00:27,200 --> 00:00:30,640
所以我们是进入到AI芯片的内容之前

12
00:00:30,640 --> 00:00:31,560
我们来回顾一下

13
00:00:31,560 --> 00:00:33,800
ZOMIE在之前的很多系列里面

14
00:00:33,800 --> 00:00:36,280
去给大家分享和汇报过的内容

15
00:00:36,280 --> 00:00:39,120
主要分开三大块

16
00:00:39,120 --> 00:00:41,400
第一块就是AI框架

17
00:00:41,400 --> 00:00:43,000
整体AI框架的核心技术

18
00:00:43,000 --> 00:00:45,040
因为AI框架要正式的

19
00:00:45,040 --> 00:00:47,600
或者AI框架要跑在我们的芯片上面

20
00:00:47,600 --> 00:00:49,960
于是就离不开我们的编译器

21
00:00:49,960 --> 00:00:52,080
于是我们在第一大的内容里面

22
00:00:52,080 --> 00:00:55,040
去给大家分享了整个AI编译器

23
00:00:55,040 --> 00:00:56,960
从传统编译器到AI编译器里面的

24
00:00:56,960 --> 00:00:57,720
一些区别

25
00:00:57,720 --> 00:01:00,360
还有AI编译器的前端优化和后端优化

26
00:01:00,360 --> 00:01:03,720
最后以Pytorch2.0作为一个结尾

27
00:01:03,720 --> 00:01:06,400
接着我们在第三大块的内容里面

28
00:01:06,400 --> 00:01:08,080
去介绍了推力引擎

29
00:01:08,080 --> 00:01:11,240
推力引擎其实也是AI框架的其中一部分

30
00:01:11,240 --> 00:01:12,600
但是它比较独立

31
00:01:12,600 --> 00:01:14,720
里面会做一些跟网络模型相关

32
00:01:14,720 --> 00:01:16,840
跟算法相关的模型小型化

33
00:01:16,840 --> 00:01:17,920
模型压缩

34
00:01:17,920 --> 00:01:20,240
最后真正来到了推力引擎里面的

35
00:01:20,240 --> 00:01:21,080
一些架构的模块

36
00:01:21,080 --> 00:01:22,200
离线的转换的图优化

37
00:01:22,200 --> 00:01:24,080
还有Kernels的优化

38
00:01:24,080 --> 00:01:25,400
谈到Kernels的优化

39
00:01:25,440 --> 00:01:27,360
就离不开我们的AI芯片

40
00:01:27,360 --> 00:01:29,640
所以我们今天来到一个正式的

41
00:01:29,640 --> 00:01:31,520
或者比较重要的一个内容了

42
00:01:31,520 --> 00:01:33,560
就是我们所有一切的根基

43
00:01:33,560 --> 00:01:34,880
AI芯片

44
00:01:34,880 --> 00:01:36,000
那在AI芯片里面

45
00:01:36,080 --> 00:01:38,720
我们主要分开两大块内容

46
00:01:38,720 --> 00:01:42,400
那第一块就是AI的整个计算体系

47
00:01:42,400 --> 00:01:43,480
那所谓的计算体系

48
00:01:43,600 --> 00:01:45,440
就是AI进入学习

49
00:01:45,440 --> 00:01:47,840
人工智能的计算的模式

50
00:01:47,840 --> 00:01:48,880
到底有哪一些

51
00:01:48,880 --> 00:01:50,040
然后根据计算模式

52
00:01:50,280 --> 00:01:51,560
我们去了解一下

53
00:01:51,560 --> 00:01:54,040
AI对于硬件的整体的计算体系

54
00:01:54,040 --> 00:01:56,680
还有它最重要的一个计算的方式

55
00:01:56,680 --> 00:01:58,600
就是我们的矩阵运算

56
00:01:58,600 --> 00:02:00,680
接着在第二大模块

57
00:02:00,680 --> 00:02:02,480
和第二个大块的内容里面

58
00:02:02,600 --> 00:02:03,960
我们去看一下

59
00:02:03,960 --> 00:02:06,400
整个AI芯片的基础

60
00:02:06,400 --> 00:02:07,800
那这个AI芯片的基础

61
00:02:07,920 --> 00:02:09,240
就非常有意思

62
00:02:09,240 --> 00:02:11,120
我们也不会讲得太深入

63
00:02:11,120 --> 00:02:13,440
而是希望能够粗略的带过

64
00:02:13,440 --> 00:02:16,200
然后以我的知识

65
00:02:16,200 --> 00:02:19,360
去给大家做一个简单的分享就好了

66
00:02:19,360 --> 00:02:21,480
如果你已经对AI芯片

67
00:02:21,480 --> 00:02:22,840
或者已经比较熟悉

68
00:02:22,840 --> 00:02:24,440
整个硬件的体系

69
00:02:24,440 --> 00:02:25,680
完全可以跳过

70
00:02:25,680 --> 00:02:26,560
不要吐槽

71
00:02:26,560 --> 00:02:27,200
确实字里面

72
00:02:27,360 --> 00:02:29,440
后面可能讲得比较粗俗

73
00:02:31,560 --> 00:02:32,640
整个AI芯片体系

74
00:02:32,720 --> 00:02:35,240
我们分开4大块内容

75
00:02:35,240 --> 00:02:35,760
那第一块

76
00:02:36,000 --> 00:02:38,520
就是我们的通用的处理器CPU

77
00:02:38,520 --> 00:02:41,360
接着我们会从数据来去看

78
00:02:41,360 --> 00:02:42,680
CPU的计算

79
00:02:42,960 --> 00:02:44,880
因为我们的数据量越来越大

80
00:02:44,880 --> 00:02:46,560
在AI里面图形图像处理

81
00:02:46,560 --> 00:02:47,520
在AI里面

82
00:02:47,640 --> 00:02:49,600
我们的数据量确实越来越大

83
00:02:49,600 --> 00:02:50,800
模型也越来越大

84
00:02:50,840 --> 00:02:52,160
于是就需要用到

85
00:02:52,160 --> 00:02:55,200
我们的通用的图形处理器GPU

86
00:02:55,560 --> 00:02:57,120
因为我们随着时代的发展

87
00:02:57,120 --> 00:03:00,000
后来又出现了很多专用的处理器

88
00:03:00,000 --> 00:03:01,640
包括NPU还有TPU

89
00:03:01,800 --> 00:03:04,840
华为就推出了自己的达芬奇架构

90
00:03:04,840 --> 00:03:06,320
然后推出了自己的生腾

91
00:03:06,320 --> 00:03:08,000
产品线有自己的NPU

92
00:03:08,000 --> 00:03:09,600
最后我们去看看

93
00:03:09,600 --> 00:03:12,480
整个计算架构体系的黄金10年

94
00:03:12,480 --> 00:03:13,560
也就是未来的

95
00:03:13,560 --> 00:03:15,240
或者现在正在发生

96
00:03:15,240 --> 00:03:17,200
已经迈进的10年

97
00:03:17,200 --> 00:03:19,120
这10年有哪些不一样

98
00:03:19,160 --> 00:03:21,080
有哪些新的知识

99
00:03:21,120 --> 00:03:23,800
但是不要觉得这么简单

100
00:03:23,800 --> 00:03:26,720
其实我们在讲图形图像处理的时候

101
00:03:26,720 --> 00:03:27,640
在讲我们的GPU

102
00:03:27,640 --> 00:03:30,000
我们会深入的去探讨一下

103
00:03:30,000 --> 00:03:32,000
GPU的整体的工作原理

104
00:03:32,000 --> 00:03:34,080
还有它的编程的本质

105
00:03:34,080 --> 00:03:36,240
就是它的硬件整体的基础

106
00:03:36,280 --> 00:03:37,680
接着我们会去看看

107
00:03:37,680 --> 00:03:39,240
以英伟达为例子的

108
00:03:39,240 --> 00:03:40,280
去了解一下

109
00:03:40,280 --> 00:03:42,080
英伟达的GPU的架构

110
00:03:42,080 --> 00:03:43,840
从菲米到hopper的架构

111
00:03:43,840 --> 00:03:44,920
里面的眼镜

112
00:03:44,920 --> 00:03:47,160
包括里面最核心的tensor core

113
00:03:47,160 --> 00:03:48,840
还有里面的NV link

114
00:03:48,840 --> 00:03:50,800
去详解详细的打开

115
00:03:50,800 --> 00:03:52,840
里面到底有什么不一样

116
00:03:52,840 --> 00:03:57,160
接着我们回到最初的GPU的初衷

117
00:03:57,160 --> 00:04:00,600
它的一个图形的处理流水线

118
00:04:00,600 --> 00:04:02,120
图形的Pipeline

119
00:04:02,120 --> 00:04:04,280
到底是怎么一步一步的

120
00:04:04,280 --> 00:04:06,880
演进到我们现在AI能够去运算

121
00:04:06,880 --> 00:04:09,400
或者用的最多的内容里面

122
00:04:09,400 --> 00:04:11,640
于是在GPU的图形流水线里面

123
00:04:11,720 --> 00:04:13,920
我们去看看图形流水线的基础

124
00:04:13,920 --> 00:04:16,040
GPU的逻辑模块跨分

125
00:04:16,040 --> 00:04:18,200
最后到图形处理的算法

126
00:04:18,200 --> 00:04:19,640
到我们的硬件

127
00:04:19,640 --> 00:04:22,160
到底是什么样的一个关系

128
00:04:22,160 --> 00:04:23,560
了解完GPU之后

129
00:04:23,760 --> 00:04:25,280
我们肯定离不开

130
00:04:25,280 --> 00:04:27,240
AI专用处理器NPU

131
00:04:27,240 --> 00:04:29,840
或者TPU里面的内容

132
00:04:29,840 --> 00:04:30,680
核心内容

133
00:04:30,680 --> 00:04:33,160
于是我们就会深入的去看看

134
00:04:33,160 --> 00:04:35,800
华为生腾达芬奇架构NPU

135
00:04:35,800 --> 00:04:37,600
里面到底有什么不一样

136
00:04:37,600 --> 00:04:39,240
我们先从架构讲起

137
00:04:39,240 --> 00:04:41,720
然后再看看它的整体的处理器

138
00:04:41,720 --> 00:04:42,240
当然了

139
00:04:42,240 --> 00:04:43,800
我们还会去分析一下

140
00:04:43,800 --> 00:04:45,040
友商的产品

141
00:04:45,040 --> 00:04:45,840
谷歌的TPU

142
00:04:46,160 --> 00:04:48,040
它的最核心脉动阵列

143
00:04:48,040 --> 00:04:49,160
是怎么去实现的

144
00:04:49,160 --> 00:04:49,680
说实话

145
00:04:49,680 --> 00:04:50,440
这个脉动阵列

146
00:04:50,440 --> 00:04:52,440
还是有一定的历史的

147
00:04:52,440 --> 00:04:53,440
然后我们去看看

148
00:04:53,440 --> 00:04:55,080
TPU的整体的架构

149
00:04:55,080 --> 00:04:57,760
从TPU的V1 V2 V3

150
00:04:57,760 --> 00:04:59,240
逐步的演进

151
00:04:59,720 --> 00:05:01,800
最近应该是上一年

152
00:05:01,800 --> 00:05:03,280
21年22年的时候

153
00:05:03,680 --> 00:05:06,840
特斯拉也推出了自己的NPU

154
00:05:06,840 --> 00:05:07,560
DUJO

155
00:05:07,560 --> 00:05:10,440
这个DUJO确实非常的有意思

156
00:05:10,440 --> 00:05:13,080
它的带宽大的非常的惊人

157
00:05:13,120 --> 00:05:14,360
在最后一个内容

158
00:05:14,480 --> 00:05:16,200
我们就去看看国内外

159
00:05:16,200 --> 00:05:17,440
其他AI芯片

160
00:05:17,440 --> 00:05:18,400
然后对它

161
00:05:18,400 --> 00:05:19,920
对整个AI芯片

162
00:05:19,920 --> 00:05:22,040
进行一个全面的思考

163
00:05:22,240 --> 00:05:23,480
这个也仅限于我

164
00:05:23,480 --> 00:05:24,800
总比个人的思考

165
00:05:24,800 --> 00:05:27,560
不代表不具有官方的意义

166
00:05:27,880 --> 00:05:30,000
也希望引起大家的共鸣

167
00:05:30,000 --> 00:05:32,000
让大家更多的参与思考

168
00:05:32,320 --> 00:05:32,800
最后

169
00:05:32,800 --> 00:05:33,080
刚

170
00:05:37,600 --> 00:05:38,160
一个模块

171
00:05:38,440 --> 00:05:42,000
就是计算体系架构的黄金10年

172
00:05:42,000 --> 00:05:44,160
为什么称它为黄金10年

173
00:05:45,560 --> 00:05:47,400
随着一开始的单核CPU

174
00:05:47,400 --> 00:05:48,560
到我们的多核CPU

175
00:05:48,560 --> 00:05:49,960
或者多核的GPU

176
00:05:50,000 --> 00:05:52,200
到现在的CPU跟GPU

177
00:05:52,200 --> 00:05:54,920
或者NPU的异构并行的架构

178
00:05:54,960 --> 00:05:56,120
到后面

179
00:05:56,160 --> 00:05:58,400
或者我们现在正在发生的

180
00:05:58,400 --> 00:06:01,040
已经是超异构并行的架构上面

181
00:06:01,040 --> 00:06:04,000
我们需要融合非常多不同的产品

182
00:06:04,000 --> 00:06:05,680
在一个AI计算中心里面

183
00:06:05,680 --> 00:06:07,240
可能就会有大量的CPU

184
00:06:07,240 --> 00:06:08,080
大量的GPU

185
00:06:08,080 --> 00:06:09,560
大量的NPU和DPU

186
00:06:09,560 --> 00:06:12,120
组成的一个超大规模的集群

187
00:06:12,160 --> 00:06:14,640
基于这个不仅是AI集群

188
00:06:14,840 --> 00:06:16,920
而是一个超异构的集群

189
00:06:16,920 --> 00:06:19,320
面对摩尔定律已经失效的

190
00:06:19,320 --> 00:06:20,560
今天我们的制程

191
00:06:20,560 --> 00:06:22,160
还不断的去演进

192
00:06:22,160 --> 00:06:23,600
于是我们现在出现了

193
00:06:23,600 --> 00:06:25,680
越来越多的专用的处理器

194
00:06:25,680 --> 00:06:26,960
不同的专用的处理器

195
00:06:26,960 --> 00:06:28,280
怎么跟我们的通用处理器

196
00:06:28,280 --> 00:06:29,160
融合在一起

197
00:06:29,160 --> 00:06:30,360
怎么跟我们的整个

198
00:06:30,360 --> 00:06:32,040
超异构并行的架构里面

199
00:06:32,040 --> 00:06:34,400
更好的软硬件的适配

200
00:06:34,440 --> 00:06:37,880
这个时候就引起了我们最后的思考

201
00:06:38,560 --> 00:06:41,240
计算体架构的黄金10年

202
00:06:41,280 --> 00:06:43,280
那最后天这个视频

203
00:06:43,480 --> 00:06:45,720
没有太多的核心本质的内容

204
00:06:45,720 --> 00:06:47,240
算是比较随

205
00:06:47,280 --> 00:06:49,640
在最后我非常推荐大家

206
00:06:49,640 --> 00:06:52,080
去看一看David里面的

207
00:06:52,080 --> 00:06:54,240
关于计算机架构的

208
00:06:54,280 --> 00:06:56,640
黄金10年的一个总结和回顾

209
00:06:56,640 --> 00:06:58,480
这里面我就抽出了

210
00:06:58,480 --> 00:07:00,520
最后的一个PPT

211
00:07:00,520 --> 00:07:03,360
里面的最后的三个总结

212
00:07:03,400 --> 00:07:04,160
第一个总结

213
00:07:04,280 --> 00:07:05,280
软件的发展

214
00:07:05,280 --> 00:07:08,840
能够去激发硬件架构的创新和革命

215
00:07:08,840 --> 00:07:10,720
那这个我是不管是

216
00:07:10,720 --> 00:07:11,680
SYSKA VSCA的

217
00:07:11,680 --> 00:07:14,560
不同的ISA指令的架构级

218
00:07:14,600 --> 00:07:16,320
实际上我们的市场

219
00:07:16,360 --> 00:07:18,240
最终会决定我们的芯片

220
00:07:18,240 --> 00:07:19,480
决定我们的架构

221
00:07:19,520 --> 00:07:21,680
往哪个方向去牵引的

222
00:07:21,680 --> 00:07:23,680
很多时候我们不用去争论太多

223
00:07:23,720 --> 00:07:25,880
让市场告诉我们答案

224
00:07:27,320 --> 00:07:30,120
提高更多的软件跟硬件的接口

225
00:07:30,120 --> 00:07:32,880
可以有去引发我们硬件架构的

226
00:07:32,880 --> 00:07:34,400
创新的机会点

227
00:07:34,600 --> 00:07:36,280
这个时候就回到我们的

228
00:07:36,280 --> 00:07:37,480
黄金10年里面的

229
00:07:37,480 --> 00:07:38,520
最后的一个分享

230
00:07:38,520 --> 00:07:41,040
或者最后的一个给大家的汇报

231
00:07:41,800 --> 00:07:43,240
易购计算和超易购计算

232
00:07:43,240 --> 00:07:45,480
我们的软硬件应该怎么去协同

233
00:07:45,480 --> 00:07:46,320
跟我们的算法