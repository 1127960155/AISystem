1
00:00:00,000 --> 00:00:11,000
哈喽大家好,我是总理,末期到12点多才来录这个课,每次都是特别的晚

2
00:00:11,000 --> 00:00:17,280
那今天呢我们来给AI芯片里面的AI的计算体系做一个整体的总结

3
00:00:17,280 --> 00:00:25,680
什么叫做计算体系,其实呢在这个内容啊,别说你,我也觉得讲的确实有点分散,而且不聚焦

4
00:00:25,760 --> 00:00:30,160
那讲到后面呢,可能你都不知道自己听的到底是一个什么样的事情

5
00:00:30,160 --> 00:00:33,360
或者我给你汇报的到底是一个怎么样的连贯的内容

6
00:00:33,360 --> 00:00:40,160
那现在呢我们今天对它进行一个串讲,简单的几分钟过一过我们之前所分享的内容

7
00:00:40,160 --> 00:00:44,240
那第一个呢我们之前所分享的是深度学习的计算模式

8
00:00:44,240 --> 00:00:51,040
去看看深度学习有哪些不一样的计算的方式和计算的模式,还有它的计算的内容

9
00:00:51,040 --> 00:00:54,080
接着呢我们去看看AI的计算体系

10
00:00:54,080 --> 00:00:57,440
计算体系里面的最重要的计算就是矩阵运算

11
00:00:57,440 --> 00:01:04,240
所以我们会从深度学习开始入手,然后再到具体的计算的这个过程

12
00:01:04,240 --> 00:01:09,920
那现在我们打开深度学习的计算模式这个内容里面呢

13
00:01:09,920 --> 00:01:15,040
我们发现其实我们在一开始的时候会讲讲AI的发展和它的方式

14
00:01:15,040 --> 00:01:19,680
接着呢我们去看看AI的非常经典的网络模型结构

15
00:01:19,680 --> 00:01:24,480
了解完这个之后呢我们看看一些模型的量化和减脂的技术

16
00:01:24,480 --> 00:01:27,440
这些所有东西呢都是围绕着AI去发展的

17
00:01:27,440 --> 00:01:28,640
下面呢我们看看

18
00:01:29,360 --> 00:01:33,280
大范是一个就是监督学习,无监督学习,还有强化学习

19
00:01:33,280 --> 00:01:37,280
针对不同的,而最热门的属于监督学习

20
00:01:37,280 --> 00:01:41,440
监督学习里面呢就有AI它发展的非常多的网络模型

21
00:01:41,440 --> 00:01:45,760
而且网络模型呢变得越来越大,随着我们的箭头所指

22
00:01:45,760 --> 00:01:48,000
于是呢我们AI的经典模型里面呢

23
00:01:48,000 --> 00:01:51,360
除了CAN网络模型还有STM,Transformer

24
00:01:51,360 --> 00:01:55,360
还有RNN这种经典的网络模型结构

25
00:01:55,360 --> 00:01:58,960
接着呢我们去看看模型的压缩和量化

26
00:01:58,960 --> 00:02:02,640
通过不同的手段呢对我们的矩阵对我们的计算呢

27
00:02:02,640 --> 00:02:04,720
其实是有非常大的影响

28
00:02:04,720 --> 00:02:07,040
最后呢网络模型结构还有

29
00:02:08,160 --> 00:02:12,160
压缩呢我们对AI的计算模式提出了一些思考

30
00:02:12,160 --> 00:02:14,640
这些思考就是我们的AI的计算模式

31
00:02:14,640 --> 00:02:18,800
对硬件有什么依赖,对硬件提出什么新的诉求

32
00:02:18,800 --> 00:02:19,600
接着呢我们

33
00:02:21,120 --> 00:02:22,880
我们在第三个内容里面呢

34
00:02:22,880 --> 00:02:27,200
去看看深度学习的计算模式里面的轻量化的模型

35
00:02:27,200 --> 00:02:29,520
还有一些大模型,模式并行

36
00:02:29,520 --> 00:02:32,640
对计算模式的一些改进和思考

37
00:02:32,640 --> 00:02:36,320
那这里面呢我们去分享了或者回顾了一些CNN系列

38
00:02:36,320 --> 00:02:39,680
还有Transformer系列的非常多的网络模型

39
00:02:39,680 --> 00:02:40,560
特别是SOTA

40
00:02:40,560 --> 00:02:43,440
然后呢我们看看Mektron LLM这种模型

41
00:02:43,440 --> 00:02:47,920
我们叫做LLM Language Large Model或者Large Language Model

42
00:02:47,920 --> 00:02:50,640
这种做了很多不同的模型并行的

43
00:02:50,640 --> 00:02:52,560
Pipeline并行的还有Sequence并行

44
00:02:52,560 --> 00:02:54,800
这种很多的并行的模式

45
00:02:54,800 --> 00:02:57,120
那了解完这些了解完轻量化的网络模型

46
00:02:57,120 --> 00:02:58,800
还有一些并行的模式之后呢

47
00:02:58,800 --> 00:03:03,200
我们对AI的计算模式也进行了一个回顾和思考

48
00:03:03,200 --> 00:03:04,720
那这里面呢到这里为止呢

49
00:03:04,720 --> 00:03:08,960
我们已经了解完了整个深度学习的计算模式

50
00:03:08,960 --> 00:03:13,440
深度学习AI它有哪些不一样的计算的特点

51
00:03:13,440 --> 00:03:15,360
那基于这些计算的特点呢

52
00:03:15,360 --> 00:03:18,480
我们引申出了下一个内容

53
00:03:18,480 --> 00:03:21,280
计算体系还有矩阵运算

54
00:03:21,280 --> 00:03:24,720
这里面值得注意的就是一个呢是计算的模式

55
00:03:24,720 --> 00:03:26,640
一个是计算的体系

56
00:03:26,640 --> 00:03:31,520
现在我们简单的过一过计算体系里面有哪些内容

57
00:03:33,120 --> 00:03:35,680
在AI的计算体系里面呢

58
00:03:35,680 --> 00:03:38,960
我们去看看AI芯片的关键的设计指标

59
00:03:38,960 --> 00:03:44,160
就是我们之前已经讲过了很多深度学习的计算的模式

60
00:03:44,160 --> 00:03:45,120
这些模式呢

61
00:03:45,120 --> 00:03:50,080
对我们的关键指标对我们设计的指标是有非常大的牵引作用的

62
00:03:50,080 --> 00:03:52,400
然后呢我们去看看矩阵的运算

63
00:03:52,400 --> 00:03:56,240
就是我们整个AI计算体系里面最核心最关键的计算

64
00:03:56,240 --> 00:03:57,520
有了这些计算之后呢

65
00:03:57,520 --> 00:03:59,680
我们可以看看比特的位数

66
00:03:59,680 --> 00:04:01,280
针对不同的应用场景呢

67
00:04:01,280 --> 00:04:03,760
它可能会使用不同的比特位数

68
00:04:03,840 --> 00:04:07,600
针对不同的运算也会使用不同的比特位数

69
00:04:07,600 --> 00:04:10,160
那接着呢我们进入第一个内容

70
00:04:10,160 --> 00:04:11,840
就是AI的关键指标

71
00:04:11,840 --> 00:04:15,440
那关键指标里面呢有两个非常非常的核心

72
00:04:15,440 --> 00:04:17,680
一个就是带宽bandwidth

73
00:04:17,680 --> 00:04:20,720
一个就是我们的PE执行引擎

74
00:04:20,720 --> 00:04:25,040
PE跟执行引擎之间会决定我们的峰值算力

75
00:04:25,040 --> 00:04:30,480
不同的PE不同的带宽之间需要找到一个很好的平衡配合点

76
00:04:30,480 --> 00:04:32,480
有了这个基础的了解之后呢

77
00:04:32,480 --> 00:04:36,000
我们就会对整个AI体系的关键的设计指标

78
00:04:36,000 --> 00:04:37,600
有精度呢吞吐率呢

79
00:04:37,600 --> 00:04:40,240
食言还有一些额外的指标

80
00:04:40,240 --> 00:04:43,200
就是能耗呢系统的价格还有易用性

81
00:04:43,200 --> 00:04:46,800
那可能前三四个呢跟我们的硬件非常相关

82
00:04:46,800 --> 00:04:49,360
那系统价格易用性这个两个事情呢

83
00:04:49,360 --> 00:04:50,960
就比较玄学了

84
00:04:50,960 --> 00:04:53,360
或者比较有大的浮动性

85
00:04:53,360 --> 00:04:55,760
然后了解完关键的设计指标之后呢

86
00:04:55,760 --> 00:04:57,360
我们看看矩阵的运算

87
00:04:57,360 --> 00:05:00,640
矩阵运算是整个AI计算体系里面

88
00:05:00,720 --> 00:05:03,600
最核心的运算的方式

89
00:05:03,600 --> 00:05:04,480
其实我们在

90
00:05:04,480 --> 00:05:09,200
AN转数码还有呢呢就没有这种计算模式全连接的

91
00:05:09,200 --> 00:05:13,680
我们都会把它转换成为具体的矩阵层

92
00:05:13,680 --> 00:05:17,360
通过矩阵层的方式去代替传统的卷机

93
00:05:17,360 --> 00:05:22,480
那这个呢是我们会说矩阵层是AI体系里面最核心的计算

94
00:05:22,480 --> 00:05:24,880
于是呢基于这个最核心的计算

95
00:05:24,880 --> 00:05:29,280
我们会去思考关于软件上面我们应该怎么去设计我们的硬件

96
00:05:29,280 --> 00:05:33,600
关于硬件上硬件上面呢怎么去符合我们的关键指标

97
00:05:33,600 --> 00:05:39,600
接着呢我们去看看最后一个内容就是比特的位宽

98
00:05:39,600 --> 00:05:43,680
我们的比我们知道矩阵的运算呢是基于最基本的

99
00:05:43,680 --> 00:05:45,200
数据单元去运算的

100
00:05:45,200 --> 00:05:49,120
而最数据单元最基本的存储单位呢就是我们的bit

101
00:05:49,120 --> 00:05:50,640
我们的位数

102
00:05:50,640 --> 00:05:52,480
所以呢针对不同的数据呢

103
00:05:52,480 --> 00:05:54,240
我们是有不同的位宽

104
00:05:54,240 --> 00:05:55,520
不同的存储格式

105
00:05:55,520 --> 00:05:59,120
而具体我们在具体的芯片设计场景里面

106
00:05:59,120 --> 00:06:03,840
我们到底拥有多少FP32多少BF16多少PF16呢

107
00:06:03,840 --> 00:06:07,120
是跟我们的芯片跟我们的应用场景相关的

108
00:06:07,120 --> 00:06:10,560
可能我的芯片呢主要是针对训练的场景

109
00:06:10,560 --> 00:06:15,440
我们可能会提供更多的FP32还有P16

110
00:06:15,440 --> 00:06:19,440
但是呢如果我芯片呢更多的可能是针对推理场景

111
00:06:19,440 --> 00:06:25,440
那这个时候呢int8跟FP16可能是更好的一种选择

112
00:06:25,440 --> 00:06:28,160
最后呢我们对整个AI芯片的设计

113
00:06:28,240 --> 00:06:31,440
特别是位宽呢做了一个整体的回顾

114
00:06:31,440 --> 00:06:36,320
接着最后了来到一个最后的内容

115
00:06:36,320 --> 00:06:38,640
我们来一个summary大串讲

116
00:06:38,640 --> 00:06:42,720
把刚才讲的知识呢再重新的回顾一把

117
00:06:42,720 --> 00:06:46,720
那首先呢我们去了解了整个深度学习的计算模式

118
00:06:46,720 --> 00:06:49,200
包括我们的经典的网络模型结构的气氛化了

119
00:06:49,200 --> 00:06:50,480
模型的量化压缩

120
00:06:50,480 --> 00:06:55,520
再到大模型去理解什么是计算

121
00:06:56,320 --> 00:06:58,880
对我们的硬件需求是什么

122
00:06:58,880 --> 00:07:01,360
我们需要什么来去更好的计算

123
00:07:01,360 --> 00:07:04,880
接着呢我们通过AI的芯片的关键指标

124
00:07:04,880 --> 00:07:08,960
去了解一款芯片如何更好的支持我们的计算

125
00:07:08,960 --> 00:07:11,200
需要关注哪些重点的工作

126
00:07:11,200 --> 00:07:14,000
那这个就是关键的设计指标

127
00:07:14,000 --> 00:07:18,560
从而引出峰值算力我们的PE和贷款之间的关系

128
00:07:18,560 --> 00:07:22,800
最后的我们就去了解一下深度学习的计算核心

129
00:07:22,800 --> 00:07:25,360
矩阵层这个内容

130
00:07:25,360 --> 00:07:28,400
来看看我们对实际的计算有哪些需求

131
00:07:28,400 --> 00:07:30,240
那为了提高我们的计算性能

132
00:07:30,240 --> 00:07:34,720
降低功耗还有满足训练不同场景的精度和要求

133
00:07:34,720 --> 00:07:38,560
我们对计算呢会引入很多复杂的

134
00:07:38,560 --> 00:07:40,880
非常多样化的比特的微宽

135
00:07:40,880 --> 00:07:43,280
所以说下面这两个呢

136
00:07:43,280 --> 00:07:46,800
是跟我们的AI计算体系相关

137
00:07:46,800 --> 00:07:51,360
上面这个呢是跟我们的AI计算模式相关

138
00:07:51,360 --> 00:07:54,960
从算法倒推到我们的软硬件

139
00:07:55,040 --> 00:07:56,960
应该怎么去设计

140
00:07:56,960 --> 00:07:58,720
应该怎么去做牵引


