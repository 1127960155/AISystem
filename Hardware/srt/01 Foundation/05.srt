1
00:00:00,000 --> 00:00:09,400
哈喽大家好,我是那个挑灯奋战的钟鸣

2
00:00:09,400 --> 00:00:15,000
同事吃完夜宵回来,现在已经到了凌晨0点23分了

3
00:00:15,000 --> 00:00:20,000
那我们今天呢还是在AI芯片里面的AI计算体系这个话题

4
00:00:20,000 --> 00:00:23,400
而今天的这个话题呢围绕着我们具体的计算

5
00:00:23,400 --> 00:00:29,400
也就是矩阵运算还有比特位两个内容来去给大家汇报的

6
00:00:29,400 --> 00:00:34,200
我们现在呢主要的工作还是去看一下我们整个计算的体系

7
00:00:34,200 --> 00:00:38,400
还有矩阵运算,那今天的主要内容就是在矩阵运算

8
00:00:38,400 --> 00:00:41,800
不过呢我们会花两个内容来去给大家介绍的

9
00:00:41,800 --> 00:00:45,400
一个就是矩阵运算,一个就是比特位刚才介绍了

10
00:00:46,600 --> 00:00:49,400
我们来到第一个内容就是矩阵运算

11
00:00:49,400 --> 00:00:53,800
那很多时候我们叫MM,就是指我们具体的矩阵运算的

12
00:00:53,800 --> 00:00:58,400
现在我们来回顾一下从卷积到具体的矩阵运算

13
00:00:58,400 --> 00:01:01,200
实际上呢很多时候卷积这个操作呢

14
00:01:01,200 --> 00:01:05,800
我们在计算机里面并不会真正的去执行卷积的操作

15
00:01:05,800 --> 00:01:10,200
而是把卷积的操作呢变成一个具体的矩阵

16
00:01:10,200 --> 00:01:13,600
然后把数的feature map呢也变成一个具体的矩阵

17
00:01:13,600 --> 00:01:18,600
通过一个矩阵层的操作代替整个卷积的操作

18
00:01:18,600 --> 00:01:22,000
因为呢我们其实在之前的课程里面也给大家分享过

19
00:01:22,000 --> 00:01:27,600
这里面呢数选个矩阵层呢最后我们输出我们的结果

20
00:01:27,600 --> 00:01:32,600
这个时候就是从卷积到矩阵运算的方式

21
00:01:32,600 --> 00:01:36,000
那下面我们来看一下实际上呢我们很多时候啊

22
00:01:36,000 --> 00:01:39,800
矩阵或者我们的张量我们的feature会非常的大

23
00:01:39,800 --> 00:01:44,000
那B呢在B呢就是我们的权重或者卷积核

24
00:01:44,000 --> 00:01:45,800
A呢就是我们的feature map

25
00:01:45,800 --> 00:01:48,200
C就是我们的结果颜色是相对应的

26
00:01:48,200 --> 00:01:51,000
那粉色呢就在计算机体系结构里面呢

27
00:01:51,000 --> 00:01:54,400
我们的缓存会分为HBM呢可能cache呢

28
00:01:54,400 --> 00:01:57,200
而在cache里面呢一般来说没有那么大

29
00:01:57,200 --> 00:01:59,600
于是呢我们会进行一个分块

30
00:01:59,600 --> 00:02:02,000
把块内容把它切出来

31
00:02:02,000 --> 00:02:03,600
把块内容把它切出来

32
00:02:03,600 --> 00:02:06,800
然后呢得到一个数之后进行一个累加

33
00:02:06,800 --> 00:02:08,200
相乘再累加

34
00:02:08,200 --> 00:02:11,000
那这个时候呢我们就得到了我们的c的操作

35
00:02:11,000 --> 00:02:14,400
相乘再累加这个操作大家会不会很熟

36
00:02:14,400 --> 00:02:18,400
我们在上一节课里面去讲到macx

37
00:02:18,400 --> 00:02:20,400
就是相乘并累加的操作

38
00:02:20,400 --> 00:02:24,000
就刚刚符合我们卷积的最核心的运算

39
00:02:24,000 --> 00:02:26,600
下面呢我们还

40
00:02:26,600 --> 00:02:29,200
那就是原始具体的卷积的操作

41
00:02:29,200 --> 00:02:32,400
我有一个卷积和呢有个input feature map

42
00:02:32,400 --> 00:02:35,400
卷积和1234呢跟这个1234

43
00:02:35,400 --> 00:02:38,000
进行一个乘加的操作

44
00:02:38,000 --> 00:02:39,600
那这个时候呢我们得到一个1

45
00:02:39,600 --> 00:02:41,400
然后后面同样的操作

46
00:02:41,400 --> 00:02:43,600
1234呢跟后面这个框

47
00:02:43,600 --> 00:02:46,000
进行一个mac的计算

48
00:02:46,000 --> 00:02:47,600
然后得到我们这个2

49
00:02:47,600 --> 00:02:49,000
那同样的往此类推

50
00:02:49,000 --> 00:02:51,400
我们就得到了整个的feature map的output

51
00:02:51,400 --> 00:02:53,400
这个是基本的卷积

52
00:02:53,400 --> 00:02:54,800
而矩阵层呢

53
00:02:54,800 --> 00:02:56,600
我们刚才只是简单的介绍了一下

54
00:02:56,600 --> 00:02:58,400
现在我们是详细的打开

55
00:02:58,400 --> 00:03:00,400
现在把全众feature

56
00:03:00,400 --> 00:03:01,600
横向的展开

57
00:03:01,600 --> 00:03:03,000
把刚才1234这个矩阵

58
00:03:03,000 --> 00:03:04,800
横向展开成1234

59
00:03:04,800 --> 00:03:07,600
横向的一条input feature map

60
00:03:07,600 --> 00:03:09,400
就我们数的特征

61
00:03:09,400 --> 00:03:11,600
就直接展开为1245

62
00:03:11,600 --> 00:03:13,200
就刚好1245

63
00:03:13,200 --> 00:03:14,800
然后2356

64
00:03:14,800 --> 00:03:15,800
4578

65
00:03:15,800 --> 00:03:16,800
5689

66
00:03:16,800 --> 00:03:19,200
这样的一个具体的矩阵

67
00:03:19,200 --> 00:03:20,200
然后这个矩阵呢

68
00:03:20,200 --> 00:03:21,600
跟这个矩阵直接相乘

69
00:03:21,600 --> 00:03:23,000
得到我们最终的结果

70
00:03:23,000 --> 00:03:24,000
output feature map

71
00:03:24,000 --> 00:03:26,000
这个就是我们从卷积

72
00:03:26,000 --> 00:03:27,000
到矩阵层

73
00:03:27,000 --> 00:03:28,800
MM的一个具体的

74
00:03:28,800 --> 00:03:30,400
换算过程

75
00:03:30,400 --> 00:03:31,400
下面

76
00:03:31,400 --> 00:03:33,400
我们来到看一看一个很有意思

77
00:03:33,400 --> 00:03:34,000
就是

78
00:03:34,000 --> 00:03:34,600
其实呢

79
00:03:34,600 --> 00:03:37,000
我们在矩阵或者我们的cache里面呢

80
00:03:37,000 --> 00:03:39,200
大部分我们都需要对我们的cache

81
00:03:39,200 --> 00:03:40,400
进行分块

82
00:03:40,400 --> 00:03:41,000
因为呢

83
00:03:41,000 --> 00:03:42,200
刚才讲到的一个矩阵层

84
00:03:42,200 --> 00:03:44,600
只是里面很小的一个具体的计算

85
00:03:44,600 --> 00:03:45,600
但是我们的feature map

86
00:03:45,600 --> 00:03:46,200
我们的feature呢

87
00:03:46,200 --> 00:03:47,000
会很大

88
00:03:47,000 --> 00:03:48,000
非常的大

89
00:03:48,000 --> 00:03:48,800
那这个时候呢

90
00:03:48,800 --> 00:03:50,200
我们系统的cache呢

91
00:03:50,200 --> 00:03:51,200
其实是放不下的

92
00:03:51,200 --> 00:03:51,600
于是呢

93
00:03:51,600 --> 00:03:54,800
就会进行分块的一个相乘

94
00:03:54,800 --> 00:03:55,800
和分块的操作

95
00:03:55,800 --> 00:03:56,600
例如第一次呢

96
00:03:56,600 --> 00:03:58,600
我先对这一个数据

97
00:03:58,600 --> 00:04:01,000
跟这一个数据进行相乘

98
00:04:01,000 --> 00:04:03,400
得到F00跟100

99
00:04:03,400 --> 00:04:03,800
接着呢

100
00:04:03,800 --> 00:04:05,200
我会第二个数据

101
00:04:05,200 --> 00:04:06,600
跟下面这个数据呢

102
00:04:06,600 --> 00:04:07,600
进行相乘

103
00:04:07,600 --> 00:04:08,800
然后位置还是相同的

104
00:04:08,800 --> 00:04:09,400
不过呢

105
00:04:09,400 --> 00:04:11,200
再进行一个累加的操作

106
00:04:11,200 --> 00:04:13,400
从我的通过分块的方式

107
00:04:13,400 --> 00:04:16,000
用空间的信息

108
00:04:16,000 --> 00:04:17,600
这个就是矩阵分块

109
00:04:17,600 --> 00:04:18,400
turing了

110
00:04:19,400 --> 00:04:21,800
这是最简单的一个原理

111
00:04:21,800 --> 00:04:22,400
我们看一下

112
00:04:22,400 --> 00:04:23,800
CPU和GPU里面呢

113
00:04:23,800 --> 00:04:25,800
支持矩阵层的一个库呢

114
00:04:25,800 --> 00:04:27,000
支持矩阵层的库呢

115
00:04:27,000 --> 00:04:27,600
现在呢

116
00:04:27,600 --> 00:04:29,000
有CPU有Openbox呢

117
00:04:29,000 --> 00:04:30,600
有Intel的MKT呢

118
00:04:30,600 --> 00:04:31,600
而GPU里面呢

119
00:04:31,600 --> 00:04:32,400
有Qobus呢

120
00:04:32,400 --> 00:04:34,400
QDNN这些都是现成的

121
00:04:34,400 --> 00:04:36,400
支持矩阵层的一些库

122
00:04:36,400 --> 00:04:38,000
而他们实现的逻辑呢

123
00:04:38,000 --> 00:04:39,600
其实很简单

124
00:04:39,600 --> 00:04:40,800
就分两步

125
00:04:40,800 --> 00:04:42,200
就是我们的这些库呢

126
00:04:42,200 --> 00:04:43,000
先感知

127
00:04:43,000 --> 00:04:45,600
首先感知我们矩阵层的一个shape

128
00:04:45,600 --> 00:04:47,400
首先我们要知道它的大小

129
00:04:47,400 --> 00:04:48,600
你要根据的大小呢

130
00:04:48,600 --> 00:04:51,400
选择最优的kernel来去实现

131
00:04:51,400 --> 00:04:52,200
那kernel是什么

132
00:04:52,200 --> 00:04:54,600
我们在之前其实跟大家分享过

133
00:04:54,600 --> 00:04:56,200
那具体的实现方式呢

134
00:04:56,200 --> 00:04:58,800
就像我们右边的这个图所示

135
00:04:58,800 --> 00:05:01,400
我们首先会对loop循环进行优化

136
00:05:01,400 --> 00:05:04,000
接着呢去利用多级的缓存

137
00:05:04,000 --> 00:05:06,000
那这里面呢就有一级的缓存

138
00:05:06,000 --> 00:05:06,600
二级的缓存

139
00:05:06,600 --> 00:05:08,000
还有三级的缓存

140
00:05:08,000 --> 00:05:10,000
用了三级的缓存

141
00:05:10,000 --> 00:05:11,400
而通过loop的展开呢

142
00:05:11,400 --> 00:05:13,600
这里面就是对loop进行展开

143
00:05:13,600 --> 00:05:16,000
然后具体的实现了整个

144
00:05:16,000 --> 00:05:18,200
矩阵层GAM的算法了

145
00:05:18,200 --> 00:05:19,800
往下我们再看一看呢

146
00:05:19,800 --> 00:05:22,000
这个就是我们具体的原始的算法

147
00:05:22,000 --> 00:05:23,800
我们需要对loop进行展开

148
00:05:23,800 --> 00:05:24,800
因为这里面的for

149
00:05:24,800 --> 00:05:26,200
嵌套实在是太多了

150
00:05:26,200 --> 00:05:27,000
如果你不展开

151
00:05:27,000 --> 00:05:29,000
你就会大量的嵌入到我们的

152
00:05:29,000 --> 00:05:30,200
for循环里面

153
00:05:30,200 --> 00:05:31,800
没有办法很好的利用我们

154
00:05:31,800 --> 00:05:35,400
利用我们架构芯片的性能了

155
00:05:35,400 --> 00:05:36,400
下面呢我们

156
00:05:36,400 --> 00:05:37,600
其实我们卷积呢

157
00:05:37,600 --> 00:05:39,200
不仅仅可以把卷积变成

158
00:05:39,200 --> 00:05:40,800
imaged clump的这种方式

159
00:05:40,800 --> 00:05:41,800
我们还可以通过

160
00:05:41,800 --> 00:05:43,000
快速复利变换呢

161
00:05:43,000 --> 00:05:44,400
还有stressor的方式呢

162
00:05:44,400 --> 00:05:45,400
还有window break

163
00:05:45,400 --> 00:05:46,800
那我们在之前的推丁引擎

164
00:05:46,800 --> 00:05:47,800
科诺优化里面呢

165
00:05:47,800 --> 00:05:49,200
其实给大家讲过

166
00:05:49,200 --> 00:05:50,200
卷积的优化了

167
00:05:50,200 --> 00:05:51,400
imaged clump的算法了

168
00:05:51,400 --> 00:05:53,000
还有window break的这些算法

169
00:05:53,000 --> 00:05:54,400
讲了非常多的一个系列

170
00:05:54,400 --> 00:05:56,000
非常大家欢迎回头过去

171
00:05:56,000 --> 00:05:57,200
看一下我给大家的

172
00:05:57,200 --> 00:06:00,000
之前的做的一些汇报成果

173
00:06:00,000 --> 00:06:02,000
下面呢我们回头看看

174
00:06:02,000 --> 00:06:03,800
在AI芯片里面

175
00:06:03,800 --> 00:06:05,600
或者在我们真正的一些

176
00:06:05,600 --> 00:06:07,400
特殊领域专用的芯片里面呢

177
00:06:07,400 --> 00:06:08,800
我们应该怎么去做

178
00:06:08,800 --> 00:06:09,800
首先第一个我们

179
00:06:09,800 --> 00:06:12,200
希望能够减少指令的开销

180
00:06:12,200 --> 00:06:14,000
所以我们每有两个操作

181
00:06:14,000 --> 00:06:15,400
第一个呢就是每个指令

182
00:06:15,400 --> 00:06:17,400
希望能够执行更多的

183
00:06:17,400 --> 00:06:18,600
层加的操作

184
00:06:18,600 --> 00:06:20,200
就是MAC的计算

185
00:06:20,200 --> 00:06:21,600
那我们可以看到CPU呢

186
00:06:21,600 --> 00:06:23,800
它有SIMD的这种架构

187
00:06:23,800 --> 00:06:26,200
然后每次呢通过vector的指令

188
00:06:26,200 --> 00:06:27,800
每次执行多个数据

189
00:06:27,800 --> 00:06:30,000
那GPU呢就有SIMT的架构

190
00:06:30,000 --> 00:06:32,400
然后可以对tensor进行一个处理

191
00:06:32,400 --> 00:06:33,400
而NPU呢

192
00:06:33,400 --> 00:06:35,000
它可能采用SIMD的架构

193
00:06:35,000 --> 00:06:37,000
也可能采用dataflow的形式

194
00:06:37,000 --> 00:06:38,800
里面呢可能会同时提供

195
00:06:38,800 --> 00:06:41,000
tensor或者vector的相关的指令

196
00:06:41,000 --> 00:06:42,200
这个事情呢就很有意思

197
00:06:42,200 --> 00:06:43,400
我们的目标就是

198
00:06:43,400 --> 00:06:45,600
要每一次执行每个时钟周期

199
00:06:45,600 --> 00:06:48,200
运行更多的MAC

200
00:06:48,200 --> 00:06:49,000
那第二个呢

201
00:06:49,000 --> 00:06:50,600
我们在硬件里面呢

202
00:06:50,600 --> 00:06:51,800
是希望能够在不增加

203
00:06:51,800 --> 00:06:53,600
内存带宽的前提下

204
00:06:53,600 --> 00:06:57,000
单个时钟周期内执行更多的MAC

205
00:06:57,000 --> 00:06:58,400
那这个呢有个很有意思的

206
00:06:58,400 --> 00:07:02,200
就单个时钟周期内执行的更多

207
00:07:02,200 --> 00:07:03,800
这也是英特尔里面

208
00:07:03,800 --> 00:07:05,800
tensor core的一种设计

209
00:07:05,800 --> 00:07:07,000
对应于华为

210
00:07:07,000 --> 00:07:09,400
NPU也是利用这种设计

211
00:07:09,400 --> 00:07:11,000
然后去实现的

212
00:07:11,000 --> 00:07:15,200
我们现在再详细的打开一下这个图

213
00:07:15,200 --> 00:07:17,200
那现在为了达到这个目标

214
00:07:17,200 --> 00:07:18,400
单个时钟周期内呢

215
00:07:18,400 --> 00:07:19,800
执行更多的MAC操作

216
00:07:19,800 --> 00:07:21,000
于是呢我们可能会将

217
00:07:21,000 --> 00:07:23,400
一个520bit的一个每个cycle

218
00:07:23,400 --> 00:07:24,600
或者每个时钟周期

219
00:07:24,600 --> 00:07:27,000
我可以执行512个bit

220
00:07:27,000 --> 00:07:28,200
于是呢我们在的时候

221
00:07:28,200 --> 00:07:30,400
我们可以执行68个指令

222
00:07:30,400 --> 00:07:32,200
而在执行32bit的时候呢

223
00:07:32,200 --> 00:07:34,200
我们可能只能执行16次

224
00:07:34,200 --> 00:07:35,000
那这个时候呢

225
00:07:35,000 --> 00:07:38,400
对我们的性能影响就非常的大了

226
00:07:38,400 --> 00:07:41,800
我假设执行64次8bit的运算

227
00:07:41,800 --> 00:07:43,800
那我们可以执行非常多的运算

228
00:07:43,800 --> 00:07:47,600
于是呢我们就有了下一个内容

229
00:07:47,600 --> 00:07:49,400
针对我位宽

230
00:07:49,400 --> 00:07:50,800
那在减少位宽之前呢

231
00:07:50,800 --> 00:07:52,800
我们还是回到矩阵层里面

232
00:07:52,800 --> 00:07:54,800
去进行一些思考

233
00:07:54,800 --> 00:07:55,600
第一个就是软

234
00:07:55,600 --> 00:07:58,200
就是软件层面software

235
00:07:58,200 --> 00:08:00,600
我们有必要去减少

236
00:08:00,600 --> 00:08:03,800
没有完全没有必要去计算的一些MAC

237
00:08:03,800 --> 00:08:06,200
使用其他算法来去代替

238
00:08:06,200 --> 00:08:07,400
就像我刚才说到的

239
00:08:07,400 --> 00:08:09,200
可能ImageClump这种方式呢

240
00:08:09,200 --> 00:08:10,600
还不一定是最优的

241
00:08:10,600 --> 00:08:12,000
在一些3x3的选集

242
00:08:12,000 --> 00:08:13,200
于是呢我们可能会用

243
00:08:13,200 --> 00:08:15,800
WindowGrid这种算法去代替

244
00:08:15,800 --> 00:08:18,000
第二个呢就是增加P1的利用率

245
00:08:18,000 --> 00:08:21,400
增加我们芯片单元的一个利用率

246
00:08:21,400 --> 00:08:23,200
例如我刚才提到的

247
00:08:23,200 --> 00:08:25,400
对kernel呢进行一个loopt优化

248
00:08:25,400 --> 00:08:28,200
还有利用多级缓存的优化

249
00:08:28,200 --> 00:08:30,000
这种方式去实现

250
00:08:30,000 --> 00:08:31,000
那第二种呢

251
00:08:31,000 --> 00:08:32,800
对我们的计算体系的思考

252
00:08:32,800 --> 00:08:35,200
就是关于硬件的hardware

253
00:08:35,200 --> 00:08:37,600
每次呢我硬件希望能够减少

254
00:08:37,600 --> 00:08:39,400
MAC的计算的时间

255
00:08:39,400 --> 00:08:40,600
那这种方式最有效的

256
00:08:40,600 --> 00:08:42,400
就是增加P1单元的

257
00:08:42,400 --> 00:08:43,800
一个计算的性能

258
00:08:43,800 --> 00:08:45,600
而增加单元的计算的性能呢

259
00:08:45,600 --> 00:08:48,200
有个最有效最有效的办法

260
00:08:48,200 --> 00:08:50,400
就是提高我们的制程

261
00:08:50,400 --> 00:08:52,200
假设我现在用7纳米的

262
00:08:52,200 --> 00:08:53,000
用5纳米

263
00:08:53,000 --> 00:08:54,400
我的单元的计算能力

264
00:08:54,400 --> 00:08:56,800
我的单元能存储的晶体管

265
00:08:56,800 --> 00:08:58,000
就会越多

266
00:08:58,000 --> 00:08:58,600
第二个呢

267
00:08:58,600 --> 00:09:02,200
就是增加MAC的一个并行的能力

268
00:09:02,200 --> 00:09:03,600
说白了很简单

269
00:09:03,600 --> 00:09:05,400
就是增加我们P1的数量

270
00:09:05,400 --> 00:09:07,200
增加我们执行单元的数量

271
00:09:07,200 --> 00:09:07,800
另外的话

272
00:09:07,800 --> 00:09:10,600
可以降低我们的比特的位宽

273
00:09:10,600 --> 00:09:13,000
来从而实现我们MAC里面

274
00:09:13,000 --> 00:09:14,200
更多的并行的操作

275
00:09:14,200 --> 00:09:16,200
刚才我们不是简单的讲了吗

276
00:09:16,200 --> 00:09:16,800
第三个呢

277
00:09:16,800 --> 00:09:19,600
就是直接增加P1的利用率

278
00:09:19,600 --> 00:09:21,200
那怎么去增加P1率呢

279
00:09:21,200 --> 00:09:22,400
其实我们在上一节课里面

280
00:09:22,400 --> 00:09:25,600
会去讲到片内的cache或者带宽

281
00:09:25,600 --> 00:09:28,000
会约束我们P1的利用率

282
00:09:28,000 --> 00:09:30,000
如果想要我们的P1的利用率呢

283
00:09:30,000 --> 00:09:32,400
我们需要找到cache和带宽

284
00:09:32,400 --> 00:09:34,400
跟P之间的一个平衡点

285
00:09:34,400 --> 00:09:36,600
让我们搬运数据的时候来得及时

286
00:09:36,600 --> 00:09:38,200
P1处理的及时

287
00:09:38,200 --> 00:09:38,800
这个时候呢

288
00:09:38,800 --> 00:09:42,200
就可以充分的去增加我们P的利用率了

289
00:09:44,300 --> 00:09:46,000
卷的不行了卷的不行了

290
00:09:46,000 --> 00:09:47,800
记得一键三连加关注哦

291
00:09:47,800 --> 00:09:49,100
所有的内容都会开源

292
00:09:49,100 --> 00:09:51,400
在下面这条链接里面

293
00:09:51,400 --> 00:09:52,000
摆了个掰

