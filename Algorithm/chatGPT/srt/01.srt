1
00:00:00,000 --> 00:00:06,920
Hello大家好

2
00:00:06,920 --> 00:00:07,920
我是ZOMI

3
00:00:07,920 --> 00:00:10,800
今天我来给大家分享一个新的内容

4
00:00:10,800 --> 00:00:13,680
就是chart gpt狂飙原理剖析

5
00:00:13,680 --> 00:00:17,440
深入的去看看chart gpt里面的核心的原理

6
00:00:17,440 --> 00:00:20,360
其实chart gpt就不用我说它是什么

7
00:00:20,360 --> 00:00:21,520
最近发生了什么

8
00:00:21,520 --> 00:00:23,960
确实已经火遍大江南北了

9
00:00:23,960 --> 00:00:26,120
然后我今天要分享的一个内容

10
00:00:26,320 --> 00:00:29,920
主要是看一下chart gpt里面的一些核心的

11
00:00:29,920 --> 00:00:30,560
基础点

12
00:00:30,560 --> 00:00:34,080
那首先会分开4个内容去给大家介绍的

13
00:00:34,080 --> 00:00:36,720
主要可能我后面会分开三个视频

14
00:00:36,720 --> 00:00:38,320
那第一个视频去看一看

15
00:00:38,320 --> 00:00:38,920
butt模型

16
00:00:38,920 --> 00:00:41,560
还有gpt这个模型的系列

17
00:00:41,560 --> 00:00:43,600
这个系列到底发生了什么

18
00:00:43,600 --> 00:00:46,120
接着我们在后面第2个内容里面

19
00:00:46,120 --> 00:00:48,360
去看看强化学习里面

20
00:00:48,360 --> 00:00:50,400
怎么去引入了人类的反馈

21
00:00:50,400 --> 00:00:51,360
就reinforcement

22
00:00:51,360 --> 00:00:53,640
human feedback这种模式

23
00:00:53,640 --> 00:00:56,800
那这种模式又加入了ppo的算法

24
00:00:57,920 --> 00:00:59,320
在第3个内容里面

25
00:00:59,560 --> 00:01:02,200
我们就会去深入的来到instruct gpt的

26
00:01:02,200 --> 00:01:04,680
一个原理的深度剖析

27
00:01:04,680 --> 00:01:08,080
其实instruct gpt就是chart gpt的一个原生

28
00:01:08,080 --> 00:01:10,640
当然了chart gpt现在的论文没有公布

29
00:01:10,640 --> 00:01:13,000
但是instruct gpt是现在为止

30
00:01:13,000 --> 00:01:16,600
跟chart gpt的算法原理是最接近的

31
00:01:17,240 --> 00:01:19,240
下面我们来到第1个内容

32
00:01:19,240 --> 00:01:24,400
从gtp12到gtp-3里面的一个技术的过渡

33
00:01:24,400 --> 00:01:25,680
或者技术的变化

34
00:01:25,680 --> 00:01:28,440
那chart gpt12大部分都是用微调的

35
00:01:28,440 --> 00:01:29,240
这种方式

36
00:01:29,400 --> 00:01:33,680
到gtp-3就引入了一个pump learning的方式

37
00:01:33,760 --> 00:01:36,400
下面我们来看看具体的内容

38
00:01:36,400 --> 00:01:38,280
像在gtp系列里面

39
00:01:38,480 --> 00:01:40,360
我们已经经历了三代

40
00:01:40,360 --> 00:01:43,040
gtp1了2了3了三代

41
00:01:43,040 --> 00:01:46,040
其实三代都是以transformer为核心

42
00:01:46,040 --> 00:01:47,840
去构造网络模型

43
00:01:47,840 --> 00:01:50,440
不同的就在于他们的一个模型层

44
00:01:50,440 --> 00:01:52,040
还有磁相量的长度

45
00:01:52,280 --> 00:01:54,640
最大的不同就是学习的方式

46
00:01:54,640 --> 00:01:57,000
learning的方式不太一样

47
00:01:57,000 --> 00:02:00,360
下面就是我汇总的一个简单的小表格

48
00:02:00,360 --> 00:02:02,200
可以看到open ai

49
00:02:02,200 --> 00:02:05,600
主导了gtp123整个系列

50
00:02:05,600 --> 00:02:08,000
从18年19年20年

51
00:02:08,000 --> 00:02:09,600
到现在的23年

52
00:02:09,600 --> 00:02:10,800
chart gpt出来

53
00:02:10,800 --> 00:02:13,360
确实我们的网络模型的参数量

54
00:02:13,360 --> 00:02:14,800
进一步的提升

55
00:02:14,800 --> 00:02:16,280
而且网络模型的参数量

56
00:02:16,680 --> 00:02:19,360
到了现在的1000多亿的规模

57
00:02:19,360 --> 00:02:22,080
基本上我们在生态里面要迅起来

58
00:02:22,080 --> 00:02:24,840
一个chart gpt或者一个gtp-3

59
00:02:24,880 --> 00:02:28,080
可能要消耗好多的集群的资源

60
00:02:28,640 --> 00:02:31,320
下面我们来看一下gtp-1

61
00:02:31,520 --> 00:02:35,080
gtp-1它主要是基于transformer的decoder

62
00:02:35,080 --> 00:02:37,520
再加上微调的这种方式

63
00:02:37,720 --> 00:02:39,760
既然是decoder跟微调

64
00:02:39,760 --> 00:02:42,400
它就分开了两个阶段

65
00:02:42,600 --> 00:02:45,760
第一个阶段就是预训练的阶段

66
00:02:45,760 --> 00:02:48,240
利用语言模型进行一个运训练

67
00:02:48,240 --> 00:02:49,320
预学习

68
00:02:49,320 --> 00:02:52,640
接着到第二阶段就需要进行微调

69
00:02:52,680 --> 00:02:55,000
微调就是针对我们的下游任务

70
00:02:55,000 --> 00:02:56,800
或者下游的一些数据

71
00:02:56,800 --> 00:02:58,200
进行file tuning

72
00:02:58,200 --> 00:02:59,120
file tuning的工作

73
00:02:59,240 --> 00:03:01,440
就会可能加几层layer层

74
00:03:01,440 --> 00:03:03,360
或者加几层其他head

75
00:03:03,360 --> 00:03:04,880
然后进行一个微调的

76
00:03:04,880 --> 00:03:05,640
微调的工作

77
00:03:05,840 --> 00:03:08,120
确实会带来一些新的入参

78
00:03:08,120 --> 00:03:09,600
新的模型层

79
00:03:11,040 --> 00:03:12,360
宗明老师你好

80
00:03:12,360 --> 00:03:14,880
像这种预训练加微调的方式

81
00:03:14,880 --> 00:03:16,840
跟Bot非常类似

82
00:03:17,360 --> 00:03:19,480
它跟Bot有什么区别吗

83
00:03:20,080 --> 00:03:23,240
小新的问题问得非常及时

84
00:03:23,240 --> 00:03:25,440
我们先来看一看这个图

85
00:03:25,440 --> 00:03:27,600
这个图就是GDP-1

86
00:03:27,600 --> 00:03:29,680
就GDP-1里面的一个图

87
00:03:29,680 --> 00:03:32,760
左边的就是transformer的一个结构

88
00:03:32,760 --> 00:03:34,240
用了transformer的结构之后

89
00:03:34,400 --> 00:03:36,360
针对不同的下游任务

90
00:03:36,520 --> 00:03:38,520
右边就列了4个下游任务

91
00:03:38,520 --> 00:03:39,120
4个下游任务

92
00:03:39,120 --> 00:03:40,560
输了不同的数据之后

93
00:03:40,760 --> 00:03:42,360
通过不同的堆叠方式

94
00:03:42,360 --> 00:03:45,800
然后去组成新的下游任务处理方式

95
00:03:46,400 --> 00:03:47,920
GDP-1的这种方式

96
00:03:48,080 --> 00:03:50,280
确实跟Bot非常类似

97
00:03:50,280 --> 00:03:51,960
但是我们看下面两个图

98
00:03:51,960 --> 00:03:53,280
有个最大的区别

99
00:03:53,280 --> 00:03:54,920
我们可以看到左边的图

100
00:03:55,240 --> 00:03:56,560
就是谷歌的Bot

101
00:03:56,560 --> 00:03:58,200
它一个架构的图

102
00:03:58,200 --> 00:04:01,480
右边就是OpenAI的一个GPT的图

103
00:04:01,480 --> 00:04:03,080
我们从下面来看

104
00:04:03,080 --> 00:04:04,920
基本上的层数都是一样的

105
00:04:04,920 --> 00:04:06,600
通过我们的磁相量

106
00:04:06,880 --> 00:04:08,440
传进去变成embedding

107
00:04:08,440 --> 00:04:10,600
然后给我们的transformer的层

108
00:04:10,600 --> 00:04:11,280
transformer层

109
00:04:11,400 --> 00:04:13,320
最后输出的是一些token

110
00:04:13,880 --> 00:04:15,600
我们看到最大的区别

111
00:04:16,120 --> 00:04:17,000
像这里面

112
00:04:17,560 --> 00:04:19,680
E2就是我们第二个embedding层

113
00:04:19,680 --> 00:04:21,880
它会向左边有一个箭头

114
00:04:21,880 --> 00:04:23,440
像embedding最后一层

115
00:04:23,440 --> 00:04:26,120
向左边也有一个箭头

116
00:04:26,160 --> 00:04:29,200
但是反观OpenAI的GDP

117
00:04:29,440 --> 00:04:32,160
它基本上只会向右边的箭头

118
00:04:32,160 --> 00:04:34,160
它没有左边的箭头

119
00:04:34,640 --> 00:04:36,480
两者之间最大的区别

120
00:04:36,480 --> 00:04:39,080
就是对任务的处理不太一样

121
00:04:39,080 --> 00:04:41,760
我们看看左边的一个输入的例子

122
00:04:41,840 --> 00:04:44,080
假设现在我们有一个

123
00:04:44,080 --> 00:04:45,200
或者我们有一句话

124
00:04:45,200 --> 00:04:47,160
中米经常更新什么

125
00:04:47,160 --> 00:04:48,080
在大晚上

126
00:04:48,240 --> 00:04:50,880
这个时候我要预测中间的一个词

127
00:04:50,880 --> 00:04:52,760
可能这里面做了个must

128
00:04:52,760 --> 00:04:54,280
中米经常更新视频

129
00:04:54,280 --> 00:04:55,080
在大晚上

130
00:04:55,080 --> 00:04:56,400
中间这个must的词

131
00:04:56,680 --> 00:04:58,760
是嵌在我左边跟右边

132
00:04:59,000 --> 00:05:01,200
假设我要预测中间的词

133
00:05:01,200 --> 00:05:02,720
我可能会根据左边

134
00:05:02,720 --> 00:05:03,760
根据我前面

135
00:05:03,760 --> 00:05:04,720
根据我后面

136
00:05:04,720 --> 00:05:05,960
根据我上下文

137
00:05:05,960 --> 00:05:07,480
去做一个预测的

138
00:05:07,520 --> 00:05:10,280
但是像GDP这种方式

139
00:05:10,560 --> 00:05:12,360
就是中米经常在大晚上

140
00:05:12,360 --> 00:05:13,280
更新什么

141
00:05:13,720 --> 00:05:14,360
什么

142
00:05:14,560 --> 00:05:15,200
我们这时候

143
00:05:15,320 --> 00:05:18,320
基本上我只会根据前文的信息

144
00:05:18,320 --> 00:05:20,920
去预测下一个单词是什么

145
00:05:20,920 --> 00:05:23,160
这种只是做一个简单的

146
00:05:23,160 --> 00:05:24,320
后项的预测

147
00:05:24,320 --> 00:05:25,000
或者预测

148
00:05:25,000 --> 00:05:26,840
我接下来要发生什么

149
00:05:26,960 --> 00:05:28,680
所以他们最大的区别

150
00:05:28,680 --> 00:05:31,080
就是语言任务上的区别

151
00:05:31,080 --> 00:05:32,760
那我们可以看一下

152
00:05:32,760 --> 00:05:34,240
一个简单的总结

153
00:05:34,240 --> 00:05:35,320
像GDP-1

154
00:05:35,600 --> 00:05:38,400
它虽然也是以语言模型作为目标

155
00:05:38,400 --> 00:05:40,880
但采用的是单向的语言模型

156
00:05:40,880 --> 00:05:42,160
注意是单向

157
00:05:42,160 --> 00:05:43,040
像BERT那种

158
00:05:43,200 --> 00:05:46,360
确实是双向的语言模型

159
00:05:46,720 --> 00:05:47,920
在网络结构方面

160
00:05:48,080 --> 00:05:49,000
BERT网络模型

161
00:05:49,160 --> 00:05:50,600
更多的是采用了

162
00:05:50,600 --> 00:05:53,160
像transformer encoder的部分

163
00:05:53,160 --> 00:05:55,600
而GDP更多的是采用了

164
00:05:55,600 --> 00:05:59,840
类似于transformer decoder的部分

165
00:06:00,000 --> 00:06:01,360
我们可以看到下面这个图

166
00:06:01,600 --> 00:06:04,520
就是GDP-1里面的一个简单的图

167
00:06:04,520 --> 00:06:05,920
里面主要是用了

168
00:06:05,920 --> 00:06:08,160
transformer decoder的模块

169
00:06:08,360 --> 00:06:08,920
简单的

170
00:06:08,920 --> 00:06:11,760
我们从单个网络模型的结构来看

171
00:06:11,760 --> 00:06:13,440
最大最明显的区别

172
00:06:13,440 --> 00:06:14,520
就是像BERT

173
00:06:14,840 --> 00:06:16,680
会采用multi-head attention

174
00:06:16,840 --> 00:06:20,320
像GDP会采用max multi-head attention

175
00:06:20,320 --> 00:06:21,280
这种方式

176
00:06:21,640 --> 00:06:22,520
总结来说

177
00:06:22,600 --> 00:06:23,880
我们从三个维度

178
00:06:23,880 --> 00:06:25,160
去看他们的区别

179
00:06:25,160 --> 00:06:26,520
第一个是语言模型

180
00:06:26,520 --> 00:06:27,360
到底是单向的

181
00:06:27,360 --> 00:06:28,400
还是双向的

182
00:06:28,480 --> 00:06:30,480
第二个我们采用了transformer

183
00:06:30,480 --> 00:06:31,520
哪个部分

184
00:06:31,520 --> 00:06:32,760
然后去组成的

185
00:06:32,760 --> 00:06:36,040
第三个在某一个具体的结构上面

186
00:06:36,040 --> 00:06:37,640
它到底是multi-head attention

187
00:06:37,640 --> 00:06:40,160
还是max multi-head attention

188
00:06:40,160 --> 00:06:41,000
三种

189
00:06:42,240 --> 00:06:43,440
下面我们来看看

190
00:06:43,440 --> 00:06:45,720
什么是max multi-head attention

191
00:06:45,960 --> 00:06:46,640
multi-head attention

192
00:06:46,760 --> 00:06:48,520
我就不再多说了

193
00:06:48,520 --> 00:06:49,400
因为在transformer

194
00:06:49,400 --> 00:06:50,920
还有BERT这些网络模型里面的

195
00:06:50,920 --> 00:06:51,400
大量的

196
00:06:51,400 --> 00:06:53,360
已经做了非常多的例子

197
00:06:53,360 --> 00:06:54,920
网上你搜也很多

198
00:06:54,920 --> 00:06:56,720
我们来看看GDP-1里面的

199
00:06:56,720 --> 00:06:58,040
max multi-head attention

200
00:06:58,040 --> 00:06:59,320
最主要的通俗理解

201
00:06:59,320 --> 00:07:00,960
就是在处理当前词的时候

202
00:07:00,960 --> 00:07:02,360
看不到后面的词

203
00:07:02,360 --> 00:07:03,760
假设我在处理一的时候

204
00:07:03,920 --> 00:07:05,520
我是看不到后面的词

205
00:07:05,520 --> 00:07:07,560
但是我会看到前面的单词

206
00:07:07,560 --> 00:07:08,320
a和o

207
00:07:08,320 --> 00:07:09,520
这种就是单向

208
00:07:09,520 --> 00:07:11,280
我去看a和o的时候

209
00:07:11,400 --> 00:07:13,320
就去预测跟it之间的

210
00:07:13,320 --> 00:07:14,240
一个attention

211
00:07:14,240 --> 00:07:15,320
还有它的分数

212
00:07:15,320 --> 00:07:17,520
还有它之间的关联关系

213
00:07:17,520 --> 00:07:19,480
然后去算qkb的词

214
00:07:19,480 --> 00:07:21,840
这个就是max multi-head attention

215
00:07:21,840 --> 00:07:23,560
一个简单的例子

216
00:07:24,080 --> 00:07:27,480
现在我们来到GDP-2

217
00:07:27,480 --> 00:07:29,040
这个模型里面

218
00:07:29,360 --> 00:07:31,240
GDP-2跟GDP-1

219
00:07:31,240 --> 00:07:32,120
最大的区别

220
00:07:32,520 --> 00:07:34,360
就是我们的标题

221
00:07:34,360 --> 00:07:36,200
没有了微调的任务

222
00:07:36,200 --> 00:07:37,440
直接使用了

223
00:07:37,440 --> 00:07:39,240
server soft learning

224
00:07:39,640 --> 00:07:41,040
谈到server soft learning

225
00:07:41,360 --> 00:07:43,000
就是我们的小样本学习

226
00:07:43,360 --> 00:07:45,200
我们来看看小样本学习

227
00:07:45,200 --> 00:07:46,920
具体分为哪几种

228
00:07:47,120 --> 00:07:48,240
现在小样本学习

229
00:07:48,440 --> 00:07:51,480
其实最主要的是下面三种模式

230
00:07:51,480 --> 00:07:53,080
第一种就是server soft

231
00:07:53,080 --> 00:07:54,800
就是零样本的学习

232
00:07:54,800 --> 00:07:56,200
针对具体的项目任务

233
00:07:56,360 --> 00:07:58,760
就不需要进行一个微调了

234
00:07:58,760 --> 00:07:59,880
像one soft learning

235
00:08:00,000 --> 00:08:01,360
就是单样本学习

236
00:08:01,360 --> 00:08:03,160
可能我有小量的样本

237
00:08:03,160 --> 00:08:05,240
进行一个简单的微调

238
00:08:05,240 --> 00:08:07,560
然后去预测更多的任务

239
00:08:07,880 --> 00:08:08,840
那few soft learning

240
00:08:09,080 --> 00:08:10,840
更多的就是少量的样本

241
00:08:10,840 --> 00:08:12,000
进行学习

242
00:08:12,000 --> 00:08:13,560
进行一个简单的微调

243
00:08:13,560 --> 00:08:15,280
完成特殊的任务

244
00:08:15,440 --> 00:08:16,800
最主要的chart gpt2

245
00:08:17,000 --> 00:08:19,200
就是使用了server soft learning

246
00:08:19,200 --> 00:08:21,440
这种学习的方式

247
00:08:22,080 --> 00:08:24,400
除了刚才我们提到的GDP-2

248
00:08:24,640 --> 00:08:26,680
采用了一种server soft learning的方式

249
00:08:26,680 --> 00:08:27,920
其实最大的区别

250
00:08:27,920 --> 00:08:30,240
就是因为我引用了server soft learning

251
00:08:30,240 --> 00:08:31,800
我需要更多的参数

252
00:08:31,800 --> 00:08:33,200
更大的网络模型

253
00:08:33,240 --> 00:08:35,240
记录我们数据的特征

254
00:08:35,440 --> 00:08:36,840
这个时候最有效的办法

255
00:08:36,840 --> 00:08:39,200
就是增大我们的网络模型

256
00:08:39,200 --> 00:08:41,080
还用更大的数据集

257
00:08:41,120 --> 00:08:42,560
从下面这个图可以看到

258
00:08:42,560 --> 00:08:43,920
其实GDP-2

259
00:08:44,680 --> 00:08:45,320
网络模型

260
00:08:45,320 --> 00:08:49,240
提供了4种不同的模型的结构

261
00:08:49,400 --> 00:08:50,160
不同模型结构

262
00:08:50,280 --> 00:08:51,600
更多的是通过decoder

263
00:08:51,600 --> 00:08:53,480
来不断的去堆叠

264
00:08:53,480 --> 00:08:55,440
所以简单的对比GDP-2

265
00:08:55,440 --> 00:08:56,360
还有GDP-1

266
00:08:56,360 --> 00:08:57,600
可以看到GDP-2

267
00:08:58,040 --> 00:08:59,560
拾弃了微调的方式

268
00:08:59,560 --> 00:09:01,160
使用了server soft learning

269
00:09:01,160 --> 00:09:03,880
因此引入了更大的网络模型

270
00:09:03,880 --> 00:09:05,920
还有更大的数据集

271
00:09:07,040 --> 00:09:09,840
下面我们来到第三个内容

272
00:09:09,840 --> 00:09:12,440
就是GDP-3了

273
00:09:12,560 --> 00:09:13,360
GDP-3

274
00:09:13,600 --> 00:09:16,400
作为一个非常划时代的一个模型

275
00:09:16,400 --> 00:09:18,040
我们看一看GDP-3

276
00:09:18,040 --> 00:09:20,880
主要是开启了NLP的新方式

277
00:09:20,880 --> 00:09:21,600
Prompt learning

278
00:09:21,600 --> 00:09:23,800
实现了小样本的学习

279
00:09:23,800 --> 00:09:25,080
把我们的server soft

280
00:09:25,080 --> 00:09:27,440
精度进一步的提升

281
00:09:27,640 --> 00:09:29,040
其实在一开始

282
00:09:29,160 --> 00:09:30,640
像Prompt tuning这种动机

283
00:09:30,800 --> 00:09:31,520
主要是解决

284
00:09:31,520 --> 00:09:33,800
目前fine tuning的两个痛点

285
00:09:34,000 --> 00:09:36,960
第一个就是降低语义的差别

286
00:09:36,960 --> 00:09:37,800
降低语义的差别

287
00:09:37,800 --> 00:09:40,440
其实下面这句话有点勇于

288
00:09:40,440 --> 00:09:41,240
很好理解

289
00:09:41,240 --> 00:09:42,440
我们的虚拟模型

290
00:09:42,440 --> 00:09:43,440
跟我们的下游任务

291
00:09:43,440 --> 00:09:45,680
其实有一个比较大的区别的

292
00:09:45,680 --> 00:09:46,920
需要引入新的参数

293
00:09:46,920 --> 00:09:48,560
或者新的网络的模型层

294
00:09:48,560 --> 00:09:49,680
针对不同的下游任务

295
00:09:49,840 --> 00:09:51,240
可能需要重新挑战

296
00:09:51,240 --> 00:09:52,480
进行一个训练

297
00:09:52,680 --> 00:09:53,320
这个时候

298
00:09:53,640 --> 00:09:55,200
我们的虚拟模型跟下游任务

299
00:09:55,200 --> 00:09:56,960
其实脱节还是比较严重的

300
00:09:56,960 --> 00:09:59,160
就像现在的CV一样

301
00:09:59,160 --> 00:10:00,920
为什么CV没有那么多大模型

302
00:10:00,920 --> 00:10:02,040
就是因为他们现在

303
00:10:02,080 --> 00:10:03,400
还没有一个很好的

304
00:10:03,400 --> 00:10:04,640
统一的范式

305
00:10:04,640 --> 00:10:05,040
当然了

306
00:10:05,040 --> 00:10:06,200
现在慢慢的出现了

307
00:10:06,200 --> 00:10:07,840
不能说完全没有

308
00:10:07,840 --> 00:10:09,440
那我们回到正题

309
00:10:09,440 --> 00:10:13,200
第二个就是避免过拟和over fitting

310
00:10:13,200 --> 00:10:14,080
这个工作

311
00:10:14,080 --> 00:10:15,960
因为我们在fine tuning的阶段

312
00:10:15,960 --> 00:10:17,800
会引入新的一些参数

313
00:10:17,800 --> 00:10:18,680
会重新训练

314
00:10:18,680 --> 00:10:20,320
这个时候对我们的预训的模型

315
00:10:20,440 --> 00:10:23,160
就有可能会造成过拟和的问题了

316
00:10:24,400 --> 00:10:26,120
区别杠杉针对这两个问题

317
00:10:26,640 --> 00:10:29,280
提出了新的Prompt一种范式

318
00:10:29,280 --> 00:10:31,320
那Prompt它一开始其实不叫Prompt

319
00:10:31,320 --> 00:10:32,520
后来大家总结总结的

320
00:10:32,520 --> 00:10:33,640
或者弄着弄着

321
00:10:33,640 --> 00:10:36,160
就把它重新的命名为Prompt了

322
00:10:36,160 --> 00:10:37,600
我们看看PPT

323
00:10:37,760 --> 00:10:40,520
这个是一个新的模型里面的一方图

324
00:10:40,520 --> 00:10:41,640
我们可以看到最上面

325
00:10:41,760 --> 00:10:44,880
就是原始的一种预训练的方式

326
00:10:44,880 --> 00:10:45,640
通过Prompt tuning

327
00:10:45,800 --> 00:10:47,280
就是我有一句话

328
00:10:47,280 --> 00:10:49,160
去指引我下面的那句话

329
00:10:49,160 --> 00:10:50,320
到底预测是什么

330
00:10:50,320 --> 00:10:51,680
我每一次训练的时候

331
00:10:51,840 --> 00:10:53,360
都会塞一句Prompt tuning

332
00:10:53,360 --> 00:10:54,280
就是塞一句

333
00:10:54,280 --> 00:10:55,800
只是性的一个语言

334
00:10:55,800 --> 00:10:57,400
或者是性的一个句子进去

335
00:10:57,400 --> 00:10:59,240
更好的对我们后面的数据

336
00:10:59,240 --> 00:11:00,400
进行一个预测

337
00:11:00,400 --> 00:11:01,440
或者训练

338
00:11:01,440 --> 00:11:02,520
那后面训练的时候

339
00:11:02,760 --> 00:11:04,760
就可能会把自己里面做一个mast

340
00:11:04,760 --> 00:11:05,800
比起一个mast

341
00:11:06,000 --> 00:11:07,240
预训练可能简单的

342
00:11:07,240 --> 00:11:08,080
只有后面

343
00:11:08,080 --> 00:11:10,840
那现在加了一句更好的句子

344
00:11:10,840 --> 00:11:12,600
或者更好的上下文

345
00:11:12,600 --> 00:11:14,720
对它进行一个指导

346
00:11:14,920 --> 00:11:16,560
那下面我们看看

347
00:11:16,560 --> 00:11:20,320
GDP-3的一个具体的GIF的图

348
00:11:20,320 --> 00:11:21,360
可以看到下面

349
00:11:21,560 --> 00:11:23,280
最上面就是我们的一些

350
00:11:23,280 --> 00:11:24,280
具体的数据

351
00:11:24,720 --> 00:11:26,000
这个就是我们的Prompt

352
00:11:26,000 --> 00:11:27,680
Prompt的一些语调

353
00:11:28,160 --> 00:11:29,720
可以看到最上面第一句话

354
00:11:29,840 --> 00:11:30,960
就是我们的Prompt语调

355
00:11:30,960 --> 00:11:32,160
Prompt语调输进来

356
00:11:32,160 --> 00:11:33,360
给我们的GDP-3之后

357
00:11:33,680 --> 00:11:35,640
我们就去对下面的句子

358
00:11:35,640 --> 00:11:37,240
进行一个预测

359
00:11:37,400 --> 00:11:39,720
可能每一次都是预测最后一句话

360
00:11:39,960 --> 00:11:41,440
或者最后一个单词

361
00:11:41,440 --> 00:11:44,120
然后下次再预测下一个单词

362
00:11:44,320 --> 00:11:46,800
这种方式就结合了GDP-2

363
00:11:46,800 --> 00:11:48,920
然后引用了Prompt learning

364
00:11:48,920 --> 00:11:49,800
这种方式

365
00:11:49,800 --> 00:11:52,960
完成了我们的GDP-1到GDP-3

366
00:11:52,960 --> 00:11:55,400
的一个整体的升级

367
00:11:55,680 --> 00:11:57,640
我们现在来总结一下

368
00:11:57,640 --> 00:11:58,960
整个GDP系列

369
00:11:59,160 --> 00:12:00,720
从一开始的fine tuning

370
00:12:00,720 --> 00:12:03,680
再到Prompt tuning这种工作

371
00:12:04,720 --> 00:12:07,480
简单的用一个图来概括一下

372
00:12:07,480 --> 00:12:08,840
我们可以看到下面这个图

373
00:12:09,000 --> 00:12:10,120
从GDP-1

374
00:12:10,120 --> 00:12:10,720
GDP-2

375
00:12:10,720 --> 00:12:11,440
GDP-3

376
00:12:11,440 --> 00:12:12,920
到instruct GDP

377
00:12:12,920 --> 00:12:14,680
到最后的chart GPT

378
00:12:14,680 --> 00:12:16,000
它们最大的不同

379
00:12:16,000 --> 00:12:18,400
就是一开始从预训练到微调

380
00:12:18,400 --> 00:12:20,840
引入了预训练加civil soft

381
00:12:20,840 --> 00:12:22,520
最后到GDP-3的时候

382
00:12:22,680 --> 00:12:25,320
就引入了预训练加Prompt tuning

383
00:12:25,320 --> 00:12:27,200
而在instruct GDP的时候

384
00:12:27,360 --> 00:12:30,000
引入了一个新的学习的方式

385
00:12:30,000 --> 00:12:31,600
instruct learning

386
00:12:31,760 --> 00:12:32,880
下面我们来看看

387
00:12:32,880 --> 00:12:35,680
什么叫做instruct learning

388
00:12:35,680 --> 00:12:36,600
所以大家不要觉得

389
00:12:36,600 --> 00:12:38,400
我在重复讲GDP-3

390
00:12:38,400 --> 00:12:39,240
没有什么意义

391
00:12:39,240 --> 00:12:41,480
我们慢慢的引导下来

392
00:12:41,480 --> 00:12:42,840
像这种Prompt tuning

393
00:12:43,120 --> 00:12:44,000
或者Prompt learning

394
00:12:44,160 --> 00:12:46,160
我们叫做提示的学习

395
00:12:46,160 --> 00:12:47,640
而instruct learning

396
00:12:47,960 --> 00:12:50,160
我们叫做指示性的学习

397
00:12:50,280 --> 00:12:52,400
它们都有相同点和区别

398
00:12:52,600 --> 00:12:54,760
相同点都是想去挖掘

399
00:12:54,760 --> 00:12:55,960
我们的语言模型

400
00:12:56,000 --> 00:12:58,240
本身所具备的知识

401
00:12:58,440 --> 00:13:00,280
这句话其实是废话

402
00:13:01,600 --> 00:13:02,920
我们的目标都是相同的

403
00:13:02,920 --> 00:13:04,640
都是搞LMM大模型

404
00:13:04,640 --> 00:13:07,320
我们来看看区别点在哪

405
00:13:07,400 --> 00:13:08,600
像Prompt这种方式

406
00:13:08,760 --> 00:13:12,000
更多的是做一种补全的功能

407
00:13:12,040 --> 00:13:13,640
确实类似于补全

408
00:13:13,640 --> 00:13:14,880
根据上半句

409
00:13:15,000 --> 00:13:17,240
上半句就是Prompt的一种提示

410
00:13:17,240 --> 00:13:20,400
生成或者完成下半句的任务

411
00:13:20,400 --> 00:13:22,200
这种更像完形填空

412
00:13:22,200 --> 00:13:24,640
补全我们整体的语言语调

413
00:13:24,640 --> 00:13:25,920
的一种模型能力

414
00:13:26,360 --> 00:13:27,360
instruct的方式

415
00:13:27,560 --> 00:13:31,760
更多的是希望激发语言模型的理解能力

416
00:13:31,760 --> 00:13:34,160
我一开始给出一个明确的指示

417
00:13:34,160 --> 00:13:35,720
让模型去做一个

418
00:13:35,720 --> 00:13:37,680
对这个指示的一个认知

419
00:13:37,680 --> 00:13:38,680
或者理解

420
00:13:39,080 --> 00:13:41,000
说起来可能比较难理解

421
00:13:41,000 --> 00:13:42,960
我们还是来看看一个具体的

422
00:13:42,960 --> 00:13:44,200
或者可爱的例子

423
00:13:44,520 --> 00:13:47,120
第一个就是我们的提示学习

424
00:13:47,120 --> 00:13:48,160
我们的Prompt learning

425
00:13:48,200 --> 00:13:50,080
假设我们现在有一句话

426
00:13:50,080 --> 00:13:51,880
他很喜欢这个项量

427
00:13:51,880 --> 00:13:53,200
太什么太好了

428
00:13:53,200 --> 00:13:54,160
太好看了

429
00:13:54,200 --> 00:13:55,880
这种就是对我们的语调

430
00:13:55,880 --> 00:13:57,000
进行一个完形填空

431
00:13:57,000 --> 00:13:58,080
或者补齐

432
00:13:58,440 --> 00:14:00,640
而此次学习更多的

433
00:14:00,640 --> 00:14:03,400
我们可以判断这句话的情感

434
00:14:03,400 --> 00:14:05,000
我给他买了个项链

435
00:14:05,000 --> 00:14:06,160
他很喜欢

436
00:14:06,160 --> 00:14:08,120
他到底是好还是不好

437
00:14:08,480 --> 00:14:10,560
我们需要去理解这句话

438
00:14:10,720 --> 00:14:13,240
这也是GDP这种单一训练模型

439
00:14:13,440 --> 00:14:14,960
跟Chat GPT这种

440
00:14:14,960 --> 00:14:16,400
可学习可反馈的模型

441
00:14:16,400 --> 00:14:17,880
最大的区别

442
00:14:17,880 --> 00:14:20,800
我们看看右边的几个图

443
00:14:21,040 --> 00:14:22,680
确实我们还是在这里面

444
00:14:23,080 --> 00:14:24,600
只是通过不同的维度

445
00:14:24,600 --> 00:14:26,160
给大家去分享

446
00:14:26,400 --> 00:14:27,320
像模型微调

447
00:14:27,560 --> 00:14:29,120
这个任务确实比较简单

448
00:14:29,120 --> 00:14:30,000
我们从预训练

449
00:14:30,000 --> 00:14:31,240
training model

450
00:14:31,240 --> 00:14:32,520
然后再到fine tuning

451
00:14:32,520 --> 00:14:34,480
接着进行一个预测

452
00:14:34,520 --> 00:14:35,320
而提示学习

453
00:14:35,480 --> 00:14:37,120
只要通过一个简单的预训练

454
00:14:37,120 --> 00:14:38,680
就可以在不同的任务上面

455
00:14:38,680 --> 00:14:39,840
做一个预测

456
00:14:39,880 --> 00:14:40,960
像提示学习

457
00:14:41,160 --> 00:14:42,280
我可能首先

458
00:14:42,400 --> 00:14:43,640
大家都要有一个预训练

459
00:14:44,040 --> 00:14:45,480
然后我会在BCD

460
00:14:45,480 --> 00:14:45,960
任务里面

461
00:14:46,080 --> 00:14:47,400
做一个仔细性的学习

462
00:14:47,400 --> 00:14:50,280
接着我回到A任务上面做预测

463
00:14:50,560 --> 00:14:52,040
就是希望让我们的模型

464
00:14:52,280 --> 00:14:54,760
更加具备理解能力

465
00:14:54,800 --> 00:14:55,640
提示学习

466
00:14:55,840 --> 00:14:57,080
更加聚焦于

467
00:14:57,080 --> 00:15:00,640
我们对语调的一种预测生成

468
00:15:01,960 --> 00:15:02,440
好了

469
00:15:02,440 --> 00:15:04,240
这一节的内容就到这里为止

470
00:15:04,240 --> 00:15:04,960
我们下一节

471
00:15:04,960 --> 00:15:06,240
更加深入的去看看

472
00:15:06,240 --> 00:15:07,360
Chat GPT里面的

473
00:15:07,360 --> 00:15:08,440
强化学习部分
