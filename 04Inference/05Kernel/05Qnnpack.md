# QNNPACK算法

## 算法介绍
QNNPACK(Quantized Neural Networks PACKage) 是 Marat Dukhan (Facebook) 开发的专门用于量化神经网络计算的加速库，其卓越的性能表现一经开源就击败了几乎全部已公开的加速算法。到目前为止，QNNPACK 仍然是已公开的，用于移动端（手机）的，性能最优的量化神经网络加速库

Marat Dukhan于2019年离开Facebook来到Google之后，发表了一篇名为The Indirect Convolution Algorithm的文章（https://doi.org/10.48550/arXiv.1907.02129），揭秘了QNNPack加速库中针对矩阵卷积运算的核心算法，即如文章标题所示的The Indirect Convolution Algorithm（间接卷积算法）。

在本节中，笔者将结合The Indirect Convolution Algorithm这篇论文以及QNNPack在开源时同期发布的一篇技术性博客QNNPACK: Open source library for optimized mobile deep learning（https://engineering.fb.com/2018/10/29/ml-applications/qnnpack/），带领大家领略间接卷积算法的魅力。

## 传统 im2col + GEMM 方法

在介绍简介卷积算法前，先回顾一下传统的矩阵卷积运算方法。

简单的1×1卷积可以直接映射到矩阵-矩阵乘法，但对于具有较大内核、填充或下采样（步幅）的卷积，则不是这种情况。这些更复杂的卷积可以通过结合im2col算法与GEMM算法来实现：即将四维的输入图像按照卷积窗尺寸进行重排成为一个二维的矩阵，同时将卷积核进行展开重排也成为一个二维的矩阵，将卷积操作转换为两个矩阵的乘法，直接使用GEMM方式完成矩阵乘即可。

im2col + GEMM方法能成功的原因本质上是其拆解后忽略内存复用后的计算过程等价于矩阵乘。

![传统im2col + GEMM方法](./images/QNNPACK01.png)

使用传统im2col + GEMM存在几个明显的缺陷：

**im2col消耗空间较大**：使用im2col方法将输入图像以及卷积核展开成为二维中间矩阵会消耗大量内存空间。

**GEMM输入缓存空间较大**：在面对大卷积核时，使用GEMM进行通用矩阵乘时需要缓存大量的行数据，就算采用分割方法同样不可避免。

针对以上缺陷，Marat Dukhan提出的间接卷积算法都能较好地解决。

## The Indirect Convolution Algorithm（间接卷积算法）

间接卷积算法是QNNPACK中的核心算法，而QNNPACK原本推出的目的是解决量化问题。

PyTorch和其他深度学习框架通常使用浮点数来表示神经网络中的权重和神经元，在训练期间。这是因为浮点数可以提供高精度的计算。然而，在模型训练完成之后，浮点数和计算往往变得过于复杂：许多类型的模型可以调整为使用低精度整数运算进行推理，而不会显著损失准确性。低精度整数表示相对于单精度甚至半精度浮点数有几个优势：内存占用减少2到4倍，这有助于将神经网络模型保存在移动处理器的小缓存中；在内存带宽受限的操作中提高性能；增加能效；在许多类型的硬件上，提高计算吞吐量。

QNNPACK使用一种与Android神经网络API兼容的线性量化方案。它假设量化值q[i]用8位无符号整数表示，并且它们与实值表示r[i]的关系如下公式：

$$ r[i]=scale×(q[i]−zero_point) $$

其中，scale是一个正的浮点数，zero_point是一个8位无符号整数，和q[i]一样。

虽然QNNPACK利用了像其他BLAS库一样的PDOT微内核，但其对具有8位元素的量化张量和移动AI使用案例的关注带来了非常不同的性能优化视角。大多数BLAS库针对科学计算使用案例，处理的矩阵通常由成千上万的双精度浮点元素组成，而QNNPACK的输入矩阵来自低精度、移动设备特定的计算机视觉模型，具有非常不同的维度。在1×1卷积中，K是输入通道数，N是输出通道数，M是图像中的像素数。在实际的移动优化网络中，K和N不大于1024，并且通常在32到256之间。

移动架构的约束规定MR和NR不能超过8。因此，即使在具有1024通道的最大模型中，PDOT微内核中读取的整个内存块最多为16KB，这甚至可以适应超低端移动核心的一级缓存。这标志着QNNPACK与其他GEMM实现之间的重要区别：其他库会重新打包A和B矩阵，以更好地利用缓存层次结构，希望通过大量计算来摊销打包开销，而QNNPACK则针对A和B面板可以适应L1缓存的情况进行优化。因此，**它旨在消除所有非计算必需的内存转换**。

“消除所有非计算必需的内存转换”即为间接卷积算法的核心特定，这样的特性同样也注定了它在非量化任务中同样能起到显著的优化作用。

![QNNPACK算法示意图](./images/QNNPACK02.png)

### Indirection Buffer（间接缓冲区）

在QNNPACK中，Marat Dukhan实现了一种更高效的算法。与其将卷积输入转换以适应矩阵-矩阵乘法的实现，不如调整微内核的实现，使其能够实时进行im2col转换。

间接卷积算法没有将实际数据从输入张量复制到im2col缓冲区，而是设置了一个间接缓冲区，其中包含指向用于计算每个输出像素的输入像素行的指针。同时，此算法还修改了矩阵-矩阵乘法微内核，使其从间接缓冲区加载指向虚拟矩阵A行的指针，这个缓冲区通常比im2col缓冲区小得多。此外，如果输入张量的内存位置在推理运行之间不变，间接缓冲区可以在初始化时设置一次指向输入行的指针，然后在多个推理运行中重复使用。从实验结果可以观察到，使用间接缓冲区的微内核不仅消除了im2col转换的开销，而且性能稍微优于矩阵-矩阵乘法微内核（这可能是因为在计算不同的输出像素时重复使用了输入行）。

![有间接缓冲区与直接GEMM对比](./images/QNNPACK03.png)

间接缓冲区是一个指向输入像素行的指针缓冲区。每行包含C个像素，并且这些行可以选择性地跨步。对于每个输出像素位置和每个内核元素，间接缓冲区包含一个指向输入像素行的指针，该行的像素将与相应内核元素的滤波器权重行进行卷积，以生成相应的输出像素。对于非单位内核的卷积，通常使用隐式填充。在带有隐式填充的卷积中，在计算卷积之前，输入张量在空间维度上被隐式地用零填充。为了处理填充卷积，间接卷积算法需要一个显式的零向量——一个由C个元素初始化为零的常量向量。显式零向量不需要与输入张量连续，并且可以在多个卷积操作之间共享。在初始化间接缓冲区时，超出输入张量范围的输入行的指针将被替换为指向显式零向量的指针。

间接缓冲区依赖于多个参数：输入、输出和滤波器张量的形状，卷积步幅、扩张和隐式填充，以及指向输入张量和显式零张量的指针，以及输入张量中像素行的步幅。这些参数可以根据其变化频率及其对间接缓冲区的影响分为几类：

*卷积步幅、扩张、内核大小、隐式填充、输入通道数和输出通道数*：这些是神经网络模型的参数，一旦模型实例化后，它们实际上是不可变的。

*输入或输出张量的高度和宽度*：这些输入参数的变化需要完全重新初始化间接缓冲区。然而，对于大多数类型的模型，特别是在生产环境中，这种变化是罕见的。

*批量大小*：批量大小的变化仅需要对先前未初始化的批次索引部分重新初始化间接缓冲区。

*输入张量或显式零向量的指针*：这些输入参数的变化需要完全重新初始化间接缓冲区。为了避免这种开销，实现卷积的高级框架可以保证在没有形状变化的情况下，张量具有持久位置。

下图展示了间接卷积算法的基本工作流程。在计算 M×N 规模大小输出时，经由间接缓冲区取出对应输入缓冲区数据，并取出权重，计算出结果，整体计算过程等价于计算 M×K 和 K×N 矩阵乘。在实现过程中，软件的执行过程分为两部分：在准备阶段，需要执行加载模型配置输入缓冲区以及重排权重使其内存布局适用于后续计算两个工作；在运行阶段对于每个输入执行 (𝑂𝐻∗𝑂𝑊/𝑀)∗(𝑂𝐶/𝑁) 次循环，每次使用 GEMM 计算 𝑀×𝑁 大小输出出。

![间接卷积算法工作流程图](./images/QNNPACK04.png)

对间接缓冲区布局解释如下。

间接缓冲区可以理解为一组卷积核大小的缓冲区，共有 𝑂𝐻×𝑂𝑊 个，每个缓冲区大小为 𝐾𝐻×𝐾𝑊 （每个缓冲区对应某个输出要使用的输入地址）。每计算一个空间位置输出，使用一个间接缓冲区；空间位置相同而通道不同的输出使用相同间接缓冲区，缓冲区中的每个指针用于索引输入中 IC 个元素。

在计算时，随着输出的索引内存地址移动，选用不同的间接缓冲区，即可得到相应的输入地址。无需再根据输出目标的坐标计算要使用的输入的地址，这等同于预先计算地址。

![间接缓冲区布局](./images/QNNPACK05.png)

### 与GEMM算法的对比

与基于GEMM的卷积算法相比，间接卷积的性能受到四个因素的影响：

1. 消除非单位卷积的im2col转换。间接卷积方法不需要执行im2col转换，这减少了内存和计算开销，因为无需将输入数据块复制到im2col缓冲区。

2. 改进的输入行缓存。对于大内核卷积，间接卷积方法通过从同一位置读取不同输出像素的输入行，提高了缓存效率。这是因为间接GEMM方法可以更好地利用缓存，而传统GEMM方法则需要从im2col缓冲区的不同位置读取数据，增加了缓存未命中率。

3. 指针加载的开销。间接缓冲区引入了缓冲区指针，需要从间接缓冲区加载输入数据行的指针，这比在常量步幅假设下直接计算这些指针略微增加了开销。

4. 循环效率的差异。间接卷积操作中，R × S（内核的高度和宽度）和C（通道数）的迭代通过两个嵌套循环进行，这可能比GEMM操作中的单个循环（R × S × C次迭代）效率稍低。单循环通常能更好地利用处理器的流水线和指令缓存，从而提高执行效率。

总体来说，间接卷积优化算法解决了卷积计算的三个问题，一是空间向量化问题，二是地址计算复杂问题，三是内存拷贝问题。同时间接卷积算法也存在一定的缺陷，即其建立的缓冲区和数据重新组织（Repacking）对内存造成大量的消耗。

在The Indirect Convolution Algorithm中作者展示了间接卷积算法、基于GEMM的算法以及ResNet18和SqueezeNet 1.0模型中仅GEMM部分的性能。可以看到间接卷积算法性能会明显优于其他算法的性能。

![性能对比](./images/QNNPACK06.png)

## 总结

间接卷积算法是对基于GEMM的卷积算法的修改，其中GEMM操作从间接缓冲区读取输入张量中行的地址。实验表明，这种修改后的类似GEMM的操作与传统的GEMM操作性能相似，并且表明两种算法之间的主要区别在于GEMM基于算法中的im2col缓冲区与间接卷积算法中的间接缓冲区之间的差异。与基于GEMM的算法中的im2col缓冲区不同，间接缓冲区在输入通道数上是恒定的，并且可以在卷积调用之间保持不变。间接卷积算法提供了基于GEMM算法的通用性，但具有更小的内存占用和消除im2col转换成本的优势。这些特点使间接卷积算法成为卷积操作默认实现的可行选项。间接卷积算法在本论文范围之外还具有有趣的性能特点。特别是，该算法在多线程卷积调用期间可能比基于GEMM的算法具有额外的性能优势。修改后的GEMM操作是计算密集型的，应该随着核心数量线性扩展，而基于GEMM的卷积中的im2col部分会被内存或缓存带宽所限制，其在核心数量上的扩展是次线性的。

## 本节视频

<html>
<iframe src="https:&as_wide=1&high_quality=1&danmaku=0&t=30&autoplay=0" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</html>
