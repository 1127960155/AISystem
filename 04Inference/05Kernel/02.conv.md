# 卷积操作原理

卷积是神经网络里面的核心计算之一，它是一种特殊的线性运算。卷积神经网络（CNN）是针对图像领域任务提出的神经网络，其受猫的视觉系统启发，堆叠使用卷积层和池化层提取特征。它在 CV 领域方面的突破性进展引领了深度学习的热潮。卷积的变种丰富，计算复杂，神经网络运行时大部分时间都耗费在计算卷积，网络模型的发展在不断增加网络的深度，因此优化卷积计算就显得尤为重要。

本章首先介绍了卷积在数学范畴中的定义，之后介绍了CNN中的卷积计算的定义。卷积层是卷积神经网络的核心部分，它通过对输入图像进行卷积操作来提取图像的特征，本章以Lenet-5为例对典型CNN网络的结构和参数进行了分析。在了解了卷积计算的基础上，本章介绍了卷积在内存中的数据格式以及张量中的卷积计算过程。

## 卷积神经网络的数学原理

在通常形式中，卷积是对两个实变函数的一种数学运算。在泛函分析中，卷积、旋积或褶积 (Convolution) 是通过两个函数f和g生成第三个函数的一种数学运算，其本质是一种特殊的积分变换，表征函数 f 与 g 经过翻转和平移的重叠部分函数值乘积对重叠长度的积分。

卷积神经网络（Convolution Neural Networks, CNN）的概念拓展自信号处理领域的卷积。信号处理的卷积定义为：
$$
(f*g)(t)\triangleq\int_{\mathbb{R}^{n}}f(\tau)g(t-\tau)d\tau 
$$

可以证明，关于几乎所有的实数 x，随着 x 的不同取值，积分定义了一个新函数 ℎ(x)，称为函数 f 与 g 的卷积，记为：
$$
f(t)=(f*g)(t)
$$

卷积计算在直觉上不易理解，其可视化后如下图所示。图中红色滑块在移动过程中与蓝色方块的积绘制成的三角图案即为卷积结果在各点上的取值：

![卷积动图](images/02.conv01.gif "卷积动图") 

对于信号处理的卷积定义为连续的表示，真正计算的过程中会把连续用离散形式进行计算：
$$
(f*g)(n)\triangleq\sum_{\mathbb{Z}^{n}}f(m)g(n-m) 
$$

将该离散卷积公式拓展到二维空间即可得到神经网络中的卷积，可简写为：
$$
S(i,j)=(I^{*}K)(i,j)=\sum_{m}\sum_{n}I(i-m,j-n)K(m,n)
$$

>其中：
 S为卷积的输出； I为卷积输入； K为卷积核的尺寸；

## CNN中的卷积计算

CNN主要由卷积层、池化层和全连接层三个部分构成。其中，卷积层是卷积神经网络的核心部分，它通过对输入图像进行卷积操作来提取图像的特征。卷积层的输入通常是一个多通道的（例如多通道图像），每个通道代表一个特征，卷积层的输出也是多通道的，其中每个通道表示一个不同的特征。池化层用于降低特征图的空间分辨率，并增强模型对输入图像的平移不变性和鲁棒性。全连接层通常用于将卷积层和池化层提取的特征进行分类或回归。它的输入是一维向量，其输出的维度与任务的分类数或回归值的维度相同。

如图1所示, 神经网络中的卷积计算过程可描述为：3 * 3 的卷积核在 8 * 8 的图像上进行滑动，每次滑动时，都把卷积核和对应位置的元素进行相乘再求和。青色区域为其感受野。

 ![卷积图](images/02.conv02.png "卷积示意图") 

### 名词解释：

>填充（padding）：防止图像边缘信息丢失，在输入图像的周围添加额外的行/列。其作用为使卷积后图像分辨率不变，方便计算特征图尺寸的变化，弥补边界
>步长（Stride）：步长是指卷积核在每一次卷积操作中滑动的距离。步长的大小可以影响输出数据的大小，也可以影响特征提取能力和计算复杂度。当步长增大时，输出数据的尺寸会减小，特征提取能力会变弱，但计算速度会加快。
>通道数（Channel）：通道数也称为深度或特征图数量，是指卷积神经网络中每一层输出的特征图数量。通道数的大小直接影响了卷积神经网络的特征提取能力和计算复杂度。通过增加通道数，可以增强卷积神经网络的特征提取能力，但也会增加计算复杂度。

>卷积核：是具有可学习参数的算子，用于对输出图像进行特征提取，输出通常为特征图。每一个卷积核代表一种模式/特征，有几个卷积核就有几张特征图,每一个卷积核都对应一个特征图。在机器学习中，卷积核的参数是由反向传播/梯度下降算法计算更新，非人工设置。其特点为：
   1. 卷积核每次仅连接K×K区域，K×K是卷积核的尺寸；
   2. 卷积核参数重复使用（参数共享），在图像上滑动。

>特征图：输出特征图的尺寸的计算公式为如下所示。
$$
F_{out}=\left[\frac{F_{in}-k+2p}s\right]+1
$$

>$$ k $$为卷积核大小
>$$ p $$为填充边的数目
>$$ s $$为步长

以下是针对各层的详细描述：

卷积层用来提取图像的底层特征。在常见的RGB图像三通道(Channel)卷积计算中，如图2所示：

![特征图计算公式](images/02.conv03.png "特征图计算公式") 

其过程可描述为：红色的卷积核层和红色通道的层进行卷积计算，绿色的卷积核层和绿色通道的层进行卷积计算，蓝色同上。之后三个通道的计算结果加起来作为最后的输出结果。假设在图2中输入图像尺寸为6×6 ，通道数为3，卷积核有1个，每个尺寸为3×3，通道数为3（与输入图像通道数一致）。卷积时，仍是以滑动窗口的形式，从左至右，从上至下，3个通道的对应位置相乘求和，输出结果为4×4×1的特征图。

该动画源于：[<RGB三通道卷积>](https://thomelane.github.io/convolutions/2DConvRGB.html/ "<RGB三通道卷积>")

### CNN过程案例：

LeNet-5的基本结构包括7层网络结构（不含输入层），其中包括2个卷积层、2个降采样层（池化层）、2个全连接层和输出层。

![LeNet手写数字识别](images/02.conv04.png "LeNet手写数字识别")

第一步把手写数字图片转成灰度图像。此时图像大小为：32×32；

C1（Convolutional layer C1）: 通过6个卷积核（每个卷积核的大小为 5×5 ，步长为1，填充为0）对灰度图进行卷积计算，生成6张特征图。特征图大小的计算过程为：
$$
F_{out}=\left[\frac{32-5}1\right]+1=28
$$

S2（Subsampling layer S2）：通过6个卷积核（每个卷积核的大小为 2×2 ，步长为2，填充为0）对上述特征图进行下采样，即池化操作，特征图大小的计算过程为：
$$
F_{out}=\left[\frac{28-2}2\right]+1=14
$$

C3（Convolutional layer C3）：再经16个卷积核（每个卷积核的大小为 5×5 ，步长为1，填充为0）对池化结果再次进行卷积，得到16张特征图，特征图大小的计算过程为：
$$
F_{out}=\left[\frac{14-5}1\right]+1=10
$$

S4（Subsampling layer S4）：再通过16个卷积核（每个卷积核的大小为 2×2 ，步长为2，填充为0）对前述特征图进行下采样，得到16张特征图，其大小的计算过程为：
$$
F_{out}=\left[\frac{10-2}2\right]+1=5
$$

C5（Fully connected layer C5）：通过120个5×5的卷积，将S4得到的16个 5×5 的特征图计算为120个长度为1×1的特征图，并通过一个带有120个神经元的全连接层进行连接。120是由 LeNet-5 的设计者根据实验得到的最佳值。
$$
F_{out}=\left[\frac{5-5}1\right]+1=1
$$

F6（Fully connected layer F6）：全连接层F6将120个神经元连接到84个神经元。

最终的输出层由10个神经元组成，每个神经元对应0-9中的一个数字，并输出最终的分类结果。在训练过程中，使用交叉熵损失函数计算输出层的误差，并通过反向传播算法更新卷积核和全连接层的权重参数。最终输出到softmax层，得到识别结果。

#### Lenet-5卷积层参数详解：

C1（Convolutional layer C1）: 

>输入图片大小：32×32
>卷积核大小：5×5
>卷积核通道数：1
>卷积核个数：6
>步长：1
>填充：0
>输出特征图大小：28×28
>产生特征图数量：6

卷积过程：

![卷积过程C1](images/02.conv05.png "卷积过程C1") 

共产生连接数：
$$
（5×5+1）×6×28×28=122304
$$

最终的特征图大小为28×28，共784个像素点。每个像素点由一次卷积计算产生，每次卷积计算产生156条连接，共计122304条连接。

可训练参数：
$$
(5×5+1) × 6=156
$$

该层共6个卷积核，每个卷积核有5×5=25个权值参数，+1代表的是每个卷积核进行卷积操作之后需要有一个额外的偏置参数$$ b $$。

C3（Convolutional layer C3）: 

>输入特征图大小：14×14
>输入特征图数量：6
>卷积核大小：5×5
>卷积核通道数：视每组特征图数量而定
>卷积核个数：16
>步长：1
>填充：0
>输出特征图大小：10×10
>产生特征图数量：16

注意：S2中的所有特征图并不直接与C3中的每一个卷积核全部相连！

 ![C3卷积图](images/02.conv06.png "C3卷积示意图") 

C3的前6个特征图（对应①）：由C3层中的前6个卷积核（编号0,1,2,3,4,5）分别与S2层中的连续的3张特征图（编号：012,123,234,345,450,501）相连接产生；

C3的6-11号特征图（对应②）：由C3层中的6,7,8,9,10,11号卷积核分别与S2层中连续的4张特征图（编号：0123,1234,2345,3450,4501,5012）相连接产生；

C3的12-14号特征图（对应③）：由C3层中的12,13,14号卷积核分别与S2层中不连续的4张特征图（编号：0134,1245,0235）相连接产生；

C3的最后一个特征图（对应④）：由C3层中的15号卷积核与S2层的所有特征图相连接产生。

>为什么S2中的所有特征图不直接与C3中的每一个卷积核全部相连呢？
>作者认为有2点原因：第一是因为不使用全连接能够保证有连接的数量保持在一个合理的界限范围内可以减少参数。第二是通过这种方式可以打破对称性，不同的卷积核通过输入不同的特征图以期望得到互补的特征。

共产生连接数：
$$
①: (5×5×3+1)×6=456
$$
$$
②,③: (5×5×4+1)×9=909
$$
$$
④: (5×5×6+1)×1=151
$$
$$
(456+909+151)×10×10=151600
$$

最终的特征图大小为10×10，共100个像素点。①中一个卷积核要对3张特征图进行卷积操作，一共有6个卷积核，共计产生456条连接；②和③中一个卷积核要对4张特征图进行卷积操作，一共有9个卷积核，共计产生909条连接；④中一个卷积核要对6张特征图进行卷积操作，一共有1个卷积核，共计产生151条连接。综上，C3层中共计产生151600条连接。

可训练参数：
$$
①: (5×5×3+1)×6=456
$$
$$
②,③: (5×5×4+1)×9=909
$$
$$
④: (5×5×6+1)×1=151
$$
$$
456+909+151=1516
$$
该层共16个卷积核，每个卷积核有5×5=25个权值参数，①组卷积核通道数为3，②和③组卷积核通道数为4，④组通道数为6。+1代表的是每个卷积核进行卷积操作之后需要有一个额外的偏置参数。

C5（Convolutional layer C5）: 

>输入特征图大小：5×5
>输入特征图数量：16
>卷积核通道数：1
>卷积核个数：120
>步长：1
>填充：0
>输出特征图大小：1×1
>产生特征图数量：6

C5中的120个卷积核与S4层的全部16个特征图全相连。

共产生连接数：
$$
（16×5×5+1）×120×1×1=48120 
$$
可训练参数：
$$
（16×5×5+1）×120×1×1=48120 
$$
最终的特征图大小为1×1，这里形成120个卷积结果。每个卷积核都与上一层的16个特征图图相连。所以共有 48120个参数，同样有48120个连接。

F6 是全连接层，共有 84 个神经元，与 C5 层进行全连接，即每个神经元都与 C5 层的 120 个1×1的特征图相连。计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过 sigmoid 函数输出。

F6 层有 84 个节点，对应于一个 7x12 的比特图，-1 表示白色，1 表示黑色，这样每个符号的比特图的黑白色就对应于一个编码。该层的训练参数和连接数为：
$$
(120 + 1)×84=10164
$$

根据对Lenet-5的分析，可以观察到，当卷积核在图像上滑动的时候，可训练参数量较少，但产生的连接计算量庞大，且部分参数在不同连接中进行了重复计算，造成了算力资源的浪费。

## 卷积的计算分析及实现

###  计算分析
>定义：
>H：图片高度；
>W：图片宽度；
>C：原始图片通道数；
>N：卷积核个数；
>K：卷积核高宽大小；
>P：图像边扩充大小；
>S：滑动步长。

在N个卷积核对一张特征图进行卷积过程中，以上述C1层为例，其经过的步骤为：

1. 一个卷积核覆盖的$$ K×K=5×5 $$的区域，对应位置的数据相乘后相加。

2. $$ N=6(Channel=1) $$个卷积核均对1所述区域做乘加操作，并在不同通道(Channel)对应位置相加（本例中每个卷积核的通道数C=1），得到的结果为$$ N $$个特征图上相应位置的数值。
$$
f_{out}(i,j)=\sum_{C=0}^{1}\sum_{m=0}^{5}\sum_{n=0}^{5}I(i+m,j+n)K(m,n,C)
$$

3. 卷积核在图像上从左到右，从上到下滑动，计算
$$
f_{out}^{l}(i,j)
$$
$$
i=0,1,……,W-1;J=0,1,……,H-1
$$
每滑动一次，计算得到第$$ l $$个特征图上的一个像素点。其滑动的总次数即为特征图的像素点数量。
. 
在卷积操作中卷积核是可学习的参数，经过上面的介绍，可知每层卷积的参数大小为C×K×K×N。卷积层的参数较少，这也是由卷积层的主要特性即局部连接和共享权重所决定。

局部连接：每个神经元仅与输入神经元的一块区域连接，这块局部区域称作感受野（receptive field）。在图像卷积操作中，即神经元在空间维度（spatial dimension，即在图像平面滑动区域）是局部连接，但在深度（通道方面的计算）上是全部连接。这种局部连接保证了学习后的卷积核能够对于局部的输入特征有最强的响应。

权重共享：计算同一个输出特征图时采用的卷积核是共享的，即一个卷积核在输入图像上滑动，产生一张特征图。该特征图的每个像素点都是由上述卷积核在输入图像上滑动卷积计算产生。这样可以很大程度上减少参数。在卷积层，通常采用多个卷积核提取不同特征，单个卷积核的不同通道之间权重不共享（比如RGB有三通道，每个通道的权重参数相互独立）。另外，偏置参数对同一个卷积核的各个参数共享。

### 基于pytorch的实现

代码来源：[<卷积 Convolution 原理及可视化>](https://zhuanlan.zhihu.com/p/76606892,"卷积 Convolution 原理及可视化")

首先定义padding模式：

深度学习框架中通常会实现三种不同的卷积模式，分别是 SAME、VALID、FULL。这三种模式的核心区别在于卷积核进行卷积操作的移动区域不同，进而导致输出的尺寸不同。

>FULL 模式下卷积核从与输入有一个点的相交的地方就开始卷积;
>VALID 模式与 FULL 模式相反，在整个卷积核与输入重叠的地方才开始卷积操作，因此不需要 padding，输出的尺寸也最小;
>SAME 模式是最常用的一种模式，SAME 的意思是卷积后输出的尺寸与输入尺寸保持一致（假定 stride 为 1）。通过将卷积核的中心与输入的第一个点进行对齐确定卷积核起始位置，然后补齐对应 padding 即可。SAME 模式下当卷积核边长为偶数时，可以通过在其中一边增加多一行（列）padding，即不对称的 padding 实现输出尺寸与输入尺寸保持一致

```
def get_padding(inputs, ks, mode="SAME"):
    """
    Return padding list in different modes.
    params: inputs (input array)
    params: ks (kernel size) [p, q]
    return: padding list [n,m,j,k]
    """
    pad = None
    if mode == "FULL":
        pad = [ks[0] - 1, ks[1] - 1, ks[0] - 1, ks[1] - 1]
    elif mode == "VALID":
        pad = [0, 0, 0, 0]
    elif mode == "SAME":
        pad = [(ks[0] - 1) // 2, (ks[1] - 1) // 2,
               (ks[0] - 1) // 2, (ks[1] - 1) // 2]
        if ks[0] % 2 == 0:
            pad[2] += 1
        if ks[1] % 2 == 0:
            pad[3] += 1
    else:
        print("Invalid mode")
    return pad
```

确定了输入尺寸、卷积核尺寸、padding 以及 stride，输出的尺寸就被确定下来。之后利用这些参数计算特征图的大小，并定义卷积。

```
def conv(inputs, kernel, stride, mode="SAME"):
    #确定卷积核的尺寸
    ks = kernel.shape[:2]
    # get_padding 确定padding的模式和数值
    pad = get_padding(inputs, ks, mode="SAME")
    padded_inputs = np.pad(inputs, pad_width=((pad[0], pad[2]), (pad[1], pad[3]), (0, 0)), mode="constant")
	#得到输入图像的尺寸和通道数
    height, width, channels = inputs.shape
    #确定输出特征图的尺寸
    out_width = int((width + pad[0] + pad[2] - ks[0]) / stride + 1)
    out_height = int((height + pad[1] + pad[3] - ks[1]) / stride + 1)
    outputs = np.empty(shape=(out_height, out_width))
    #进行卷积计算
    for r, y in enumerate(range(0, padded_inputs.shape[0]-ks[1]+1, stride)):
        for c, x in enumerate(range(0, padded_inputs.shape[1]-ks[0]+1, stride)):
            outputs[r][c] = np.sum(padded_inputs[y:y+ks[1], x:x+ks[0], :] * kernel)
    return outputs

```

## 卷积的优化手段

### Tensor运算

张量（英文Tensor）是标量、矢量、矩阵等概念的总称与拓展，是机器学习领域的基础数据结构。程序中的张量是一个多维数组的数据结构。
```
#define MAX_DIM 6
struct Tensor {
    // 维度信息
    size_t dim[MAX_DIM];
    uint8_t num_dim;

    // 数据信息
    float* data;
    size_t num_data;
};
```

0维张量，就是一个数。1维张量等同于一个向量。2维张量对应一个矩阵。3维张量则是一个立方体。

![张量](images/02.conv07.png "张量") 

张量集到张量集的映射称为张量计算。

用编程语言来说，输入是若干张量，输出也是若干个张量，并且无副作用（参考函数式编程）的函数称之为张量计算。

张量有 “维度” 和 “数据” 两个组成要素，张量计算，也就包含维度与数据这两个组成要素的处理。

比如矩阵乘法C = MatMul(A, B)，首先是根据输入的两个张量A, B确定C的维度，然后根据A和B的数据再去计算C的数据。具体一些可参考下面的代码：

```
Tensor* MatMul(Tensor* A, Tensor* B) {
    Tensor* C = new Tensor;
    // 计算维度
    C->num_dim = 2;
    C->dim[0] = A->dim[0];
    C->dim[1] = B->dim[1];

    // 分配内存
    C->data = malloc(C->dim[0]*C->dim[1]*sizeof(float));

    // 计算数据
    Matrix::multi(C, A, B);
    return C;
}
```

### Tensor内存布局

NHWC和NCHW是卷积神经网络(cnn)中广泛使用的数据格式。它们决定了多维数据，如图像、点云或特征图如何存储在内存中。

>NHWC(样本数，高度，宽度，通道):这种格式存储数据通道在最后，是TensorFlow的默认格式>NCHW(样本数，通道，高度，宽度):通道位于高度和宽度尺寸之前，经常与PyTorch一起使用。

### Tensor卷积运算

当中张量的内存布局为 NHWC 时，卷积计算相应的伪代码如下。其中外三层循环遍历输出C的每个数据点，对于每个输出数据都需要经由内三层循环累加求和得到（点积）。

```
for (int oh = 0; oh < OH; oh++) {
  for (int ow = 0; ow < OW; ow++) {
    for (int oc = 0; oc < OC; oc++) {
      C[oh][ow][oc] = 0;
      for (int kh = 0; kh < KH, kh++){
        for (int kw = 0; kw < KW, kw++){
          for (int ic = 0; ic < IC, ic++){
            C[oh][ow][oc] += A[oh+kh][ow+kw][ic] * B[kh][kw][ic];
          }
        }
      }
    }
  }
}
```

和矩阵乘的优化方法类似，我们也可针对该计算进行向量化、并行化、循环展开的基本的优化操作。

## 总结

本篇介绍了卷积计算的数学原理及其在CNN的应用过程。以Lenet-5为例，分析了Lenet-5中每层的参数计算情况和连接情况。可以观察到，当卷积核在图像上滑动的时候，可训练参数量较少，但产生的连接计算量庞大，且部分参数在不同连接中进行了重复计算，造成了算力资源的浪费。为解决此问题，诸多研究者了各种各样的卷积优化算法，该部分将于后续文章进行详细介绍。

## 参考文献

- [1] [ 卷积神经网络优化算法 ]( https://zhenhuaw.me/blog/2019/convolution-neural-networks-optimization.html)
- [2] [ 卷积及其代码实现 ](https://blog.csdn.net/Biyoner/article/details/88916247)
- [3] [ 卷积算子优化 ](https://zhuanlan.zhihu.com/p/661166785)
- [4] [图像数据通道格式：NCHW和NHWC的区别](https://www.jianshu.com/p/61de601bc90f)
- [5] [Lecun Y , Bottou L .Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86(11):2278-2324.DOI:10.1109/5.726791.](https://ieeexplore.ieee.org/document/726791)
- [6] [Fukushima, Kunihiko and Sei Miyake. “Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition.” (1982).](https://www.semanticscholar.org/paper/Neocognitron%3A-A-Self-Organizing-Neural-Network-for-Fukushima-Miyake/9b2541b8d8ca872149b4dabd2ccdc0cacc46ebf5)
- [7] [ Bouvrie J .Notes on Convolutional Neural Networks[J].neural nets, 2006.](https://www.semanticscholar.org/paper/Notes-on-Convolutional-Neural-Networks-Bouvrie/2a4393aa1bc3cb7fe2deecc88720bfb84dabb263)
- [8] [Krizhevsky A , Sutskever I , Hinton G .ImageNet Classification with Deep Convolutional Neural Networks[J].Advances in neural information processing systems, 2012, 25(2).DOI:10.1145/3065386.](https://dl.acm.org/doi/10.1145/3065386)
- [9] [卷积神经网络经典回顾之LeNet-5](https://zhuanlan.zhihu.com/p/616996325)
- [10] [网络解析（一）：LeNet-5详解](https://cuijiahua.com/blog/2018/01/dl_3.html)
- [11] [这可能是神经网络 LeNet-5 最详细的解释了！](https://cloud.tencent.com/developer/article/1931721)
- [12] [PyTorch实现经典网络之LeNet5](https://www.jianshu.com/p/56833f9d6d66)
- [13] [卷积 Convolution 原理及可视化](https://zhuanlan.zhihu.com/p/76606892)

## 本节视频

<html>
<iframe src="https://www.bilibili.com/video/BV1No4y1e7KX/?spm_id_from=333.337.search-card.all.click&vd_source=096daa038c279ccda6e4f8c5eea82de7" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</html>

