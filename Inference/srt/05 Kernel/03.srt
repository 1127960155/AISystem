1
00:00:00,000 --> 00:00:06,800
Hello 大家好,宗明又回来了

2
00:00:06,800 --> 00:00:09,640
今天我们还是在推理引擎的最后一个内容

3
00:00:09,640 --> 00:00:10,800
Kernels 优化

4
00:00:10,800 --> 00:00:13,200
今天主要是给大家去分享一下

5
00:00:13,200 --> 00:00:16,800
Img2Col 这种卷积的优化方式

6
00:00:16,800 --> 00:00:20,000
回到我们整个 Kernel 优化的课程系列

7
00:00:20,000 --> 00:00:23,200
我们会讲算法的优化内存的布局

8
00:00:23,200 --> 00:00:25,600
还有编译和调度优化

9
00:00:25,600 --> 00:00:28,000
在整体里面算法的优化

10
00:00:28,000 --> 00:00:30,600
我们将会深入的去讲解一下

11
00:00:30,600 --> 00:00:33,800
而算法的优化更多的是集中在 Kernel 层

12
00:00:33,800 --> 00:00:36,000
这里面很多不同的算法

13
00:00:36,000 --> 00:00:38,400
或者我们理解到的具体执行的算法

14
00:00:38,400 --> 00:00:40,800
都承载在我们的 Kernel 层

15
00:00:40,800 --> 00:00:42,400
在这一节课程里面

16
00:00:42,400 --> 00:00:44,800
我们将会聚焦两个内容

17
00:00:44,800 --> 00:00:47,000
第一个内容就是 Img2Col

18
00:00:47,000 --> 00:00:50,800
第二个就是 Spatial Pack Optimizer

19
00:00:50,800 --> 00:00:53,000
空间组合优化两个方式

20
00:00:53,000 --> 00:00:55,400
现在我们来到第一个内容

21
00:00:55,600 --> 00:00:58,800
就是 Img2Col 整体的算法原理

22
00:01:00,200 --> 00:01:03,200
在 Img2Col 的算法原理

23
00:01:03,200 --> 00:01:05,200
其实 IMG2Clone

24
00:01:05,200 --> 00:01:07,400
我们简单叫做 Image to Column

25
00:01:07,400 --> 00:01:10,200
然后其实这种方式是

26
00:01:10,200 --> 00:01:13,400
Caffe 早期的 AI 框架里面去采用的

27
00:01:13,400 --> 00:01:15,200
为什么说是早期

28
00:01:15,200 --> 00:01:18,600
是因为一开始卷积的计算方式

29
00:01:18,600 --> 00:01:19,600
确实太复杂了

30
00:01:19,600 --> 00:01:21,000
而且不容易优化

31
00:01:21,000 --> 00:01:24,200
于是 Caffe 一开始就采用了 Img2Col

32
00:01:24,200 --> 00:01:26,600
这种方式把我们高维的张量

33
00:01:26,600 --> 00:01:29,400
转换成为低维的矩阵的相乘

34
00:01:29,400 --> 00:01:32,400
我们简单的看看下面的示例图

35
00:01:32,400 --> 00:01:35,000
我们知道在整个神经网络里面

36
00:01:35,000 --> 00:01:37,000
基本上很多计算

37
00:01:37,000 --> 00:01:40,200
都是用高维的张量去进行计算的

38
00:01:40,200 --> 00:01:41,800
而高维的张量的表示

39
00:01:41,800 --> 00:01:45,200
一般使用 NHWC 这种表示方式

40
00:01:45,200 --> 00:01:47,200
然后我们会把高维的张量

41
00:01:47,200 --> 00:01:49,400
这种 NHWC 转换成为

42
00:01:49,400 --> 00:01:51,600
通过 Image to Column 这种方式

43
00:01:51,600 --> 00:01:54,600
转换成为 GEMM 或者 BLAS MTK 这种库

44
00:01:54,600 --> 00:01:57,200
可以进行直接矩阵层的操作

45
00:01:57,200 --> 00:01:59,800
接着我们进行一个逆变的操作

46
00:01:59,800 --> 00:02:02,000
Column to Image 这种方式

47
00:02:02,000 --> 00:02:05,200
把我们的张量恢复成为 NHWC 的格式

48
00:02:05,200 --> 00:02:07,400
给下一个算子去进行计算

49
00:02:07,400 --> 00:02:10,000
而这里面我们就把卷积的方式

50
00:02:10,000 --> 00:02:12,000
就变成 GEMM 的方式了

51
00:02:12,000 --> 00:02:15,800
下面我们看一个比较具体的例子

52
00:02:15,800 --> 00:02:17,200
在具体例子进入之前

53
00:02:17,200 --> 00:02:19,800
我们看看 Img2col 整体的算法过程

54
00:02:19,800 --> 00:02:22,000
虽然我们只看算法过程没什么意思

55
00:02:22,000 --> 00:02:25,200
但是有助于我们后面的了解

56
00:02:25,200 --> 00:02:27,400
首先这里面分开两个步骤

57
00:02:27,400 --> 00:02:30,400
第一个步骤就是 Image to Column

58
00:02:30,400 --> 00:02:33,000
就把我们的输入的数据

59
00:02:33,000 --> 00:02:34,800
还有我们的权重的数据

60
00:02:34,800 --> 00:02:36,000
转换排布

61
00:02:36,000 --> 00:02:40,000
转换成为 Matmul 可以进行计算的排布

62
00:02:40,000 --> 00:02:41,800
所以这里面分开两个步骤

63
00:02:41,800 --> 00:02:44,400
第一个步骤就是我们的第一行

64
00:02:44,400 --> 00:02:46,200
第一句话 Image to Column

65
00:02:46,200 --> 00:02:48,400
第二个步骤就是 Matmul

66
00:02:48,400 --> 00:02:50,600
第二行第二句话的意思

67
00:02:50,600 --> 00:02:52,400
下面我们具体来看看

68
00:02:52,400 --> 00:02:55,600
一般的图像是怎么操作的

69
00:02:55,600 --> 00:02:57,800
可以看到图像的数的维度

70
00:02:57,800 --> 00:02:59,000
一般都是三维

71
00:02:59,000 --> 00:03:01,000
H W 3

72
00:03:01,000 --> 00:03:03,800
H 就是长、宽乘以三个信道

73
00:03:03,800 --> 00:03:05,400
是我们一般的图片

74
00:03:05,400 --> 00:03:08,000
而卷积核可能会有四维

75
00:03:08,000 --> 00:03:10,000
N、C、KH、KW

76
00:03:10,000 --> 00:03:12,600
KH、KW代表我们的卷积核

77
00:03:12,600 --> 00:03:14,200
Kernel 的长和宽

78
00:03:14,200 --> 00:03:17,800
而 C 是代表单一个卷积核的Channel数

79
00:03:17,800 --> 00:03:20,800
N 代表是有多少这样的一个小组

80
00:03:20,800 --> 00:03:22,800
最后的输出的维度就是

81
00:03:22,800 --> 00:03:26,400
N H W 我们最右边的图所示

82
00:03:26,400 --> 00:03:30,200
当然这是最简单的图片的卷积的操作

83
00:03:30,200 --> 00:03:31,800
现在我们来看一下

84
00:03:31,800 --> 00:03:33,200
在我们的神经网络里面

85
00:03:33,200 --> 00:03:36,600
数据的排布一般都是高维的、四维的

86
00:03:36,600 --> 00:03:39,800
甚至到了点云它可能是五维的

87
00:03:39,800 --> 00:03:41,600
我们默认的以四维为例子

88
00:03:41,600 --> 00:03:45,000
N H W C 输入的就不是图片了

89
00:03:45,000 --> 00:03:46,200
而是 Feature Map

90
00:03:46,200 --> 00:03:48,200
或者我们的一个 Tensor

91
00:03:48,200 --> 00:03:50,000
Tensor 的维度就是 N

92
00:03:50,000 --> 00:03:52,200
IH、IW、IC

93
00:03:52,200 --> 00:03:55,200
I 就是 Input Height、Input Width

94
00:03:55,200 --> 00:03:57,600
输入的 Feature Map 长和宽

95
00:03:57,600 --> 00:04:00,800
而 I C 就是 Input Channels 的大小

96
00:04:00,800 --> 00:04:02,800
一共有 N 组这样的维度

97
00:04:02,800 --> 00:04:04,800
而卷积核的维度

98
00:04:04,800 --> 00:04:07,200
可能我们在前面加了个 K W

99
00:04:07,200 --> 00:04:09,600
K H Kernels Width Kernels Height

100
00:04:09,600 --> 00:04:13,800
然后 I C 另外有一个就是 Featured N

101
00:04:13,800 --> 00:04:15,600
这个是相同的

102
00:04:15,600 --> 00:04:18,000
而输出的维度其实也有所不同

103
00:04:18,000 --> 00:04:21,000
大家要注意的就是前面的下标

104
00:04:21,000 --> 00:04:23,800
哪个是 I 哪个是 O 哪个是 N

105
00:04:23,800 --> 00:04:26,400
输出就是 O H O W 乘以 O C

106
00:04:26,400 --> 00:04:29,800
当然了同样有 N 组这样的一些张量

107
00:04:29,800 --> 00:04:30,600
或者 Feature Map

108
00:04:30,600 --> 00:04:33,400
下面我们看一下更加具体的例子

109
00:04:33,400 --> 00:04:34,800
可以看到 Img2col

110
00:04:34,800 --> 00:04:39,400
最重要的是改变了数据的排布的方式

111
00:04:39,400 --> 00:04:41,200
既然改变了数据的排布方式

112
00:04:41,200 --> 00:04:44,400
就可以方便我们把刚才权重的数据

113
00:04:44,400 --> 00:04:46,200
变成一个二维的矩阵

114
00:04:46,200 --> 00:04:50,000
把我们 Feature Map 变成了一个二维的矩阵

115
00:04:50,000 --> 00:04:52,800
通过行跟列相乘

116
00:04:52,800 --> 00:04:56,000
得到我们最终的输出的结果

117
00:04:56,000 --> 00:04:58,800
就完成了整个卷积的计算

118
00:04:58,800 --> 00:04:59,600
很有意思

119
00:04:59,600 --> 00:05:02,400
更多的是数学上面的变换

120
00:05:02,400 --> 00:05:06,400
那下面我们看看怎么进行算法的重排

121
00:05:06,400 --> 00:05:09,800
或者怎么对我们的内存的数据进行重排

122
00:05:09,800 --> 00:05:12,600
可以看到灰色的这个小框框

123
00:05:12,800 --> 00:05:17,200
是我们卷积核或者滑动窗口的大小

124
00:05:17,200 --> 00:05:20,600
那滑动窗口是 1 2 3 4 5 6 这么排的数据

125
00:05:20,600 --> 00:05:23,400
但实际上我们的数据在滑动窗口里面

126
00:05:23,400 --> 00:05:25,600
是 1 2 3 7 8 9

127
00:05:25,600 --> 00:05:28,000
那可能下面还有更大的数了

128
00:05:28,000 --> 00:05:31,000
那这个时候我们就把一个滑动窗口的数据

129
00:05:31,000 --> 00:05:33,000
对它进行展开

130
00:05:33,000 --> 00:05:35,000
同样对第二个滑动窗口

131
00:05:35,000 --> 00:05:37,000
是第二个Channel的滑动窗口

132
00:05:37,000 --> 00:05:39,200
对它进行展开

133
00:05:39,200 --> 00:05:41,600
不断的展开成为一行

134
00:05:41,600 --> 00:05:46,400
那这一行对应的就是 kw 乘以 kh 乘以 ic

135
00:05:46,400 --> 00:05:49,600
是完完全全跟我们的卷积核展开的方式

136
00:05:49,600 --> 00:05:52,200
是对应起来就方便我们相乘

137
00:05:52,200 --> 00:05:55,000
而我们一共有多少行呢

138
00:05:55,000 --> 00:05:57,600
多少就是 oh 乘以 ow 行了

139
00:05:57,600 --> 00:06:00,400
这个就是对应到我们的输出

140
00:06:00,400 --> 00:06:04,600
下面我们看一下怎么对权重的数据进行重排

141
00:06:04,600 --> 00:06:06,200
权重的数据进行重排

142
00:06:06,200 --> 00:06:07,600
其实很好理解

143
00:06:07,600 --> 00:06:09,600
而且很有意思一点就是

144
00:06:09,600 --> 00:06:13,800
我们权重的数据重排不是在 kernel 执行的时候进行重排的

145
00:06:13,800 --> 00:06:16,200
在我们的推定引擎架构里面

146
00:06:16,200 --> 00:06:20,600
一般对我们的 Img2col这种转换的方式的数据重排

147
00:06:20,600 --> 00:06:25,400
会在我们的模型转换或者图优化的过程当中

148
00:06:25,400 --> 00:06:29,000
特别是布局优化或者内存优化的时候

149
00:06:29,000 --> 00:06:31,200
进行转换重排的

150
00:06:31,200 --> 00:06:34,200
但有可能我们在 Runtime 的预编译阶段

151
00:06:34,200 --> 00:06:35,800
或者 Runtime 的预执行阶段

152
00:06:35,800 --> 00:06:38,000
进行重排也是有可能的

153
00:06:38,000 --> 00:06:41,200
具体就取决于我们的推定引擎的架构是怎么设计的

154
00:06:41,200 --> 00:06:43,600
这个模块应该装载在哪里

155
00:06:43,600 --> 00:06:48,800
现在又回到我们刚才的 img2col 的这种算法过程里面

156
00:06:48,800 --> 00:06:51,200
对权重的数据进行重排

157
00:06:51,200 --> 00:06:54,200
权重数据进行重排是比较简单的

158
00:06:54,200 --> 00:06:57,200
我们可以看到左边的紫色的这小框框

159
00:06:57,200 --> 00:06:59,400
就是我们的一个卷积核

160
00:06:59,400 --> 00:07:02,200
那卷积核我们 1 2 3 4 5 6 7 8 9

161
00:07:02,200 --> 00:07:05,200
直接把它展开成为一行

162
00:07:05,200 --> 00:07:06,800
可以看到直接展开成一行

163
00:07:07,000 --> 00:07:09,400
然后对第二个 channel 进行展开

164
00:07:09,400 --> 00:07:10,800
第三个 channel 进行展开

165
00:07:10,800 --> 00:07:12,800
每个 filter 对它进行展开

166
00:07:12,800 --> 00:07:17,000
所以一共有 n 行 n 乘以 kw 乘以 kh 乘以 ic

167
00:07:17,000 --> 00:07:19,400
就组成了一个大的矩阵

168
00:07:19,400 --> 00:07:22,800
把我们高维的四维的张量的数据

169
00:07:22,800 --> 00:07:24,600
变成一个二维的矩阵

170
00:07:24,600 --> 00:07:26,200
既然变成一个二维矩阵

171
00:07:26,200 --> 00:07:29,600
就非常好的利用我们 GEMM 的特性

172
00:07:29,600 --> 00:07:32,200
对它进行一个计算

173
00:07:32,200 --> 00:07:35,200
现在我们整体的看看一个过程

174
00:07:35,200 --> 00:07:36,600
这里面分开两步

175
00:07:36,600 --> 00:07:38,600
上面的是原来高维的数据

176
00:07:38,600 --> 00:07:39,600
高维的张量

177
00:07:39,600 --> 00:07:41,400
进行一个卷积的过程

178
00:07:41,400 --> 00:07:42,800
这个就是卷积核

179
00:07:42,800 --> 00:07:44,200
这个就是我们的 feature map

180
00:07:44,200 --> 00:07:47,000
最终得到我们的输出的结果

181
00:07:47,000 --> 00:07:51,000
然后我们把它进行 image to column 的方式

182
00:07:51,000 --> 00:07:52,000
把我们的权重

183
00:07:52,000 --> 00:07:54,400
把我们的卷积核进行转换

184
00:07:54,400 --> 00:07:57,600
成为一个单独的二维的矩阵

185
00:07:57,600 --> 00:08:00,400
接着我们把 feature map 同样进行展开

186
00:08:00,400 --> 00:08:02,400
变成一个单独的矩阵

187
00:08:02,400 --> 00:08:05,600
接着两个矩阵相乘得到我们的输出的矩阵

188
00:08:05,600 --> 00:08:06,600
输出的矩阵

189
00:08:06,600 --> 00:08:08,200
最后的箭头是向上的

190
00:08:08,200 --> 00:08:09,400
大家值得注意的就是

191
00:08:09,400 --> 00:08:11,200
我们需要通过 column to image

192
00:08:11,200 --> 00:08:13,400
把它逆变回来

193
00:08:13,400 --> 00:08:15,400
接下来我们整体的看看

194
00:08:15,400 --> 00:08:17,400
img2col 的算法流程

195
00:08:17,400 --> 00:08:19,000
算法流程分为四步

196
00:08:19,000 --> 00:08:22,400
第一步就是对我们的输入的数据

197
00:08:22,400 --> 00:08:24,400
进行展开

198
00:08:24,400 --> 00:08:28,200
展开成为一个独特的独立的权重

199
00:08:28,200 --> 00:08:30,600
第二个就是对我们的权重的数据

200
00:08:30,600 --> 00:08:32,400
进行展开

201
00:08:32,400 --> 00:08:34,400
同样就是就展开重排

202
00:08:34,400 --> 00:08:37,800
接着对上面一二步得到的两个矩阵

203
00:08:37,800 --> 00:08:39,200
进行相乘

204
00:08:39,200 --> 00:08:41,200
最终得到我们的输出的矩阵

205
00:08:41,200 --> 00:08:42,400
输出的矩阵

206
00:08:42,400 --> 00:08:45,200
同样需要进行一个逆变的过程

207
00:08:45,200 --> 00:08:47,800
所以整体来说分开四个步骤

208
00:08:47,800 --> 00:08:50,800
四个步骤的执行方式和执行的模块

209
00:08:50,800 --> 00:08:52,000
都是不一样的

210
00:08:52,000 --> 00:08:55,200
可能 1 3 4

211
00:08:55,200 --> 00:08:58,000
是进行到我们的具体的 kernel 层里面

212
00:08:58,000 --> 00:08:59,200
但是第二个

213
00:08:59,200 --> 00:09:01,000
可能会在我们的预编译阶段

214
00:09:01,000 --> 00:09:02,200
或者在我们的

215
00:09:02,400 --> 00:09:04,800
离线转换优化模块里面去实现

216
00:09:04,800 --> 00:09:06,600
那下面我们来总结一下

217
00:09:06,600 --> 00:09:09,400
Img2col计算的方式

218
00:09:09,400 --> 00:09:10,800
可以看到 Img2col

219
00:09:10,800 --> 00:09:14,000
就是把我们传统的卷积大量的计算

220
00:09:14,000 --> 00:09:17,000
使用 GEMM 这种经过优化的库

221
00:09:17,000 --> 00:09:19,400
来进行一个加速的

222
00:09:19,400 --> 00:09:21,800
但是有个问题就是使用 Img2col

223
00:09:21,800 --> 00:09:23,600
我们可以看到我们需要对数据

224
00:09:23,600 --> 00:09:25,000
进行重排

225
00:09:25,000 --> 00:09:26,800
把三维或者高维的数据

226
00:09:26,800 --> 00:09:29,200
展开成为二维的矩阵

227
00:09:29,200 --> 00:09:30,400
那这个时候

228
00:09:30,400 --> 00:09:32,800
我们就需要对数据的数据

229
00:09:32,800 --> 00:09:34,600
拷贝多份

230
00:09:34,600 --> 00:09:37,800
而且就对我们的内存有开销了

231
00:09:37,800 --> 00:09:40,200
第二个就是转换之后

232
00:09:40,200 --> 00:09:42,000
我们就有很多不同

233
00:09:42,000 --> 00:09:45,000
已经实现好的高速的优化库

234
00:09:45,000 --> 00:09:49,400
BLAS、MKL、NumPy 这种去实现

235
00:09:49,400 --> 00:09:50,600
然后值得一提的

236
00:09:50,600 --> 00:09:52,600
就是我们刚才也给大家介绍过

237
00:09:52,600 --> 00:09:55,200
就是我们首先会在权重

238
00:09:55,200 --> 00:09:58,000
会预先的去把它转换成为Img2col

239
00:09:58,000 --> 00:09:59,800
而不是在真正全众来的时候

240
00:09:59,800 --> 00:10:00,800
或者计算的时候

241
00:10:00,800 --> 00:10:02,000
我才做转换

242
00:10:02,000 --> 00:10:03,600
我们在训练的阶段

243
00:10:03,600 --> 00:10:07,000
其实已经获得到我们的权重的数据了

244
00:10:07,000 --> 00:10:08,200
而 Input 的数据

245
00:10:08,200 --> 00:10:10,800
确实只有在数据真正来的时候

246
00:10:10,800 --> 00:10:12,000
数据流来的时候

247
00:10:12,000 --> 00:10:12,800
我们才能感知

248
00:10:12,800 --> 00:10:17,400
那这时候确实没办法进行提前的重排

249
00:10:17,400 --> 00:10:20,200
下面我们来到第二个内容

250
00:10:20,200 --> 00:10:22,800
也是这一节小课里面的

251
00:10:22,800 --> 00:10:23,600
最后一个内容

252
00:10:23,600 --> 00:10:26,000
空间的组合优化

253
00:10:26,000 --> 00:10:28,200
像 Img2col这种方式

254
00:10:28,200 --> 00:10:29,200
到空间组合优化

255
00:10:29,200 --> 00:10:30,800
Img2col可以理解为一个

256
00:10:30,800 --> 00:10:34,000
比较朴素的卷积的优化的手段

257
00:10:34,000 --> 00:10:35,200
把卷积的方式

258
00:10:35,200 --> 00:10:37,800
变换成为一个矩阵层的方式

259
00:10:37,800 --> 00:10:39,200
而空间组合优化

260
00:10:39,200 --> 00:10:41,400
更多的是基于一个分字的思想

261
00:10:41,400 --> 00:10:42,200
既然分治

262
00:10:42,200 --> 00:10:45,200
我们就可以知道里面很重要的一个词

263
00:10:45,200 --> 00:10:46,800
就是空间

264
00:10:46,800 --> 00:10:47,600
空间这两个字

265
00:10:47,600 --> 00:10:49,600
就帮我们的卷积的计算

266
00:10:49,600 --> 00:10:50,800
利用空间的特征

267
00:10:50,800 --> 00:10:52,800
划分成为若干份了

268
00:10:52,800 --> 00:10:54,400
然后进行分别处理

269
00:10:54,400 --> 00:10:55,400
那我们可以看到

270
00:10:55,400 --> 00:10:58,200
下面就是空间组合优化的一种方式

271
00:10:58,200 --> 00:10:58,600
当然了

272
00:10:58,600 --> 00:11:01,400
这里面不是用 GEMM 来去示例

273
00:11:01,400 --> 00:11:03,600
也不是用 Img2col 来示例

274
00:11:03,600 --> 00:11:06,200
而是直接用传统的卷积的方式

275
00:11:06,200 --> 00:11:07,600
进行示例

276
00:11:07,600 --> 00:11:09,600
这里面我们对输入的数据

277
00:11:09,600 --> 00:11:12,400
划分成为四个模块

278
00:11:12,400 --> 00:11:13,200
四个部分

279
00:11:13,200 --> 00:11:16,000
也就是 IH 还有 IW

280
00:11:16,000 --> 00:11:18,200
进行两两切分

281
00:11:18,200 --> 00:11:20,000
划分成为四块

282
00:11:20,000 --> 00:11:20,800
这第一块

283
00:11:20,800 --> 00:11:21,800
第二块

284
00:11:21,800 --> 00:11:23,000
第三块

285
00:11:23,000 --> 00:11:24,000
第四块

286
00:11:24,000 --> 00:11:25,400
分别对我们的权重

287
00:11:25,400 --> 00:11:26,400
进行卷积

288
00:11:26,400 --> 00:11:27,400
得到我们的输出

289
00:11:27,400 --> 00:11:29,200
最后把输出拼接到一起

290
00:11:29,200 --> 00:11:30,200
这种就是最简单

291
00:11:30,200 --> 00:11:32,600
最朴素的空间优化的方法了

292
00:11:32,600 --> 00:11:34,000
现在我们看一下

293
00:11:34,000 --> 00:11:37,000
整个空间优化的原理

294
00:11:37,000 --> 00:11:38,400
原理还是非常简单的

295
00:11:38,400 --> 00:11:39,800
主要是下面这几个图

296
00:11:39,800 --> 00:11:42,400
划这几个图确实花了不少时间

297
00:11:42,400 --> 00:11:43,600
像空间组合优化

298
00:11:43,600 --> 00:11:45,600
其实是非常好理解的原理

299
00:11:45,600 --> 00:11:47,200
首先我们会把输入的

300
00:11:47,200 --> 00:11:49,000
一个很大的 Feature Map

301
00:11:49,000 --> 00:11:51,200
把它分成 Unpack 层

302
00:11:51,200 --> 00:11:53,400
多个不同的 Feature Map

303
00:11:53,400 --> 00:11:54,800
根据不同的小的 Feature Map

304
00:11:54,800 --> 00:11:56,200
跟我们的权重

305
00:11:56,200 --> 00:11:58,600
跟我们的数据进行卷积

306
00:11:58,600 --> 00:12:00,800
得到多个数据的输出

307
00:12:00,800 --> 00:12:02,000
但是有一点值得注意的

308
00:12:02,000 --> 00:12:04,400
就是这里面的小框框的窗口

309
00:12:04,400 --> 00:12:06,000
或者跨分的一个小模块

310
00:12:06,000 --> 00:12:07,800
必须要跟我们的卷积核的

311
00:12:07,800 --> 00:12:10,400
Windows 的大小相匹配

312
00:12:10,400 --> 00:12:12,400
而且跟我们的 Stride 相匹配

313
00:12:12,400 --> 00:12:14,200
这个时候就可以很好的

314
00:12:14,200 --> 00:12:16,400
利用我们的计算机的存储结构

315
00:12:16,400 --> 00:12:18,600
获得我们的性能的提升

316
00:12:18,600 --> 00:12:21,200
为什么说是计算机的存储结构了

317
00:12:21,200 --> 00:12:22,800
因为我们知道计算机里面

318
00:12:22,800 --> 00:12:24,600
或者我们的 CPU GPU 里面

319
00:12:24,800 --> 00:12:27,000
还有 L0 L1 L2

320
00:12:27,000 --> 00:12:29,000
不同的 Cache

321
00:12:29,000 --> 00:12:31,200
有不同的性能的提升

322
00:12:31,200 --> 00:12:33,000
下面我们看一下

323
00:12:33,000 --> 00:12:35,800
空间左右化一些注意的点

324
00:12:35,800 --> 00:12:38,000
其实我们在上文里面

325
00:12:38,000 --> 00:12:39,400
讲了不管是 Img2col

326
00:12:39,400 --> 00:12:41,400
还是空间左右化

327
00:12:41,400 --> 00:12:44,800
我们都忽略了 Padding 的操作

328
00:12:44,800 --> 00:12:46,200
有了 Padding 这个操作

329
00:12:46,200 --> 00:12:47,800
其实还是需要注意

330
00:12:47,800 --> 00:12:49,400
Padding 为 Value 的时候

331
00:12:49,400 --> 00:12:51,200
可以基本上忽略了

332
00:12:51,200 --> 00:12:53,600
但是 Padding 等于 Same 的时候

333
00:12:53,600 --> 00:12:55,200
需要利用边界补0

334
00:12:55,200 --> 00:12:56,600
不在边界补0的时候

335
00:12:56,600 --> 00:12:59,400
需要利用 0g 的张量的值

336
00:12:59,400 --> 00:13:00,600
所以一般来说

337
00:13:00,600 --> 00:13:02,400
我们都会多出了

338
00:13:02,400 --> 00:13:05,800
那么一小个模块进行重叠计算的

339
00:13:05,800 --> 00:13:07,600
这也是在我们真正计算的时候

340
00:13:07,600 --> 00:13:10,200
需要注意的一个内容

341
00:13:10,200 --> 00:13:11,400
那我们现在来看看

342
00:13:11,400 --> 00:13:15,600
空间组合优化的 Coins 它的问题

343
00:13:15,600 --> 00:13:18,600
在真正的空间组合优化这种方式

344
00:13:18,600 --> 00:13:20,800
确实用的非常多

345
00:13:20,800 --> 00:13:22,800
它是我们 Kernel 实现的一个

346
00:13:22,800 --> 00:13:24,200
很重要的 Trick

347
00:13:24,200 --> 00:13:26,400
假设我们现在把一些张量

348
00:13:26,400 --> 00:13:29,000
分成边长为 4 或者 8

349
00:13:29,000 --> 00:13:30,400
为什么会为 4 和 8

350
00:13:30,400 --> 00:13:32,600
是因为方便我们的 AI 编译器

351
00:13:32,600 --> 00:13:34,200
或者我们的传统编译器

352
00:13:34,200 --> 00:13:37,200
进行向量化的操作

353
00:13:37,200 --> 00:13:39,000
向量化的转变

354
00:13:39,000 --> 00:13:41,000
不过值得注意的就是

355
00:13:41,000 --> 00:13:45,600
这个模块并不是分的越小越好的

356
00:13:45,600 --> 00:13:46,600
当然了越小

357
00:13:46,600 --> 00:13:47,800
它有个好处就是

358
00:13:47,800 --> 00:13:51,200
充分的利用了计算机体系里面的

359
00:13:51,200 --> 00:13:52,600
多级的 Cache

360
00:13:52,600 --> 00:13:54,400
但是模块越小

361
00:13:54,400 --> 00:13:56,200
局部性也就越高

362
00:13:56,200 --> 00:13:57,200
负面的作用就是

363
00:13:57,200 --> 00:14:00,800
消耗更多的额外的内存

364
00:14:00,800 --> 00:14:03,000
这也是它带来的好处和问题

365
00:14:03,000 --> 00:14:05,000
所以我们在 Kernel 实现的时候

366
00:14:05,000 --> 00:14:06,600
需要把握一个度

367
00:14:06,600 --> 00:14:08,800
寻找一个合适的划分的方式

368
00:14:08,800 --> 00:14:11,000
或者合适的划分的尺寸

369
00:14:11,000 --> 00:14:12,200
是一个不容易的事情

370
00:14:12,200 --> 00:14:14,400
我们需要经过大量的时间的优化

371
00:14:14,400 --> 00:14:15,600
当然了这里我们也可以通过

372
00:14:15,600 --> 00:14:18,400
AI 编译器去自动的寻优

373
00:14:18,600 --> 00:14:21,200
但是在推理场景

374
00:14:21,200 --> 00:14:23,000
一般寻优完一次之后

375
00:14:23,000 --> 00:14:25,200
我们基本上就很少去改动了

376
00:14:25,200 --> 00:14:29,000
那最后我们来到回头

377
00:14:29,000 --> 00:14:31,200
看看整个推理引擎架构里面

378
00:14:31,200 --> 00:14:34,000
我们主要讲的是在 Kernel 优化

379
00:14:34,000 --> 00:14:35,000
而 Kernel 优化

380
00:14:35,000 --> 00:14:36,600
其实这里面有很多种

381
00:14:36,600 --> 00:14:38,200
第一种像左边的这个

382
00:14:38,200 --> 00:14:40,000
就是针对 x86 的

383
00:14:40,000 --> 00:14:41,600
而这种中间的这个

384
00:14:41,600 --> 00:14:43,000
就针对 GPU 的

385
00:14:43,000 --> 00:14:44,600
不管是 PC 的 GPU

386
00:14:44,600 --> 00:14:47,200
还是手机的 GPU 都会有

387
00:14:47,200 --> 00:14:50,200
而另外一种是针对我们的编译器的

388
00:14:50,200 --> 00:14:51,800
就通过编译器来实现的

389
00:14:51,800 --> 00:14:54,400
所以说可能我们的 Kernel 层

390
00:14:54,400 --> 00:14:56,800
在整个推理引擎的代码里面

391
00:14:56,800 --> 00:14:58,800
占了绝大部分

392
00:14:58,800 --> 00:15:00,400
大部分都是 Kernel 层

393
00:15:00,400 --> 00:15:02,000
一个 CUDA 的算子

394
00:15:02,000 --> 00:15:05,400
我们可能就有很多种不同的实现

395
00:15:05,400 --> 00:15:07,200
例如我们会实现

396
00:15:07,200 --> 00:15:08,800
Image Clump 的这种方式

397
00:15:08,800 --> 00:15:10,400
我们对 3x3 的卷积

398
00:15:10,400 --> 00:15:12,000
可能会使用 Winograd

399
00:15:12,000 --> 00:15:14,800
另外我们会使用 TNM Pack 的方式

400
00:15:14,800 --> 00:15:16,000
针对普通的卷积

401
00:15:16,000 --> 00:15:17,600
我们有普通卷积的实现方式

402
00:15:17,600 --> 00:15:19,400
所以说一个卷积的操作

403
00:15:19,400 --> 00:15:22,000
我们就可能有七八种 Kernel 了

404
00:15:22,000 --> 00:15:23,200
针对 x86 里面

405
00:15:23,200 --> 00:15:25,600
可能同样的一个卷积操作

406
00:15:25,600 --> 00:15:27,200
又有七八种 Kernel 了

407
00:15:27,200 --> 00:15:28,200
那我们一个推理引擎

408
00:15:28,200 --> 00:15:30,200
要同时支持 CPU

409
00:15:30,200 --> 00:15:32,400
也要同时具体 GPU

410
00:15:32,400 --> 00:15:34,000
可能一个 3x3 的卷积

411
00:15:34,000 --> 00:15:34,800
Winograd

412
00:15:34,800 --> 00:15:37,000
就有两个 Kernel 的实现方式了

413
00:15:37,000 --> 00:15:38,600
所以说为什么 Kernel 层

414
00:15:38,600 --> 00:15:40,200
是非常的厚重

415
00:15:40,200 --> 00:15:41,600
也是这个原因

416
00:15:41,600 --> 00:15:42,200
好了

417
00:15:42,200 --> 00:15:44,800
今天的内容就到这里为止

418
00:15:44,800 --> 00:15:45,600
谢谢各位

419
00:15:45,600 --> 00:15:46,600
拜了个拜

