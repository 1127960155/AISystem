0
0:00:00.000 --> 0:00:05.040
啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦啦

1
0:00:06.120 --> 0:00:08.880
哈喽大家好我就是那个上今天的班

2
0:00:08.940 --> 0:00:11.320
所以昨天的叫的宗明

3
0:00:11.320 --> 0:00:16.480
那今天呢我们来到一个新的内容推动引擎里面的科诺优化

4
0:00:16.620 --> 0:00:20.600
专门的针对我们推动引擎里面的科诺进行优化

5
0:00:20.880 --> 0:00:28.400
毫不意外我们每次在一个新的内容之前呢都会做一个全面的一个介绍介绍一下我们接下来要去讲

6
0:00:28.400 --> 0:00:30.720
或者要给大家分享和汇报哪些内容

7
0:00:30.720 --> 0:00:34.000
首先我们看一下其实前面我们讲了很多内容了

8
0:00:34.000 --> 0:00:41.000
推理系统然后再到推理引擎里面的小型化了优化压缩还有推理的转换和优化

9
0:00:41.000 --> 0:00:46.480
接下来我们真正来到一些执行方面的内容就是我们第一个科诺的优化

10
0:00:46.480 --> 0:00:50.960
那科诺优化我们会分开四个内容给大家去汇报的

11
0:00:50.960 --> 0:00:53.800
第一个就是具体的算法的优化

12
0:00:53.800 --> 0:00:58.560
针对推理引擎的卷机科诺算子进行层面的优化

13
0:00:58.560 --> 0:01:03.600
接着我们看一下内存布局对于我们科诺优化的作用还有它的意义

14
0:01:03.600 --> 0:01:10.680
最后呢我们会去看一下汇编的优化特别是在指令和汇编层面怎么去进行优化

15
0:01:10.680 --> 0:01:14.880
然后呢讲完这个内容之后呢我们真正的去到了调度的优化

16
0:01:14.880 --> 0:01:19.160
调度的优化呢就是把上面的这些优化呢全部都用起来

17
0:01:19.360 --> 0:01:25.240
在推理引擎执行之前呢进行一个调度的优化把我们的科诺进行排好把我们的内存排好

18
0:01:25.240 --> 0:01:30.880
把我们的汇编指令的编译好然后再到我们的温探的执行

19
0:01:30.880 --> 0:01:34.320
那温探呢就是把我们的具体的科诺吊起来

20
0:01:35.520 --> 0:01:45.280
下面呢我们重新的回到推理引擎的整体架构可以看到之前的内容啊是的之前的内容我们主要是集中在上面的这个模块

21
0:01:45.280 --> 0:01:57.160
中间呢通过一个统一的按压进行一个穿通把我们的模型的转换呢独特优化了模型的压缩包括端约协同的一些学习都建立在一个统一的按压里面

22
0:01:57.160 --> 0:02:10.680
接下来我们到了下面的这个内容那下面这个内容呢分开两个颜色第一个颜色呢就是粉粉嫩嫩的温探第二个颜色呢就是橙色的科诺

23
0:02:10.680 --> 0:02:40.640
在温探呢其实大部分我们去用的时候都是温探去用的但是呢我们会写很多不同的算子那这些算子呢都是在科诺城里面去承载的而科诺城你可以看到里面是东西或者内容呢确实是非常非常的多现在呢我们打开一下科诺城里面的内容那往左边的看一下其实科诺城呢它主要是高性能的算子城大家都可以直接这么认为就好

24
0:02:40.640 --> 0:02:58.360
了接着呢科诺城门会做很多新的事情第一个我们需要对这些算子科诺进行优化然后执行这些算子科诺还有对这些算子科诺进行调度那它主要的作用是在这上面那下面呢我们再认真地看看这个架构图

25
0:02:58.360 --> 0:02:59.360
在这个架构图里面呢我分开两个区块一个呢叫做人工的高性能算子另外一个呢叫做高性能的算子库有两个东西那两个东西区别还是蛮大的首先我们看一下像在我们的插八六或者阿姆的CPU里面的大部分像neo指令集呢我们基本上都会用neo来去实现的而一些在插八六里面呢我们可能会使用一些AVX的指令去实现我们的算子

26
0:03:28.360 --> 0:03:58.360
那在GPU里面呢我们会使用酷打啦OpenCL啦温卡啦还有metal去实现我们一些人工定义的高性能的算子至于在一些MPU里面呢可能在华为生成的会用tick还有在一些边缘推新片里面呢也会用到TVM去生成一些算子那这个呢就是高性能的人工的算子库大部分呢都是我们先写好一个人工定义的算子然后去进行一个极致的优化优化完成

27
0:03:58.360 --> 0:04:28.360
之后呢其实有很多同类型的算子我们可以把它封装起来变成例如酷电啦MKL电啦这种就变成一个高性能的算子库给我们的温探去调度的当然温探也可以直接调我们人工实现的算子具体怎么调就要看我们温探的策略了讲完整体的架构图之后呢我们来看看推理流程那推理流程呢其实我们之前也讲过了在整体推理流程里面呢

28
0:04:28.360 --> 0:04:58.360
我们整个推理引擎它不仅只有这个安卷这个引擎它包括离线模块而离线模块呢是把训练框架的网络模型转成自己的一个推理的模块那这个推理模块呢会经过压缩也可以不经过压缩然后给到我们的离线模块经过一些呃编译的优化或者图优化优化完成了就真正的在线执行那在线执行的这个执行推理引擎这里面呢叫做温探

29
0:04:58.360 --> 0:05:00.440
把我们的一些算子调度起来

30
0:05:00.440 --> 0:05:04.360
而后面执行的就是算子就是我们的科诺科诺层

31
0:05:04.360 --> 0:05:08.160
所以呢我们一般都会在第五这个位置去呈现

32
0:05:08.160 --> 0:05:12.520
而具体你们可能用的比较少大部分都是集成在推理引擎里面的

33
0:05:12.520 --> 0:05:16.720
我们很多底层的这些算子都通过温探去调起

34
0:05:16.720 --> 0:05:23.280
一般呢通过温探呢就冒号点点问就可以把我们整个推理引擎执行起来了

35
0:05:23.280 --> 0:05:27.920
所以说很多时候我们的算子的开发同事我们的科诺的优化的同事

36
0:05:28.000 --> 0:05:30.960
是非常的苦逼的因为他做的很多工作

37
0:05:30.960 --> 0:05:33.520
你感知不到那是没有他是不行的

38
0:05:33.520 --> 0:05:36.280
他需要做很多大量极致的优化

39
0:05:36.560 --> 0:05:39.000
今天的内容呢就到这里为止

40
0:05:39.000 --> 0:05:44.960
我们将会在后面详细地展开科诺优化到底做了哪些不一样的东西

41
0:05:44.960 --> 0:05:47.440
科诺优化有哪些更细节的内容

42
0:05:47.640 --> 0:05:49.400
谢谢各位摆了个拜

43
0:05:49.760 --> 0:05:53.160
卷得不行了卷得不行了记得一键三连加关注哦

44
0:05:53.160 --> 0:05:56.360
所有的内容都会开源在下面这条链接里面

45
0:05:56.760 --> 0:05:57.640
摆了个拜

46
0:05:57.920 --> 0:05:58.160
好

