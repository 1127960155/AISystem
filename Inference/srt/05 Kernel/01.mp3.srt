1
00:00:00,000 --> 00:00:04,480
【开场音乐】

2
00:00:04,480 --> 00:00:06,680
Hello 大家好

3
00:00:06,680 --> 00:00:08,880
我就是那个上今天的班

4
00:00:08,880 --> 00:00:11,280
所以昨天叫的Zoomie

5
00:00:11,280 --> 00:00:13,640
今天我们来到一个新的内容

6
00:00:13,640 --> 00:00:16,480
推丁引擎里面的Kernel优化

7
00:00:16,480 --> 00:00:19,680
专门的针对我们推丁引擎里面的Kernel进行优化

8
00:00:20,680 --> 00:00:21,480
毫不意外

9
00:00:21,480 --> 00:00:23,720
我们每次在一个新的内容之前

10
00:00:23,720 --> 00:00:25,880
都会做一个全面的介绍

11
00:00:25,880 --> 00:00:28,400
介绍一下我们接下来要去讲

12
00:00:28,480 --> 00:00:30,680
或者要给大家分享和汇报哪些内容

13
00:00:30,680 --> 00:00:31,800
首先我们看一下

14
00:00:31,800 --> 00:00:33,920
其实前面我们讲了很多内容了

15
00:00:33,920 --> 00:00:34,960
推理系统

16
00:00:34,960 --> 00:00:37,800
然后再到推理引擎里面的小型化

17
00:00:37,800 --> 00:00:38,560
优化压缩

18
00:00:38,560 --> 00:00:40,920
还有推理的转换和优化

19
00:00:40,920 --> 00:00:44,120
接下来我们真正来到一些运行方面的内容

20
00:00:44,120 --> 00:00:46,520
就是我们第一个Kernel的优化

21
00:00:46,520 --> 00:00:50,920
那Kernel优化我们会分开四个内容给大家去汇报的

22
00:00:50,920 --> 00:00:53,680
第一个就是具体的算法的优化

23
00:00:54,200 --> 00:00:55,800
针对推理引擎的卷机

24
00:00:55,800 --> 00:00:58,520
Kernel算子进行层面的优化

25
00:00:58,520 --> 00:01:00,600
接着我们看一下内存布局

26
00:01:00,600 --> 00:01:02,440
对于我们Kernel优化的作用

27
00:01:02,440 --> 00:01:03,600
还有它的意义

28
00:01:03,600 --> 00:01:06,840
最后我们会去看一下汇编的优化

29
00:01:06,840 --> 00:01:09,120
特别是在指令和汇编层面

30
00:01:09,120 --> 00:01:10,640
怎么去进行优化

31
00:01:10,640 --> 00:01:11,200
然后呢

32
00:01:11,200 --> 00:01:12,120
剪完这个内容之后

33
00:01:12,120 --> 00:01:14,880
我们真正的去到了调度的优化

34
00:01:14,880 --> 00:01:15,720
调度的优化

35
00:01:15,720 --> 00:01:17,480
就是把上面的这些优化

36
00:01:17,480 --> 00:01:19,280
全部都用起来

37
00:01:19,280 --> 00:01:21,160
在推丁引擎运行之前

38
00:01:21,160 --> 00:01:22,680
进行一个调度的优化

39
00:01:22,680 --> 00:01:24,000
帮我们的Kernel进行排好

40
00:01:24,000 --> 00:01:25,160
帮我们的内存排好

41
00:01:25,280 --> 00:01:27,520
帮汇编指令的编译好

42
00:01:27,520 --> 00:01:30,880
然后再到我们的One Time的运行

43
00:01:30,880 --> 00:01:33,440
那One Time就是把我们的具体的Kernel

44
00:01:33,440 --> 00:01:34,280
吊起来

45
00:01:35,560 --> 00:01:39,040
下面我们重新的回到推丁引擎的整体架构

46
00:01:39,040 --> 00:01:40,800
可以看到之前的内容

47
00:01:40,800 --> 00:01:41,200
是的

48
00:01:41,200 --> 00:01:41,920
之前的内容

49
00:01:41,920 --> 00:01:45,280
我们主要是集中在上面的这个模块

50
00:01:45,280 --> 00:01:49,440
中间通过一个统一的IR进行一个串通

51
00:01:49,440 --> 00:01:50,840
把我们的模型的转换

52
00:01:50,840 --> 00:01:51,520
图的优化了

53
00:01:51,520 --> 00:01:52,280
模型的压缩

54
00:01:52,280 --> 00:01:54,480
包括端与斜同的一些学习

55
00:01:54,520 --> 00:01:57,080
都创建在一个统一的IR里面

56
00:01:57,080 --> 00:01:59,920
接下来我们到了下面的内容

57
00:01:59,920 --> 00:02:03,600
下面的内容分开两个颜色

58
00:02:03,600 --> 00:02:07,040
第一个颜色就是粉粉嫩嫩的One Time

59
00:02:07,040 --> 00:02:10,640
第二个颜色就是橙色的Kernel

60
00:02:10,640 --> 00:02:11,400
在One Time

61
00:02:11,400 --> 00:02:13,200
其实大部分我们去用的时候

62
00:02:13,200 --> 00:02:14,880
都是One Time去用的

63
00:02:14,880 --> 00:02:17,560
但是我们会写很多不同的算子

64
00:02:17,560 --> 00:02:21,880
这些算子都是在Kernel城里面去承载的

65
00:02:21,880 --> 00:02:24,200
而Kernel城你可以看到里面是东西

66
00:02:24,200 --> 00:02:28,240
或者内容确实是非常多

67
00:02:28,760 --> 00:02:32,880
现在我们打开一下Kernel城里面的内容

68
00:02:32,880 --> 00:02:34,520
往左边看一下

69
00:02:34,520 --> 00:02:38,880
其实Kernel城它主要是高性能的算子城

70
00:02:38,880 --> 00:02:41,280
大家都可以直接这么认为就好了

71
00:02:41,280 --> 00:02:44,480
接着Kernel城我们会做很多新的事情

72
00:02:44,480 --> 00:02:47,640
第一个我们需要对这些算子Kernel进行优化

73
00:02:47,640 --> 00:02:49,520
然后运行这些算子Kernel

74
00:02:49,520 --> 00:02:52,160
还有对这些算子Kernel进行调度

75
00:02:52,200 --> 00:02:54,200
它主要的作用是在这三面

76
00:02:54,200 --> 00:02:58,680
下面我们再认真的看看架构图

77
00:02:59,760 --> 00:03:02,840
在这个架构图里面我翻开两个虚框

78
00:03:02,840 --> 00:03:06,120
一个叫做人工的高性能算子

79
00:03:06,120 --> 00:03:09,880
另外一个叫做高性能的算子库

80
00:03:09,880 --> 00:03:11,040
有两个东西

81
00:03:11,040 --> 00:03:13,280
两个东西区别还是蛮大的

82
00:03:13,280 --> 00:03:14,600
首先我们看一下

83
00:03:14,920 --> 00:03:18,080
像在我们的X86或者ARM的CPU里面

84
00:03:18,080 --> 00:03:19,760
大部分像NEO指定集

85
00:03:19,920 --> 00:03:22,360
我们基本上都会用NEO来去实现的

86
00:03:22,360 --> 00:03:24,200
而一些在X86里面

87
00:03:24,280 --> 00:03:27,000
我们可能会使用一些AVX的指令

88
00:03:27,000 --> 00:03:28,960
去实现我们的算子

89
00:03:28,960 --> 00:03:31,520
那在GPU里面我们会使用CUDA

90
00:03:31,520 --> 00:03:32,960
OpenCL Wincar

91
00:03:32,960 --> 00:03:35,800
还有Metal去实现我们一些

92
00:03:35,800 --> 00:03:38,400
人工定义的高性能的算子

93
00:03:38,400 --> 00:03:40,240
至于在一些MPU里面

94
00:03:40,400 --> 00:03:42,600
可能在华为生腾会用TIC

95
00:03:42,600 --> 00:03:44,960
还有在一些边缘推理芯片里面

96
00:03:45,120 --> 00:03:48,480
也会用到TVM去生成一些算子

97
00:03:48,680 --> 00:03:51,480
那这个就是高性能的人工的算子库

98
00:03:51,480 --> 00:03:53,880
大部分都是我们先写好一个

99
00:03:53,880 --> 00:03:55,040
人工定义的算子

100
00:03:55,040 --> 00:03:57,600
然后去进行一个极致的优化

101
00:03:57,600 --> 00:03:58,640
优化完之后

102
00:03:58,800 --> 00:04:01,040
其实有很多同类型的算子

103
00:04:01,040 --> 00:04:03,040
我们可以把它封装起来

104
00:04:03,040 --> 00:04:06,320
变成例如QDNA MKLDNA这种

105
00:04:06,320 --> 00:04:08,360
就变成一个高性能的算子库

106
00:04:08,360 --> 00:04:10,360
给我们的WinTime去调度的

107
00:04:10,360 --> 00:04:12,040
当然WinTime也可以直接调

108
00:04:12,040 --> 00:04:14,000
我们人工实现的算子

109
00:04:14,440 --> 00:04:15,320
具体怎么调

110
00:04:15,320 --> 00:04:17,920
就要看我们WinTime的策略了

111
00:04:18,800 --> 00:04:20,480
讲完整体的架构图之后

112
00:04:20,760 --> 00:04:23,320
我们来看看推理流程

113
00:04:23,480 --> 00:04:26,480
推理流程其实我们之前也讲过了

114
00:04:26,480 --> 00:04:27,880
在整体推理流程里面

115
00:04:28,040 --> 00:04:30,120
就是在我们整个推理引擎

116
00:04:30,120 --> 00:04:32,800
它不仅只有这个Engine这个引擎

117
00:04:32,800 --> 00:04:34,280
它包括脱机模块

118
00:04:34,280 --> 00:04:38,240
而脱机模块是把训练框架的网络模型

119
00:04:38,240 --> 00:04:41,680
转成自己的一个推理的模块

120
00:04:41,880 --> 00:04:43,520
这个推理模块会经过压缩

121
00:04:43,520 --> 00:04:45,040
也可以不经过压缩

122
00:04:45,040 --> 00:04:47,400
然后给到我们的脱机模块

123
00:04:47,400 --> 00:04:50,240
经过一些编译的优化

124
00:04:50,240 --> 00:04:51,080
或者图优化

125
00:04:51,080 --> 00:04:53,880
优化完之后就真正的在线运行

126
00:04:54,120 --> 00:04:56,160
在线运行的运行推理引擎

127
00:04:56,160 --> 00:04:57,880
这里面叫做WinTime

128
00:04:57,880 --> 00:05:00,400
是把我们的一些算子调度起来

129
00:05:00,400 --> 00:05:02,200
而后面运行的就是算子

130
00:05:02,200 --> 00:05:04,320
就是我们的Kernel层

131
00:05:04,320 --> 00:05:07,320
所以我们一般都会在第五这个位置

132
00:05:07,320 --> 00:05:08,120
去呈现

133
00:05:08,120 --> 00:05:10,000
而具体你们可能用的比较少

134
00:05:10,000 --> 00:05:12,480
大部分都是集成在推理引擎里面的

135
00:05:12,480 --> 00:05:14,680
我们很多底层的这些算子

136
00:05:14,960 --> 00:05:16,680
都通过WinTime去调起

137
00:05:16,840 --> 00:05:19,040
一般通过WinTime就冒号

138
00:05:19,040 --> 00:05:20,160
点点问

139
00:05:20,160 --> 00:05:23,240
就可以把我们整个推理引擎运行起来了

140
00:05:23,240 --> 00:05:25,000
所以说很多时候

141
00:05:25,000 --> 00:05:26,360
我们的算子的开发同事

142
00:05:26,360 --> 00:05:27,920
我们的Kernel的优化的同事

143
00:05:27,920 --> 00:05:29,440
是非常的苦逼的

144
00:05:29,440 --> 00:05:30,920
因为他做的很多任务作

145
00:05:30,920 --> 00:05:31,840
你感知不到

146
00:05:31,840 --> 00:05:33,480
那是没有他是不行的

147
00:05:33,480 --> 00:05:35,080
他需要做很多大量的

148
00:05:35,080 --> 00:05:36,200
细致的优化

149
00:05:36,600 --> 00:05:38,960
今天的内容就到这里为止

150
00:05:38,960 --> 00:05:42,400
我们将会在后面详细的展开Kernel优化

151
00:05:42,400 --> 00:05:44,880
到底做了哪些不一样的东西

152
00:05:44,920 --> 00:05:47,320
Kernel优化有哪些更细节的内容

153
00:05:47,320 --> 00:05:48,280
谢谢各位

154
00:05:48,280 --> 00:05:49,360
拜了个拜

155
00:05:49,360 --> 00:05:50,480
卷的不行了

156
00:05:50,480 --> 00:05:51,280
卷的不行了

157
00:05:51,280 --> 00:05:53,080
记得一键三连加关注哦

158
00:05:53,080 --> 00:05:56,280
所有的内容都会开源在下面这条链接里面

159
00:05:56,280 --> 00:05:57,600
拜了个拜

