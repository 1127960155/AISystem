0
0:00:00.000 --> 0:00:04.480
【开场音乐】

1
0:00:04.480 --> 0:00:06.680
Hello 大家好

2
0:00:06.680 --> 0:00:08.880
我就是那个上今天的班

3
0:00:08.880 --> 0:00:11.280
所以昨天叫的Zoomie

4
0:00:11.280 --> 0:00:13.640
今天我们来到一个新的内容

5
0:00:13.640 --> 0:00:16.480
推丁引擎里面的Kernel优化

6
0:00:16.480 --> 0:00:19.680
专门的针对我们推丁引擎里面的Kernel进行优化

7
0:00:20.680 --> 0:00:21.480
毫不意外

8
0:00:21.480 --> 0:00:23.720
我们每次在一个新的内容之前

9
0:00:23.720 --> 0:00:25.880
都会做一个全面的介绍

10
0:00:25.880 --> 0:00:28.400
介绍一下我们接下来要去讲

11
0:00:28.480 --> 0:00:30.680
或者要给大家分享和汇报哪些内容

12
0:00:30.680 --> 0:00:31.800
首先我们看一下

13
0:00:31.800 --> 0:00:33.920
其实前面我们讲了很多内容了

14
0:00:33.920 --> 0:00:34.960
推理系统

15
0:00:34.960 --> 0:00:37.800
然后再到推理引擎里面的小型化

16
0:00:37.800 --> 0:00:38.560
优化压缩

17
0:00:38.560 --> 0:00:40.920
还有推理的转换和优化

18
0:00:40.920 --> 0:00:44.120
接下来我们真正来到一些运行方面的内容

19
0:00:44.120 --> 0:00:46.520
就是我们第一个Kernel的优化

20
0:00:46.520 --> 0:00:50.920
那Kernel优化我们会分开四个内容给大家去汇报的

21
0:00:50.920 --> 0:00:53.680
第一个就是具体的算法的优化

22
0:00:54.200 --> 0:00:55.800
针对推理引擎的卷机

23
0:00:55.800 --> 0:00:58.520
Kernel算子进行层面的优化

24
0:00:58.520 --> 0:01:00.600
接着我们看一下内存布局

25
0:01:00.600 --> 0:01:02.440
对于我们Kernel优化的作用

26
0:01:02.440 --> 0:01:03.600
还有它的意义

27
0:01:03.600 --> 0:01:06.840
最后我们会去看一下汇编的优化

28
0:01:06.840 --> 0:01:09.120
特别是在指令和汇编层面

29
0:01:09.120 --> 0:01:10.640
怎么去进行优化

30
0:01:10.640 --> 0:01:11.200
然后呢

31
0:01:11.200 --> 0:01:12.120
剪完这个内容之后

32
0:01:12.120 --> 0:01:14.880
我们真正的去到了调度的优化

33
0:01:14.880 --> 0:01:15.720
调度的优化

34
0:01:15.720 --> 0:01:17.480
就是把上面的这些优化

35
0:01:17.480 --> 0:01:19.280
全部都用起来

36
0:01:19.280 --> 0:01:21.160
在推丁引擎运行之前

37
0:01:21.160 --> 0:01:22.680
进行一个调度的优化

38
0:01:22.680 --> 0:01:24.000
帮我们的Kernel进行排好

39
0:01:24.000 --> 0:01:25.160
帮我们的内存排好

40
0:01:25.280 --> 0:01:27.520
帮汇编指令的编译好

41
0:01:27.520 --> 0:01:30.880
然后再到我们的One Time的运行

42
0:01:30.880 --> 0:01:33.440
那One Time就是把我们的具体的Kernel

43
0:01:33.440 --> 0:01:34.280
吊起来

44
0:01:35.560 --> 0:01:39.040
下面我们重新的回到推丁引擎的整体架构

45
0:01:39.040 --> 0:01:40.800
可以看到之前的内容

46
0:01:40.800 --> 0:01:41.200
是的

47
0:01:41.200 --> 0:01:41.920
之前的内容

48
0:01:41.920 --> 0:01:45.280
我们主要是集中在上面的这个模块

49
0:01:45.280 --> 0:01:49.440
中间通过一个统一的IR进行一个串通

50
0:01:49.440 --> 0:01:50.840
把我们的模型的转换

51
0:01:50.840 --> 0:01:51.520
图的优化了

52
0:01:51.520 --> 0:01:52.280
模型的压缩

53
0:01:52.280 --> 0:01:54.480
包括端与斜同的一些学习

54
0:01:54.520 --> 0:01:57.080
都创建在一个统一的IR里面

55
0:01:57.080 --> 0:01:59.920
接下来我们到了下面的内容

56
0:01:59.920 --> 0:02:03.600
下面的内容分开两个颜色

57
0:02:03.600 --> 0:02:07.040
第一个颜色就是粉粉嫩嫩的One Time

58
0:02:07.040 --> 0:02:10.640
第二个颜色就是橙色的Kernel

59
0:02:10.640 --> 0:02:11.400
在One Time

60
0:02:11.400 --> 0:02:13.200
其实大部分我们去用的时候

61
0:02:13.200 --> 0:02:14.880
都是One Time去用的

62
0:02:14.880 --> 0:02:17.560
但是我们会写很多不同的算子

63
0:02:17.560 --> 0:02:21.880
这些算子都是在Kernel城里面去承载的

64
0:02:21.880 --> 0:02:24.200
而Kernel城你可以看到里面是东西

65
0:02:24.200 --> 0:02:28.240
或者内容确实是非常多

66
0:02:28.760 --> 0:02:32.880
现在我们打开一下Kernel城里面的内容

67
0:02:32.880 --> 0:02:34.520
往左边看一下

68
0:02:34.520 --> 0:02:38.880
其实Kernel城它主要是高性能的算子城

69
0:02:38.880 --> 0:02:41.280
大家都可以直接这么认为就好了

70
0:02:41.280 --> 0:02:44.480
接着Kernel城我们会做很多新的事情

71
0:02:44.480 --> 0:02:47.640
第一个我们需要对这些算子Kernel进行优化

72
0:02:47.640 --> 0:02:49.520
然后运行这些算子Kernel

73
0:02:49.520 --> 0:02:52.160
还有对这些算子Kernel进行调度

74
0:02:52.200 --> 0:02:54.200
它主要的作用是在这三面

75
0:02:54.200 --> 0:02:58.680
下面我们再认真的看看架构图

76
0:02:59.760 --> 0:03:02.840
在这个架构图里面我翻开两个虚框

77
0:03:02.840 --> 0:03:06.120
一个叫做人工的高性能算子

78
0:03:06.120 --> 0:03:09.880
另外一个叫做高性能的算子库

79
0:03:09.880 --> 0:03:11.040
有两个东西

80
0:03:11.040 --> 0:03:13.280
两个东西区别还是蛮大的

81
0:03:13.280 --> 0:03:14.600
首先我们看一下

82
0:03:14.920 --> 0:03:18.080
像在我们的X86或者ARM的CPU里面

83
0:03:18.080 --> 0:03:19.760
大部分像NEO指定集

84
0:03:19.920 --> 0:03:22.360
我们基本上都会用NEO来去实现的

85
0:03:22.360 --> 0:03:24.200
而一些在X86里面

86
0:03:24.280 --> 0:03:27.000
我们可能会使用一些AVX的指令

87
0:03:27.000 --> 0:03:28.960
去实现我们的算子

88
0:03:28.960 --> 0:03:31.520
那在GPU里面我们会使用CUDA

89
0:03:31.520 --> 0:03:32.960
OpenCL Wincar

90
0:03:32.960 --> 0:03:35.800
还有Metal去实现我们一些

91
0:03:35.800 --> 0:03:38.400
人工定义的高性能的算子

92
0:03:38.400 --> 0:03:40.240
至于在一些MPU里面

93
0:03:40.400 --> 0:03:42.600
可能在华为生腾会用TIC

94
0:03:42.600 --> 0:03:44.960
还有在一些边缘推理芯片里面

95
0:03:45.120 --> 0:03:48.480
也会用到TVM去生成一些算子

96
0:03:48.680 --> 0:03:51.480
那这个就是高性能的人工的算子库

97
0:03:51.480 --> 0:03:53.880
大部分都是我们先写好一个

98
0:03:53.880 --> 0:03:55.040
人工定义的算子

99
0:03:55.040 --> 0:03:57.600
然后去进行一个极致的优化

100
0:03:57.600 --> 0:03:58.640
优化完之后

101
0:03:58.800 --> 0:04:01.040
其实有很多同类型的算子

102
0:04:01.040 --> 0:04:03.040
我们可以把它封装起来

103
0:04:03.040 --> 0:04:06.320
变成例如QDNA MKLDNA这种

104
0:04:06.320 --> 0:04:08.360
就变成一个高性能的算子库

105
0:04:08.360 --> 0:04:10.360
给我们的WinTime去调度的

106
0:04:10.360 --> 0:04:12.040
当然WinTime也可以直接调

107
0:04:12.040 --> 0:04:14.000
我们人工实现的算子

108
0:04:14.440 --> 0:04:15.320
具体怎么调

109
0:04:15.320 --> 0:04:17.920
就要看我们WinTime的策略了

110
0:04:18.800 --> 0:04:20.480
讲完整体的架构图之后

111
0:04:20.760 --> 0:04:23.320
我们来看看推理流程

112
0:04:23.480 --> 0:04:26.480
推理流程其实我们之前也讲过了

113
0:04:26.480 --> 0:04:27.880
在整体推理流程里面

114
0:04:28.040 --> 0:04:30.120
就是在我们整个推理引擎

115
0:04:30.120 --> 0:04:32.800
它不仅只有这个Engine这个引擎

116
0:04:32.800 --> 0:04:34.280
它包括脱机模块

117
0:04:34.280 --> 0:04:38.240
而脱机模块是把训练框架的网络模型

118
0:04:38.240 --> 0:04:41.680
转成自己的一个推理的模块

119
0:04:41.880 --> 0:04:43.520
这个推理模块会经过压缩

120
0:04:43.520 --> 0:04:45.040
也可以不经过压缩

121
0:04:45.040 --> 0:04:47.400
然后给到我们的脱机模块

122
0:04:47.400 --> 0:04:50.240
经过一些编译的优化

123
0:04:50.240 --> 0:04:51.080
或者图优化

124
0:04:51.080 --> 0:04:53.880
优化完之后就真正的在线运行

125
0:04:54.120 --> 0:04:56.160
在线运行的运行推理引擎

126
0:04:56.160 --> 0:04:57.880
这里面叫做WinTime

127
0:04:57.880 --> 0:05:00.400
是把我们的一些算子调度起来

128
0:05:00.400 --> 0:05:02.200
而后面运行的就是算子

129
0:05:02.200 --> 0:05:04.320
就是我们的Kernel层

130
0:05:04.320 --> 0:05:07.320
所以我们一般都会在第五这个位置

131
0:05:07.320 --> 0:05:08.120
去呈现

132
0:05:08.120 --> 0:05:10.000
而具体你们可能用的比较少

133
0:05:10.000 --> 0:05:12.480
大部分都是集成在推理引擎里面的

134
0:05:12.480 --> 0:05:14.680
我们很多底层的这些算子

135
0:05:14.960 --> 0:05:16.680
都通过WinTime去调起

136
0:05:16.840 --> 0:05:19.040
一般通过WinTime就冒号

137
0:05:19.040 --> 0:05:20.160
点点问

138
0:05:20.160 --> 0:05:23.240
就可以把我们整个推理引擎运行起来了

139
0:05:23.240 --> 0:05:25.000
所以说很多时候

140
0:05:25.000 --> 0:05:26.360
我们的算子的开发同事

141
0:05:26.360 --> 0:05:27.920
我们的Kernel的优化的同事

142
0:05:27.920 --> 0:05:29.440
是非常的苦逼的

143
0:05:29.440 --> 0:05:30.920
因为他做的很多任务作

144
0:05:30.920 --> 0:05:31.840
你感知不到

145
0:05:31.840 --> 0:05:33.480
那是没有他是不行的

146
0:05:33.480 --> 0:05:35.080
他需要做很多大量的

147
0:05:35.080 --> 0:05:36.200
细致的优化

148
0:05:36.600 --> 0:05:38.960
今天的内容就到这里为止

149
0:05:38.960 --> 0:05:42.400
我们将会在后面详细的展开Kernel优化

150
0:05:42.400 --> 0:05:44.880
到底做了哪些不一样的东西

151
0:05:44.920 --> 0:05:47.320
Kernel优化有哪些更细节的内容

152
0:05:47.320 --> 0:05:48.280
谢谢各位

153
0:05:48.280 --> 0:05:49.360
拜了个拜

154
0:05:49.360 --> 0:05:50.480
卷的不行了

155
0:05:50.480 --> 0:05:51.280
卷的不行了

156
0:05:51.280 --> 0:05:53.080
记得一键三连加关注哦

157
0:05:53.080 --> 0:05:56.280
所有的内容都会开源在下面这条链接里面

158
0:05:56.280 --> 0:05:57.600
拜了个拜

