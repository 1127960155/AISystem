0
0:00:00.000 --> 0:00:04.600
啦啦啦啦啦

1
0:00:04.600 --> 0:00:06.820
哈喽大家好宗明又回来了

2
0:00:06.820 --> 0:00:10.740
今天的我们还是在推定引擎的最后一个内容科诺斯优化

3
0:00:10.820 --> 0:00:13.240
那今天主要是给大家去分享一下

4
0:00:13.240 --> 0:00:17.020
image 和chioform这种卷机的优化方式

5
0:00:17.020 --> 0:00:20.100
回到我们整个科诺优化的课程系列呢

6
0:00:20.100 --> 0:00:23.300
我们科诺优化会讲算法的优化内存的布局

7
0:00:23.300 --> 0:00:25.540
还有编译和调度的优化

8
0:00:25.580 --> 0:00:27.240
那在整体里面呢

9
0:00:27.240 --> 0:00:30.600
算法的优化我们将会深入地去讲解一下

10
0:00:30.600 --> 0:00:34.560
而算法的优化呢更多的是集中在科诺层之里面

11
0:00:34.560 --> 0:00:38.640
很多不同的算法或者我们理解到的具体执行的算法呢

12
0:00:38.640 --> 0:00:40.800
都承载在我们的科诺层

13
0:00:41.200 --> 0:00:44.760
在这节课程里面呢我们将会聚焦两个内容

14
0:00:44.760 --> 0:00:46.920
那第一个内容呢就是image to clump

15
0:00:46.920 --> 0:00:53.080
第二个呢就是spatial pack optimizer空间组合优化两个方式

16
0:00:53.080 --> 0:00:56.840
那现在我们来到第一个内容就是image to clump

17
0:00:56.920 --> 0:00:58.800
整体的算法原理

18
0:01:00.200 --> 0:01:05.200
在image to clump的算法原理呢其实I am to clump吧

19
0:01:05.200 --> 0:01:07.560
我们简单叫做I am to clump吧

20
0:01:07.920 --> 0:01:13.400
然后呢其实这种方式呢是科费早期就早期的AI框架里面去采用的

21
0:01:13.400 --> 0:01:20.880
为什么说是早期呢是因为一开始呢卷机的计算方式呢确实太复杂了而且不容易优化

22
0:01:20.880 --> 0:01:24.960
于是呢科费呢一开始就采用了image to clump这种方式呢

23
0:01:25.000 --> 0:01:29.360
把我们高维的脏量转换成为低维的矩阵的乡城

24
0:01:29.360 --> 0:01:32.280
那我们简单地看看下面的这个示例图

25
0:01:32.280 --> 0:01:40.120
我们知道呢在整个神经网络里面基本上啊很多计算呢都是用高维的脏量去进行计算的

26
0:01:40.120 --> 0:01:45.240
而高维的脏量的表示呢一般使用nhwc这种表示方式

27
0:01:45.240 --> 0:01:54.200
然后呢我们会把高维的脏量这种nhwc呢转换成为通过I am to clump这种方式呢转换成为gmm或者plusmtk这种

28
0:01:54.720 --> 0:02:07.520
可以进行直接矩阵层的操作接着呢我们进行一个逆变的操作clump to image这种方式把我们的脏量呢恢复成为nhwc的格式给下个算子去进行计算

29
0:02:07.520 --> 0:02:14.800
而这里面呢我们就把卷机的方式呢就变成gmm的方式了下面我们看一个比较具体的例子

30
0:02:15.400 --> 0:02:22.120
哦在具体例子进入之前呢我们看看image clump的整体的算法过程虽然我们只看算法过程没什么意思

31
0:02:22.120 --> 0:02:50.760
但是呢有助于我们后面的了解首先呢这里面分开两个步骤第一个步骤呢就是image to clump就把我们的输入的数据还有我们的权重的数据呢转换排布转换成为matmul可以进行计算的排布所以这里面呢分开两个步骤第一个步骤呢就是我们的第一行第一句话image to clump第二个步骤呢就是matmul第二行第二句话的意思

32
0:02:50.760 --> 0:03:20.760
那下面呢我们具体来看看一般的图像呢是怎么操作的那可以看到呢图像的数的维度呢一般都是三维hw三h就是长宽乘以三个通道是我们一般的图片而卷机盒呢可能会有四维nckhkwkh呢kw代表我们的卷机盒kernels的长和宽而c呢是代表单一个卷机盒的圈数n代表是有多少这样的一个小组

33
0:03:20.760 --> 0:03:50.760
那最后的输出的维度呢就是nhw我们最右边的这个图所示当然这是最简单的图片的卷机的操作现在我们来看一下在我们的神经网络里面的数据的排布一般都是高维的四维的甚至到了点云它可能是五维的那我们默认的以四维为例子nhwc输入的就不是图片了而是feature map或者我们的一个tensortensor的维度呢就是nihw

34
0:03:50.760 --> 0:04:20.760
ici呢就是input heightinput width输入的feature map长和宽而ic呢就是input channels的大小一共有n组这样的维度而卷机盒的维度呢可能我们在前面呢加了个kwkh kernels wide kernels high然后ic另外有一个呢就是feature n这个呢是相同的而输出的维度呢其实也有所不同大家要注意的就是前面的下边

35
0:04:20.760 --> 0:04:50.760
标哪个是i哪个是o哪个是n那输出呢就是ohow乘以oc当然了同样有n组这样的一些张量或者feature map下面呢我们看一下更加具体的例子可以看到imagecom的真重要的是改变了数据的排布的方式既然改变了数据的排布方式就可以方便了我们把刚才权重的数据变成一个二维的矩阵把我们feature map变成了一个二维的矩阵

36
0:04:50.760 --> 0:05:20.760
行跟列相成得到我们最终的输出的结果就完成了整个卷机的计算很有意思更多的是数学上面的变换那下面呢我们看看怎么进行算法的重排或者怎么对我们的内存的数据进行重排可以看到灰色的这个小框框呢是我们卷机盒或者滑动窗口的大小那滑动窗口呢是一二三四五六这么排的数据

37
0:05:20.760 --> 0:05:50.760
但实际上呢我们的数据在滑动窗口里面呢是一二三七八九那可能下面还有更大的数了那这个时候呢我们就把一个滑动窗口的数据呢对它进行展开同样对第二个滑动窗口是第二个圈裸的滑动窗口啊对它进行展开不断的展开成为一行那这一行呢对应的就是kw乘以kh乘以ic是完完全全跟我们的卷机盒展开的方式是对应起来

38
0:05:50.760 --> 0:06:20.760
方便我们相乘嘛而我们一共有多少行呢多少行就是oh乘以ow行了这个就是对应到我们的输出下面呢我们看一下怎么对权重的数据进行重排权重的数据进行重排呢其实很好理解而且很有意思一点就是我们权重的数据重排不是在克努执行的时候进行重排的在我们的推定引擎架构里面呢一般对我们的银皮克勒这种转换的方式的数据重排呢

39
0:06:20.760 --> 0:06:50.760
是在我们的模型转换或者图优化的过程当中特别是布局优化或者类层优化的时候进行转换重排的但那有可能我们在温泰的预编译阶段或者温泰的预执行阶段进行重排也是有可能的具体就取决于我们的推定引擎的架构是怎么设计的这个模块应该装载在哪里现在呢又回到我们刚才的image to clump的这种算法过程里面对权重的数据进行

40
0:06:50.760 --> 0:07:20.760
重排权重数据进行重排是比较简单的我们可以看到左边的紫色的这小框框呢就是我们的一个卷积核那卷积核呢我们一二三四五六七八九直接把它展开成为一行可以看到直接展开成一行然后对第二个圈颅进行展开第三个圈颅进行展开每个fit对它进行展开所以一共有n行n乘以k w乘以k h乘以ic就组成了一个大的矩阵帮我们高维的

41
0:07:20.760 --> 0:07:50.760
四维的张量的数据呢变成一个二维的矩阵既然变成一个二维矩阵就非常好的利用我们gmm的特性对它进行一个计算现在呢我们整体的看看一个过程这里面呢分开两部上面的是原来高维的数据高维的张量进行一个卷积的过程这个呢就是卷积核这个就是我们的feature map最终得到我们的输出的结果然后呢我们把它进行image to clump的方式呢

42
0:07:50.760 --> 0:08:20.760
帮我们的权重帮我们的卷积核呢进行转换成为一个单独的二维的矩阵接着呢我们把feature map同样进行展开变成一个单独的矩阵接着呢两个矩阵相称得到我们的输出的矩阵那输出的矩阵的最后的箭头是向上的大家值得注意的就是我们需要通过clump to image把它逆变回来接下来了我们整体的看看image to clump的算法流程算法流程呢分为四步第一步呢就是对我们的

43
0:08:20.760 --> 0:08:50.760
输入的数据进行展开展开成为一个独特的独立的权重第二个呢就是对我们的权重的数据呢进行展开同样就是就展开重排接着呢对上面一二步得到的两个矩阵呢进行相称最终得到我们的输出的矩阵输出的矩阵呢同样需要进行一个逆变的过程所以整体来说呢分开四个步骤四个步骤的执行方式和执行的模块

44
0:08:50.760 --> 0:09:20.760
都是不一样的可能一三四呢是进行到我们的具体的康总程里面但是第二个呢可能会在我们的预编一阶段或者在我们的离线转换优化模块里面去实现那下面呢我们来总结一下image to clump的这个计算的方式可以看到image to clump呢就是把我们传统的卷积大量的计算呢使用GMM这种经过优化的库来进行一个加速的但是有个问题就是

45
0:09:20.760 --> 0:09:50.760
使用image to clump我们可以看到我们需要对数据进行重排把三维块的高危的数据呢展开成为二维的矩阵那这个时候呢我们就需要对数据的数据呢拷贝多份而且就对我们的内存有开销了第二个呢就是转换之后呢我们就有很多不同已经实现好的高速的优化库Plus啊MPT啊Lumpi啊这种去实现然后值得一提的就是

46
0:09:50.760 --> 0:10:20.760
我们刚才也给大家介绍过就是我们首先会在权重啊会预先的去把它转换成为image clump而不是在真正权重来的时候或者计算的时候我才做转换我们在训练的阶段呢其实已经获得到我们的权重的数据了而input的数据呢确实只有在数据真正来的时候数据流来的时候我们才能感知那这时候呢确实没办法进行提前的重排下面呢我们来到第二个内容也是

47
0:10:20.760 --> 0:10:50.760
这一节小课里面的只有一个内容空间的组合优化像image clump呢这种方式呢到空间组合优化image clump可以理解为一个比较朴素的卷迹的优化的手段嘛把卷迹的方式呢变换成为一个矩阵层的方式而空间组合优化呢更多的是基于一个分字的思想既然分字呢我们就可以知道里面很重要的一个词就是空间空间这两个字就帮我们的卷迹的计算呢利用空间的特征

48
0:10:50.760 --> 0:11:20.760
呢划分成为若干份了然后进行分别处理啊那我们可以看到下面就是空间组合优化的一种方式当然了这里面呢不是用gm来去示例也不是用image clump来示例而是直接用传统的卷迹的方式进行示例那这里面呢我们对数据的划分成为四个模块四个部分也就是i h呢还有i w呢进行两两切分划花成为四块这第一块

49
0:11:20.760 --> 0:11:50.760
第二块第三块第四块分别对我们的权重呢进行卷接得到我们的输出最后呢把输出拼接到一起这种就是最简单最朴素的空间优化的方法啦现在呢我们看一下整个空间优化的原理啊原理还是非常简单的主要是下面这几个图画这几个图确实花了不少时间像空间组合优化呢其实是非常好理解的原理首先我们会把输入的一个很大的feature map呢把它分成unpacked

50
0:11:50.760 --> 0:12:20.760
呈多个不同的feature map根据不同的小的feature map呢给我们的权重跟我们的数据呢进行卷接得到多个数据的输出但是有一点呢值得注意的就是这里面的这个小框框的窗口或者划分的一个小模块呢必须要跟我们的卷机和的Windows的大小相匹配而且跟我们的stripe相匹配这个时候呢就可以很好的利用我们的计算机的存储结构获得我们的性能的提升为什么说是计算机的存储

51
0:12:20.760 --> 0:12:50.760
结构呢因为我们知道计算机里面或者我们的cpu gpu里面呢还有l零l一l二不同的cache不同的cache有不同的性能的提升嘛那先下面呢我们看一下空间组合优化一些注意的点其实呢我们在上文里面呢讲了不管是一直空还是空间组合优化我们都忽略了拍等的这个操作有了拍等这个操作呢其实还是需要注意拍等为value的时候呢可以基本上

52
0:12:50.760 --> 0:13:20.760
忽略了但是拍等等于same的时候呢需要利用边界补龄不在边界补龄的时候呢需要利用邻居的张亮的值所以呢一般来说我们都会多出了那么一小个模块进行重叠计算的这也是在我们真正计算的时候需要注意的一个内容那我们现在来看看空间组合优化的coins它的问题在真正的空间组合优化这种方式确实用得非常多

53
0:13:20.760 --> 0:13:50.760
它是我们可能实现的一个很重要的trick假设呢我们现在把一些张亮的分成编藏为四或者八为什么会为四和八呢是因为方便我们的AI编译器或者我们的传统编译器呢进行向量化的操作向量化的转变不过值得注意的就是这个呀模块呀并不是分得越小越好的当然了越小它有个好处就是充分的利用了计算机体系里面的

54
0:13:50.760 --> 0:14:20.760
多极的cache但是模块越小呢局部性也就越高负面的作用呢就是消耗更多的额外的内存这也是它带来的好处和问题所以我们在克弄实现的时候呢需要把握一个度寻找一个合适的划分的方式或者合适的划分的尺寸是一个不容易的事情我们需要经过大量的时间的优化这样呢这里我们也可以通过AI编译器去自动地寻优但是在推理场景

55
0:14:20.760 --> 0:14:50.760
一般寻优完一次之后我们基本上就很少去改动了那最后我们来到回头看看整个推理引擎架构里面我们主要讲的是在克弄优化而克弄优化其实这里面有很多种第一种像左边的这个就是针对x86的而这种中间的这个就针对GPU的不管是PC的GPU还是手机的GPU都会有而另外一种是针对我们的编译器的

56
0:14:50.760 --> 0:15:20.760
来实现的所以说可能我们的克弄成啊在整个推理引擎的代码里面占了绝大部分大部分都是克弄成一个酷大的算子我们可能就有很多种不同的实现例如我们会实现去image crumb的这种方式我们对三乘三的卷机呢可能会使用Window Grid另外呢我们会使用QAMPack这种方式针对普通的卷机呢我们有普通卷机的实现方式所以说一个卷机的操作我们就可能有七八种

57
0:15:20.760 --> 0:15:50.760
克弄了针对x86里面可能同样的一个卷机操作又七八种克弄了那我们一个推理引擎要同时支持CPU也要同时积蓄GPU可能一个三乘三的卷机Window Grid就两个克弄的实现方式呢所以说为什么克弄成是非常的厚重也是这个原因好了今天的内容呢就到这里为止谢谢各位摆了个摆卷得不行了卷得不行了记得一键三连加关注哦

58
0:15:50.760 --> 0:15:55.150
内容都会开源在下面这条链接里面摆了个掰

