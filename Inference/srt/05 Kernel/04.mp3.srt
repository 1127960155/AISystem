1
00:00:00,000 --> 00:00:06,520
Hello大家好我是宗明

2
00:00:06,520 --> 00:00:09,720
在这一节课里面其实我已经NG了非常多遍

3
00:00:09,720 --> 00:00:11,600
才有今天这个视频

4
00:00:11,600 --> 00:00:13,960
现在我们还是来到卷机的优化

5
00:00:13,960 --> 00:00:17,800
我们看一下整体在推进期里面其实介绍了很多内容

6
00:00:17,800 --> 00:00:20,480
而我们现在集中在 Kernels 的优化

7
00:00:20,480 --> 00:00:24,520
而 Kernels 的优化更多的算法优化是最内核的

8
00:00:24,520 --> 00:00:27,440
而算法的优化我们终于来到一个很内核的概念

9
00:00:27,440 --> 00:00:29,560
就是 Winogrid 这个内容

10
00:00:29,600 --> 00:00:34,240
而现在所有的工作都沉淀在我们的 Kernel 城里面

11
00:00:34,240 --> 00:00:38,440
可以看到了我们其实在上一节课或者上两节内容里面

12
00:00:38,440 --> 00:00:40,640
简单的去介绍一个卷机的概念

13
00:00:40,640 --> 00:00:43,840
什幺是 Image Clamp 还有空间组合的优化

14
00:00:43,840 --> 00:00:49,720
在这一节里面我们重点的去看看 Winogrid 这个算法的优化

15
00:00:49,720 --> 00:00:52,120
这个算法叫做 Winogrid

16
00:00:52,120 --> 00:00:55,520
它不是 Grid 它不是球岛的缩写

17
00:00:55,520 --> 00:00:57,880
因为这个算法是 Winogrid

18
00:00:57,880 --> 00:00:59,480
这个人他是个人民

19
00:00:59,480 --> 00:01:02,760
最早在 1980 年的时候已经发表了这篇文章

20
00:01:02,760 --> 00:01:05,320
但是当时并没有引起太多的轰动了

21
00:01:05,320 --> 00:01:08,640
因为那个时候卷机的计算还不是没有现在这幺火

22
00:01:08,640 --> 00:01:11,440
而且计算量也没有今天这幺复杂

23
00:01:11,440 --> 00:01:15,280
到了 3PL 2016 年又有人基于 Winogrid 这个算法

24
00:01:15,280 --> 00:01:18,760
重新的提出了一篇新的文章

25
00:01:18,760 --> 00:01:23,600
这个算法迅速的在我们整个算法的圈里面火起来

26
00:01:23,600 --> 00:01:27,440
现在有很多推理引擎都会去实现 Winogrid 这个算法

27
00:01:27,440 --> 00:01:28,960
包括 Minespot Lite 了

28
00:01:28,960 --> 00:01:32,240
MMN 这些很多推理引擎都会去实现的

29
00:01:32,240 --> 00:01:37,760
里面最内核的一个原理就是使用把很多大量的矩阵乘

30
00:01:37,760 --> 00:01:41,600
或者大量的单点的乘法变成加法的操作

31
00:01:41,600 --> 00:01:43,280
或者减少乘法的操作

32
00:01:43,280 --> 00:01:46,360
那下面我们看一下具体的一个算法的原理

33
00:01:46,360 --> 00:01:48,400
算法原理我会很快的过掉

34
00:01:48,400 --> 00:01:52,000
然后更多的是希望跟大家去看看工程的实现部分

35
00:01:52,000 --> 00:01:55,120
首先我们现在有一个输的信号是我们的 FF

36
00:01:55,120 --> 00:01:56,480
有很多的数据

37
00:01:56,520 --> 00:01:59,760
然后现在有个卷积和卷积的最小的计算

38
00:01:59,760 --> 00:02:02,240
那肯定会有卷积和 G0 G1 G2

39
00:02:02,240 --> 00:02:06,200
那整个卷积的计算我们把它换成一个 ImageColumn 的方式

40
00:02:06,200 --> 00:02:08,280
就变成两个矩阵相乘

41
00:02:08,280 --> 00:02:13,840
于是有 D0 D1 D2 乘以 G1 G2 G3 就变成我们的 R0

42
00:02:13,840 --> 00:02:15,840
然后接着有 D1 D2 D3

43
00:02:15,840 --> 00:02:19,680
再同样的乘以 G0 G1 G2 就得到我们的 R1

44
00:02:19,680 --> 00:02:23,760
这个就是我们的卷积 ImageColumn 的计算方式

45
00:02:24,240 --> 00:02:27,000
实际的计算操作 R0 就等于这条公式

46
00:02:27,000 --> 00:02:28,040
R1 等于这条公式

47
00:02:28,040 --> 00:02:32,480
里面的很内核的就是用了三次的乘法两次的加法

48
00:02:32,480 --> 00:02:35,680
一共就用了六次的乘法四次的加法

49
00:02:35,680 --> 00:02:39,560
数据量这幺少就已经用了非常多的乘加的操作

50
00:02:39,560 --> 00:02:41,040
于是 Winograd 这个算法

51
00:02:41,040 --> 00:02:46,600
确实希望能够极大的去减少我们的乘法的操作

52
00:02:46,600 --> 00:02:49,480
因为这里面有很多元素都是相同的

53
00:02:49,480 --> 00:02:52,400
相同的元素能不能提前算出来

54
00:02:52,440 --> 00:02:54,160
不要每次都算一遍了

55
00:02:54,160 --> 00:02:57,360
据这个思想 Winograd 就证明了

56
00:02:57,360 --> 00:02:58,840
有几条公式

57
00:02:58,840 --> 00:03:00,960
首先刚才的那个矩阵乘

58
00:03:00,960 --> 00:03:07,040
实际上是可以等于 M1 M2 M3 M2-M3-M4

59
00:03:07,040 --> 00:03:09,440
那这些 M1 M2 M3 M4

60
00:03:09,440 --> 00:03:12,640
他们希望能够提前算出来的

61
00:03:12,640 --> 00:03:15,600
像这两个就先提前算出来

62
00:03:15,600 --> 00:03:17,920
另外一些就可以大量的复用

63
00:03:17,920 --> 00:03:20,560
就大量的复用里面的操作

64
00:03:20,560 --> 00:03:23,080
和里面已经算好的数据

65
00:03:23,080 --> 00:03:26,640
所以说整个算法或者整个卷迹的操作

66
00:03:26,640 --> 00:03:32,920
就变成 R0 R1等加于上面的这条公式

67
00:03:32,920 --> 00:03:36,200
下面我们简单的去根据这条公式

68
00:03:36,200 --> 00:03:39,680
反向的推导它的一个成立的方式

69
00:03:41,080 --> 00:03:43,600
下面我们看一下 Winograd 的原理推导

70
00:03:43,600 --> 00:03:46,360
我们现在有刚才有那条公式

71
00:03:46,360 --> 00:03:50,800
所以我们现在 M1 M2 M3 M2-M3-M4

72
00:03:50,800 --> 00:03:52,680
等于 R0 下面等于 R1

73
00:03:52,680 --> 00:03:56,680
现在我令 M1和M4等于下面两条

74
00:03:56,680 --> 00:03:59,520
于是我们下面就可以约掉 M1和M4

75
00:03:59,520 --> 00:04:03,240
于是重新得到了下面的一个新的公式

76
00:04:03,240 --> 00:04:04,520
约掉还不够

77
00:04:04,520 --> 00:04:05,840
我们现在观察 M2

78
00:04:05,840 --> 00:04:08,640
实际上它里面包含非常多的数据

79
00:04:08,640 --> 00:04:11,320
我们先把这里面的数据重新的减少

80
00:04:11,320 --> 00:04:13,400
将其转换成为多项式

81
00:04:13,400 --> 00:04:15,000
然后进行一个拆分

82
00:04:15,040 --> 00:04:17,920
于是我们重新的得到 M2 的公式

83
00:04:17,920 --> 00:04:20,800
同理我们对 M3 也进行无上的操作

84
00:04:20,800 --> 00:04:23,840
于是我们重新得到 M1 M2 M3

85
00:04:23,840 --> 00:04:26,800
这个时候我们实际上有两条公式

86
00:04:26,800 --> 00:04:28,120
就还是那条公式

87
00:04:28,120 --> 00:04:31,160
我们在 M2 和 M3 同时加上一个值

88
00:04:31,160 --> 00:04:33,080
其实 B 公式是不变的

89
00:04:33,080 --> 00:04:36,920
但是 A 公式我们需要给 M1 减去两倍的值

90
00:04:36,920 --> 00:04:38,400
那这个加上这个值

91
00:04:38,400 --> 00:04:39,520
这个值是什幺呢

92
00:04:39,520 --> 00:04:41,320
是下面的这条公式

93
00:04:41,320 --> 00:04:44,080
可以同时进行转换和约减

94
00:04:44,120 --> 00:04:47,280
那这个时候 M1 M2 M3 重新的计算

95
00:04:47,280 --> 00:04:48,920
就等于下面这条公式

96
00:04:48,920 --> 00:04:52,560
但是我们假设给 M2 同时也加上一个值

97
00:04:52,560 --> 00:04:54,440
给 M3 减去一个值

98
00:04:54,440 --> 00:04:56,880
这个值还是变成另外一条公式

99
00:04:56,880 --> 00:04:59,680
这个时候我们就可以重新的去计算

100
00:04:59,680 --> 00:05:02,160
整体的 M1 M2 M3 M4

101
00:05:02,160 --> 00:05:04,880
就有了一种新的计算的公式

102
00:05:04,880 --> 00:05:07,760
而下面这一个也是像我们刚才所说的

103
00:05:07,760 --> 00:05:10,840
它可以提前算好算出来

104
00:05:10,840 --> 00:05:13,920
而我们整个矩阵层就没有那幺复杂了

105
00:05:13,920 --> 00:05:15,280
通过 M1 M2 M3

106
00:05:15,280 --> 00:05:18,080
我们就可以极大的减少了我们的计算

107
00:05:18,080 --> 00:05:20,440
当然了这里听不懂没有关系

108
00:05:20,440 --> 00:05:22,480
我们还是回到重点

109
00:05:22,480 --> 00:05:24,920
就是我们的工程的实现

110
00:05:24,920 --> 00:05:27,320
那具体的算法原理为什幺这幺推导

111
00:05:27,320 --> 00:05:31,000
其实很多人或者在 kernel 的算法优化工程师里面

112
00:05:31,000 --> 00:05:33,440
不知道也不影响我们后续的工作

113
00:05:33,440 --> 00:05:36,040
大家只需要知道我们确实有这种算法

114
00:05:36,040 --> 00:05:38,280
能够很好的加快我们的工作就行了

115
00:05:38,280 --> 00:05:40,200
加快我们的 kernel 的计算

116
00:05:40,200 --> 00:05:42,680
下面我们把刚才的那条公式

117
00:05:42,720 --> 00:05:44,120
就 y 就是我们的输出

118
00:05:44,280 --> 00:05:46,240
我们的 g 有一个卷集和

119
00:05:46,240 --> 00:05:47,760
d 就是我们的 feature map

120
00:05:47,760 --> 00:05:52,720
而小 g 就是我们的一个卷集和的变换矩阵

121
00:05:52,720 --> 00:05:57,240
大 b 就是我们输入的数据的变换矩阵

122
00:05:57,240 --> 00:06:00,280
而 at 就是我们输出的数据的变换矩阵

123
00:06:00,280 --> 00:06:02,200
我们把刚才的那条计算公式

124
00:06:02,200 --> 00:06:03,480
就 manowar 的这个算法

125
00:06:03,480 --> 00:06:05,920
转换成为具体的矩阵层

126
00:06:05,920 --> 00:06:11,320
而这里面三个参数其实都可以提前算出来的

127
00:06:11,320 --> 00:06:12,320
提前算出来之后

128
00:06:12,440 --> 00:06:13,760
只需要放在内存里面

129
00:06:13,760 --> 00:06:14,840
让它去读

130
00:06:14,840 --> 00:06:17,560
之后就会把我们的 feature map 和权重

131
00:06:17,560 --> 00:06:19,240
进行一个简单的矩阵层

132
00:06:19,440 --> 00:06:22,680
就可以得到我们最终的卷集和的输出

133
00:06:22,920 --> 00:06:24,840
这个就是最简单的原理

134
00:06:24,840 --> 00:06:27,680
同样放在二维里面也是成立的

135
00:06:27,680 --> 00:06:29,320
只不过二维的计算公式

136
00:06:29,680 --> 00:06:32,760
可能会稍微更加复杂一点点

137
00:06:32,760 --> 00:06:36,080
下面我们来看看整体的一个

138
00:06:36,080 --> 00:06:37,600
initialize.cum.的展开的方式

139
00:06:37,600 --> 00:06:38,640
是下面这一条

140
00:06:38,640 --> 00:06:40,560
把所有的输入的 feature map

141
00:06:40,640 --> 00:06:42,000
进行一个重排

142
00:06:42,320 --> 00:06:44,360
另外一方面对 kernels 的数据

143
00:06:44,520 --> 00:06:45,520
进行重排

144
00:06:45,520 --> 00:06:46,920
得到新的数据

145
00:06:46,920 --> 00:06:49,440
有人就会想问了

146
00:06:49,440 --> 00:06:51,800
或者小新就可能会跳出来问了

147
00:06:51,800 --> 00:06:54,080
这个跟 window 管有什幺区别呢

148
00:06:54,080 --> 00:06:56,520
这不就 initialize.cum.的计算方式吗

149
00:06:56,520 --> 00:06:57,520
很有意思的

150
00:06:57,520 --> 00:07:00,160
我们看一看下面这条内容

151
00:07:00,160 --> 00:07:01,120
这里面可以看到

152
00:07:01,360 --> 00:07:02,440
基本上就变成我们的

153
00:07:02,440 --> 00:07:04,360
window管的计算方式了

154
00:07:04,760 --> 00:07:06,560
而 m1加 m2加 m3

155
00:07:06,560 --> 00:07:08,240
m2-m3-m4

156
00:07:09,040 --> 00:07:10,440
这条公式的计算

157
00:07:10,680 --> 00:07:15,160
就是对应于刚才的 m1-m2-m3-m4

158
00:07:15,160 --> 00:07:16,640
四个数的计算了

159
00:07:17,680 --> 00:07:18,960
下面我们看一下

160
00:07:18,960 --> 00:07:21,480
具体 window grid 的工程实现

161
00:07:21,480 --> 00:07:22,880
大家听不懂也没有关系

162
00:07:22,880 --> 00:07:26,680
后面我会把这些都整理成一个文档

163
00:07:26,680 --> 00:07:28,680
然后方便大家去取悦

164
00:07:28,680 --> 00:07:30,440
下面我们重新的看一下

165
00:07:30,440 --> 00:07:31,440
整体的工程实现

166
00:07:31,440 --> 00:07:33,320
工程实现主要分开四个步骤

167
00:07:33,320 --> 00:07:36,000
我们往下面这个图看一看

168
00:07:36,000 --> 00:07:39,640
首先我们会对输入的卷积和

169
00:07:39,640 --> 00:07:40,680
进行一个变换

170
00:07:40,680 --> 00:07:42,600
变换就是我们的 U

171
00:07:42,600 --> 00:07:45,280
G G T

172
00:07:45,800 --> 00:07:46,960
接着我们第二步

173
00:07:46,960 --> 00:07:50,600
就是对输入的数据进行变换

174
00:07:50,600 --> 00:07:51,800
得到我们的 V

175
00:07:51,800 --> 00:07:53,400
B D D

176
00:07:53,400 --> 00:07:54,720
我们的输入的 feature map

177
00:07:55,080 --> 00:07:56,440
然后再乘以 B

178
00:07:56,440 --> 00:07:59,520
第三步就是对我们的 m 矩阵

179
00:07:59,520 --> 00:08:00,480
进行计算

180
00:08:00,480 --> 00:08:02,400
就我们的 window grid 具体的算法

181
00:08:02,400 --> 00:08:06,560
把 V 和 U 两个矩阵进行相乘

182
00:08:06,560 --> 00:08:09,440
最后一步就是计算输出的结果

183
00:08:09,560 --> 00:08:11,120
乘以 A T

184
00:08:11,120 --> 00:08:14,680
看上去好像还是挺简单的

185
00:08:14,680 --> 00:08:15,520
并不复杂

186
00:08:15,520 --> 00:08:18,360
而且这里面的 G B和 A

187
00:08:18,600 --> 00:08:21,000
都是提前算出来的

188
00:08:21,000 --> 00:08:22,040
至于怎幺算出来

189
00:08:22,200 --> 00:08:23,680
就是根据我刚才推导的公式

190
00:08:23,680 --> 00:08:24,680
来去算出来的

191
00:08:24,680 --> 00:08:26,360
现在我们看一下

192
00:08:26,360 --> 00:08:28,360
具体的实现的步骤

193
00:08:28,360 --> 00:08:29,240
刚才说第一步

194
00:08:29,440 --> 00:08:32,080
是首先算我们的 G和 T

195
00:08:32,080 --> 00:08:33,360
那这个 G T 怎幺来的

196
00:08:33,360 --> 00:08:35,360
就是真的是通过公式推导的

197
00:08:35,360 --> 00:08:36,520
通过公式推导之前

198
00:08:36,840 --> 00:08:39,320
提前算好这个 G

199
00:08:39,400 --> 00:08:40,160
而这个大 G

200
00:08:40,280 --> 00:08:41,920
我们确实有一条公式可以算

201
00:08:41,920 --> 00:08:43,640
现在也有一个 GitHub 的网站

202
00:08:43,640 --> 00:08:45,120
可以给大家去算出来

203
00:08:46,240 --> 00:08:48,080
大家打开 GitHub 的网站

204
00:08:48,240 --> 00:08:50,040
就可以把我们刚才的

205
00:08:50,040 --> 00:08:53,280
window grid 的 CNN 的一些全纵

206
00:08:53,440 --> 00:08:55,000
提前的算出来

207
00:08:55,000 --> 00:08:56,920
我这边就不带着大家一起去算了

208
00:08:56,920 --> 00:08:58,160
大家可以去用一下

209
00:08:58,160 --> 00:08:59,680
这边就可以看到 A T

210
00:08:59,680 --> 00:09:01,080
它提前给我们算出来

211
00:09:01,080 --> 00:09:02,280
B 也给我们算出来

212
00:09:02,280 --> 00:09:03,840
G 也给我们算出来了

213
00:09:03,840 --> 00:09:05,320
所以还是挺有意思的

214
00:09:05,520 --> 00:09:06,840
现在我们重新的回到

215
00:09:06,840 --> 00:09:08,760
我们的 slide ppt 里面

216
00:09:08,880 --> 00:09:11,640
假设我们的 G 已经提前算出来了

217
00:09:11,640 --> 00:09:13,320
现在我们需要通过

218
00:09:13,320 --> 00:09:14,520
window grid 这个变换

219
00:09:14,920 --> 00:09:16,200
把 G 和 G T

220
00:09:16,680 --> 00:09:18,200
把三乘三的全纵

221
00:09:18,440 --> 00:09:21,200
转换成为四乘四的矩阵

222
00:09:21,480 --> 00:09:24,680
下面首先第一步是对全纵进行转换

223
00:09:24,960 --> 00:09:25,880
全纵进行转换

224
00:09:26,200 --> 00:09:27,240
前面有个大 G

225
00:09:27,240 --> 00:09:28,080
后面有个大 G

226
00:09:28,080 --> 00:09:29,680
我们就把全纵的数据

227
00:09:29,920 --> 00:09:32,760
转换成为一个四乘四的矩阵

228
00:09:32,760 --> 00:09:33,800
而这里面 IC

229
00:09:33,800 --> 00:09:35,560
就是我们的 channels 的大小

230
00:09:35,560 --> 00:09:38,120
然后把这个脏量里面相同位置的点

231
00:09:38,120 --> 00:09:39,840
假设我们现在以蓝色为例

232
00:09:39,840 --> 00:09:44,120
转换成为一个 IC 乘以 OC 的矩阵

233
00:09:44,360 --> 00:09:45,320
这里面是蓝色

234
00:09:45,320 --> 00:09:47,600
我们把它全部都重排

235
00:09:47,880 --> 00:09:49,600
展开成为这幺一列

236
00:09:49,600 --> 00:09:50,800
OC 乘以 IC

237
00:09:50,800 --> 00:09:52,080
四乘四乘以 16

238
00:09:52,080 --> 00:09:54,760
这幺一个具体的矩阵

239
00:09:54,760 --> 00:09:56,440
那转换成为这个矩阵

240
00:09:56,600 --> 00:09:58,520
只是为了后面的矩阵层

241
00:09:58,520 --> 00:09:59,760
方便去运算

242
00:10:00,080 --> 00:10:02,160
第二个步骤是对我们的 feature map

243
00:10:02,160 --> 00:10:04,520
就输入的数据进行转换

244
00:10:04,520 --> 00:10:05,560
同样这个数据

245
00:10:05,720 --> 00:10:07,840
我们有一个大 B 还有个 B T

246
00:10:08,000 --> 00:10:09,880
进行一个具体的相乘之后

247
00:10:10,120 --> 00:10:12,640
我们就会对它进行重新的转换

248
00:10:12,640 --> 00:10:15,320
成为另外一个脏量的形式

249
00:10:15,320 --> 00:10:17,720
同样的我们对脏量的形式

250
00:10:18,080 --> 00:10:20,360
进行一个数据的重排

251
00:10:20,360 --> 00:10:21,680
这边有一个 read layout

252
00:10:21,680 --> 00:10:24,040
就是确实需要进行数据的重排

253
00:10:24,040 --> 00:10:24,920
重排完之后

254
00:10:25,120 --> 00:10:27,880
同样我们这里面是四乘四乘以16

255
00:10:27,880 --> 00:10:29,120
的这种方式

256
00:10:29,120 --> 00:10:31,320
下面假设 A 就是我们的 feature map 的输入

257
00:10:31,320 --> 00:10:32,880
B 就是我们的全众

258
00:10:33,120 --> 00:10:35,600
这两个矩阵进行一个相乘之后

259
00:10:35,760 --> 00:10:37,720
就得到一个新的矩阵

260
00:10:37,720 --> 00:10:39,960
新的矩阵确实也需要进行一个

261
00:10:39,960 --> 00:10:40,720
read layout

262
00:10:40,720 --> 00:10:43,200
read layout 就是数据的重排

263
00:10:43,200 --> 00:10:44,200
数据重排之后

264
00:10:44,360 --> 00:10:46,880
就得到最终的接近最终的结果

265
00:10:46,880 --> 00:10:47,800
最终结果之前

266
00:10:48,200 --> 00:10:49,480
A 也是提前算出来

267
00:10:49,480 --> 00:10:51,840
我们对它进行一个转换

268
00:10:51,840 --> 00:10:53,360
或者一个相乘

269
00:10:53,360 --> 00:10:55,320
得到新的数据的方式

270
00:10:55,320 --> 00:10:56,240
新的数据方式

271
00:10:56,560 --> 00:10:57,880
对它进行 rewrite

272
00:10:57,880 --> 00:10:59,280
write 成我们的 output

273
00:10:59,280 --> 00:11:02,040
这个就是卷机的最终的输出了

274
00:11:02,040 --> 00:11:03,000
整体这个流程

275
00:11:03,200 --> 00:11:05,480
就是 window grid 的算法了

276
00:11:05,680 --> 00:11:09,160
下面我们简单的对 window grid 这个算法

277
00:11:09,160 --> 00:11:11,280
进行一个回顾和思考

278
00:11:12,000 --> 00:11:14,040
虽然从原理看上去

279
00:11:14,360 --> 00:11:15,640
乘法减少了

280
00:11:15,640 --> 00:11:18,920
但好像算法的复杂度上升了

281
00:11:19,200 --> 00:11:22,920
下面我们看一下它整体的一个约束和缺点

282
00:11:22,920 --> 00:11:24,120
就是它的一些问题

283
00:11:24,640 --> 00:11:26,360
第一个点就是 window grid 这个算法

284
00:11:26,880 --> 00:11:29,680
非常不推荐在一些非常小的卷机盒

285
00:11:29,680 --> 00:11:32,640
或者一些非常小的一些卷机的方法里面去用的

286
00:11:32,640 --> 00:11:33,800
因为我们可以看到

287
00:11:33,800 --> 00:11:36,320
我们有大量的辅助的矩阵

288
00:11:36,320 --> 00:11:38,200
就刚才的 GBA

289
00:11:38,200 --> 00:11:40,000
这些辅助矩阵是非常大的

290
00:11:40,000 --> 00:11:41,680
会影响我们的实际的效果

291
00:11:42,040 --> 00:11:44,400
第二点就是不同规模的卷机

292
00:11:44,400 --> 00:11:47,400
需要使用不同规模的辅助矩阵

293
00:11:47,640 --> 00:11:51,280
实际上实时计算这些辅助矩阵是不现实的

294
00:11:51,280 --> 00:11:53,160
所以我们都会把它存起来

295
00:11:53,160 --> 00:11:54,080
而预存起来

296
00:11:54,200 --> 00:11:56,280
有可能会导致我们的存储

297
00:11:56,280 --> 00:11:58,880
或者我们的进程爆炸

298
00:11:59,240 --> 00:12:00,400
虽然 window grid 这个算法

299
00:12:00,560 --> 00:12:02,080
减少了我们的乘法的次数

300
00:12:02,080 --> 00:12:05,040
但是加法的数量也会相对应的增加

301
00:12:05,040 --> 00:12:08,560
而且我们的内存要存储辅助矩阵

302
00:12:08,560 --> 00:12:10,960
确实增加了我们的内存

303
00:12:10,960 --> 00:12:13,520
而随着我们的卷机盒的分块的尺寸增加

304
00:12:13,520 --> 00:12:16,400
我们还要考虑更多的加法和转换的代价

305
00:12:16,400 --> 00:12:18,760
而且每个切分的块越大

306
00:12:18,760 --> 00:12:20,200
转换矩阵就越大

307
00:12:20,200 --> 00:12:22,880
整体的计算精度也会有所损失

308
00:12:22,880 --> 00:12:25,640
所以说 window grid 这个算法

309
00:12:26,280 --> 00:12:29,800
基本上只适用于一些比较小的卷机盒和 TIE

310
00:12:30,600 --> 00:12:32,480
这个时候就很有意思了

311
00:12:32,480 --> 00:12:34,560
我们在实际的工程当中

312
00:12:34,560 --> 00:12:35,960
window grid 这个算法

313
00:12:35,960 --> 00:12:38,640
基本上只会对一些有限的

314
00:12:38,640 --> 00:12:41,400
3x3 的卷机进行一个运算

315
00:12:41,400 --> 00:12:43,280
1x1 的卷机不是用 window grid

316
00:12:43,280 --> 00:12:47,600
7x7 5x5 的卷机也不会启动 window grid 这个 kernel

317
00:12:47,600 --> 00:12:49,880
所以说还是很有意思的

318
00:12:49,880 --> 00:12:50,960
在 one time 的时候

319
00:12:51,120 --> 00:12:54,760
我们就会去决定我们到底用哪个 kernel

320
00:12:55,160 --> 00:12:58,560
那下面在具体时限上面的约束

321
00:12:58,600 --> 00:13:00,000
其实也是有的

322
00:13:00,400 --> 00:13:01,920
在实际时间当中

323
00:13:02,040 --> 00:13:03,240
我们最普遍的算法

324
00:13:03,240 --> 00:13:05,320
就是希望能够提前算出来

325
00:13:05,320 --> 00:13:06,680
提前能够固定的数据

326
00:13:07,160 --> 00:13:08,760
就提前把它做好

327
00:13:08,760 --> 00:13:10,600
所以我们会有一个预编译的阶段

328
00:13:10,600 --> 00:13:12,760
或者离线模块转换的阶段

329
00:13:12,760 --> 00:13:15,920
就是为了把一些能算的提前算出来

330
00:13:15,920 --> 00:13:17,120
在推丁引擎里面

331
00:13:17,240 --> 00:13:20,040
我们基本上不需要能够处理一些长尾的问题

332
00:13:20,040 --> 00:13:21,640
而是一些常用的

333
00:13:21,640 --> 00:13:23,680
或者一些很通用的算法问题

334
00:13:23,680 --> 00:13:25,640
或者一些通用的网络模型结构

335
00:13:25,640 --> 00:13:27,760
所以对于一些特定的网络模型结构

336
00:13:27,880 --> 00:13:29,120
假设G是固定的

337
00:13:29,120 --> 00:13:30,760
所以我们会把特定网络的G

338
00:13:31,000 --> 00:13:34,000
直接把它提前的算出来

339
00:13:34,000 --> 00:13:34,720
算好之后

340
00:13:34,720 --> 00:13:36,080
下一次直接运算就行了

341
00:13:36,080 --> 00:13:39,640
就不需要每一次我都需要重新的计算

342
00:13:39,640 --> 00:13:41,240
另外一个很自然的想法

343
00:13:41,240 --> 00:13:42,760
就是像我们刚才所说的

344
00:13:42,760 --> 00:13:45,880
它利用了空间的组织的方式

345
00:13:45,880 --> 00:13:47,280
跟 imagePlumb都一样的

346
00:13:47,280 --> 00:13:50,040
进行分片拆分

347
00:13:50,040 --> 00:13:51,520
将 input 的数据拆分成

348
00:13:51,520 --> 00:13:54,200
多个小规模的卷积

349
00:13:54,200 --> 00:13:56,200
这也是一个很好的优化方法

350
00:13:56,800 --> 00:13:59,160
好了,今天的内容就到这里为止

351
00:13:59,160 --> 00:14:00,200
我们今天主要是讲了

352
00:14:00,200 --> 00:14:03,440
WinQuery 怎幺去加速二维卷积的计算

353
00:14:03,440 --> 00:14:05,960
而这套公式就是 WinQuery 这个算法

354
00:14:05,960 --> 00:14:08,440
原来的论文推导出来的

355
00:14:08,440 --> 00:14:09,480
至于为什幺这幺推导

356
00:14:09,480 --> 00:14:11,920
我们在上面其实已经简单的介绍过

357
00:14:11,920 --> 00:14:13,480
可能我讲得不太清楚

358
00:14:13,480 --> 00:14:16,160
也希望欢迎大家去写更多的文章

359
00:14:16,160 --> 00:14:19,120
或者引发大家一个更好的一些思考

360
00:14:19,120 --> 00:14:21,120
今天的内容就先到这里为止

361
00:14:21,120 --> 00:14:22,640
谢谢各位,拜拜

362
00:14:22,640 --> 00:14:24,920
卷得不行了

363
00:14:24,960 --> 00:14:26,760
记得一键三连加关注哦

364
00:14:26,760 --> 00:14:28,360
所有的内容都会开源在

365
00:14:28,360 --> 00:14:30,360
下面这条链接里面

366
00:14:30,360 --> 00:14:31,600
拜拜

