0
0:00:00.000 --> 0:00:05.060
吧吧吧吧吧吧吧吧

1
0:00:05.060 --> 0:00:06.500
哈喽大家好我是宗米

2
0:00:06.500 --> 0:00:10.380
在这节课里面呢其实我已经NG了非常多遍才有

3
0:00:10.380 --> 0:00:11.640
今天这个视频

4
0:00:11.640 --> 0:00:14.140
而现在呢我们还是来到卷vey的优化

5
0:00:14.140 --> 0:00:17.860
我们看一下整体在推进期里面其实介绍了很多内容

6
0:00:17.860 --> 0:00:20.580
而我们现在呢集中在 kernels的优化

7
0:00:20.580 --> 0:00:24.600
而 kernels 的优化呢更多的算法优化是最核心的

8
0:00:24.600 --> 0:00:27.940
而算法的优化呢我们终于来到一个很核心的概念就是

9
0:00:27.940 --> 0:00:29.620
window grade这个内容

10
0:00:29.620 --> 0:00:34.340
而现在所有的工作呢都沉淀在我们的克洛城里面

11
0:00:34.340 --> 0:00:38.460
可以看到了我们其实在上一节课呢或者上两节内容里面呢

12
0:00:38.460 --> 0:00:43.900
简单地去介绍一个卷迹的概念什么是Image Clamp还有空间组合的优化

13
0:00:43.900 --> 0:00:49.860
在这一节里面呢我们重点地去看看Vinograd这个算法的优化

14
0:00:49.860 --> 0:00:55.700
这个算法呢叫做Vinograd它不是贵的它不是求导的缩写

15
0:00:55.700 --> 0:00:59.500
因为呢这个算法呢是Vinograd这个人他是个人民

16
0:00:59.500 --> 0:01:02.780
最早在一九八零年的时候已经发表了这篇文章

17
0:01:02.780 --> 0:01:08.700
但是呢当时候并没有引起太多的轰动啊因为那个时候卷迹的计算还不是没有现在这么火

18
0:01:08.700 --> 0:01:11.460
而且计算量也没有今天这么复杂

19
0:01:11.460 --> 0:01:18.820
到了随飘二零一六年呢又有人基于Vinograd这个算法呢重新地提出了一篇新的文章

20
0:01:18.820 --> 0:01:23.660
这个算法呢迅速地在我们整个算法的圈里面呢火起来

21
0:01:23.660 --> 0:01:27.460
现在呢有很多推力引擎呢都会去实现Vinograd这个算法

22
0:01:27.460 --> 0:01:32.260
包括Models for Light了MMN这些很多推力引擎呢都会去实现的

23
0:01:32.260 --> 0:01:43.380
里面最核心的一个原理呢就是使用把很多大量的矩阵层或者大量的单减的层法变成加法的操作或者减少层法的操作

24
0:01:43.380 --> 0:01:48.420
那下面呢我们看一下具体的一个算法的原理算法原理我会很快地过掉

25
0:01:48.420 --> 0:01:52.060
然后更多的是希望跟大家去看看工程的实现部分

26
0:01:52.060 --> 0:01:56.540
首先呢我们现在有一个输的信号呢是我们的FF有很多的数据嘛

27
0:01:56.540 --> 0:02:02.340
然后呢现在有个卷积和卷积的最小的计算那肯定会有卷积和居零居一居二

28
0:02:02.340 --> 0:02:08.340
那整个卷积的计算呢我们把它换成一个ImageColumn的方式呢就变成两个矩阵相乘

29
0:02:08.340 --> 0:02:13.900
于是呢有低零低一低二乘以居一居二居三就变成我们的阿零

30
0:02:13.900 --> 0:02:24.180
然后接着有低第二低三在同样的乘以居零居一居二就得到我们的阿一这个就是我们的卷积ImageColumn的计算方式

31
0:02:24.180 --> 0:02:32.500
实际的计算操作呢阿零呢就等于这条公式阿一等于这条公式里面呢很核心的就是用了三次的乘法两次的加法

32
0:02:32.500 --> 0:02:39.500
一共呢就用了六次的乘法四次的加法数据量这么少就已经用了非常多的乘加的操作

33
0:02:39.500 --> 0:02:46.580
于是呢温多贵这个算法呢确实希望能够极大地去减少我们的乘法的操作

34
0:02:46.580 --> 0:02:52.380
因为这里面有很多元素都是相同的相同的元素能不能提前算出来

35
0:02:52.380 --> 0:02:58.780
不要每次都算一遍了据这个思想了温多贵就证明了有几条公式

36
0:02:58.780 --> 0:03:06.980
首先呢刚才的那个矩阵乘呢实际上是可以等于m一加m二加m三m二减m三减m四

37
0:03:06.980 --> 0:03:15.580
那这些m一m二m三m四呢他们希望能够能够提前算出来的像这两个呢就先提前算出来

38
0:03:15.580 --> 0:03:20.540
另外一些呢就可以大量地复用就大量地复用里面的操作

39
0:03:20.540 --> 0:03:33.020
或里面已经算好的数据所以说整个算法或者整个卷迹的操作呢就变成阿零阿一等加于上面的这条公式

40
0:03:33.020 --> 0:03:41.140
下面呢我们简单地去根据这条公式呢反向的推导它的一个成立的方式

41
0:03:41.140 --> 0:03:46.420
下面我们看一下温多贵的的原理推导啊我们现在有刚才有那条公式嘛

42
0:03:46.420 --> 0:03:56.780
所以我们现在的m一加m二加m三m二减m三减m四呢等于阿零下面等于阿一现在呢我另m一呢和m四呢等于下面两条

43
0:03:56.780 --> 0:04:03.300
于是呢我们下面就可以约掉m一和m四于是重新得到了下面的一个新的公式

44
0:04:03.300 --> 0:04:15.060
哎约掉还不够我们现在观察m二呢实际上它里面包含非常多的数据我们希望把这里面的数据呢重新的减少将其呢转换成为多项式然后进行一个拆分

45
0:04:15.060 --> 0:04:23.940
于是呢我们重新的得到m二的公式同理我们对m三呢也进行如上的操作于是呢我们重新得到m一m二m三

46
0:04:23.940 --> 0:04:44.140
那这个时候呢我们实际上有两条公式就还是那条公式我们在m二和m三呢同时加上一个值其实b公式呢是不变的但是a公式呢我们需要给m一减去两倍的值那这个加上这个值这个值是什么呢是下面的这条公式可以同时进行转换和约减

47
0:04:44.140 --> 0:05:13.980
那这个时候m一m二m三重新的计算呢就等于下面这条公式但是呢我们假设给m二同时加上一个值给m三减去一个值这个值还是变成另外一条公式呢这个时候呢我们就可以重新的去计算整体的m一m二m三m四就有了一种新的计算的公式而下面这一个呢也是像我们刚才所说的它可以提前算好算出来而我们整个矩阵层呢就没有那么复杂了

48
0:05:13.980 --> 0:05:25.020
通过m一m二m三呢我们就可以极大的减少了我们的计算当然了这里听不懂没有关系我们还是回到重点就是我们的工程的实现

49
0:05:25.020 --> 0:05:40.260
那具体的算法原理为什么这么推导其实很多人或者在科诺的算法优化工程师里面呢不知道也不影响我们后续的工作大家只需要知道我们确实有这种算法能够很好的加快我们的工作就行了加快我们的科诺的计算

50
0:05:40.260 --> 0:06:00.300
下面呢我们把刚才的那条公式就y呢就是我们的输出嘛我们的g呢有一个卷积和d呢就是我们的feature map而这个小g呢就是我们的一个卷积和的变换矩阵大b呢就是我们输入的数据的变换矩阵而a t呢就是我们输出的数据的变换矩阵

51
0:06:00.300 --> 0:06:30.300
而把刚才的那条计算公式就manowar的这个算法呢转换成为具体的矩阵层而这里面的三个参数其实都可以提前算出来的提前算出来之后呢只需要放在内存里面让它去读就能就可以把我们的feature map和权重呢进行一个简单的矩阵层呢就可以得到我们最终的卷积和的输出那这个呢就是最简单的原理同样放在二维里面呢也是成立的只不过二维的计算公式呢可能

52
0:06:30.300 --> 0:07:00.300
会稍微更加复杂一点点下面呢我们来看看整体的一个一米计划的展开的方式是下面这一条把所有的输入的feature map呢进行一个重排另外方面呢对克诺斯的这个数据呢进行重排得到新的数据哎有人就会想问了或者小新就可能会跳出来问了这个跟mino管有什么区别呢这不就一米计划的计算方式吗很有意思我们看看下面这条内容

53
0:07:00.300 --> 0:07:04.780
这面可以看到了基本上就变成我们的vnogrid的计算方式了

54
0:07:04.780 --> 0:07:09.020
而m一加m二加m三m二减m三减m四呢

55
0:07:09.020 --> 0:07:17.740
这条公式的计算呢就是对应于刚才的m一m二m三m四四个数的计算了

56
0:07:17.740 --> 0:07:21.660
下面我们看一下具体vnogrid的工程实现

57
0:07:21.660 --> 0:07:28.860
大家听不懂也没有关系后面我会把这些都整理成一个文档然后方便大家去取悦

58
0:07:28.860 --> 0:07:36.140
下面我们重新的看一下整体的工程实现工程实现主要分开四个步骤我们往下面这个图看一看

59
0:07:36.140 --> 0:07:45.780
首先呢我们会对输入的卷积和进行一个变换那变换的就是我们的u了大区乘以小区然后乘以大区的t

60
0:07:45.780 --> 0:07:56.500
接着呢我们第二步就是对输入的数据进行变换得到我们的v大b乘以d低我们的输入的feature map嘛然后再乘以b

61
0:07:56.540 --> 0:08:11.420
第三步呢就是对我们的m矩阵进行计算就我们的vnogrid的具体的算法把v和u两个矩阵进行相乘最后一步呢就是计算输出的结果乘以at

62
0:08:11.420 --> 0:08:24.900
哎看上去好像还是挺简单的并不复杂而且这里面的gb和a呢都是提前算出来的至于怎么算出来呢就是根据我刚才推导的公式来去算出来的

63
0:08:25.140 --> 0:08:45.060
现在呢我们看一下具体的实现的步骤刚才说第一步呢是首先算我们的大区和gt那这个gt怎么来的就是真的是通过公式推导的通过公式推导之前呢提前算好这个大区而这个大区呢我们确实有一条公式可以算现在呢也有一个github的网站可以给大家去算出来

64
0:08:45.060 --> 0:08:46.060
大家打开这个github的网站呢就可以把我们刚才的vnogrid的这个先的一些群众提前的算出来我这边呢就不带着大家一起去算了大家可以去用一下这边就可以看到at他提前给我们算出来b也给我们算出来g也给我们算出来了所以还是挺有意思的现在我们重新的回到我们的slidePPT里面假设我们的g呢已经提前算出来了现在呢我们需要通过vnogrid这个变换呢

65
0:09:15.060 --> 0:09:45.060
把g和gt呢把三乘三的群众呢转换成为四乘四的矩阵下面的首先第一步是对群众进行转换那群众进行转换呢前面有个大区后面有个大区我们就把群众的数据呢转换成为一个四乘四的矩阵而这里面的ic就是我们的channels的大小然后把这个张亮里面相同位置的点假设我们现在以蓝色为例转换成为一个ic乘以oc的矩阵这里面是

66
0:09:45.060 --> 0:10:15.060
蓝色我们把它全部都从牌展开成为这么一列oc乘以ic四乘四乘以十六这么一个具体的矩阵那转换成为这个矩阵呢只是为了后面的矩阵层方便去运算那第二步骤呢是对我们的feature map去输入的数据呢进行转换同样这个数据呢我们有个大b还有个bt那进行一个具体的相乘之后呢我们就会对它进行重新的转换成为另外一个张亮的形式

67
0:10:15.060 --> 0:10:45.060
同样的我们对这个张亮的形式呢进行一个数据的重排这边呢有一个withlayout就是确实需要进行数据的重排重排完之后呢同样我们这里面是四乘四乘以十六的这种方式下面假设a就是我们的feature map的输入b就是我们的权重这两个矩阵呢进行一个相乘之后呢就得到一个新的矩阵新的矩阵确实也需要进行一个withlayout的withlayout就是重排数据的重排数据重排之后呢就得到

68
0:10:45.060 --> 0:11:15.060
最终的接近最终的结果最终结果之前呢这个a也是提前算出来我们对它进行一个转换或者一个相乘得到新的数据的方式新的数据方式呢对它进行rewrite外称我们的output这个就是卷机的最终的输出了整体这个流程呢就是Window Grid的算法了那下面呢我们简单地对Window Grid这个算法进行一个回顾和思考虽然呢从原理看上去呢乘法

69
0:11:15.060 --> 0:11:45.060
减少了但好像算法的复杂度上升了下面呢我们看一下它整体的一个约束和缺点就是它的一些问题嘛第一个点呢就是Window Grid这个算法呢非常不推荐在一些非常小的卷机盒或者一些非常小的一些卷机的方法里面去用的因为我们可以看到我们有大量的辅助的矩阵就刚才的GBA这些辅助矩阵是非常大的会影响我们的实际的效果第二点呢就是不同规模的卷机需要使用

70
0:11:45.060 --> 0:11:47.420
不同规模的辅助矩阵

71
0:11:47.420 --> 0:11:51.380
那实际上呢实时计算这些辅助矩阵是不现实的

72
0:11:51.380 --> 0:11:53.180
所以我们都会把它存起来

73
0:11:53.180 --> 0:11:59.140
而欲存起来呢又可能会导致我们的存储或者我们的程序爆炸

74
0:11:59.140 --> 0:12:05.060
虽然Window Grid这个算法呢减少了我们乘法的次数但是加法的数量呢也会相对应的增加

75
0:12:05.060 --> 0:12:11.020
而且我们的内存呢要存储辅助矩阵确实增加了我们的内存

76
0:12:11.020 --> 0:12:16.460
而随着我们的卷机盒的分块的尺寸增加我们还要考虑更多的加法和转换的代价

77
0:12:16.460 --> 0:12:22.980
而且每个切分的块越大转换矩阵就越大整体的计算精度呢也会有所损失

78
0:12:22.980 --> 0:12:30.220
所以说Window Grid这个算法基本上只适用于一些比较小的卷机盒和钛

79
0:12:30.220 --> 0:12:40.980
那这个时候就很有意思了我们在实际的工程当中啊Window Grid这个算法基本上只会对一些有限的三乘三的卷机进行一个运用

80
0:12:40.980 --> 0:12:47.500
一乘一的卷机不受Window Grid七乘七五乘五的卷机也不会启动Window Grid这个科诺

81
0:12:47.500 --> 0:12:54.740
所以说还是很有意思的在温摊的时候呢我们就会去决定我们到底用哪个科诺

82
0:12:54.740 --> 0:12:59.980
那下面呢在具体时限上面的约束其实也是有的

83
0:12:59.980 --> 0:13:08.500
在实际时间当中呢我们最普遍的算法就是希望能够提前算出来提前能够固定了数据呢就提前把它做好

84
0:13:08.500 --> 0:13:15.740
所以我们会有一个预编译的阶段或者一些模块转换的阶段就是为了把一些能算的提前算出来

85
0:13:15.740 --> 0:13:25.500
在推定引擎里面呢我们基本上不希望能够处理一些常为的问题而是一些常用的或者一些很通用的算法问题或者一些通用的网络模型结构

86
0:13:25.500 --> 0:13:28.980
所以对一些特定的网络模型结构呢假设据是固定的

87
0:13:28.980 --> 0:13:37.540
所以我们会把特定网络的据呢直接把它提前地算出来算好之后下一次直接运算就行了就不需要每一次

88
0:13:37.540 --> 0:13:45.860
我都需要重新地计算另外一个很自然的想法就是像我们刚才所说的它利用了空间的组织的方式

89
0:13:45.860 --> 0:13:56.260
跟一米数差不多一样地进行分片拆分将input的数据呢拆分成若干个小规模的卷积这也是一个很好的优化方法

90
0:13:56.260 --> 0:14:07.420
好了今天的内容呢就到这里为止我们今天主要是讲了微诺贵怎么去加速二维卷积的计算而这套公式呢就是微诺贵这个算法原来的论文

91
0:14:07.420 --> 0:14:31.260
推导出来的至于为什么这么推导了我们在上面呢其实已经简单地介绍过可能我讲得不太清楚也希望欢迎大家去写更多的文章或者引发大家一个更好的一些思考那今天的内容呢就先到这里为止谢谢各位摆了个掰卷的不行了卷的不行了记得一键三连加关注哦所有的内容都会开源在下面这条链接里面摆了个掰

