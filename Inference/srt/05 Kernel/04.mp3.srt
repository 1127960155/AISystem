0
0:00:00.000 --> 0:00:06.520
Hello大家好我是宗明

1
0:00:06.520 --> 0:00:09.720
在这一节课里面其实我已经NG了非常多遍

2
0:00:09.720 --> 0:00:11.600
才有今天这个视频

3
0:00:11.600 --> 0:00:13.960
现在我们还是来到卷机的优化

4
0:00:13.960 --> 0:00:17.800
我们看一下整体在推进期里面其实介绍了很多内容

5
0:00:17.800 --> 0:00:20.480
而我们现在集中在 Kernels 的优化

6
0:00:20.480 --> 0:00:24.520
而 Kernels 的优化更多的算法优化是最内核的

7
0:00:24.520 --> 0:00:27.440
而算法的优化我们终于来到一个很内核的概念

8
0:00:27.440 --> 0:00:29.560
就是 Winogrid 这个内容

9
0:00:29.600 --> 0:00:34.240
而现在所有的工作都沉淀在我们的 Kernel 城里面

10
0:00:34.240 --> 0:00:38.440
可以看到了我们其实在上一节课或者上两节内容里面

11
0:00:38.440 --> 0:00:40.640
简单的去介绍一个卷机的概念

12
0:00:40.640 --> 0:00:43.840
什幺是 Image Clamp 还有空间组合的优化

13
0:00:43.840 --> 0:00:49.720
在这一节里面我们重点的去看看 Winogrid 这个算法的优化

14
0:00:49.720 --> 0:00:52.120
这个算法叫做 Winogrid

15
0:00:52.120 --> 0:00:55.520
它不是 Grid 它不是球岛的缩写

16
0:00:55.520 --> 0:00:57.880
因为这个算法是 Winogrid

17
0:00:57.880 --> 0:00:59.480
这个人他是个人民

18
0:00:59.480 --> 0:01:02.760
最早在 1980 年的时候已经发表了这篇文章

19
0:01:02.760 --> 0:01:05.320
但是当时并没有引起太多的轰动了

20
0:01:05.320 --> 0:01:08.640
因为那个时候卷机的计算还不是没有现在这幺火

21
0:01:08.640 --> 0:01:11.440
而且计算量也没有今天这幺复杂

22
0:01:11.440 --> 0:01:15.280
到了 3PL 2016 年又有人基于 Winogrid 这个算法

23
0:01:15.280 --> 0:01:18.760
重新的提出了一篇新的文章

24
0:01:18.760 --> 0:01:23.600
这个算法迅速的在我们整个算法的圈里面火起来

25
0:01:23.600 --> 0:01:27.440
现在有很多推理引擎都会去实现 Winogrid 这个算法

26
0:01:27.440 --> 0:01:28.960
包括 Minespot Lite 了

27
0:01:28.960 --> 0:01:32.240
MMN 这些很多推理引擎都会去实现的

28
0:01:32.240 --> 0:01:37.760
里面最内核的一个原理就是使用把很多大量的矩阵乘

29
0:01:37.760 --> 0:01:41.600
或者大量的单点的乘法变成加法的操作

30
0:01:41.600 --> 0:01:43.280
或者减少乘法的操作

31
0:01:43.280 --> 0:01:46.360
那下面我们看一下具体的一个算法的原理

32
0:01:46.360 --> 0:01:48.400
算法原理我会很快的过掉

33
0:01:48.400 --> 0:01:52.000
然后更多的是希望跟大家去看看工程的实现部分

34
0:01:52.000 --> 0:01:55.120
首先我们现在有一个输的信号是我们的 FF

35
0:01:55.120 --> 0:01:56.480
有很多的数据

36
0:01:56.520 --> 0:01:59.760
然后现在有个卷积和卷积的最小的计算

37
0:01:59.760 --> 0:02:02.240
那肯定会有卷积和 G0 G1 G2

38
0:02:02.240 --> 0:02:06.200
那整个卷积的计算我们把它换成一个 ImageColumn 的方式

39
0:02:06.200 --> 0:02:08.280
就变成两个矩阵相乘

40
0:02:08.280 --> 0:02:13.840
于是有 D0 D1 D2 乘以 G1 G2 G3 就变成我们的 R0

41
0:02:13.840 --> 0:02:15.840
然后接着有 D1 D2 D3

42
0:02:15.840 --> 0:02:19.680
再同样的乘以 G0 G1 G2 就得到我们的 R1

43
0:02:19.680 --> 0:02:23.760
这个就是我们的卷积 ImageColumn 的计算方式

44
0:02:24.240 --> 0:02:27.000
实际的计算操作 R0 就等于这条公式

45
0:02:27.000 --> 0:02:28.040
R1 等于这条公式

46
0:02:28.040 --> 0:02:32.480
里面的很内核的就是用了三次的乘法两次的加法

47
0:02:32.480 --> 0:02:35.680
一共就用了六次的乘法四次的加法

48
0:02:35.680 --> 0:02:39.560
数据量这幺少就已经用了非常多的乘加的操作

49
0:02:39.560 --> 0:02:41.040
于是 Winograd 这个算法

50
0:02:41.040 --> 0:02:46.600
确实希望能够极大的去减少我们的乘法的操作

51
0:02:46.600 --> 0:02:49.480
因为这里面有很多元素都是相同的

52
0:02:49.480 --> 0:02:52.400
相同的元素能不能提前算出来

53
0:02:52.440 --> 0:02:54.160
不要每次都算一遍了

54
0:02:54.160 --> 0:02:57.360
据这个思想 Winograd 就证明了

55
0:02:57.360 --> 0:02:58.840
有几条公式

56
0:02:58.840 --> 0:03:00.960
首先刚才的那个矩阵乘

57
0:03:00.960 --> 0:03:07.040
实际上是可以等于 M1 M2 M3 M2-M3-M4

58
0:03:07.040 --> 0:03:09.440
那这些 M1 M2 M3 M4

59
0:03:09.440 --> 0:03:12.640
他们希望能够提前算出来的

60
0:03:12.640 --> 0:03:15.600
像这两个就先提前算出来

61
0:03:15.600 --> 0:03:17.920
另外一些就可以大量的复用

62
0:03:17.920 --> 0:03:20.560
就大量的复用里面的操作

63
0:03:20.560 --> 0:03:23.080
和里面已经算好的数据

64
0:03:23.080 --> 0:03:26.640
所以说整个算法或者整个卷迹的操作

65
0:03:26.640 --> 0:03:32.920
就变成 R0 R1等加于上面的这条公式

66
0:03:32.920 --> 0:03:36.200
下面我们简单的去根据这条公式

67
0:03:36.200 --> 0:03:39.680
反向的推导它的一个成立的方式

68
0:03:41.080 --> 0:03:43.600
下面我们看一下 Winograd 的原理推导

69
0:03:43.600 --> 0:03:46.360
我们现在有刚才有那条公式

70
0:03:46.360 --> 0:03:50.800
所以我们现在 M1 M2 M3 M2-M3-M4

71
0:03:50.800 --> 0:03:52.680
等于 R0 下面等于 R1

72
0:03:52.680 --> 0:03:56.680
现在我令 M1和M4等于下面两条

73
0:03:56.680 --> 0:03:59.520
于是我们下面就可以约掉 M1和M4

74
0:03:59.520 --> 0:04:03.240
于是重新得到了下面的一个新的公式

75
0:04:03.240 --> 0:04:04.520
约掉还不够

76
0:04:04.520 --> 0:04:05.840
我们现在观察 M2

77
0:04:05.840 --> 0:04:08.640
实际上它里面包含非常多的数据

78
0:04:08.640 --> 0:04:11.320
我们先把这里面的数据重新的减少

79
0:04:11.320 --> 0:04:13.400
将其转换成为多项式

80
0:04:13.400 --> 0:04:15.000
然后进行一个拆分

81
0:04:15.040 --> 0:04:17.920
于是我们重新的得到 M2 的公式

82
0:04:17.920 --> 0:04:20.800
同理我们对 M3 也进行无上的操作

83
0:04:20.800 --> 0:04:23.840
于是我们重新得到 M1 M2 M3

84
0:04:23.840 --> 0:04:26.800
这个时候我们实际上有两条公式

85
0:04:26.800 --> 0:04:28.120
就还是那条公式

86
0:04:28.120 --> 0:04:31.160
我们在 M2 和 M3 同时加上一个值

87
0:04:31.160 --> 0:04:33.080
其实 B 公式是不变的

88
0:04:33.080 --> 0:04:36.920
但是 A 公式我们需要给 M1 减去两倍的值

89
0:04:36.920 --> 0:04:38.400
那这个加上这个值

90
0:04:38.400 --> 0:04:39.520
这个值是什幺呢

91
0:04:39.520 --> 0:04:41.320
是下面的这条公式

92
0:04:41.320 --> 0:04:44.080
可以同时进行转换和约减

93
0:04:44.120 --> 0:04:47.280
那这个时候 M1 M2 M3 重新的计算

94
0:04:47.280 --> 0:04:48.920
就等于下面这条公式

95
0:04:48.920 --> 0:04:52.560
但是我们假设给 M2 同时也加上一个值

96
0:04:52.560 --> 0:04:54.440
给 M3 减去一个值

97
0:04:54.440 --> 0:04:56.880
这个值还是变成另外一条公式

98
0:04:56.880 --> 0:04:59.680
这个时候我们就可以重新的去计算

99
0:04:59.680 --> 0:05:02.160
整体的 M1 M2 M3 M4

100
0:05:02.160 --> 0:05:04.880
就有了一种新的计算的公式

101
0:05:04.880 --> 0:05:07.760
而下面这一个也是像我们刚才所说的

102
0:05:07.760 --> 0:05:10.840
它可以提前算好算出来

103
0:05:10.840 --> 0:05:13.920
而我们整个矩阵层就没有那幺复杂了

104
0:05:13.920 --> 0:05:15.280
通过 M1 M2 M3

105
0:05:15.280 --> 0:05:18.080
我们就可以极大的减少了我们的计算

106
0:05:18.080 --> 0:05:20.440
当然了这里听不懂没有关系

107
0:05:20.440 --> 0:05:22.480
我们还是回到重点

108
0:05:22.480 --> 0:05:24.920
就是我们的工程的实现

109
0:05:24.920 --> 0:05:27.320
那具体的算法原理为什幺这幺推导

110
0:05:27.320 --> 0:05:31.000
其实很多人或者在 kernel 的算法优化工程师里面

111
0:05:31.000 --> 0:05:33.440
不知道也不影响我们后续的工作

112
0:05:33.440 --> 0:05:36.040
大家只需要知道我们确实有这种算法

113
0:05:36.040 --> 0:05:38.280
能够很好的加快我们的工作就行了

114
0:05:38.280 --> 0:05:40.200
加快我们的 kernel 的计算

115
0:05:40.200 --> 0:05:42.680
下面我们把刚才的那条公式

116
0:05:42.720 --> 0:05:44.120
就 y 就是我们的输出

117
0:05:44.280 --> 0:05:46.240
我们的 g 有一个卷集和

118
0:05:46.240 --> 0:05:47.760
d 就是我们的 feature map

119
0:05:47.760 --> 0:05:52.720
而小 g 就是我们的一个卷集和的变换矩阵

120
0:05:52.720 --> 0:05:57.240
大 b 就是我们输入的数据的变换矩阵

121
0:05:57.240 --> 0:06:00.280
而 at 就是我们输出的数据的变换矩阵

122
0:06:00.280 --> 0:06:02.200
我们把刚才的那条计算公式

123
0:06:02.200 --> 0:06:03.480
就 manowar 的这个算法

124
0:06:03.480 --> 0:06:05.920
转换成为具体的矩阵层

125
0:06:05.920 --> 0:06:11.320
而这里面三个参数其实都可以提前算出来的

126
0:06:11.320 --> 0:06:12.320
提前算出来之后

127
0:06:12.440 --> 0:06:13.760
只需要放在内存里面

128
0:06:13.760 --> 0:06:14.840
让它去读

129
0:06:14.840 --> 0:06:17.560
之后就会把我们的 feature map 和权重

130
0:06:17.560 --> 0:06:19.240
进行一个简单的矩阵层

131
0:06:19.440 --> 0:06:22.680
就可以得到我们最终的卷集和的输出

132
0:06:22.920 --> 0:06:24.840
这个就是最简单的原理

133
0:06:24.840 --> 0:06:27.680
同样放在二维里面也是成立的

134
0:06:27.680 --> 0:06:29.320
只不过二维的计算公式

135
0:06:29.680 --> 0:06:32.760
可能会稍微更加复杂一点点

136
0:06:32.760 --> 0:06:36.080
下面我们来看看整体的一个

137
0:06:36.080 --> 0:06:37.600
initialize.cum.的展开的方式

138
0:06:37.600 --> 0:06:38.640
是下面这一条

139
0:06:38.640 --> 0:06:40.560
把所有的输入的 feature map

140
0:06:40.640 --> 0:06:42.000
进行一个重排

141
0:06:42.320 --> 0:06:44.360
另外一方面对 kernels 的数据

142
0:06:44.520 --> 0:06:45.520
进行重排

143
0:06:45.520 --> 0:06:46.920
得到新的数据

144
0:06:46.920 --> 0:06:49.440
有人就会想问了

145
0:06:49.440 --> 0:06:51.800
或者小新就可能会跳出来问了

146
0:06:51.800 --> 0:06:54.080
这个跟 window 管有什幺区别呢

147
0:06:54.080 --> 0:06:56.520
这不就 initialize.cum.的计算方式吗

148
0:06:56.520 --> 0:06:57.520
很有意思的

149
0:06:57.520 --> 0:07:00.160
我们看一看下面这条内容

150
0:07:00.160 --> 0:07:01.120
这里面可以看到

151
0:07:01.360 --> 0:07:02.440
基本上就变成我们的

152
0:07:02.440 --> 0:07:04.360
window管的计算方式了

153
0:07:04.760 --> 0:07:06.560
而 m1加 m2加 m3

154
0:07:06.560 --> 0:07:08.240
m2-m3-m4

155
0:07:09.040 --> 0:07:10.440
这条公式的计算

156
0:07:10.680 --> 0:07:15.160
就是对应于刚才的 m1-m2-m3-m4

157
0:07:15.160 --> 0:07:16.640
四个数的计算了

158
0:07:17.680 --> 0:07:18.960
下面我们看一下

159
0:07:18.960 --> 0:07:21.480
具体 window grid 的工程实现

160
0:07:21.480 --> 0:07:22.880
大家听不懂也没有关系

161
0:07:22.880 --> 0:07:26.680
后面我会把这些都整理成一个文档

162
0:07:26.680 --> 0:07:28.680
然后方便大家去取悦

163
0:07:28.680 --> 0:07:30.440
下面我们重新的看一下

164
0:07:30.440 --> 0:07:31.440
整体的工程实现

165
0:07:31.440 --> 0:07:33.320
工程实现主要分开四个步骤

166
0:07:33.320 --> 0:07:36.000
我们往下面这个图看一看

167
0:07:36.000 --> 0:07:39.640
首先我们会对输入的卷积和

168
0:07:39.640 --> 0:07:40.680
进行一个变换

169
0:07:40.680 --> 0:07:42.600
变换就是我们的 U

170
0:07:42.600 --> 0:07:45.280
G G T

171
0:07:45.800 --> 0:07:46.960
接着我们第二步

172
0:07:46.960 --> 0:07:50.600
就是对输入的数据进行变换

173
0:07:50.600 --> 0:07:51.800
得到我们的 V

174
0:07:51.800 --> 0:07:53.400
B D D

175
0:07:53.400 --> 0:07:54.720
我们的输入的 feature map

176
0:07:55.080 --> 0:07:56.440
然后再乘以 B

177
0:07:56.440 --> 0:07:59.520
第三步就是对我们的 m 矩阵

178
0:07:59.520 --> 0:08:00.480
进行计算

179
0:08:00.480 --> 0:08:02.400
就我们的 window grid 具体的算法

180
0:08:02.400 --> 0:08:06.560
把 V 和 U 两个矩阵进行相乘

181
0:08:06.560 --> 0:08:09.440
最后一步就是计算输出的结果

182
0:08:09.560 --> 0:08:11.120
乘以 A T

183
0:08:11.120 --> 0:08:14.680
看上去好像还是挺简单的

184
0:08:14.680 --> 0:08:15.520
并不复杂

185
0:08:15.520 --> 0:08:18.360
而且这里面的 G B和 A

186
0:08:18.600 --> 0:08:21.000
都是提前算出来的

187
0:08:21.000 --> 0:08:22.040
至于怎幺算出来

188
0:08:22.200 --> 0:08:23.680
就是根据我刚才推导的公式

189
0:08:23.680 --> 0:08:24.680
来去算出来的

190
0:08:24.680 --> 0:08:26.360
现在我们看一下

191
0:08:26.360 --> 0:08:28.360
具体的实现的步骤

192
0:08:28.360 --> 0:08:29.240
刚才说第一步

193
0:08:29.440 --> 0:08:32.080
是首先算我们的 G和 T

194
0:08:32.080 --> 0:08:33.360
那这个 G T 怎幺来的

195
0:08:33.360 --> 0:08:35.360
就是真的是通过公式推导的

196
0:08:35.360 --> 0:08:36.520
通过公式推导之前

197
0:08:36.840 --> 0:08:39.320
提前算好这个 G

198
0:08:39.400 --> 0:08:40.160
而这个大 G

199
0:08:40.280 --> 0:08:41.920
我们确实有一条公式可以算

200
0:08:41.920 --> 0:08:43.640
现在也有一个 GitHub 的网站

201
0:08:43.640 --> 0:08:45.120
可以给大家去算出来

202
0:08:46.240 --> 0:08:48.080
大家打开 GitHub 的网站

203
0:08:48.240 --> 0:08:50.040
就可以把我们刚才的

204
0:08:50.040 --> 0:08:53.280
window grid 的 CNN 的一些全纵

205
0:08:53.440 --> 0:08:55.000
提前的算出来

206
0:08:55.000 --> 0:08:56.920
我这边就不带着大家一起去算了

207
0:08:56.920 --> 0:08:58.160
大家可以去用一下

208
0:08:58.160 --> 0:08:59.680
这边就可以看到 A T

209
0:08:59.680 --> 0:09:01.080
它提前给我们算出来

210
0:09:01.080 --> 0:09:02.280
B 也给我们算出来

211
0:09:02.280 --> 0:09:03.840
G 也给我们算出来了

212
0:09:03.840 --> 0:09:05.320
所以还是挺有意思的

213
0:09:05.520 --> 0:09:06.840
现在我们重新的回到

214
0:09:06.840 --> 0:09:08.760
我们的 slide ppt 里面

215
0:09:08.880 --> 0:09:11.640
假设我们的 G 已经提前算出来了

216
0:09:11.640 --> 0:09:13.320
现在我们需要通过

217
0:09:13.320 --> 0:09:14.520
window grid 这个变换

218
0:09:14.920 --> 0:09:16.200
把 G 和 G T

219
0:09:16.680 --> 0:09:18.200
把三乘三的全纵

220
0:09:18.440 --> 0:09:21.200
转换成为四乘四的矩阵

221
0:09:21.480 --> 0:09:24.680
下面首先第一步是对全纵进行转换

222
0:09:24.960 --> 0:09:25.880
全纵进行转换

223
0:09:26.200 --> 0:09:27.240
前面有个大 G

224
0:09:27.240 --> 0:09:28.080
后面有个大 G

225
0:09:28.080 --> 0:09:29.680
我们就把全纵的数据

226
0:09:29.920 --> 0:09:32.760
转换成为一个四乘四的矩阵

227
0:09:32.760 --> 0:09:33.800
而这里面 IC

228
0:09:33.800 --> 0:09:35.560
就是我们的 channels 的大小

229
0:09:35.560 --> 0:09:38.120
然后把这个脏量里面相同位置的点

230
0:09:38.120 --> 0:09:39.840
假设我们现在以蓝色为例

231
0:09:39.840 --> 0:09:44.120
转换成为一个 IC 乘以 OC 的矩阵

232
0:09:44.360 --> 0:09:45.320
这里面是蓝色

233
0:09:45.320 --> 0:09:47.600
我们把它全部都重排

234
0:09:47.880 --> 0:09:49.600
展开成为这幺一列

235
0:09:49.600 --> 0:09:50.800
OC 乘以 IC

236
0:09:50.800 --> 0:09:52.080
四乘四乘以 16

237
0:09:52.080 --> 0:09:54.760
这幺一个具体的矩阵

238
0:09:54.760 --> 0:09:56.440
那转换成为这个矩阵

239
0:09:56.600 --> 0:09:58.520
只是为了后面的矩阵层

240
0:09:58.520 --> 0:09:59.760
方便去运算

241
0:10:00.080 --> 0:10:02.160
第二个步骤是对我们的 feature map

242
0:10:02.160 --> 0:10:04.520
就输入的数据进行转换

243
0:10:04.520 --> 0:10:05.560
同样这个数据

244
0:10:05.720 --> 0:10:07.840
我们有一个大 B 还有个 B T

245
0:10:08.000 --> 0:10:09.880
进行一个具体的相乘之后

246
0:10:10.120 --> 0:10:12.640
我们就会对它进行重新的转换

247
0:10:12.640 --> 0:10:15.320
成为另外一个脏量的形式

248
0:10:15.320 --> 0:10:17.720
同样的我们对脏量的形式

249
0:10:18.080 --> 0:10:20.360
进行一个数据的重排

250
0:10:20.360 --> 0:10:21.680
这边有一个 read layout

251
0:10:21.680 --> 0:10:24.040
就是确实需要进行数据的重排

252
0:10:24.040 --> 0:10:24.920
重排完之后

253
0:10:25.120 --> 0:10:27.880
同样我们这里面是四乘四乘以16

254
0:10:27.880 --> 0:10:29.120
的这种方式

255
0:10:29.120 --> 0:10:31.320
下面假设 A 就是我们的 feature map 的输入

256
0:10:31.320 --> 0:10:32.880
B 就是我们的全众

257
0:10:33.120 --> 0:10:35.600
这两个矩阵进行一个相乘之后

258
0:10:35.760 --> 0:10:37.720
就得到一个新的矩阵

259
0:10:37.720 --> 0:10:39.960
新的矩阵确实也需要进行一个

260
0:10:39.960 --> 0:10:40.720
read layout

261
0:10:40.720 --> 0:10:43.200
read layout 就是数据的重排

262
0:10:43.200 --> 0:10:44.200
数据重排之后

263
0:10:44.360 --> 0:10:46.880
就得到最终的接近最终的结果

264
0:10:46.880 --> 0:10:47.800
最终结果之前

265
0:10:48.200 --> 0:10:49.480
A 也是提前算出来

266
0:10:49.480 --> 0:10:51.840
我们对它进行一个转换

267
0:10:51.840 --> 0:10:53.360
或者一个相乘

268
0:10:53.360 --> 0:10:55.320
得到新的数据的方式

269
0:10:55.320 --> 0:10:56.240
新的数据方式

270
0:10:56.560 --> 0:10:57.880
对它进行 rewrite

271
0:10:57.880 --> 0:10:59.280
write 成我们的 output

272
0:10:59.280 --> 0:11:02.040
这个就是卷机的最终的输出了

273
0:11:02.040 --> 0:11:03.000
整体这个流程

274
0:11:03.200 --> 0:11:05.480
就是 window grid 的算法了

275
0:11:05.680 --> 0:11:09.160
下面我们简单的对 window grid 这个算法

276
0:11:09.160 --> 0:11:11.280
进行一个回顾和思考

277
0:11:12.000 --> 0:11:14.040
虽然从原理看上去

278
0:11:14.360 --> 0:11:15.640
乘法减少了

279
0:11:15.640 --> 0:11:18.920
但好像算法的复杂度上升了

280
0:11:19.200 --> 0:11:22.920
下面我们看一下它整体的一个约束和缺点

281
0:11:22.920 --> 0:11:24.120
就是它的一些问题

282
0:11:24.640 --> 0:11:26.360
第一个点就是 window grid 这个算法

283
0:11:26.880 --> 0:11:29.680
非常不推荐在一些非常小的卷机盒

284
0:11:29.680 --> 0:11:32.640
或者一些非常小的一些卷机的方法里面去用的

285
0:11:32.640 --> 0:11:33.800
因为我们可以看到

286
0:11:33.800 --> 0:11:36.320
我们有大量的辅助的矩阵

287
0:11:36.320 --> 0:11:38.200
就刚才的 GBA

288
0:11:38.200 --> 0:11:40.000
这些辅助矩阵是非常大的

289
0:11:40.000 --> 0:11:41.680
会影响我们的实际的效果

290
0:11:42.040 --> 0:11:44.400
第二点就是不同规模的卷机

291
0:11:44.400 --> 0:11:47.400
需要使用不同规模的辅助矩阵

292
0:11:47.640 --> 0:11:51.280
实际上实时计算这些辅助矩阵是不现实的

293
0:11:51.280 --> 0:11:53.160
所以我们都会把它存起来

294
0:11:53.160 --> 0:11:54.080
而预存起来

295
0:11:54.200 --> 0:11:56.280
有可能会导致我们的存储

296
0:11:56.280 --> 0:11:58.880
或者我们的进程爆炸

297
0:11:59.240 --> 0:12:00.400
虽然 window grid 这个算法

298
0:12:00.560 --> 0:12:02.080
减少了我们的乘法的次数

299
0:12:02.080 --> 0:12:05.040
但是加法的数量也会相对应的增加

300
0:12:05.040 --> 0:12:08.560
而且我们的内存要存储辅助矩阵

301
0:12:08.560 --> 0:12:10.960
确实增加了我们的内存

302
0:12:10.960 --> 0:12:13.520
而随着我们的卷机盒的分块的尺寸增加

303
0:12:13.520 --> 0:12:16.400
我们还要考虑更多的加法和转换的代价

304
0:12:16.400 --> 0:12:18.760
而且每个切分的块越大

305
0:12:18.760 --> 0:12:20.200
转换矩阵就越大

306
0:12:20.200 --> 0:12:22.880
整体的计算精度也会有所损失

307
0:12:22.880 --> 0:12:25.640
所以说 window grid 这个算法

308
0:12:26.280 --> 0:12:29.800
基本上只适用于一些比较小的卷机盒和 TIE

309
0:12:30.600 --> 0:12:32.480
这个时候就很有意思了

310
0:12:32.480 --> 0:12:34.560
我们在实际的工程当中

311
0:12:34.560 --> 0:12:35.960
window grid 这个算法

312
0:12:35.960 --> 0:12:38.640
基本上只会对一些有限的

313
0:12:38.640 --> 0:12:41.400
3x3 的卷机进行一个运算

314
0:12:41.400 --> 0:12:43.280
1x1 的卷机不是用 window grid

315
0:12:43.280 --> 0:12:47.600
7x7 5x5 的卷机也不会启动 window grid 这个 kernel

316
0:12:47.600 --> 0:12:49.880
所以说还是很有意思的

317
0:12:49.880 --> 0:12:50.960
在 one time 的时候

318
0:12:51.120 --> 0:12:54.760
我们就会去决定我们到底用哪个 kernel

319
0:12:55.160 --> 0:12:58.560
那下面在具体时限上面的约束

320
0:12:58.600 --> 0:13:00.000
其实也是有的

321
0:13:00.400 --> 0:13:01.920
在实际时间当中

322
0:13:02.040 --> 0:13:03.240
我们最普遍的算法

323
0:13:03.240 --> 0:13:05.320
就是希望能够提前算出来

324
0:13:05.320 --> 0:13:06.680
提前能够固定的数据

325
0:13:07.160 --> 0:13:08.760
就提前把它做好

326
0:13:08.760 --> 0:13:10.600
所以我们会有一个预编译的阶段

327
0:13:10.600 --> 0:13:12.760
或者离线模块转换的阶段

328
0:13:12.760 --> 0:13:15.920
就是为了把一些能算的提前算出来

329
0:13:15.920 --> 0:13:17.120
在推丁引擎里面

330
0:13:17.240 --> 0:13:20.040
我们基本上不需要能够处理一些长尾的问题

331
0:13:20.040 --> 0:13:21.640
而是一些常用的

332
0:13:21.640 --> 0:13:23.680
或者一些很通用的算法问题

333
0:13:23.680 --> 0:13:25.640
或者一些通用的网络模型结构

334
0:13:25.640 --> 0:13:27.760
所以对于一些特定的网络模型结构

335
0:13:27.880 --> 0:13:29.120
假设G是固定的

336
0:13:29.120 --> 0:13:30.760
所以我们会把特定网络的G

337
0:13:31.000 --> 0:13:34.000
直接把它提前的算出来

338
0:13:34.000 --> 0:13:34.720
算好之后

339
0:13:34.720 --> 0:13:36.080
下一次直接运算就行了

340
0:13:36.080 --> 0:13:39.640
就不需要每一次我都需要重新的计算

341
0:13:39.640 --> 0:13:41.240
另外一个很自然的想法

342
0:13:41.240 --> 0:13:42.760
就是像我们刚才所说的

343
0:13:42.760 --> 0:13:45.880
它利用了空间的组织的方式

344
0:13:45.880 --> 0:13:47.280
跟 imagePlumb都一样的

345
0:13:47.280 --> 0:13:50.040
进行分片拆分

346
0:13:50.040 --> 0:13:51.520
将 input 的数据拆分成

347
0:13:51.520 --> 0:13:54.200
多个小规模的卷积

348
0:13:54.200 --> 0:13:56.200
这也是一个很好的优化方法

349
0:13:56.800 --> 0:13:59.160
好了,今天的内容就到这里为止

350
0:13:59.160 --> 0:14:00.200
我们今天主要是讲了

351
0:14:00.200 --> 0:14:03.440
WinQuery 怎幺去加速二维卷积的计算

352
0:14:03.440 --> 0:14:05.960
而这套公式就是 WinQuery 这个算法

353
0:14:05.960 --> 0:14:08.440
原来的论文推导出来的

354
0:14:08.440 --> 0:14:09.480
至于为什幺这幺推导

355
0:14:09.480 --> 0:14:11.920
我们在上面其实已经简单的介绍过

356
0:14:11.920 --> 0:14:13.480
可能我讲得不太清楚

357
0:14:13.480 --> 0:14:16.160
也希望欢迎大家去写更多的文章

358
0:14:16.160 --> 0:14:19.120
或者引发大家一个更好的一些思考

359
0:14:19.120 --> 0:14:21.120
今天的内容就先到这里为止

360
0:14:21.120 --> 0:14:22.640
谢谢各位,拜拜

361
0:14:22.640 --> 0:14:24.920
卷得不行了

362
0:14:24.960 --> 0:14:26.760
记得一键三连加关注哦

363
0:14:26.760 --> 0:14:28.360
所有的内容都会开源在

364
0:14:28.360 --> 0:14:30.360
下面这条链接里面

365
0:14:30.360 --> 0:14:31.600
拜拜

