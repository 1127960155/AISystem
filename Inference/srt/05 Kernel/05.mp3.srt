0
0:00:00.000 --> 0:00:06.600
Hello 大家好,我是曾铭

1
0:00:06.600 --> 0:00:08.280
在 kernel 优化这个内容里面

2
0:00:08.360 --> 0:00:09.800
我知道应该看的人很少了

3
0:00:09.800 --> 0:00:11.600
而且我讲的确实并不太好

4
0:00:11.600 --> 0:00:14.280
今天我们来到了一个新的内容

5
0:00:14.280 --> 0:00:17.600
叫做间接优化 indirect 优化

6
0:00:17.600 --> 0:00:20.960
这个间接优化的方式还是很有意思的

7
0:00:20.960 --> 0:00:22.240
或者它有一些背景的

8
0:00:22.240 --> 0:00:24.960
我们看一下在整体的推进型的架构图

9
0:00:25.040 --> 0:00:26.840
我们现在位于 kernel 层

10
0:00:26.840 --> 0:00:28.120
就中间的这一层

11
0:00:28.120 --> 0:00:30.400
每个 kernel 或者每一个卷积

12
0:00:30.400 --> 0:00:32.440
我们看到的每一个卷积算子

13
0:00:32.440 --> 0:00:35.480
下面底层可能会对接非常多个 kernel 的

14
0:00:35.480 --> 0:00:37.640
所以在实际的实践过程当中

15
0:00:37.840 --> 0:00:40.840
你看到的你用到的是一个算子

16
0:00:41.040 --> 0:00:43.760
但是你们可能会执行不同的 kernel

17
0:00:43.760 --> 0:00:47.040
而不同的 kernel 是我们的 one time 去决定的

18
0:00:47.040 --> 0:00:49.560
在整个卷积 kernel 的优化内容里面

19
0:00:49.680 --> 0:00:51.560
我们现在来到了最后一个内容

20
0:00:51.560 --> 0:00:55.600
QNN Pack 间接卷积优化 indirect algorithm

21
0:00:55.840 --> 0:00:58.920
什幺为之间接的卷积优化呢

22
0:00:58.920 --> 0:01:00.280
我们现在来看一下

23
0:01:00.280 --> 0:01:02.920
首先一个很重要的概念就是

24
0:01:02.920 --> 0:01:03.920
QNN Pack

25
0:01:03.920 --> 0:01:06.240
QNN Pack 就是 Quantilization

26
0:01:06.240 --> 0:01:08.240
Nature Network Package

27
0:01:08.240 --> 0:01:09.920
它是由 Facebook

28
0:01:09.920 --> 0:01:11.520
这个人后来去了谷歌

29
0:01:11.520 --> 0:01:13.320
后来现在不知道去哪了

30
0:01:13.320 --> 0:01:14.760
然后他在 Facebook 的时候

31
0:01:14.960 --> 0:01:18.120
当时候是为了对神级网络模型量化

32
0:01:18.120 --> 0:01:19.640
提出的一个算法

33
0:01:19.640 --> 0:01:21.080
当时候提出来的时候

34
0:01:21.280 --> 0:01:22.400
整体的性能

35
0:01:22.480 --> 0:01:24.160
确实已经击败了所有

36
0:01:24.200 --> 0:01:25.600
以公开的加速算法

37
0:01:25.600 --> 0:01:26.320
所以这个算法

38
0:01:26.680 --> 0:01:28.800
不仅仅能够用在量化的时候

39
0:01:28.800 --> 0:01:30.800
非量化的时候也可以去使用

40
0:01:30.800 --> 0:01:32.640
而且效果还是非常的惊人

41
0:01:33.640 --> 0:01:35.440
作者离开了 Facebook 之后

42
0:01:35.520 --> 0:01:36.640
因为在 Facebook 时候

43
0:01:36.760 --> 0:01:37.800
这个算法确实太好

44
0:01:37.800 --> 0:01:39.840
没有公开太多的实现的细节

45
0:01:39.840 --> 0:01:41.360
直到他离开了 Facebook 之后

46
0:01:41.520 --> 0:01:43.880
他就把这篇文章发表了出来

47
0:01:43.880 --> 0:01:45.040
而且就论证了

48
0:01:45.040 --> 0:01:48.520
确实这个算法的效果特别的好

49
0:01:49.480 --> 0:01:51.120
下面我们回顾一下

50
0:01:51.120 --> 0:01:53.400
InVisual Comp 的整体的一个算法

51
0:01:53.400 --> 0:01:55.880
现在其实很多卷积的算法

52
0:01:55.880 --> 0:01:58.320
基本上很少会叠代很多个 for

53
0:01:58.320 --> 0:02:01.120
更多的是使用 InVisual Comp 的算法去实现的

54
0:02:01.120 --> 0:02:02.920
所以我们不管是讲到

55
0:02:02.920 --> 0:02:03.960
Luminoid 算法

56
0:02:04.080 --> 0:02:05.880
还是 QNN Packet 算法

57
0:02:06.320 --> 0:02:08.080
都基本上会经过 InVisual Comp

58
0:02:08.080 --> 0:02:09.880
来去进行一个比较

59
0:02:10.120 --> 0:02:11.920
假设我们现在要算一个

60
0:02:11.920 --> 0:02:13.760
MR乘以NR的小块的时候

61
0:02:14.120 --> 0:02:15.760
传统的 GM 的方法

62
0:02:15.920 --> 0:02:18.720
就是对 K 维度进行一个拆分

63
0:02:19.320 --> 0:02:20.160
下面我们看一下

64
0:02:20.160 --> 0:02:21.680
InVisual Comp 的整体的算法

65
0:02:21.720 --> 0:02:23.880
首先 InVisual Comp 假设我们的

66
0:02:23.880 --> 0:02:25.240
B 就是我们的 Kernels

67
0:02:25.240 --> 0:02:26.920
然后 A 就是 FeatureMap

68
0:02:26.920 --> 0:02:29.360
C 就是最终的输出的数据

69
0:02:29.360 --> 0:02:31.480
会把 Kernels 的一列

70
0:02:31.480 --> 0:02:33.320
乘以我们 FeatureMap 的一行

71
0:02:33.320 --> 0:02:36.520
得到最终输出的一个元素的值

72
0:02:36.520 --> 0:02:38.880
所以说它的计算量还是挺大的

73
0:02:38.880 --> 0:02:41.200
每次都要把很多的数据塞进去

74
0:02:41.200 --> 0:02:44.400
当然了为了更加的方便我们进行操作

75
0:02:44.400 --> 0:02:45.880
我们一般不会单算一个数

76
0:02:45.880 --> 0:02:48.760
而是会同一时间会算很多数

77
0:02:48.760 --> 0:02:51.000
也就是我们的矢量化的操作

78
0:02:51.080 --> 0:02:55.320
就把很多个 B 和 A 同时进行矩阵乘

79
0:02:55.320 --> 0:02:59.240
得到我们 C 里面的很多的数值

80
0:02:59.240 --> 0:03:03.200
那这个就是一个简单的矢量化的加速

81
0:03:04.480 --> 0:03:06.920
后来有了分块之后

82
0:03:06.920 --> 0:03:08.480
或者分块的概念起来之后

83
0:03:08.680 --> 0:03:10.920
在传统的方法就是对我们的 K 维度

84
0:03:10.920 --> 0:03:14.120
就 B 的卷积和按 K 维度进行拆分

85
0:03:14.120 --> 0:03:15.400
在一次计算的时候

86
0:03:15.520 --> 0:03:17.240
只算 K 的某个值

87
0:03:17.240 --> 0:03:19.000
然后 A 就是我们的 FeatureMap

88
0:03:19.040 --> 0:03:21.280
也是按这个维度进行拆分

89
0:03:21.280 --> 0:03:22.840
然后算每一个值

90
0:03:22.840 --> 0:03:25.840
然后再把这些值进行一个累加

91
0:03:25.840 --> 0:03:27.520
但这个时候就会引起

92
0:03:27.520 --> 0:03:30.280
额外的输出的加载和存储了

93
0:03:30.560 --> 0:03:32.160
每次都会有额外的数据

94
0:03:32.160 --> 0:03:35.200
在内存里面重新的加载和存储

95
0:03:36.000 --> 0:03:37.640
下面我们简单的看一下

96
0:03:37.640 --> 0:03:39.440
QNPack 这个算法的思想

97
0:03:39.440 --> 0:03:42.280
这里面就 QNPack indirect 的方法

98
0:03:42.280 --> 0:03:46.760
基本上就消除了输出部分的额外的仿存

99
0:03:46.760 --> 0:03:50.000
虽然可以看到 B 还是按 K 维度进行拆分

100
0:03:50.000 --> 0:03:51.360
不是说不拆分

101
0:03:51.360 --> 0:03:52.560
而是拆分之后

102
0:03:53.000 --> 0:03:55.000
不和其他维度进行交换

103
0:03:55.000 --> 0:03:57.680
和重新的一个额外的仿存的计算

104
0:03:58.040 --> 0:03:59.480
具体它是怎幺实现的

105
0:03:59.480 --> 0:04:01.040
我们下面来分解一下

106
0:04:01.040 --> 0:04:02.320
在进入下个内容之前

107
0:04:02.640 --> 0:04:04.200
小心有两个问题

108
0:04:04.440 --> 0:04:06.040
第一个问题就是

109
0:04:07.600 --> 0:04:08.720
钟鸣老师你好

110
0:04:08.720 --> 0:04:11.240
你刚才提到 InVisCram 优化算法

111
0:04:11.440 --> 0:04:12.840
有两个问题

112
0:04:12.920 --> 0:04:16.720
第一个就是会占用额外大量的内存

113
0:04:17.480 --> 0:04:22.200
第二个是需要对输入的数据进行额外的拷贝

114
0:04:22.560 --> 0:04:25.400
这两点 QNPack 怎幺来解决吗

115
0:04:26.520 --> 0:04:27.560
很有意思

116
0:04:27.920 --> 0:04:30.080
QNPack 最内核的算法

117
0:04:30.080 --> 0:04:32.960
叫做间接卷积优化算法

118
0:04:33.280 --> 0:04:36.640
它的答案就是有一个间接的缓冲区

119
0:04:36.880 --> 0:04:38.040
Indirect Buffer

120
0:04:38.280 --> 0:04:40.480
首先创建一个间接的缓冲区

121
0:04:40.720 --> 0:04:43.120
对内存进行重新的组织

122
0:04:43.120 --> 0:04:44.480
我们叫做 Repacking

123
0:04:44.520 --> 0:04:47.880
这样就可以提高整体的命中率

124
0:04:47.880 --> 0:04:49.320
从而提高我们的性能

125
0:04:49.320 --> 0:04:51.960
所以说在我们卷积的优化

126
0:04:51.960 --> 0:04:53.360
或者一些 kernel 的优化

127
0:04:53.360 --> 0:04:56.040
我们是离不开对内存的一个优化的

128
0:04:56.040 --> 0:04:57.960
它们俩是相辅相成

129
0:04:57.960 --> 0:05:00.320
下面我们简单的来去看一下

130
0:05:00.320 --> 0:05:02.360
什幺叫做间接缓冲区

131
0:05:02.360 --> 0:05:04.240
就是间接卷积算法最内核的

132
0:05:04.240 --> 0:05:05.800
就是间接缓冲区了

133
0:05:07.000 --> 0:05:08.280
原来这样

134
0:05:08.480 --> 0:05:10.240
快点给我讲讲吧

135
0:05:14.520 --> 0:05:16.440
好下面我们来到了

136
0:05:16.440 --> 0:05:20.440
Indirect 卷积算法的整体工作流程

137
0:05:20.720 --> 0:05:22.360
首先 Indirect 卷积算法

138
0:05:22.400 --> 0:05:24.440
我们简单的看看下面这个图

139
0:05:24.440 --> 0:05:25.800
后面的所有图

140
0:05:26.080 --> 0:05:27.960
它的颜色我都是对齐的

141
0:05:28.000 --> 0:05:29.160
简单的来讲讲

142
0:05:29.160 --> 0:05:30.080
input 的数据

143
0:05:30.080 --> 0:05:31.160
或者我们的 feature map

144
0:05:31.520 --> 0:05:33.960
会以红色的模块作为主

145
0:05:34.000 --> 0:05:35.600
然后我们的权重

146
0:05:35.840 --> 0:05:38.160
会以绿色的小方框作为主

147
0:05:38.200 --> 0:05:39.840
而最终 output 的输出

148
0:05:40.040 --> 0:05:42.680
我们也会用层次的模块

149
0:05:42.680 --> 0:05:45.040
作为一个主要的颜色

150
0:05:45.280 --> 0:05:47.600
这里面 IH IC IW

151
0:05:47.600 --> 0:05:48.720
H和W

152
0:05:49.040 --> 0:05:50.880
就是我们的长和宽

153
0:05:50.880 --> 0:05:52.520
对于 I 就是 input

154
0:05:52.560 --> 0:05:54.400
而 O 就是 output

155
0:05:54.440 --> 0:05:56.400
而 K 就是 kernels 的大小

156
0:05:57.160 --> 0:05:59.240
这些概念在我们前几节课

157
0:05:59.480 --> 0:06:02.600
都是完完全全是对应起来的

158
0:06:02.600 --> 0:06:03.680
现在我们可以看到

159
0:06:03.960 --> 0:06:05.880
实际上我们不会把所有的

160
0:06:05.880 --> 0:06:07.000
input 的 feature map

161
0:06:07.520 --> 0:06:08.920
同时加载到我们的 L1

162
0:06:08.920 --> 0:06:10.320
或者 L2 缓存里面

163
0:06:10.320 --> 0:06:12.080
而是先把一部分的数据

164
0:06:12.240 --> 0:06:14.960
搬到我们的输入的缓冲区

165
0:06:14.960 --> 0:06:16.400
也就是 input buffer

166
0:06:16.680 --> 0:06:19.320
然后这里面 indirect convolution

167
0:06:19.320 --> 0:06:20.680
间接卷迹优化算法

168
0:06:20.840 --> 0:06:23.360
就引入了一个间接的缓冲区

169
0:06:23.360 --> 0:06:25.400
indirect buffer 这个内容

170
0:06:25.960 --> 0:06:26.960
而间接的缓冲区

171
0:06:27.120 --> 0:06:29.240
是整个算法的一个内核

172
0:06:29.240 --> 0:06:30.440
在网络计算的时候

173
0:06:30.560 --> 0:06:33.720
我们首先会计算 mxm 的输出

174
0:06:33.720 --> 0:06:36.800
也就是 mxm 的简单的输出

175
0:06:37.040 --> 0:06:38.120
这一个内容

176
0:06:38.520 --> 0:06:41.200
每次我只计算一小个模块

177
0:06:41.520 --> 0:06:44.160
现在我们已经了解了 indirect buffer

178
0:06:44.160 --> 0:06:46.480
下面大家可以重新的看看这个图

179
0:06:46.480 --> 0:06:49.840
我们下面也会详细的去展开介绍的

180
0:06:50.600 --> 0:06:53.720
在计算 mxm 规模的大小输出的时候

181
0:06:54.120 --> 0:06:55.800
我们的间接缓冲区

182
0:06:55.960 --> 0:06:58.040
就会取出对应的数据

183
0:06:58.040 --> 0:07:00.840
这里面对应的数据就是 icxm

184
0:07:00.840 --> 0:07:03.800
然后也会取出对应的权重的数据

185
0:07:03.800 --> 0:07:06.680
去计算 icxm 和 icxn

186
0:07:06.680 --> 0:07:09.120
最后是得到我们的 mxm 的数据

187
0:07:09.120 --> 0:07:10.880
塞给我们的输出

188
0:07:11.040 --> 0:07:12.880
这里面怎幺去预储数据

189
0:07:12.880 --> 0:07:15.840
indirect buffer 里面的数据的排布

190
0:07:16.120 --> 0:07:18.160
就显得尤为重要了

191
0:07:18.520 --> 0:07:20.120
下面我们看一下

192
0:07:20.120 --> 0:07:21.800
在实际的实践当中

193
0:07:22.160 --> 0:07:25.160
软件的执行就分为两个部分

194
0:07:25.920 --> 0:07:27.840
第一部分就是准备阶段

195
0:07:27.840 --> 0:07:29.000
在加载模型的时候

196
0:07:29.080 --> 0:07:32.280
我们就需要去配置输入的缓冲区

197
0:07:32.280 --> 0:07:33.560
也就是 indirect buffer

198
0:07:33.880 --> 0:07:36.040
第二步我们需要重排权重

199
0:07:36.280 --> 0:07:38.040
重排权重其实一模一样

200
0:07:38.040 --> 0:07:39.400
我们可以在离线转换模块

201
0:07:39.400 --> 0:07:40.280
或者预编译阶段

202
0:07:40.600 --> 0:07:41.560
进行重排

203
0:07:41.560 --> 0:07:43.200
使得我们的内存布局

204
0:07:43.640 --> 0:07:45.440
是方便我们后续

205
0:07:45.440 --> 0:07:47.520
跟输入缓冲区进行相成的

206
0:07:47.760 --> 0:07:49.680
接着第二步就是运行阶段

207
0:07:49.840 --> 0:07:50.840
真正的运行阶段

208
0:07:50.840 --> 0:07:52.240
就是我们的 one time 阶段

209
0:07:52.240 --> 0:07:54.400
或者 one time 调起 kernel 的时候

210
0:07:54.400 --> 0:07:56.320
我们需要对每个输入的执行

211
0:07:56.680 --> 0:07:58.880
进行 OH 乘以 OW 除以 M

212
0:07:58.880 --> 0:08:01.200
乘以 OC 除以 N 次循环

213
0:08:01.200 --> 0:08:02.480
很多次循环

214
0:08:02.480 --> 0:08:04.160
每次使用 GMM

215
0:08:04.160 --> 0:08:07.240
去计算 M 乘 N 的大小的输出

216
0:08:08.080 --> 0:08:09.920
下面我们来到间接缓冲区

217
0:08:09.920 --> 0:08:10.840
里面最内核的

218
0:08:10.840 --> 0:08:12.680
看看它到底是怎幺布局的

219
0:08:13.160 --> 0:08:14.560
首先间接缓冲区

220
0:08:14.560 --> 0:08:15.960
我们的 localindoorbuff

221
0:08:15.960 --> 0:08:17.240
可以简单理解为

222
0:08:17.240 --> 0:08:19.240
一组卷集和大小的缓冲区

223
0:08:19.240 --> 0:08:21.560
一共有 OH 乘以 OW 个

224
0:08:21.560 --> 0:08:23.560
每个这是简单的一个

225
0:08:23.880 --> 0:08:27.120
每个缓冲区大小为 KH 乘以 KW

226
0:08:27.800 --> 0:08:28.600
在计算的时候

227
0:08:28.760 --> 0:08:30.200
随着我们整体的输出的

228
0:08:30.200 --> 0:08:31.600
所有的内存地址的移动

229
0:08:31.720 --> 0:08:34.240
选用不同的间接的缓冲区

230
0:08:34.240 --> 0:08:36.560
你就可以得到相应的输出的地址

231
0:08:36.560 --> 0:08:39.320
没有必要去根据输出的目标重新去

232
0:08:39.320 --> 0:08:40.440
锁定我们的地址

233
0:08:40.720 --> 0:08:43.480
这种方式其实类似于我们传统进程里面的

234
0:08:43.480 --> 0:08:45.200
用空间换时间的概念

235
0:08:45.680 --> 0:08:47.360
现在我们放大来看一下

236
0:08:47.360 --> 0:08:49.560
左边这个红色都是我们的 featuremap

237
0:08:49.560 --> 0:08:50.640
或者我们的输入码

238
0:08:50.640 --> 0:08:52.640
我们会预取一个 input buffer

239
0:08:52.640 --> 0:08:55.040
把一些一部分的数据预取出来

240
0:08:55.040 --> 0:08:57.080
假设我们现在取的一个简单的

241
0:08:57.080 --> 0:08:58.040
一个快的数据

242
0:08:58.040 --> 0:09:00.560
里面 IH 乘以 IW 乘以 IC

243
0:09:00.560 --> 0:09:04.120
这个时候我们对之前里面的某个卷集和

244
0:09:04.120 --> 0:09:05.920
或者对里面的某个 kernels 大小

245
0:09:05.920 --> 0:09:07.520
就会把它取出来

246
0:09:07.640 --> 0:09:13.000
把数据按照 012 1234 4567

247
0:09:13.000 --> 0:09:15.600
这种方式进行一个预取

248
0:09:15.600 --> 0:09:17.480
预取成为 indirect buffer

249
0:09:17.480 --> 0:09:20.480
把它变成一个间接的缓冲区

250
0:09:20.480 --> 0:09:21.960
这个间接缓冲区很有意思

251
0:09:21.960 --> 0:09:23.960
就 0123 1234 2345

252
0:09:23.960 --> 0:09:26.920
然后通过这种方式就以空间换时间

253
0:09:26.920 --> 0:09:29.800
把大量的数据全部取出来

254
0:09:29.800 --> 0:09:31.880
方便我们后续的直接相乘

255
0:09:31.880 --> 0:09:32.640
直接相乘之后

256
0:09:32.640 --> 0:09:35.120
直接得到我们的最后的结果了

257
0:09:36.120 --> 0:09:37.760
其实卷集可以使用

258
0:09:37.760 --> 0:09:39.920
AVG Clump 这种优化的算法

259
0:09:39.920 --> 0:09:41.960
本质原因主要是拆分之后

260
0:09:41.960 --> 0:09:43.720
我们可以忽略内存附用之后的

261
0:09:43.720 --> 0:09:46.760
整个计算过程等价于矩阵乘

262
0:09:46.760 --> 0:09:48.960
也就是使用矩阵乘

263
0:09:48.960 --> 0:09:52.680
对我们的卷集进行一个替换

264
0:09:52.680 --> 0:09:54.760
而间接缓冲区就可以通过大量的

265
0:09:54.760 --> 0:09:56.320
复制我们的地址的数据

266
0:09:56.320 --> 0:09:58.760
然后通过子帧或者模拟子帧的方式

267
0:09:58.760 --> 0:10:00.960
模拟出对输入的仿存

268
0:10:00.960 --> 0:10:02.160
这种方式的优点

269
0:10:02.160 --> 0:10:04.120
就是解决空间限量化的问题

270
0:10:04.120 --> 0:10:06.920
同时可以计算很多个数据

271
0:10:06.920 --> 0:10:09.760
第2个就是地址计算会变得更加简单

272
0:10:09.760 --> 0:10:12.160
因为我不需要不断的去寻子了

273
0:10:12.160 --> 0:10:14.160
或者子帧来回的去跳跃

274
0:10:14.160 --> 0:10:15.880
而是直接根据下一个地址

275
0:10:15.880 --> 0:10:17.840
去预取数据就行了

276
0:10:17.840 --> 0:10:19.760
第3个就是解决我们的内存

277
0:10:19.760 --> 0:10:22.280
大量的重复拷贝的问题

278
0:10:22.280 --> 0:10:24.080
但是缺点也很明确

279
0:10:24.080 --> 0:10:26.840
就是创建整个数据的缓冲区

280
0:10:26.840 --> 0:10:29.320
需要大量的内存空间

281
0:10:29.320 --> 0:10:32.600
第4个就是数据进行重排 Repacking

282
0:10:32.600 --> 0:10:35.360
会消耗我们大量的仿存

283
0:10:35.360 --> 0:10:37.480
或者大量的预编译的时间

284
0:10:38.360 --> 0:10:41.400
下面我们对整个卷迹算法

285
0:10:41.400 --> 0:10:43.240
进行总结一下

286
0:10:43.560 --> 0:10:45.280
最后一个内容

287
0:10:45.280 --> 0:10:46.960
就是对我们之前讲到的

288
0:10:46.960 --> 0:10:49.120
好几个 kernel 卷迹优化的算法

289
0:10:49.320 --> 0:10:51.560
进行一个横向的总结

290
0:10:51.560 --> 0:10:55.320
首先我们上面的视频所讲的方法

291
0:10:55.520 --> 0:10:58.280
都是通用的卷迹的优化方法

292
0:10:58.520 --> 0:10:59.480
随着神经网络

293
0:10:59.480 --> 0:11:02.760
或者很多的新的 AI 处理器的出现

294
0:11:03.200 --> 0:11:05.160
我们整个算法的优化

295
0:11:05.160 --> 0:11:07.320
其实还在不断的深挖的

296
0:11:07.320 --> 0:11:10.040
因为不同的卷迹的方式

297
0:11:10.040 --> 0:11:12.160
会使用到不同的处理器里面的

298
0:11:12.160 --> 0:11:13.720
一些重要的指令

299
0:11:13.720 --> 0:11:15.880
而且有可能会有更多的新的指令

300
0:11:15.880 --> 0:11:16.680
会提出

301
0:11:16.680 --> 0:11:17.880
例如一开始之前

302
0:11:17.880 --> 0:11:19.360
可能五六年前

303
0:11:19.360 --> 0:11:20.840
我在做深度学习的时候

304
0:11:20.960 --> 0:11:22.240
还没想到会使用到

305
0:11:22.240 --> 0:11:23.600
int8 相关的指令的

306
0:11:23.600 --> 0:11:24.920
或者一些张量的指令

307
0:11:24.920 --> 0:11:27.000
现在 int4, int2

308
0:11:27.000 --> 0:11:28.880
或者 int8 的指令越来越多

309
0:11:28.920 --> 0:11:30.960
而相关的除了相量化的指令

310
0:11:30.960 --> 0:11:32.560
还出现了张量化的指令

311
0:11:32.560 --> 0:11:33.600
也越来越多

312
0:11:33.600 --> 0:11:35.720
不管是 SIMP 还是 MND 的架构

313
0:11:35.720 --> 0:11:37.800
也会不断的去演进

314
0:11:38.720 --> 0:11:39.200
好了

315
0:11:39.200 --> 0:11:40.960
今天的内容就到这里为止

316
0:11:40.960 --> 0:11:41.680
谢谢各位

317
0:11:41.680 --> 0:11:42.840
拜拜

318
0:11:43.680 --> 0:11:44.440
卷得不行了

319
0:11:44.440 --> 0:11:45.320
卷得不行了

320
0:11:45.320 --> 0:11:46.760
记得一键三连加关注

321
0:11:47.160 --> 0:11:48.520
所有的内容都会开源

322
0:11:48.520 --> 0:11:50.360
在下面这条链接里面

323
0:11:50.720 --> 0:11:51.680
拜拜

