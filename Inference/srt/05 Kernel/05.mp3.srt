1
00:00:00,000 --> 00:00:06,600
Hello 大家好,我是曾铭

2
00:00:06,600 --> 00:00:08,280
在 kernel 优化这个内容里面

3
00:00:08,360 --> 00:00:09,800
我知道应该看的人很少了

4
00:00:09,800 --> 00:00:11,600
而且我讲的确实并不太好

5
00:00:11,600 --> 00:00:14,280
今天我们来到了一个新的内容

6
00:00:14,280 --> 00:00:17,600
叫做间接优化 indirect 优化

7
00:00:17,600 --> 00:00:20,960
这个间接优化的方式还是很有意思的

8
00:00:20,960 --> 00:00:22,240
或者它有一些背景的

9
00:00:22,240 --> 00:00:24,960
我们看一下在整体的推进型的架构图

10
00:00:25,040 --> 00:00:26,840
我们现在位于 kernel 层

11
00:00:26,840 --> 00:00:28,120
就中间的这一层

12
00:00:28,120 --> 00:00:30,400
每个 kernel 或者每一个卷积

13
00:00:30,400 --> 00:00:32,440
我们看到的每一个卷积算子

14
00:00:32,440 --> 00:00:35,480
下面底层可能会对接非常多个 kernel 的

15
00:00:35,480 --> 00:00:37,640
所以在实际的实践过程当中

16
00:00:37,840 --> 00:00:40,840
你看到的你用到的是一个算子

17
00:00:41,040 --> 00:00:43,760
但是你们可能会执行不同的 kernel

18
00:00:43,760 --> 00:00:47,040
而不同的 kernel 是我们的 one time 去决定的

19
00:00:47,040 --> 00:00:49,560
在整个卷积 kernel 的优化内容里面

20
00:00:49,680 --> 00:00:51,560
我们现在来到了最后一个内容

21
00:00:51,560 --> 00:00:55,600
QNN Pack 间接卷积优化 indirect algorithm

22
00:00:55,840 --> 00:00:58,920
什幺为之间接的卷积优化呢

23
00:00:58,920 --> 00:01:00,280
我们现在来看一下

24
00:01:00,280 --> 00:01:02,920
首先一个很重要的概念就是

25
00:01:02,920 --> 00:01:03,920
QNN Pack

26
00:01:03,920 --> 00:01:06,240
QNN Pack 就是 Quantilization

27
00:01:06,240 --> 00:01:08,240
Nature Network Package

28
00:01:08,240 --> 00:01:09,920
它是由 Facebook

29
00:01:09,920 --> 00:01:11,520
这个人后来去了谷歌

30
00:01:11,520 --> 00:01:13,320
后来现在不知道去哪了

31
00:01:13,320 --> 00:01:14,760
然后他在 Facebook 的时候

32
00:01:14,960 --> 00:01:18,120
当时候是为了对神级网络模型量化

33
00:01:18,120 --> 00:01:19,640
提出的一个算法

34
00:01:19,640 --> 00:01:21,080
当时候提出来的时候

35
00:01:21,280 --> 00:01:22,400
整体的性能

36
00:01:22,480 --> 00:01:24,160
确实已经击败了所有

37
00:01:24,200 --> 00:01:25,600
以公开的加速算法

38
00:01:25,600 --> 00:01:26,320
所以这个算法

39
00:01:26,680 --> 00:01:28,800
不仅仅能够用在量化的时候

40
00:01:28,800 --> 00:01:30,800
非量化的时候也可以去使用

41
00:01:30,800 --> 00:01:32,640
而且效果还是非常的惊人

42
00:01:33,640 --> 00:01:35,440
作者离开了 Facebook 之后

43
00:01:35,520 --> 00:01:36,640
因为在 Facebook 时候

44
00:01:36,760 --> 00:01:37,800
这个算法确实太好

45
00:01:37,800 --> 00:01:39,840
没有公开太多的实现的细节

46
00:01:39,840 --> 00:01:41,360
直到他离开了 Facebook 之后

47
00:01:41,520 --> 00:01:43,880
他就把这篇文章发表了出来

48
00:01:43,880 --> 00:01:45,040
而且就论证了

49
00:01:45,040 --> 00:01:48,520
确实这个算法的效果特别的好

50
00:01:49,480 --> 00:01:51,120
下面我们回顾一下

51
00:01:51,120 --> 00:01:53,400
InVisual Comp 的整体的一个算法

52
00:01:53,400 --> 00:01:55,880
现在其实很多卷积的算法

53
00:01:55,880 --> 00:01:58,320
基本上很少会叠代很多个 for

54
00:01:58,320 --> 00:02:01,120
更多的是使用 InVisual Comp 的算法去实现的

55
00:02:01,120 --> 00:02:02,920
所以我们不管是讲到

56
00:02:02,920 --> 00:02:03,960
Luminoid 算法

57
00:02:04,080 --> 00:02:05,880
还是 QNN Packet 算法

58
00:02:06,320 --> 00:02:08,080
都基本上会经过 InVisual Comp

59
00:02:08,080 --> 00:02:09,880
来去进行一个比较

60
00:02:10,120 --> 00:02:11,920
假设我们现在要算一个

61
00:02:11,920 --> 00:02:13,760
MR乘以NR的小块的时候

62
00:02:14,120 --> 00:02:15,760
传统的 GM 的方法

63
00:02:15,920 --> 00:02:18,720
就是对 K 维度进行一个拆分

64
00:02:19,320 --> 00:02:20,160
下面我们看一下

65
00:02:20,160 --> 00:02:21,680
InVisual Comp 的整体的算法

66
00:02:21,720 --> 00:02:23,880
首先 InVisual Comp 假设我们的

67
00:02:23,880 --> 00:02:25,240
B 就是我们的 Kernels

68
00:02:25,240 --> 00:02:26,920
然后 A 就是 FeatureMap

69
00:02:26,920 --> 00:02:29,360
C 就是最终的输出的数据

70
00:02:29,360 --> 00:02:31,480
会把 Kernels 的一列

71
00:02:31,480 --> 00:02:33,320
乘以我们 FeatureMap 的一行

72
00:02:33,320 --> 00:02:36,520
得到最终输出的一个元素的值

73
00:02:36,520 --> 00:02:38,880
所以说它的计算量还是挺大的

74
00:02:38,880 --> 00:02:41,200
每次都要把很多的数据塞进去

75
00:02:41,200 --> 00:02:44,400
当然了为了更加的方便我们进行操作

76
00:02:44,400 --> 00:02:45,880
我们一般不会单算一个数

77
00:02:45,880 --> 00:02:48,760
而是会同一时间会算很多数

78
00:02:48,760 --> 00:02:51,000
也就是我们的矢量化的操作

79
00:02:51,080 --> 00:02:55,320
就把很多个 B 和 A 同时进行矩阵乘

80
00:02:55,320 --> 00:02:59,240
得到我们 C 里面的很多的数值

81
00:02:59,240 --> 00:03:03,200
那这个就是一个简单的矢量化的加速

82
00:03:04,480 --> 00:03:06,920
后来有了分块之后

83
00:03:06,920 --> 00:03:08,480
或者分块的概念起来之后

84
00:03:08,680 --> 00:03:10,920
在传统的方法就是对我们的 K 维度

85
00:03:10,920 --> 00:03:14,120
就 B 的卷积和按 K 维度进行拆分

86
00:03:14,120 --> 00:03:15,400
在一次计算的时候

87
00:03:15,520 --> 00:03:17,240
只算 K 的某个值

88
00:03:17,240 --> 00:03:19,000
然后 A 就是我们的 FeatureMap

89
00:03:19,040 --> 00:03:21,280
也是按这个维度进行拆分

90
00:03:21,280 --> 00:03:22,840
然后算每一个值

91
00:03:22,840 --> 00:03:25,840
然后再把这些值进行一个累加

92
00:03:25,840 --> 00:03:27,520
但这个时候就会引起

93
00:03:27,520 --> 00:03:30,280
额外的输出的加载和存储了

94
00:03:30,560 --> 00:03:32,160
每次都会有额外的数据

95
00:03:32,160 --> 00:03:35,200
在内存里面重新的加载和存储

96
00:03:36,000 --> 00:03:37,640
下面我们简单的看一下

97
00:03:37,640 --> 00:03:39,440
QNPack 这个算法的思想

98
00:03:39,440 --> 00:03:42,280
这里面就 QNPack indirect 的方法

99
00:03:42,280 --> 00:03:46,760
基本上就消除了输出部分的额外的仿存

100
00:03:46,760 --> 00:03:50,000
虽然可以看到 B 还是按 K 维度进行拆分

101
00:03:50,000 --> 00:03:51,360
不是说不拆分

102
00:03:51,360 --> 00:03:52,560
而是拆分之后

103
00:03:53,000 --> 00:03:55,000
不和其他维度进行交换

104
00:03:55,000 --> 00:03:57,680
和重新的一个额外的仿存的计算

105
00:03:58,040 --> 00:03:59,480
具体它是怎幺实现的

106
00:03:59,480 --> 00:04:01,040
我们下面来分解一下

107
00:04:01,040 --> 00:04:02,320
在进入下个内容之前

108
00:04:02,640 --> 00:04:04,200
小心有两个问题

109
00:04:04,440 --> 00:04:06,040
第一个问题就是

110
00:04:07,600 --> 00:04:08,720
钟鸣老师你好

111
00:04:08,720 --> 00:04:11,240
你刚才提到 InVisCram 优化算法

112
00:04:11,440 --> 00:04:12,840
有两个问题

113
00:04:12,920 --> 00:04:16,720
第一个就是会占用额外大量的内存

114
00:04:17,480 --> 00:04:22,200
第二个是需要对输入的数据进行额外的拷贝

115
00:04:22,560 --> 00:04:25,400
这两点 QNPack 怎幺来解决吗

116
00:04:26,520 --> 00:04:27,560
很有意思

117
00:04:27,920 --> 00:04:30,080
QNPack 最内核的算法

118
00:04:30,080 --> 00:04:32,960
叫做间接卷积优化算法

119
00:04:33,280 --> 00:04:36,640
它的答案就是有一个间接的缓冲区

120
00:04:36,880 --> 00:04:38,040
Indirect Buffer

121
00:04:38,280 --> 00:04:40,480
首先创建一个间接的缓冲区

122
00:04:40,720 --> 00:04:43,120
对内存进行重新的组织

123
00:04:43,120 --> 00:04:44,480
我们叫做 Repacking

124
00:04:44,520 --> 00:04:47,880
这样就可以提高整体的命中率

125
00:04:47,880 --> 00:04:49,320
从而提高我们的性能

126
00:04:49,320 --> 00:04:51,960
所以说在我们卷积的优化

127
00:04:51,960 --> 00:04:53,360
或者一些 kernel 的优化

128
00:04:53,360 --> 00:04:56,040
我们是离不开对内存的一个优化的

129
00:04:56,040 --> 00:04:57,960
它们俩是相辅相成

130
00:04:57,960 --> 00:05:00,320
下面我们简单的来去看一下

131
00:05:00,320 --> 00:05:02,360
什幺叫做间接缓冲区

132
00:05:02,360 --> 00:05:04,240
就是间接卷积算法最内核的

133
00:05:04,240 --> 00:05:05,800
就是间接缓冲区了

134
00:05:07,000 --> 00:05:08,280
原来这样

135
00:05:08,480 --> 00:05:10,240
快点给我讲讲吧

136
00:05:14,520 --> 00:05:16,440
好下面我们来到了

137
00:05:16,440 --> 00:05:20,440
Indirect 卷积算法的整体工作流程

138
00:05:20,720 --> 00:05:22,360
首先 Indirect 卷积算法

139
00:05:22,400 --> 00:05:24,440
我们简单的看看下面这个图

140
00:05:24,440 --> 00:05:25,800
后面的所有图

141
00:05:26,080 --> 00:05:27,960
它的颜色我都是对齐的

142
00:05:28,000 --> 00:05:29,160
简单的来讲讲

143
00:05:29,160 --> 00:05:30,080
input 的数据

144
00:05:30,080 --> 00:05:31,160
或者我们的 feature map

145
00:05:31,520 --> 00:05:33,960
会以红色的模块作为主

146
00:05:34,000 --> 00:05:35,600
然后我们的权重

147
00:05:35,840 --> 00:05:38,160
会以绿色的小方框作为主

148
00:05:38,200 --> 00:05:39,840
而最终 output 的输出

149
00:05:40,040 --> 00:05:42,680
我们也会用层次的模块

150
00:05:42,680 --> 00:05:45,040
作为一个主要的颜色

151
00:05:45,280 --> 00:05:47,600
这里面 IH IC IW

152
00:05:47,600 --> 00:05:48,720
H和W

153
00:05:49,040 --> 00:05:50,880
就是我们的长和宽

154
00:05:50,880 --> 00:05:52,520
对于 I 就是 input

155
00:05:52,560 --> 00:05:54,400
而 O 就是 output

156
00:05:54,440 --> 00:05:56,400
而 K 就是 kernels 的大小

157
00:05:57,160 --> 00:05:59,240
这些概念在我们前几节课

158
00:05:59,480 --> 00:06:02,600
都是完完全全是对应起来的

159
00:06:02,600 --> 00:06:03,680
现在我们可以看到

160
00:06:03,960 --> 00:06:05,880
实际上我们不会把所有的

161
00:06:05,880 --> 00:06:07,000
input 的 feature map

162
00:06:07,520 --> 00:06:08,920
同时加载到我们的 L1

163
00:06:08,920 --> 00:06:10,320
或者 L2 缓存里面

164
00:06:10,320 --> 00:06:12,080
而是先把一部分的数据

165
00:06:12,240 --> 00:06:14,960
搬到我们的输入的缓冲区

166
00:06:14,960 --> 00:06:16,400
也就是 input buffer

167
00:06:16,680 --> 00:06:19,320
然后这里面 indirect convolution

168
00:06:19,320 --> 00:06:20,680
间接卷迹优化算法

169
00:06:20,840 --> 00:06:23,360
就引入了一个间接的缓冲区

170
00:06:23,360 --> 00:06:25,400
indirect buffer 这个内容

171
00:06:25,960 --> 00:06:26,960
而间接的缓冲区

172
00:06:27,120 --> 00:06:29,240
是整个算法的一个内核

173
00:06:29,240 --> 00:06:30,440
在网络计算的时候

174
00:06:30,560 --> 00:06:33,720
我们首先会计算 mxm 的输出

175
00:06:33,720 --> 00:06:36,800
也就是 mxm 的简单的输出

176
00:06:37,040 --> 00:06:38,120
这一个内容

177
00:06:38,520 --> 00:06:41,200
每次我只计算一小个模块

178
00:06:41,520 --> 00:06:44,160
现在我们已经了解了 indirect buffer

179
00:06:44,160 --> 00:06:46,480
下面大家可以重新的看看这个图

180
00:06:46,480 --> 00:06:49,840
我们下面也会详细的去展开介绍的

181
00:06:50,600 --> 00:06:53,720
在计算 mxm 规模的大小输出的时候

182
00:06:54,120 --> 00:06:55,800
我们的间接缓冲区

183
00:06:55,960 --> 00:06:58,040
就会取出对应的数据

184
00:06:58,040 --> 00:07:00,840
这里面对应的数据就是 icxm

185
00:07:00,840 --> 00:07:03,800
然后也会取出对应的权重的数据

186
00:07:03,800 --> 00:07:06,680
去计算 icxm 和 icxn

187
00:07:06,680 --> 00:07:09,120
最后是得到我们的 mxm 的数据

188
00:07:09,120 --> 00:07:10,880
塞给我们的输出

189
00:07:11,040 --> 00:07:12,880
这里面怎幺去预储数据

190
00:07:12,880 --> 00:07:15,840
indirect buffer 里面的数据的排布

191
00:07:16,120 --> 00:07:18,160
就显得尤为重要了

192
00:07:18,520 --> 00:07:20,120
下面我们看一下

193
00:07:20,120 --> 00:07:21,800
在实际的实践当中

194
00:07:22,160 --> 00:07:25,160
软件的执行就分为两个部分

195
00:07:25,920 --> 00:07:27,840
第一部分就是准备阶段

196
00:07:27,840 --> 00:07:29,000
在加载模型的时候

197
00:07:29,080 --> 00:07:32,280
我们就需要去配置输入的缓冲区

198
00:07:32,280 --> 00:07:33,560
也就是 indirect buffer

199
00:07:33,880 --> 00:07:36,040
第二步我们需要重排权重

200
00:07:36,280 --> 00:07:38,040
重排权重其实一模一样

201
00:07:38,040 --> 00:07:39,400
我们可以在离线转换模块

202
00:07:39,400 --> 00:07:40,280
或者预编译阶段

203
00:07:40,600 --> 00:07:41,560
进行重排

204
00:07:41,560 --> 00:07:43,200
使得我们的内存布局

205
00:07:43,640 --> 00:07:45,440
是方便我们后续

206
00:07:45,440 --> 00:07:47,520
跟输入缓冲区进行相成的

207
00:07:47,760 --> 00:07:49,680
接着第二步就是运行阶段

208
00:07:49,840 --> 00:07:50,840
真正的运行阶段

209
00:07:50,840 --> 00:07:52,240
就是我们的 one time 阶段

210
00:07:52,240 --> 00:07:54,400
或者 one time 调起 kernel 的时候

211
00:07:54,400 --> 00:07:56,320
我们需要对每个输入的执行

212
00:07:56,680 --> 00:07:58,880
进行 OH 乘以 OW 除以 M

213
00:07:58,880 --> 00:08:01,200
乘以 OC 除以 N 次循环

214
00:08:01,200 --> 00:08:02,480
很多次循环

215
00:08:02,480 --> 00:08:04,160
每次使用 GMM

216
00:08:04,160 --> 00:08:07,240
去计算 M 乘 N 的大小的输出

217
00:08:08,080 --> 00:08:09,920
下面我们来到间接缓冲区

218
00:08:09,920 --> 00:08:10,840
里面最内核的

219
00:08:10,840 --> 00:08:12,680
看看它到底是怎幺布局的

220
00:08:13,160 --> 00:08:14,560
首先间接缓冲区

221
00:08:14,560 --> 00:08:15,960
我们的 localindoorbuff

222
00:08:15,960 --> 00:08:17,240
可以简单理解为

223
00:08:17,240 --> 00:08:19,240
一组卷集和大小的缓冲区

224
00:08:19,240 --> 00:08:21,560
一共有 OH 乘以 OW 个

225
00:08:21,560 --> 00:08:23,560
每个这是简单的一个

226
00:08:23,880 --> 00:08:27,120
每个缓冲区大小为 KH 乘以 KW

227
00:08:27,800 --> 00:08:28,600
在计算的时候

228
00:08:28,760 --> 00:08:30,200
随着我们整体的输出的

229
00:08:30,200 --> 00:08:31,600
所有的内存地址的移动

230
00:08:31,720 --> 00:08:34,240
选用不同的间接的缓冲区

231
00:08:34,240 --> 00:08:36,560
你就可以得到相应的输出的地址

232
00:08:36,560 --> 00:08:39,320
没有必要去根据输出的目标重新去

233
00:08:39,320 --> 00:08:40,440
锁定我们的地址

234
00:08:40,720 --> 00:08:43,480
这种方式其实类似于我们传统进程里面的

235
00:08:43,480 --> 00:08:45,200
用空间换时间的概念

236
00:08:45,680 --> 00:08:47,360
现在我们放大来看一下

237
00:08:47,360 --> 00:08:49,560
左边这个红色都是我们的 featuremap

238
00:08:49,560 --> 00:08:50,640
或者我们的输入码

239
00:08:50,640 --> 00:08:52,640
我们会预取一个 input buffer

240
00:08:52,640 --> 00:08:55,040
把一些一部分的数据预取出来

241
00:08:55,040 --> 00:08:57,080
假设我们现在取的一个简单的

242
00:08:57,080 --> 00:08:58,040
一个快的数据

243
00:08:58,040 --> 00:09:00,560
里面 IH 乘以 IW 乘以 IC

244
00:09:00,560 --> 00:09:04,120
这个时候我们对之前里面的某个卷集和

245
00:09:04,120 --> 00:09:05,920
或者对里面的某个 kernels 大小

246
00:09:05,920 --> 00:09:07,520
就会把它取出来

247
00:09:07,640 --> 00:09:13,000
把数据按照 012 1234 4567

248
00:09:13,000 --> 00:09:15,600
这种方式进行一个预取

249
00:09:15,600 --> 00:09:17,480
预取成为 indirect buffer

250
00:09:17,480 --> 00:09:20,480
把它变成一个间接的缓冲区

251
00:09:20,480 --> 00:09:21,960
这个间接缓冲区很有意思

252
00:09:21,960 --> 00:09:23,960
就 0123 1234 2345

253
00:09:23,960 --> 00:09:26,920
然后通过这种方式就以空间换时间

254
00:09:26,920 --> 00:09:29,800
把大量的数据全部取出来

255
00:09:29,800 --> 00:09:31,880
方便我们后续的直接相乘

256
00:09:31,880 --> 00:09:32,640
直接相乘之后

257
00:09:32,640 --> 00:09:35,120
直接得到我们的最后的结果了

258
00:09:36,120 --> 00:09:37,760
其实卷集可以使用

259
00:09:37,760 --> 00:09:39,920
AVG Clump 这种优化的算法

260
00:09:39,920 --> 00:09:41,960
本质原因主要是拆分之后

261
00:09:41,960 --> 00:09:43,720
我们可以忽略内存附用之后的

262
00:09:43,720 --> 00:09:46,760
整个计算过程等价于矩阵乘

263
00:09:46,760 --> 00:09:48,960
也就是使用矩阵乘

264
00:09:48,960 --> 00:09:52,680
对我们的卷集进行一个替换

265
00:09:52,680 --> 00:09:54,760
而间接缓冲区就可以通过大量的

266
00:09:54,760 --> 00:09:56,320
复制我们的地址的数据

267
00:09:56,320 --> 00:09:58,760
然后通过子帧或者模拟子帧的方式

268
00:09:58,760 --> 00:10:00,960
模拟出对输入的仿存

269
00:10:00,960 --> 00:10:02,160
这种方式的优点

270
00:10:02,160 --> 00:10:04,120
就是解决空间限量化的问题

271
00:10:04,120 --> 00:10:06,920
同时可以计算很多个数据

272
00:10:06,920 --> 00:10:09,760
第2个就是地址计算会变得更加简单

273
00:10:09,760 --> 00:10:12,160
因为我不需要不断的去寻子了

274
00:10:12,160 --> 00:10:14,160
或者子帧来回的去跳跃

275
00:10:14,160 --> 00:10:15,880
而是直接根据下一个地址

276
00:10:15,880 --> 00:10:17,840
去预取数据就行了

277
00:10:17,840 --> 00:10:19,760
第3个就是解决我们的内存

278
00:10:19,760 --> 00:10:22,280
大量的重复拷贝的问题

279
00:10:22,280 --> 00:10:24,080
但是缺点也很明确

280
00:10:24,080 --> 00:10:26,840
就是创建整个数据的缓冲区

281
00:10:26,840 --> 00:10:29,320
需要大量的内存空间

282
00:10:29,320 --> 00:10:32,600
第4个就是数据进行重排 Repacking

283
00:10:32,600 --> 00:10:35,360
会消耗我们大量的仿存

284
00:10:35,360 --> 00:10:37,480
或者大量的预编译的时间

285
00:10:38,360 --> 00:10:41,400
下面我们对整个卷迹算法

286
00:10:41,400 --> 00:10:43,240
进行总结一下

287
00:10:43,560 --> 00:10:45,280
最后一个内容

288
00:10:45,280 --> 00:10:46,960
就是对我们之前讲到的

289
00:10:46,960 --> 00:10:49,120
好几个 kernel 卷迹优化的算法

290
00:10:49,320 --> 00:10:51,560
进行一个横向的总结

291
00:10:51,560 --> 00:10:55,320
首先我们上面的视频所讲的方法

292
00:10:55,520 --> 00:10:58,280
都是通用的卷迹的优化方法

293
00:10:58,520 --> 00:10:59,480
随着神经网络

294
00:10:59,480 --> 00:11:02,760
或者很多的新的 AI 处理器的出现

295
00:11:03,200 --> 00:11:05,160
我们整个算法的优化

296
00:11:05,160 --> 00:11:07,320
其实还在不断的深挖的

297
00:11:07,320 --> 00:11:10,040
因为不同的卷迹的方式

298
00:11:10,040 --> 00:11:12,160
会使用到不同的处理器里面的

299
00:11:12,160 --> 00:11:13,720
一些重要的指令

300
00:11:13,720 --> 00:11:15,880
而且有可能会有更多的新的指令

301
00:11:15,880 --> 00:11:16,680
会提出

302
00:11:16,680 --> 00:11:17,880
例如一开始之前

303
00:11:17,880 --> 00:11:19,360
可能五六年前

304
00:11:19,360 --> 00:11:20,840
我在做深度学习的时候

305
00:11:20,960 --> 00:11:22,240
还没想到会使用到

306
00:11:22,240 --> 00:11:23,600
int8 相关的指令的

307
00:11:23,600 --> 00:11:24,920
或者一些张量的指令

308
00:11:24,920 --> 00:11:27,000
现在 int4, int2

309
00:11:27,000 --> 00:11:28,880
或者 int8 的指令越来越多

310
00:11:28,920 --> 00:11:30,960
而相关的除了相量化的指令

311
00:11:30,960 --> 00:11:32,560
还出现了张量化的指令

312
00:11:32,560 --> 00:11:33,600
也越来越多

313
00:11:33,600 --> 00:11:35,720
不管是 SIMP 还是 MND 的架构

314
00:11:35,720 --> 00:11:37,800
也会不断的去演进

315
00:11:38,720 --> 00:11:39,200
好了

316
00:11:39,200 --> 00:11:40,960
今天的内容就到这里为止

317
00:11:40,960 --> 00:11:41,680
谢谢各位

318
00:11:41,680 --> 00:11:42,840
拜拜

319
00:11:43,680 --> 00:11:44,440
卷得不行了

320
00:11:44,440 --> 00:11:45,320
卷得不行了

321
00:11:45,320 --> 00:11:46,760
记得一键三连加关注

322
00:11:47,160 --> 00:11:48,520
所有的内容都会开源

323
00:11:48,520 --> 00:11:50,360
在下面这条链接里面

324
00:11:50,720 --> 00:11:51,680
拜拜

