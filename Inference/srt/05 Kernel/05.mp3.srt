0
0:00:00.000 --> 0:00:04.500
啪啪啪啪啪啪啪

1
0:00:05.280 --> 0:00:06.660
哈喽大家好我是宗米

2
0:00:06.740 --> 0:00:09.900
在颗能优化这个内容里面呢我知道应该看人很少了

3
0:00:09.960 --> 0:00:11.940
而且我讲的确实并不太好啊

4
0:00:12.120 --> 0:00:17.580
那今天呢我们来到了一个新的内容叫做间接优化indirect优化

5
0:00:17.840 --> 0:00:22.300
那这个间接优化的方式呢还是很有意思的或者它有些背景的

6
0:00:22.420 --> 0:00:28.100
我们看一下在整体的推理引擎的架构图呢我们现在位于颗能厂就中间的这一层

7
0:00:28.100 --> 0:00:35.500
每个克诺呢或者每一个卷积我们看到的每一个卷积算子下面底层可能会对接非常多个克诺的

8
0:00:35.500 --> 0:00:41.000
所以在实际的实践过程当中啊你看到的你用到的是一个算子

9
0:00:41.000 --> 0:00:47.100
但是你们可能会执行不同的克诺而不同的克诺呢是我们的温泰呢去决定的

10
0:00:47.100 --> 0:00:51.500
在整个卷积克诺的优化内容里面呢我们现在来到了最后一个内容

11
0:00:51.500 --> 0:00:58.900
QAMPAC间接卷积优化indirect algorithm什么为之间接的卷积优化呢

12
0:00:58.900 --> 0:01:03.900
我们现在来看一下首先呢一个很重要的概念就是QAMPAC

13
0:01:03.900 --> 0:01:08.400
QAMPAC就是quantilization nature network package

14
0:01:08.400 --> 0:01:13.400
它是由飞斯布这个人呢后来去了谷歌后来现在不知道去哪了

15
0:01:13.400 --> 0:01:19.600
然后呢他在飞斯布的时候呢当时候是为了对神经网络模型量化提出的一个算法

16
0:01:19.600 --> 0:01:25.600
当时候提出来的时候呢整体的性能啊确实已经击败了所有已公开的加速算法

17
0:01:25.600 --> 0:01:32.600
所以这个算法呢不仅仅能够用在量化的时候非量化的时候也可以去使用而且效果还是非常的惊人

18
0:01:33.600 --> 0:01:39.900
作者呢离开了飞斯布之后呢因为在飞斯布的时候呢这个算法确实太好没有公开太多的实现的细节

19
0:01:39.900 --> 0:01:45.100
直到他离开了飞斯布之后呢他就把这篇文章呢发表了出来而且就论证了

20
0:01:45.100 --> 0:01:48.600
确实这个算法的效果呢特别的好

21
0:01:49.600 --> 0:01:53.600
下面呢我们回顾一下云比数克拉姆的整体的一个算法

22
0:01:53.600 --> 0:01:58.100
现在其实很多呃卷机的算法基本上很少会迭代很多个負

23
0:01:58.100 --> 0:02:01.100
更多的是使用云比数克拉姆的算法去实现的

24
0:02:01.100 --> 0:02:06.100
所以我们不管是讲到雷米诺贵的算法呢还是QA派克的算法呢

25
0:02:06.100 --> 0:02:10.100
都基本上会经云比数克拉姆来去进行一个比较

26
0:02:10.100 --> 0:02:19.100
那假设呢我们现在要算一个mR乘以nR的小块的时候呢传统的GM的方法呢就是对k维度呢进行一个拆分的

27
0:02:19.100 --> 0:02:21.600
下面我们看一下云比克拉姆的整体的算法

28
0:02:21.600 --> 0:02:25.600
首先云比克拉姆的假设我们的B呢就是我们的科诺斯

29
0:02:25.600 --> 0:02:27.100
然后A呢就是feature map

30
0:02:27.100 --> 0:02:29.600
C呢就是最终的输出的数据

31
0:02:29.600 --> 0:02:36.600
会把科诺斯的一列乘以我们feature maps的一行得到最终输出的一个元素的值

32
0:02:36.600 --> 0:02:41.100
所以说它的计算量还是挺大的每次都要把很多的数据塞进去

33
0:02:41.100 --> 0:02:46.100
当然了为了更加的方便我们进行操作我们一般不会单算一个数

34
0:02:46.100 --> 0:02:48.600
而是会同一时间呢会算很多数

35
0:02:48.600 --> 0:02:51.100
也就是我们的向量化的操作

36
0:02:51.100 --> 0:02:59.100
就把很多个B呢和A呢同时进行矩阵层得到我们C里面的很多的数值

37
0:02:59.100 --> 0:03:04.100
那这个呢就是一个简单的向量化的加速

38
0:03:04.100 --> 0:03:08.600
后来呢有了分块之后或者分块的概念起来之后呢

39
0:03:08.600 --> 0:03:14.100
在传统的方法呢就是对我们的k维度就B的卷积和按k维度进行拆分

40
0:03:14.100 --> 0:03:17.100
在一次计算的时候呢只算k的某个值

41
0:03:17.100 --> 0:03:21.100
然后A呢就是我们的feature map也是按这个维度进行拆分

42
0:03:21.100 --> 0:03:25.600
然后算每一个值然后呢再把这些值呢进行一个累加

43
0:03:25.600 --> 0:03:30.600
但这个时候呢就会引起额外的输出的加载和存储了

44
0:03:30.600 --> 0:03:35.600
每次呢都会有额外的数据在内存里面呢重新的加载和存储

45
0:03:35.600 --> 0:03:39.600
下面呢我们简单的看一下qmpeg这个算法的思想

46
0:03:39.600 --> 0:03:46.600
那这里面呢就qmpeg indirect的方法基本上呢就消除了输出部分的额外的网存

47
0:03:46.600 --> 0:03:51.100
虽然呢可以看到B呢还是按k维度进行拆分不是说不拆分

48
0:03:51.100 --> 0:03:57.600
而是拆分之后呢不和其他维度进行交换和重新的一个额外的网存的计算

49
0:03:57.600 --> 0:04:01.100
具体它是怎么实现的我们下面来分解一下

50
0:04:01.100 --> 0:04:04.100
在进入下个内容之前呢小心有两个问题

51
0:04:04.100 --> 0:04:06.100
第一个问题呢就是

52
0:04:07.600 --> 0:04:13.100
中明老师你好你刚才提到image crumb这个优化算法呢有两个问题

53
0:04:13.100 --> 0:04:17.600
第一个呢就是会占用额外大量的内存

54
0:04:17.600 --> 0:04:22.600
第二个呢是需要对输入的数据呢进行额外的拷贝

55
0:04:22.600 --> 0:04:26.600
这两点qmpeg怎么来解决吗

56
0:04:26.600 --> 0:04:27.600
很有意思

57
0:04:27.600 --> 0:04:33.600
qmpeg呢最核心的算法叫做间接卷积优化算法

58
0:04:33.600 --> 0:04:38.600
它的答案呢就是有一个间接的缓冲区indirect buffer

59
0:04:38.600 --> 0:04:40.600
首先建立一个间接的缓冲区

60
0:04:40.600 --> 0:04:44.600
对内存进行重新的组织我们叫做repacking

61
0:04:44.600 --> 0:04:49.100
这样呢就可以提高整体的命中率从而提高我们的性能

62
0:04:49.100 --> 0:04:53.100
所以说呢在我们卷积的优化或者一些克诺的优化

63
0:04:53.100 --> 0:04:56.100
我们是离不开对内存的一个优化的

64
0:04:56.100 --> 0:04:58.100
它们两是相辅相成

65
0:04:58.100 --> 0:05:02.100
下面呢我们简单的来去看一下什么叫做间接缓冲区

66
0:05:02.100 --> 0:05:06.100
就是间接卷积算法最核心的就是间接缓冲区了

67
0:05:06.600 --> 0:05:10.600
哦原来这样快点给我讲讲吧

68
0:05:14.600 --> 0:05:20.600
好下面我们来到了indirect卷积这个算法的整体工作流程

69
0:05:20.600 --> 0:05:24.600
首先呢indirect卷积算法呢我们简单的看看下面这个图

70
0:05:24.600 --> 0:05:28.100
后面的所有图呢它的颜色我都是对齐的

71
0:05:28.100 --> 0:05:31.600
简单的来讲讲input的数据或者我们的feature map呢

72
0:05:31.600 --> 0:05:34.100
会以红色的这个模块作为主

73
0:05:34.100 --> 0:05:38.100
然后呢我们的权重呢会以绿色的小方方作为主

74
0:05:38.100 --> 0:05:45.100
而最终output的输出呢我们也会用层次这个模块作为一个主要的颜色

75
0:05:45.100 --> 0:05:52.600
这里面的i h i c i w呢h和w呢就是我们的长和宽对于i呢就是input

76
0:05:52.600 --> 0:05:56.600
而o呢就是output而k呢就是克诺的大小

77
0:05:56.600 --> 0:06:02.600
这些概念呢在我们前几节课呢都是完完全全是对应起来的

78
0:06:02.600 --> 0:06:07.100
现在我们可以看到呢实际上呢我们不会把所有的input的feature map

79
0:06:07.100 --> 0:06:10.100
同时加入到我们的l一或者l二款存里面

80
0:06:10.100 --> 0:06:15.100
而是先把一部分的数据呢搬到我们的输入的缓冲区

81
0:06:15.100 --> 0:06:16.600
也就是input的buffer

82
0:06:16.600 --> 0:06:25.600
然后呢这里面indirect convolution间接卷积优化算法呢就引入了一个间接的缓冲区indirect buffer这个内容

83
0:06:25.600 --> 0:06:29.100
而间接的缓冲区呢是整个算法的一个核心

84
0:06:29.100 --> 0:06:33.600
在网络计算的时候呢我们首先会计算m乘以m的输出

85
0:06:33.600 --> 0:06:36.600
也就是m乘以m的简单的输出

86
0:06:36.600 --> 0:06:41.100
借一个内容每次呢我只计算一小个模块

87
0:06:41.100 --> 0:06:46.600
那现在呢我们已经了解了indirect buffer下面大家可以重新的看看这个图

88
0:06:46.600 --> 0:06:50.100
我们下面呢也会详细的去展开介绍的

89
0:06:50.100 --> 0:06:53.600
在计算m乘以m规模的大小输出的时候呢

90
0:06:53.600 --> 0:06:57.600
我们的间接缓冲区呢就会取出对应的数据

91
0:06:58.100 --> 0:07:01.100
这里面对应的数据就是ic乘以m

92
0:07:01.100 --> 0:07:06.600
然后呢也会取出对应的群中的数据去计算ic乘以m和ic乘以n

93
0:07:06.600 --> 0:07:11.100
最后呢只得到我们的m乘以m的数据塞给我们的输出

94
0:07:11.100 --> 0:07:18.600
这里面怎么去预储数据indirect buffer里面的数据的排布就显得尤为重要了

95
0:07:18.600 --> 0:07:25.600
下面呢我们看一下在实际的实现当中啊软件的执行呢就分为两个部分

96
0:07:25.600 --> 0:07:33.600
第一部分呢就是准备阶段在加载模型的时候呢我们就需要去配置输入的缓冲区也就是indirect buffer

97
0:07:33.600 --> 0:07:38.100
第二步呢我们需要重排全众那重排全众呢其实一模一样

98
0:07:38.100 --> 0:07:43.600
我们可以在理性转化模块或者预编一阶段呢进行重排使得我们的内存布局呢

99
0:07:43.600 --> 0:07:47.600
是方便我们后续跟输入缓冲区进行相成的

100
0:07:47.600 --> 0:07:52.100
接着呢第二步就是运行阶段呢真正的运行阶段就是我们的温碳阶段

101
0:07:52.100 --> 0:08:01.100
或者温碳吊起科诺的时候我们需要对每个数据的执行呢进行OH乘以OW除以M乘以OC除以N次循环

102
0:08:01.100 --> 0:08:08.100
很多次循环每次呢使用GMM去计算M乘N的大小的输出

103
0:08:08.100 --> 0:08:13.100
下面呢我们来到间接缓冲区里面最核心的看看它到底是怎么布局的

104
0:08:13.100 --> 0:08:19.100
首先呢间接缓冲区我们的local indirect buffer呢可以理解简单理解为一组卷迹和大小的缓冲区

105
0:08:19.100 --> 0:08:27.100
一共呢有OH乘以OW各每个这是简单的一个嘛每个缓冲区呢大小为KH乘以KW

106
0:08:27.100 --> 0:08:34.100
在计算的时候呢随着我们整体的输出的所有的内存地址的移动呢使用不同的间接的缓冲区

107
0:08:34.100 --> 0:08:40.100
就可以得到相应的输出的地址没有必要去根据输出的目标重新去索引我们的地址

108
0:08:40.100 --> 0:08:45.100
这种方式呢其实类似于我们传统程序里面的用空间换时间的概念

109
0:08:45.100 --> 0:08:50.100
现在我们放大来看一下左边这个呢红色都是我们的feature map或者我们的输入码

110
0:08:50.100 --> 0:09:00.100
我们会预取一个input buffer把一些一部分的数据呢预取出来假设我们现在取的一个简单的一个快的数据里面的IH乘以IW乘以IC

111
0:09:00.100 --> 0:09:07.100
这个时候呢我们对之前里面的某个卷迹和块对里面的某个kernels大小就会把它取出来

112
0:09:07.100 --> 0:09:20.100
把数据呢按照零一二一二三四四五六七这种方式呢进行一个预取预取成为indirect buffer把它变成一个间接的缓冲区

113
0:09:20.100 --> 0:09:24.100
这个间接缓冲区很有意思就零一二三一二三四二三四五

114
0:09:24.100 --> 0:09:29.100
然后通过这种方式呢就以空间换时间把大量的数据呢全部取出来

115
0:09:29.100 --> 0:09:35.100
方便我们后续的直接相乘直接相乘之后直接得到我们的最后的结果了

116
0:09:36.100 --> 0:09:46.100
其实卷迹可以使用invisclone这种优化的算法本子原因呢主要是拆分之后我们可以顾虑内存附用之后的整个计算过程等价于矩战层

117
0:09:46.100 --> 0:09:52.100
也就是使用矩战层呢对我们的卷迹进行一个替换

118
0:09:52.100 --> 0:09:56.100
而间接缓冲区呢就可以通过大量的复制我们的地址的数据

119
0:09:56.100 --> 0:10:04.100
然后通过子针或者模拟子针的方式呢模拟出对输入的防存这种方式的优点呢就是解决空间限量化的问题

120
0:10:04.100 --> 0:10:12.100
同时可以计算很多个数据第二个呢就是地址计算呢会变得更加简单因为我不需要不断的去寻子了

121
0:10:12.100 --> 0:10:22.100
或者子针来回的去跳跃而是直接根据下一个地址去预取数据就行了第三个呢就是解决我们的内存大量的重复拷备的问题

122
0:10:22.100 --> 0:10:29.100
但是缺点也很明确啊就是建立整个数据的缓冲区呢需要大量的内存空间

123
0:10:29.100 --> 0:10:38.100
第三个呢就是数据进行重排复制会消耗我们大量的防存或者大量的预编译的时间

124
0:10:38.100 --> 0:10:51.100
下面呢我们对整个卷迹算法呢进行总结一下最后呢最后一个内容就是对我们之前讲到的好几个颗粒卷迹优化的算法呢进行一个横向的总结

125
0:10:51.100 --> 0:10:58.100
首先我们上面的视频所讲的方法呢都是通用的卷迹的优化方法

126
0:10:58.100 --> 0:11:07.100
那随着神经网络或者很多的新的AI处理器的出现呢我们整个算法的优化其实还在不断的深挖呢

127
0:11:07.100 --> 0:11:16.100
因为不同的卷迹的方式会使用到不同的处理器里面的一些重要的指令而且有可能会有更多的新的指令会提出

128
0:11:16.100 --> 0:11:25.100
例如一开始之前可能五年五六年前我在做深度学习的时候呢还没想到会使用到英特巴相关的指令的或者一些张亮的指令

129
0:11:25.100 --> 0:11:38.100
现在呢英特四英特奥或者英特巴的指令越来越多而相关的除了相量化的指令还出现了张量化的指令也越来越多不管是simp还是md的架构也会不断的趋于演进

130
0:11:38.100 --> 0:11:54.100
那好了今天的内容呢就到这里为止谢谢各位摆了个拜卷得不行了卷得不行了记得一键三连加关注哦所有的内容都会开源在下面这条链接里面摆了个拜

