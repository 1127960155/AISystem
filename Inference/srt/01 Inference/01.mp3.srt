0
0:00:00.000 --> 0:00:04.580


1
0:00:06.300 --> 0:00:08.160
哈喽大家好我是ZOMI

2
0:00:08.160 --> 0:00:11.400
好久没有更新了因为之前换了新冠嘛

3
0:00:11.400 --> 0:00:13.520
到了晚上十二点之后呢就特别地困

4
0:00:13.520 --> 0:00:15.080
然后就不能再干了

5
0:00:16.080 --> 0:00:18.700
虽然呢壁杆上面有些同学呢叫我干弟啊

6
0:00:18.700 --> 0:00:21.320
但实际上呢嗯还是干不动了

7
0:00:21.320 --> 0:00:26.320
那今天呢我们来到一个新的内容叫做推理系统推理系统系列

8
0:00:26.320 --> 0:00:35.120
而正式去了解什么是推理系统之前呢我们去了解一下推理系统这个系列我们将会给大家汇报哪些内容

9
0:00:35.120 --> 0:00:55.720
主要给大家汇报的内容呢分开四块那第一块呢就是整个推理系统的介绍第二个内容呢就是模型的小型化这块呢更多的是聚焦一些算法第三个呢就是离线优化压缩的一些算法最后一块呢就是不符合运行的优化

10
0:00:55.720 --> 0:01:25.720
那我们足快地打开来去看一下我们将会讲解或者分享哪些内容第一个呢就是推理系统啊我们可以看到其实推理系统和推理引擎是不太一样的系统更多的是聚焦于整个推理的服务而推理的引擎呢更多的是指我们的一个把AI算法跑起来那接着呢我们去看看推理的一个工作的流程去了解一下推理系统和推理引擎它整个工作流需要做哪些内容然后呢我们就会去深入地去看看推理系统具体

11
0:01:25.720 --> 0:01:55.720
有哪些工作推理系统的有哪些系统比较好的系统性的介绍一下接着呢我们会比较宏观地去介绍一下推理引擎的整体的架构还有推理引擎的一个工作的流程那这一块呢可能推理引擎是我们后面所有工作的一个重点包括模型小型化了离线的优化了还有我们在线部署的优化都是围绕着推理引擎去展开的哦在第二个大结的内容里面呢就是我们的模型小型化其实这个呢我们更多的是

12
0:01:55.720 --> 0:02:25.720
聚焦于一些小型化的笨笨或者小型化的搜桃网络模型那例如呢我们会讲很多CNN的一些小型化的结构包括摩拜的一飞行带的瑟芳的斯奎斯内还有诺亚的高斯特内这一块呢我们更多是围绕着神经网络的一个小型化去展开接着呢因为最近啊全索玛特别的火而全索玛的小型化的研究呢也是非常的热门至少在这两年来说呢特别的热门所以我们会讲讲全索玛小型化的一个

13
0:02:25.720 --> 0:02:27.520
具体的算法的结构

14
0:02:28.320 --> 0:02:34.840
在第二个大的内容里面的模型的小型化这个可能更多的不是跟系统相关的而是跟算法相关

15
0:02:35.040 --> 0:02:55.200
接着呢我们在第三个内容离线的优化压缩离线的优化压缩其实跟嗯系统相关的性也不太大更多的也是跟算法相关第一个就是低比特的量化就我们可能嗯四比特八比特的一些量化的算法我们会去系统性的去介绍接着呢去介绍一下二子化网络

16
0:02:55.720 --> 0:03:04.520
二子化网络这个很有意思啊就二子化就是零跟一这种二子化的网络那这块呢我们会简单的去介绍一下最新的一个研究

17
0:03:04.640 --> 0:03:15.160
那接着呢我们去看看模型的剪子还有模型的蒸留那这块呢其实整个小型化的压缩在端侧是非常的热门或者基本上你是离不开的哦

18
0:03:16.560 --> 0:03:22.640
在最后第四部分呢我们正式的进入到推力引擎的一个在线部署和优化的

19
0:03:23.280 --> 0:03:27.520
首先第一个呢就是图的转化优化包括一些算子融合从牌替换

20
0:03:28.440 --> 0:03:36.880
这块呢其实跟我们的AI框架或者AI系统或者AI编译器呢其实比较相关我们会把很多相关的知识呢把它串起来

21
0:03:37.200 --> 0:03:41.120
接着呢我们会去看看在线部署的一些并发资讯还有内存分配

22
0:03:42.480 --> 0:03:50.240
最后呢会看一个比较难的问题动态的batch还有binpacking还有一些推力引擎具体是怎么实现的一些底层的one time的优化

23
0:03:50.240 --> 0:03:55.040
那这一块呢就是第四部分那接下来我们将会进入正式的内容

24
0:03:56.800 --> 0:04:00.080
我们现在来看一下典型的深度学习的推理的一些应用

25
0:04:01.400 --> 0:04:10.000
像左边的这个呢就是人脸脸膜的一个应用那除了人脸脸膜了它还会做一些人脸的识别眼睛的识别人脸头像的朝向

26
0:04:10.280 --> 0:04:17.280
那右边的这两张图呢还是比较有意思的就是利用华为HMS core里面去实现的而HMS core里面

27
0:04:18.120 --> 0:04:23.360
很多技术的支撑呢就是我在后面提供相关的技术的当然了包括我很多的同事的努力

28
0:04:24.160 --> 0:04:38.920
这个呢就是玩游戏我们去检测人脸的头像的位置在哪里然后人脸像上了这个小机器人或者小飞船就往上往下那这个呢就检测我们的手势的识别那要是开炮呢就可能把手张开就可以了

29
0:04:39.240 --> 0:04:43.120
像这种应用的还是很有意思的而且应用的也是非常的多

30
0:04:44.120 --> 0:04:47.320
那我们往下看一下特别是我们现在在

31
0:04:48.320 --> 0:05:12.680
典型的对话机器人我们在淘宝或者在拼多多经常去咨询一些客户的时候我其实个人来说我最讨厌的就是遇到一些对话机器人每次我问问题呢他就谈个对话机器人出来然后就是帮我解答一些最基础的问题那这种的服务体验不是很好但是对于那些平台厂商来说呢能够节省他们大量的人力咨询的问题和人力压力的问题

32
0:05:12.680 --> 0:05:29.240
例如我只是简单的去问一个物流现在的物流你发哪个物流或者你现在的物流情况怎么样了像这种的完全可以用对话机器人来去解决而最新的确实GPT啊确实也是非常的火或者可以说火到一塌糊涂大家可以去了解一下

33
0:05:31.240 --> 0:05:39.760
那接下来我们看一下另外一个应用就是推荐系统那推荐系统呢可能更多的是不是说那个离线推荐而是在线推荐

34
0:05:39.760 --> 0:06:03.760
但是推荐系统呢现在大部分呢至少我认识阿里巴巴或者我当时候应该是几年前去面试阿里巴巴的时候呢他就去问我很多相关的工作而里面呢我当时候面试的一个岗位呢也是从事于淘宝推荐就下面很多推荐呢其实而这个呢也是用了非常多的AI的算法然后更多的是AI的推理的应用和推理的算法

35
0:06:03.760 --> 0:06:04.480
那接下来我们再看一个最近比较火的一个应用叫做AIGC那这个呢是我在自郁亮子卫的一篇报道关于抖音的报道你可以看到一开始我输一张图片然后这张图片我可以选各种的风格我是一个肌肉男然后呢我输入进去呢也是变成非常多的不同的风格这种呢就是AIGC也是我应该是一年前呢我就非常留意这个技术了也启动了一些相关的

36
0:06:33.760 --> 0:07:03.760
一些合作技术所以说这块应该是这后半年才华起来的也是非常有意思那像我们刚才所说到的很多都是深度学习的一些推理的应用里面没有训练相关我们更多是集中在推理而在这个过程当中呢我们整个推理系统我们以淘宝的推荐为例啊可能在推理系统而不是推理引擎啊是系统我们会考虑的问题呢可能会非常多了利于我们被用户所调用的API的接口呢

37
0:07:03.760 --> 0:07:33.760
我们的数据呢怎么去生成我们怎么去在网络的影响下了低延时的反馈用户的结果另外的话因为我们手机上面嘛我们怎么利用多样性的一个加速器我们手机里面SOC加速的资源怎么把它利用起来另外的话可能我们的用户的吞吐量大了那这个访问的服务怎么去做一些容哉或者扩容的问题另外的话对于网络来说我怎么上线新的一些网络模型那这个时候呢怎么做AP text

38
0:07:33.760 --> 0:08:03.760
都是一些很大的挑战也是我们做系统里面需要考虑的一些问题那现在我们总结两个点如果我们简单地赋用原有的web的服务呢其实是没有办法去解决所有的问题的特别是在深度学习这个大部分都用推理的时候呢很多系统性的问题和挑战就会出现了那第二点呢就是深度学习的训练和推理过程其实是不同的哦而他们的生命周期呢也是不同的


