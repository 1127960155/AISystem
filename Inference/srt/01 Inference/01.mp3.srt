0
0:00:00.000 --> 0:00:04.560
巴巴巴巴巴巴巴巴巴

1
0:00:06.320 --> 0:00:07.400
哈喽大家好

2
0:00:07.400 --> 0:00:08.200
我是钟米

3
0:00:08.200 --> 0:00:09.440
好久没有更新了

4
0:00:09.440 --> 0:00:11.120
因为之前换了新罐

5
0:00:11.120 --> 0:00:13.640
到了晚上12点之后就特别的困

6
0:00:13.640 --> 0:00:15.000
然后就不能再干了

7
0:00:16.080 --> 0:00:18.640
虽然B站上面有些同学叫我干弟

8
0:00:18.720 --> 0:00:21.280
但实际上还是干不动了

9
0:00:21.480 --> 0:00:23.200
今天我们来到一个新的内容

10
0:00:23.200 --> 0:00:25.120
叫做推理系统

11
0:00:25.120 --> 0:00:26.200
推理系统系列

12
0:00:27.200 --> 0:00:29.960
而正式去了解什幺是推理系统之前

13
0:00:30.080 --> 0:00:32.440
我们去了解一下推理系统系列

14
0:00:32.440 --> 0:00:35.160
我们将会给大家汇报哪些内容

15
0:00:36.480 --> 0:00:39.760
主要给大家汇报的内容分开四块

16
0:00:39.920 --> 0:00:42.400
第一块就是整个推理系统的介绍

17
0:00:42.840 --> 0:00:45.880
第二个内容就是模型的小型化

18
0:00:45.880 --> 0:00:48.440
这块更多的是聚焦一些算法

19
0:00:48.440 --> 0:00:51.800
第三个就是离线优化压缩的一些算法

20
0:00:52.240 --> 0:00:55.600
最后一块就是部署和运行的优化

21
0:00:55.800 --> 0:00:57.400
我们足快的打开来去看一下

22
0:00:57.400 --> 0:00:59.600
我们将会讲解或者分享哪些内容

23
0:00:59.600 --> 0:01:01.080
第一个就是推理系统

24
0:01:01.360 --> 0:01:04.040
我们可以看到其实推理系统和推理引擎

25
0:01:04.040 --> 0:01:05.320
是不太一样的

26
0:01:05.320 --> 0:01:08.600
系统更多的是聚焦于整个推理的服务

27
0:01:08.600 --> 0:01:10.960
而推理的引擎更多的是指我们的

28
0:01:10.960 --> 0:01:13.360
一个把AI算法跑起来

29
0:01:13.480 --> 0:01:16.480
接着我们去看看推理的一个工作的流程

30
0:01:16.480 --> 0:01:19.040
去了解一下推理系统和推理引擎

31
0:01:19.040 --> 0:01:21.480
它整个工作流需要做哪些内容

32
0:01:21.480 --> 0:01:25.040
然后我们就会去深入的去看看推理系统

33
0:01:25.160 --> 0:01:26.600
具体有哪些工作

34
0:01:26.600 --> 0:01:28.560
推理系统有哪些系统

35
0:01:28.560 --> 0:01:30.640
比较好的系统性的介绍一下

36
0:01:30.640 --> 0:01:33.120
接着我们会比较宏观的去介绍一下

37
0:01:33.120 --> 0:01:35.160
推理引擎的整体的架构

38
0:01:35.160 --> 0:01:37.200
还有推理引擎的一个工作的流程

39
0:01:37.200 --> 0:01:39.080
这一块可能推理引擎

40
0:01:39.360 --> 0:01:41.520
是我们后面所有工作的一个重点

41
0:01:41.520 --> 0:01:43.640
包括模型小型化、离线的优化

42
0:01:43.640 --> 0:01:45.800
还有我们在线部署的优化

43
0:01:45.800 --> 0:01:48.320
都是围绕着推理引擎去展开的

44
0:01:49.800 --> 0:01:52.120
在第二个大节的内容里面

45
0:01:52.280 --> 0:01:53.800
就是我们的模型小型化

46
0:01:53.800 --> 0:01:56.680
其实这个我们更多的是聚焦于一些

47
0:01:57.040 --> 0:01:58.320
小型化的BadBomb

48
0:01:58.320 --> 0:02:00.240
或者小型化的Sota网络模型

49
0:02:00.360 --> 0:02:03.680
例如我们会讲很多CNN的一些小型化的结构

50
0:02:03.680 --> 0:02:06.440
包括MobileNet, EfficientNet, ServerNet, SquishNet

51
0:02:06.440 --> 0:02:08.840
还有诺亚的GhostNet

52
0:02:08.840 --> 0:02:10.760
这一块我们更多的是围绕着

53
0:02:10.760 --> 0:02:13.320
神经网络的一个小型化去展开

54
0:02:13.320 --> 0:02:16.320
接着因为最近全苏莫特别的火

55
0:02:16.320 --> 0:02:20.280
而全苏莫的小型化的研究也是非常的热门

56
0:02:20.280 --> 0:02:23.200
至少在这两年来说特别的热门

57
0:02:23.240 --> 0:02:25.440
所以我们会讲全苏莫小型化的

58
0:02:25.440 --> 0:02:27.400
一个具体的算法的结构

59
0:02:28.240 --> 0:02:29.480
在第二个大的内容里面

60
0:02:29.720 --> 0:02:31.920
模型的小型化可能更多的

61
0:02:31.920 --> 0:02:33.480
不是跟系统相关的

62
0:02:33.480 --> 0:02:34.760
而是跟算法相关

63
0:02:34.760 --> 0:02:36.720
接着我们在第三个内容

64
0:02:36.720 --> 0:02:37.920
离线的优化压缩

65
0:02:37.920 --> 0:02:38.880
离线的优化压缩

66
0:02:38.880 --> 0:02:42.000
其实跟系统相关的性也不太大

67
0:02:42.000 --> 0:02:43.960
更多的也是跟算法相关

68
0:02:43.960 --> 0:02:46.160
第一个就是低比特的量化

69
0:02:46.160 --> 0:02:48.800
就我们可能4比特8比特的

70
0:02:48.800 --> 0:02:50.160
一些量化的算法

71
0:02:50.160 --> 0:02:52.760
我们会去系统性的去介绍

72
0:02:52.880 --> 0:02:55.000
接着去介绍一下二值化网络

73
0:02:55.800 --> 0:02:57.200
二值化网络很有意思

74
0:02:57.200 --> 0:03:00.440
二值化就是0跟1这种二值化的网络

75
0:03:00.720 --> 0:03:02.880
这一块我们会简单的去介绍一下

76
0:03:02.880 --> 0:03:04.480
最新的一个研究

77
0:03:04.800 --> 0:03:06.960
接着我们去看看模型的剪辞

78
0:03:06.960 --> 0:03:08.400
还有模型的蒸馏

79
0:03:08.640 --> 0:03:10.880
这一块其实整个小型化的压缩

80
0:03:10.880 --> 0:03:13.200
在端测是非常的热门

81
0:03:13.200 --> 0:03:14.880
或者基本上你是离不开的

82
0:03:16.640 --> 0:03:18.200
在最后第4部分

83
0:03:18.320 --> 0:03:20.600
我们正式的进入到推力引擎的

84
0:03:20.600 --> 0:03:22.560
一个在线部署和优化的

85
0:03:23.240 --> 0:03:25.400
首先第一个就是图的转换优化

86
0:03:25.400 --> 0:03:27.680
包括一些算子的融合重排替换

87
0:03:28.320 --> 0:03:29.960
这块其实跟我们的AI框架

88
0:03:29.960 --> 0:03:31.000
或者AI系统

89
0:03:31.000 --> 0:03:31.960
或者AI编译器

90
0:03:32.320 --> 0:03:33.880
其实比较相关

91
0:03:33.880 --> 0:03:35.840
我们会把很多相关的知识

92
0:03:35.960 --> 0:03:37.000
把它串起来

93
0:03:37.040 --> 0:03:38.560
接着我们会去看看

94
0:03:38.560 --> 0:03:40.160
在线部署的一些并发自行

95
0:03:40.160 --> 0:03:41.240
还有内存分配

96
0:03:42.320 --> 0:03:44.240
最后会看一个比较难的问题

97
0:03:44.240 --> 0:03:45.760
动态的batch和binpacking

98
0:03:45.760 --> 0:03:47.440
还有一些推力引擎具体

99
0:03:47.440 --> 0:03:48.280
是怎幺实现的

100
0:03:48.280 --> 0:03:50.280
一些底层的one time的优化

101
0:03:50.480 --> 0:03:52.520
这一块就是第4部分

102
0:03:52.720 --> 0:03:55.280
接下来我们将会进入正式的内容

103
0:03:56.920 --> 0:03:57.920
我们现在来看一下

104
0:03:57.920 --> 0:04:00.320
典型的深度学习的推理的一些应用

105
0:04:01.480 --> 0:04:02.360
像左边的这个

106
0:04:02.480 --> 0:04:04.760
就是人脸landmark的一个应用

107
0:04:04.960 --> 0:04:06.120
除了人脸landmark

108
0:04:06.120 --> 0:04:08.000
它还会做一些人脸的识别

109
0:04:08.000 --> 0:04:08.800
眼睛的识别

110
0:04:08.800 --> 0:04:10.240
人脸头像的朝向

111
0:04:10.480 --> 0:04:11.680
右边的这两张图

112
0:04:11.840 --> 0:04:12.960
还是比较有意思的

113
0:04:13.160 --> 0:04:15.680
利用华为HMS core里面去实现的

114
0:04:15.680 --> 0:04:17.440
而HMS core里面

115
0:04:18.120 --> 0:04:19.120
很多技术的支撑

116
0:04:19.280 --> 0:04:21.360
就是我在后面提供相关的技术的

117
0:04:21.360 --> 0:04:23.400
当然了包括我很多的同事的努力

118
0:04:24.040 --> 0:04:25.280
这个就是玩游戏

119
0:04:25.280 --> 0:04:26.240
我们去检测

120
0:04:26.240 --> 0:04:28.360
人脸的头像的位置在哪里

121
0:04:28.360 --> 0:04:30.200
然后人脸像上了小机器人

122
0:04:30.200 --> 0:04:32.680
或者小飞船就往上往下

123
0:04:32.880 --> 0:04:35.240
这个就检测我们的手势的识别

124
0:04:35.600 --> 0:04:36.520
要是开炮

125
0:04:36.840 --> 0:04:38.960
就可能把手张开就可以了

126
0:04:39.160 --> 0:04:41.120
像这种应用还是很有意思的

127
0:04:41.120 --> 0:04:43.160
而且应用也是非常的多

128
0:04:44.720 --> 0:04:45.960
我们往下看一下

129
0:04:45.960 --> 0:04:47.680
特别是我们现在在

130
0:04:48.480 --> 0:04:50.320
典型的对话机器人

131
0:04:50.320 --> 0:04:52.400
我们在淘宝或者在拼多多

132
0:04:52.400 --> 0:04:54.680
经常去咨询一些客户的时候

133
0:04:54.680 --> 0:04:55.920
我其实个人来说

134
0:04:55.920 --> 0:04:56.560
我最讨厌的

135
0:04:56.560 --> 0:04:58.320
就是遇到一些对话机器人

136
0:04:58.320 --> 0:04:59.320
每次我问问题

137
0:04:59.480 --> 0:05:01.160
他就谈个对话机器人出来

138
0:05:01.160 --> 0:05:04.000
然后帮我解答一些最基础的问题

139
0:05:04.160 --> 0:05:05.920
这种的服务体验不是很好

140
0:05:05.920 --> 0:05:08.920
但是对于那些平台厂商来说

141
0:05:09.280 --> 0:05:11.680
能够节省他们大量的人力咨询的问题

142
0:05:11.680 --> 0:05:12.880
和人力压力的问题

143
0:05:12.880 --> 0:05:15.680
例如我只是简单的去问一个物流

144
0:05:15.680 --> 0:05:16.480
现在的物流

145
0:05:16.480 --> 0:05:17.480
你发哪个物流

146
0:05:17.480 --> 0:05:19.480
或者你现在的物流情况怎幺样了

147
0:05:19.480 --> 0:05:22.600
像这种完全可以用对话机器人来去解决

148
0:05:22.600 --> 0:05:24.280
而最新的chart gpt

149
0:05:24.440 --> 0:05:25.960
确实也是非常的火

150
0:05:26.240 --> 0:05:27.680
或者可以说火到一塌糊涂

151
0:05:27.680 --> 0:05:29.320
大家可以去了解一下

152
0:05:31.280 --> 0:05:32.520
接下来我们看一下

153
0:05:32.520 --> 0:05:34.840
另外一个应用就是推荐系统

154
0:05:35.000 --> 0:05:36.480
推荐系统可能更多的

155
0:05:36.480 --> 0:05:38.680
是不是说离线推荐

156
0:05:38.680 --> 0:05:39.880
而是在线推荐

157
0:05:40.560 --> 0:05:42.240
但是推荐系统现在大部分

158
0:05:42.440 --> 0:05:43.800
至少我认识阿里巴巴

159
0:05:43.800 --> 0:05:44.760
或者我当时候

160
0:05:44.760 --> 0:05:45.760
应该是几年前

161
0:05:45.760 --> 0:05:47.160
去面试阿里巴巴的时候

162
0:05:47.520 --> 0:05:50.120
他就去问我很多相关的工作

163
0:05:50.120 --> 0:05:52.560
而里面我当时候面试的一个岗位

164
0:05:52.920 --> 0:05:55.200
也是从事于淘宝推荐

165
0:05:55.200 --> 0:05:56.360
就下面很多推荐

166
0:05:56.480 --> 0:06:00.760
其实这个也是用了非常多的AI的算法

167
0:06:00.760 --> 0:06:02.920
然后更多的是AI的推理的应用

168
0:06:02.920 --> 0:06:03.960
或者推理的算法

169
0:06:04.680 --> 0:06:06.200
接下来我们再看一个

170
0:06:06.200 --> 0:06:10.160
最近比较火的一个应用

171
0:06:10.160 --> 0:06:12.000
叫做AIGC

172
0:06:12.200 --> 0:06:15.160
这个是我在自于量子位的一篇报道

173
0:06:15.160 --> 0:06:16.240
关于抖音的报道

174
0:06:16.240 --> 0:06:18.440
你可以看到一开始我输一张图片

175
0:06:18.440 --> 0:06:19.200
然后这张图片

176
0:06:19.200 --> 0:06:21.000
我可以选各种的风格

177
0:06:21.000 --> 0:06:22.360
我是一个肌肉男

178
0:06:22.360 --> 0:06:23.960
然后我输入进去

179
0:06:24.120 --> 0:06:26.840
也是变成非常多的不同的风格

180
0:06:26.840 --> 0:06:28.840
这种就是AIGC

181
0:06:28.840 --> 0:06:30.800
也是我应该是一年前

182
0:06:30.880 --> 0:06:32.520
我就非常留意这个技术了

183
0:06:32.520 --> 0:06:35.240
也启动了一些相关的一些合作技术

184
0:06:35.240 --> 0:06:37.880
所以说这块应该是在后半年才

185
0:06:37.880 --> 0:06:38.560
火起来的

186
0:06:38.560 --> 0:06:39.840
也是非常有意思

187
0:06:41.480 --> 0:06:43.200
像我们刚才所说到的

188
0:06:43.200 --> 0:06:46.520
很多都是深度学习的一些推理的应用

189
0:06:46.520 --> 0:06:47.960
里面没有训练相关

190
0:06:47.960 --> 0:06:49.480
我们更多的是集中在推理

191
0:06:49.480 --> 0:06:50.720
而在这个过程当中

192
0:06:50.880 --> 0:06:52.360
我们整个推理系统

193
0:06:52.360 --> 0:06:53.960
我们以淘宝的推荐为例

194
0:06:54.240 --> 0:06:55.680
可能在推理系统

195
0:06:55.680 --> 0:06:56.520
而不是推理引擎

196
0:06:56.640 --> 0:06:57.240
是系统

197
0:06:58.120 --> 0:06:59.480
我们会考虑的问题

198
0:06:59.640 --> 0:07:00.800
可能会非常多了

199
0:07:00.800 --> 0:07:02.560
利于我们被用户所调用的

200
0:07:02.560 --> 0:07:03.320
API的接口

201
0:07:03.640 --> 0:07:05.520
我们的数据怎幺去生成

202
0:07:05.520 --> 0:07:07.640
我们怎幺去在网络的

203
0:07:07.640 --> 0:07:08.920
影响下了低延时的

204
0:07:08.920 --> 0:07:10.120
反馈用户的结果

205
0:07:10.120 --> 0:07:11.040
另外的话

206
0:07:11.040 --> 0:07:12.280
因为我们手机上面

207
0:07:12.480 --> 0:07:14.600
我们怎幺利用多样性的一个加速器

208
0:07:14.600 --> 0:07:15.840
我们手机里面

209
0:07:15.840 --> 0:07:17.760
SoC加速的资源

210
0:07:17.760 --> 0:07:18.840
怎幺把它利用起来

211
0:07:18.840 --> 0:07:19.320
另外的话

212
0:07:19.320 --> 0:07:21.560
可能我们的用户的吞吐量大了

213
0:07:21.880 --> 0:07:23.480
这个访问的服务

214
0:07:23.480 --> 0:07:24.920
怎幺去做一些溶灾

215
0:07:24.920 --> 0:07:26.080
或者扩容的问题

216
0:07:26.680 --> 0:07:27.240
另外的话

217
0:07:27.240 --> 0:07:28.280
对于网络来说

218
0:07:28.280 --> 0:07:31.040
我怎幺上线新的一些网络模型

219
0:07:31.240 --> 0:07:33.000
这个时候怎幺做AB text

220
0:07:33.920 --> 0:07:35.320
都是一些很大的挑战

221
0:07:35.320 --> 0:07:36.560
也是我们做系统里面

222
0:07:36.560 --> 0:07:38.240
需要考虑的一些问题

223
0:07:38.440 --> 0:07:40.000
现在我们总结两个点

224
0:07:42.720 --> 0:07:43.840
如果我们简单的附用

225
0:07:43.840 --> 0:07:45.040
原有的web的服务

226
0:07:45.280 --> 0:07:47.400
其实是没有办法去解决所有的问题的

227
0:07:47.400 --> 0:07:49.360
特别是在深度学习

228
0:07:49.720 --> 0:07:51.000
大部分都用推理的时候

229
0:07:51.400 --> 0:07:52.840
很多系统性的问题

230
0:07:52.840 --> 0:07:54.320
它挑战就会出现了

231
0:07:55.720 --> 0:07:56.800
第二点就是

232
0:07:56.800 --> 0:07:59.720
深度学习的训练和推理过程

233
0:07:59.720 --> 0:08:00.760
其实是不同的

234
0:08:01.240 --> 0:08:03.760
而他们的生命周期也是不同的

235
0:08:06.600 --> 0:08:08.360
今天我们整体的介绍

236
0:08:08.520 --> 0:08:09.760
就先到这里为止

237
0:08:09.760 --> 0:08:10.320
好了

238
0:08:10.320 --> 0:08:11.040
谢谢各位

239
0:08:11.040 --> 0:08:11.960
拜拜

240
0:08:13.280 --> 0:08:14.440
卷的不行了

241
0:08:14.440 --> 0:08:15.280
卷的不行了

242
0:08:15.280 --> 0:08:16.720
记得一键三连加关注

243
0:08:17.160 --> 0:08:18.480
所有的内容都会开源

244
0:08:18.480 --> 0:08:20.200
在下面这条链接里面

245
0:08:20.720 --> 0:08:21.040
拜了

246
0:08:21.040 --> 0:08:21.520
拜拜

