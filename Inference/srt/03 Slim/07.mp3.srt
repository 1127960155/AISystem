0
0:00:00.000 --> 0:00:04.400


1
0:00:05.400 --> 0:00:08.400
哈喽大家好我们来到知识增留的下集

2
0:00:08.400 --> 0:00:10.720
这里是增米的电台

3
0:00:11.200 --> 0:00:16.360
在上一期里面呢我们已经充分地去了解了知识增留的一个算法提出的背景

4
0:00:16.360 --> 0:00:19.320
还有知识增留的知识的形态

5
0:00:19.320 --> 0:00:25.000
今天的我给大家去汇报的内容呢主要是下面两个具体的知识增留的方法

6
0:00:25.000 --> 0:00:28.480
还有一些很经典的知识增留的论文去解读

7
0:00:28.480 --> 0:00:32.880
第一个内容是知识征流的方法

8
0:00:32.880 --> 0:00:37.280
同样出自于知识征流的综述这篇论文里面

9
0:00:37.280 --> 0:00:40.880
知识征流呢其实组合分为三个方法

10
0:00:41.880 --> 0:00:45.780
第一个呢就是离线征流offline的distillation

11
0:00:45.780 --> 0:00:49.680
第二种呢就是在线的征流online的distillation

12
0:00:49.680 --> 0:00:54.080
第三种呢就是自征流的方式一共有三种

13
0:00:55.080 --> 0:00:57.280
这里面呢则有两种颜色

14
0:00:57.280 --> 0:00:59.580
一种是红色一种是绿色

15
0:00:59.580 --> 0:01:03.180
红色呢就代表预训练的模型已经训练好的

16
0:01:03.180 --> 0:01:08.080
另外一种呢绿色就代表我们将要去训练的模型

17
0:01:09.480 --> 0:01:14.580
下面我们来打开看看第一种方法就是offline的distillation

18
0:01:14.580 --> 0:01:23.680
离线的征流的方式其实呢现在来看大部分的算法都采用offline的这种方式就是离线征流

19
0:01:23.680 --> 0:01:25.680
而征流的过程分为两个阶段

20
0:01:25.680 --> 0:01:32.480
第一个阶段就是左边的征流前我们先训练一个教师的模型teach model先把它训练好

21
0:01:33.380 --> 0:01:40.380
第二步呢就是把教师网络的模型的知识征流给学生网络就进行一个知识迁移的过程

22
0:01:41.180 --> 0:01:47.280
因此offline的distillation呢就是离线征流的这种方式呢更侧重于知识的迁移部分

23
0:01:47.780 --> 0:01:52.080
怎么去迁移迁移什么知识这个点非常重要

24
0:01:52.880 --> 0:01:55.480
这里面呢值得注意的就是在步骤一

25
0:01:55.480 --> 0:02:00.680
征流前教师网络模型进行一个预训练码就是提前训练我们的教师模型

26
0:02:00.680 --> 0:02:06.880
那这个教师模型呢一般来说教师模型的参数量呢会比较大而且训练的时间呢也会比较长

27
0:02:07.680 --> 0:02:13.480
现在呀好多好多的大模型都是采用这种方式去得到一个小模型的

28
0:02:13.480 --> 0:02:18.980
例如bit网络模型就推出了tinybit也就是这种征流的方式

29
0:02:18.980 --> 0:02:25.380
好像VIT也推出了tinyVIT这种征流的方式同样都是采用offline distillation

30
0:02:26.480 --> 0:02:29.480
不过这种方式呢也有自身的弊端

31
0:02:29.980 --> 0:02:35.980
通常这种模式呢就是学生网络模型呢过度的依赖于我们的教师网络模型

32
0:02:36.980 --> 0:02:41.980
下面我们看一下第二种征流的方式online distillation

33
0:02:43.480 --> 0:02:48.780
虽然在线征流跟离线征流啊都是左边一个教师模型右边一个学生模型

34
0:02:48.780 --> 0:02:52.980
不过有一点比较大的区别就是这两个模型都是绿的

35
0:02:52.980 --> 0:03:01.480
这不代表老师和学生都绿了而是代表老师和学生都是一个在线学习的过程就是一起去学习

36
0:03:06.980 --> 0:03:16.480
教师模型和学生的模型的参数同时更新整个知识征流的算法呢就变成一体一个端到端可训练可学习的方案

37
0:03:16.480 --> 0:03:21.480
而不是教师模型自己先学学习完之后再把知识征流给学生

38
0:03:21.480 --> 0:03:27.480
这种呢属于离线offline的方式教师跟学生同时学习属于online的方式

39
0:03:27.480 --> 0:03:30.980
那online的方式呢有一个比较大的缺点就是

40
0:03:30.980 --> 0:03:36.980
在一个在线的环境里面呢很难去获得一个参数量又大精度又好的教师模型

41
0:03:37.980 --> 0:03:42.480
第三个知识征流的方式呢叫做self distillation

42
0:03:42.480 --> 0:03:48.980
就是教师模型和学生模型呢其实就是一个模型它进行一个自学习的过程

43
0:03:49.480 --> 0:03:51.980
端到端的可训练可学习的方案

44
0:03:52.980 --> 0:03:58.980
其实这种方式呢也属于online distillation就是在线征流的其中一个特例

45
0:04:01.480 --> 0:04:04.980
现在呢我们总结一下刚才讲到的三种知识征流的方法

46
0:04:04.980 --> 0:04:09.980
三种知识征流的方法呢可以看作三种不同的学习过程

47
0:04:09.980 --> 0:04:15.480
那第一种就是刚才讲到的offline distillation最常用的离线征流方法

48
0:04:15.980 --> 0:04:19.480
主要是指一个知识渊博的老师他自己已经学完了

49
0:04:19.480 --> 0:04:22.480
然后直接把他学到的知识传授给学生

50
0:04:22.480 --> 0:04:26.480
那现在第二种呢就是online distillation在线的知识征流

51
0:04:26.480 --> 0:04:30.480
是指老师和学生一起学习一起成长

52
0:04:30.480 --> 0:04:36.480
第三种就是self distillation就是学生自己学习自己成长

53
0:04:39.480 --> 0:04:44.480
下面呢我们一个最经典的算法应该是一六年到一七年的时候

54
0:04:44.480 --> 0:04:48.480
希腾第一次提出知识征流这个概念的这篇文章

55
0:04:48.480 --> 0:04:52.480
那下面这篇文章呢比较粗暴名字呢叫做

56
0:04:57.480 --> 0:05:01.480
在正式了解这篇文章之前呢我们要提前去看看两个概念

57
0:05:01.480 --> 0:05:05.480
一个叫做hard target一个叫做soft target

58
0:05:05.480 --> 0:05:10.480
在传统神经网络模型当中的训练啊其实我们首先定一个损失函数

59
0:05:10.480 --> 0:05:20.480
然后定一个优化器优化器在不断地去优化我们的损失函数目的呢是使得我们的预测值呢尽可能的接近于我们的真实值就是y等于y label

60
0:05:20.480 --> 0:05:30.480
那这个就是我们的目标而为了产生这个目标呢损失函数就是使我们神经网络的损失值和真实值呢之间尽可能的少

61
0:05:30.480 --> 0:05:36.480
我们看看下面左边的这个图假设我现在有四个数字零一三四五六七八九十

62
0:05:36.480 --> 0:05:39.480
我输进去一张图片是二

63
0:05:39.480 --> 0:05:42.480
我们希望预测是二的概率越高越好

64
0:05:42.480 --> 0:05:49.480
这种方式呢在数学或者统计方面呢就是对我们的光触真实的数据求极大的释然子

65
0:05:49.480 --> 0:05:52.480
我们看一下右边的这个图

66
0:05:52.480 --> 0:05:59.480
在知识增留里面呢我们就像右边的这个图所是希望能够学习到更多的其他额外相关的知识

67
0:05:59.480 --> 0:06:08.480
就是我假设输进去的一个数字手写数字可能长得像三这个时候呢我们希望神经网络呢学到更多的勇于的信息

68
0:06:08.480 --> 0:06:17.480
告诉我这个肯定是二那肯定是最好的把手写数字的字体长得有点像三这个勇于的信息也告诉出来那这个肯定是最好的

69
0:06:17.480 --> 0:06:28.480
因此呢我们看一下左边的这个图跟右边的这个所是左边的这个呢我们叫做hard target右边的这个呢我们叫做soft target带有一些其他勇于的信息

70
0:06:28.480 --> 0:06:33.480
下面我们再了解另外一个概念叫做soft maxed with temperature

71
0:06:33.480 --> 0:06:41.480
在soft maxed函数里面呢增加了一个温度系数下面我们看一下这条公式的几个数字的含义

72
0:06:41.480 --> 0:07:00.480
Qi呢就是指第三个类别的输出的概率而Zi呢就是指第三个类别输出的logic下面我们需要对每个类别输出的logic进行一个指数的求核那就得到了我们soft maxed的函数了下面呢我们进行了一个修改

73
0:07:00.480 --> 0:07:12.480
把刚才的soft target就是soft label的信息给到我们的soft maxed函数这里面呢就增加了一个温度的系数TZi除以TZj除以T

74
0:07:12.480 --> 0:07:18.480
哎当温度等于一的时候其实大家看到没有其实等于我们标准的soft maxed的函数

75
0:07:18.480 --> 0:07:23.480
记得数字越高呢soft maxed输出的概率的分布呢就越平滑

76
0:07:23.480 --> 0:07:47.480
分布的信息三呢也就越大所以负标签所携带的一些额外的勇于的信息呢也会相对的放大这个时候呢我们网络模型的训练呢就更关注于我们一些负标签的勇于的信息就是我们刚才讲到的这个图soft target里面的一些勇于的信息额外的信息也把它记录下来就是通过简单地设置一个温度系数来控制

77
0:07:48.480 --> 0:08:15.480
那下面我们再看一个比较明确的图随着梯的增加呢梯从小到大我们可以看到soft maxed的输出的分布呢就会越平滑信息三呢也就会越大信息的差异呢也就会越少看看呢怎么找到一个合理的梯得到我们中间这种图呢是很关键的一步下面我们就来探讨一下如何选择这个梯

78
0:08:15.480 --> 0:08:45.480
实际上呢选择温度梯呢主要是下面一种情况假设想从负标签里面呢学习到更多的有用的知识有用的信息或者一些额外的参数我们的温度梯呢就适当地去调高一点点但是呢当我们想减少负标签对我们整个神经网络或者对我们的预测值的干扰的时候呢我们的温度梯呢就适当地往低去调整就好了当然啦梯的大小应该设置为多少

79
0:08:45.480 --> 0:09:15.480
就我们实际的情况实际的任务进行设定的再分类任务和检测任务我们的梯的选择也是不同的接下来呢就正式地回到知识增留这个算法里面首先去了解一下知识增留算法的训练流程呢跟传统的训练流程的一个不一样的区别第一个呢就是传统的训练流程传统训练流程我们刚才讲到了其实我们最大的目标呢就是训练我们的hard target

80
0:09:15.480 --> 0:09:45.480
对光处真实的样本求极大的释然softmax的值但是呢在知识增留的训练过程当中呢我们更多的是希望学习到很多soft target利用教师模型的分类的概率呢作为soft target就像周米给大家去汇报AI系统的这个相关的知识呢我一般来说都不会照着字来念而是参与了很多我自己的理解或者额外的知识一样

81
0:09:45.480 --> 0:10:15.480
毫不意外的就是这篇文章的知识增留呢采用了一个offline的离线的增留方式然后呢结构上面就采用了经典的师生的网络模型teacher呢就是知识的输出子student呢就是知识的接收指握整个知识增留呢分为两个阶段注意是两个第一个就是训练我们的教师模型第二个就是学生模型进行增留就是学习下面呢

82
0:10:15.480 --> 0:10:45.480
我就分开两个给大家进行一个汇报现在呢更多的是一个字面和概念的意义的了解后面我们会展开一个图让大家看得更清楚首先我们训练teacher模组的时候呢teacher模组我们叫做NetT特点就是这个网络模型呢相对来说比较复杂像传说么之类的大模型呢确实更加适合教师模型那唯一的要求就是对于输入的x呢它都能输出一个y那这个y呢

83
0:10:45.480 --> 0:11:15.480
经过softmax的映射呢能够输出对应概率的一个预测的概率的类别值接着第二步就是学生模型进行增留那学生模型进增留了说白了就是我们需要训练一个student模组我们叫做NetX它的特点就是参数量呢相对来说比我们的teacher模组要少我们的模型结构呢也相对来说简单同样的有个要求就是对于输入的x呢我们都能够输出y而y呢经过softmax的

84
0:11:15.480 --> 0:11:45.480
映射后呢能够与NetX分别对应起来用大白话来说呢就是teacher模组我要预测一千个分内我的student模组也需要预测一千个分内而不是变成五百个分内那这是没办法做映射啦在预训练阶段呢会训练一个性能比较好的teacher模组所以呢我们会把teacher模组的信息呢给到我们的student模组去学习下面我们来看一下真正的一个算法流程首先第一步我需要训练一个

85
0:11:45.480 --> 0:11:49.040
teacher模组就上面的这个teacher模组我先把它训练出来

86
0:11:50.040 --> 0:11:54.760
接着呢我利用一个高温的t呢就是这个t的值呢是的比较大

87
0:11:55.040 --> 0:11:59.440
产生一个soft target把很多勇于的信息呢保留起来

88
0:12:00.440 --> 0:12:05.520
接着呢就是第二步啦第二步就是我们的student模组的学习和征留的过程

89
0:12:05.720 --> 0:12:11.200
那有两个点特别是需要注意的就是在我们的第三步第三步的时候呢

90
0:12:11.280 --> 0:12:17.080
这里面呢说白了就使用一个soft target还有hard target同时训练student模组

91
0:12:17.760 --> 0:12:25.600
那可以看到呢我们上面有一部分就这里面呢有两个损失函数拼在一起作为一个总的损失函数

92
0:12:26.200 --> 0:12:30.760
这个损失函数呢就是我们的t呢会比较高跟上面的可以保持一致

93
0:12:30.880 --> 0:12:35.960
然后呢训练一个soft target通过distillation loss呢去进行一个学习

94
0:12:36.840 --> 0:12:51.360
那第二个呢就是我们的hard target通过一个通用的或者普通的一个损失函数去训练学生网络模型最后最后一步就是推理了推理的时候呢我们把t视之为一进行一个学生模型的在线推理

95
0:12:52.080 --> 0:13:04.520
所以student模组的训练或者征留的过程呢会相对来说复杂一点它有两个损失一个是distillation loss一个是student的loss下面呢我们来看一下具体的一个loss的情况

96
0:13:06.120 --> 0:13:14.040
这个l呢就是对应的总的损失函数这里面刚才讲到了有两个损失函数一个损失函数呢就是针对一个soft label的损失函数

97
0:13:14.320 --> 0:13:31.760
一个损失函数呢就是对应hard label的一个损失函数而soft label的损失函数呢就是来自于我们teacher modelhard label呢就是来自于我们真实的数据标签通过两种方式或者通过两个损失函数把它合在一起变成一个总的损失函数来去学习

98
0:13:31.760 --> 0:13:39.480
虽然说我们只需要看懂了这个图的流程基本上你就明白这个算法是怎么去实现了

99
0:13:40.880 --> 0:13:56.800
好了今年的内容呢就到此为止如果大家有兴趣的话也可以看一下相关的文献和内容


