0
0:00:00.000 --> 0:00:04.480
【资讯互动】

1
0:00:04.480 --> 0:00:08.360
哈喽大家好,我们来到知识增留的下集

2
0:00:08.360 --> 0:00:10.360
这里是增米的电台

3
0:00:11.360 --> 0:00:12.240
在上一期里面呢

4
0:00:12.240 --> 0:00:13.880
我们已经充分地去了解了

5
0:00:13.880 --> 0:00:16.320
知识增留的一个算法提出的背景

6
0:00:16.320 --> 0:00:19.520
还有知识增留的知识的形态

7
0:00:19.520 --> 0:00:21.920
今天呢我给大家去汇报的内容呢

8
0:00:21.920 --> 0:00:24.960
主要是下面两个具体的知识增留的方法

9
0:00:24.960 --> 0:00:28.080
还有HITMAN经典的知识增留的论文去解读

10
0:00:29.080 --> 0:00:32.880
第一个内容是知识增留的方法

11
0:00:32.880 --> 0:00:37.280
同样出自于知识增留的综述这篇论文里面

12
0:00:37.280 --> 0:00:40.880
知识增留呢其实主要分为三个方法

13
0:00:40.880 --> 0:00:42.760
第一个呢就是

14
0:00:42.760 --> 0:00:45.760
离线增留offline的distillation

15
0:00:45.760 --> 0:00:49.720
第二种呢就是在线的增留online的distillation

16
0:00:49.720 --> 0:00:52.880
第三种呢就是自增留的方式

17
0:00:52.880 --> 0:00:54.120
一共有三种

18
0:00:54.120 --> 0:00:57.280
这里面呢则有两种颜色

19
0:00:57.280 --> 0:00:59.520
一种是红色一种是绿色

20
0:00:59.520 --> 0:01:03.120
红色呢就代表预训练的模型已经训练好的

21
0:01:03.120 --> 0:01:08.120
另外一种呢绿色就代表我们将要去训练的模型

22
0:01:09.320 --> 0:01:11.920
下面我们来打开看一看第一种方法

23
0:01:11.920 --> 0:01:14.520
就是offline的distillation

24
0:01:14.520 --> 0:01:17.120
离线的增留的方式

25
0:01:17.120 --> 0:01:20.120
其实呢现在来看大部分的算法

26
0:01:20.120 --> 0:01:22.200
都采用offline的这种方式

27
0:01:22.200 --> 0:01:23.640
就是离线增留

28
0:01:23.640 --> 0:01:25.720
而增留的过程分为两个阶段

29
0:01:25.760 --> 0:01:27.480
第一个阶段就是左边的

30
0:01:27.480 --> 0:01:31.040
增留前我们先训练一个教师的模型teachmodel

31
0:01:31.040 --> 0:01:32.560
先把它训练好

32
0:01:33.440 --> 0:01:36.400
第二步呢就是把教师网络的模型的知识

33
0:01:36.400 --> 0:01:38.360
增留给学生网络

34
0:01:38.360 --> 0:01:40.480
就进行一个知识迁移的过程

35
0:01:41.200 --> 0:01:43.160
因此offline的distillation呢

36
0:01:43.160 --> 0:01:44.880
就是离线增留的这种方式呢

37
0:01:44.880 --> 0:01:47.360
更侧重于知识的迁移部分

38
0:01:47.760 --> 0:01:49.200
怎幺去迁移

39
0:01:49.200 --> 0:01:50.720
迁移什幺知识

40
0:01:50.720 --> 0:01:52.240
这个点非常重要

41
0:01:52.880 --> 0:01:54.560
这里面呢值得注意的就是

42
0:01:54.560 --> 0:01:55.520
在步骤一

43
0:01:55.520 --> 0:01:58.080
增留前教师网络模型进行一个预训练

44
0:01:58.080 --> 0:02:00.720
就提前训练我们的教师模型

45
0:02:00.720 --> 0:02:02.000
那这个教师模型呢

46
0:02:02.000 --> 0:02:04.480
一般来说教师模型的参数量呢会比较大

47
0:02:04.480 --> 0:02:06.920
而且训练的时间呢也会比较长

48
0:02:07.720 --> 0:02:10.160
现在呀好多好多的大模型

49
0:02:10.160 --> 0:02:11.760
都是采用这种方式

50
0:02:11.760 --> 0:02:13.520
去得到一个小模型的

51
0:02:13.520 --> 0:02:16.760
例如BERT网络模型就推出了tinyBERT

52
0:02:16.760 --> 0:02:19.000
也就是这种增留的方式

53
0:02:19.000 --> 0:02:21.760
好像VIT也推出了tinyVIT

54
0:02:21.760 --> 0:02:23.080
这种增留的方式

55
0:02:23.120 --> 0:02:25.440
同样都是采用offline distillation

56
0:02:26.720 --> 0:02:29.480
不过这种方式呢也有自身的弊端

57
0:02:29.920 --> 0:02:32.920
通常这种模式呢就是学生网络模型呢

58
0:02:32.920 --> 0:02:35.920
过度的依赖于我们的教师网络模型

59
0:02:37.000 --> 0:02:40.240
下面我们看一下第二种增留的方式

60
0:02:40.240 --> 0:02:41.920
online distillation

61
0:02:43.480 --> 0:02:45.240
虽然在线增留跟离线增留啊

62
0:02:45.240 --> 0:02:47.040
都是左边一个教师模型

63
0:02:47.040 --> 0:02:48.720
右边一个学生模型

64
0:02:48.840 --> 0:02:50.800
不过有一点比较大的区别就是

65
0:02:50.800 --> 0:02:53.040
这两个模型都是绿的

66
0:02:53.080 --> 0:02:55.200
这不代表老师和学生都绿了

67
0:02:55.200 --> 0:02:57.480
而是代表老师和学生

68
0:02:57.480 --> 0:02:59.880
都是一个在线学习的过程

69
0:02:59.880 --> 0:03:01.560
就是一起去学习

70
0:03:07.120 --> 0:03:09.880
教师模型和学生的模型的参数

71
0:03:09.880 --> 0:03:11.000
同时更新

72
0:03:11.440 --> 0:03:13.000
整个知识增留的算法呢

73
0:03:13.000 --> 0:03:14.960
就变成一体一个端到端

74
0:03:14.960 --> 0:03:16.600
可训练可学习的方案

75
0:03:16.600 --> 0:03:18.920
而不是教师模型自己先学

76
0:03:18.920 --> 0:03:21.320
学习完之后再把知识增留给学生

77
0:03:21.840 --> 0:03:23.960
这种属于离线offline的方式

78
0:03:23.960 --> 0:03:26.080
教师跟学生同时学习

79
0:03:26.080 --> 0:03:27.640
属于online的方式

80
0:03:27.640 --> 0:03:28.800
那online的方式呢

81
0:03:28.800 --> 0:03:30.960
有一个比较大的缺点就是

82
0:03:31.440 --> 0:03:33.000
在一个在线的环境里面呢

83
0:03:33.000 --> 0:03:35.040
很难去获得一个参数量又大

84
0:03:35.040 --> 0:03:37.120
精度又好的教师模型

85
0:03:38.320 --> 0:03:40.680
第三个知识增留的方式呢

86
0:03:40.680 --> 0:03:42.520
叫做self distillation

87
0:03:42.520 --> 0:03:45.320
就是教师模型和学生模型呢

88
0:03:45.320 --> 0:03:46.880
其实就是一个模型

89
0:03:46.880 --> 0:03:49.360
它进行一个自学习的过程

90
0:03:49.480 --> 0:03:52.080
端到端的可训练可学习的方案

91
0:03:53.000 --> 0:03:54.280
其实这种方式呢

92
0:03:54.280 --> 0:03:56.200
也属于online distillation

93
0:03:56.200 --> 0:03:59.080
就是在线增留的其中一个特例

94
0:04:01.280 --> 0:04:02.640
现在呢我们总结一下

95
0:04:02.640 --> 0:04:05.080
刚才讲到的三种知识增留的方法

96
0:04:05.080 --> 0:04:06.440
三种知识增留的方法呢

97
0:04:06.440 --> 0:04:10.080
可以看作三种不同的学习过程

98
0:04:10.080 --> 0:04:11.720
那第一种就是刚才讲到的

99
0:04:11.720 --> 0:04:13.160
offline distillation

100
0:04:13.160 --> 0:04:15.560
最常用的离线增留方法

101
0:04:16.200 --> 0:04:18.120
主要是指一个知识渊博的老师

102
0:04:18.120 --> 0:04:19.360
他自己已经学完了

103
0:04:19.360 --> 0:04:22.720
然后直接把他学到的知识传授给学生

104
0:04:22.720 --> 0:04:23.720
那现在第二种呢

105
0:04:23.720 --> 0:04:25.480
就是online distillation

106
0:04:25.480 --> 0:04:26.800
在线的知识增留

107
0:04:26.800 --> 0:04:29.640
是指老师和学生一起学习

108
0:04:29.640 --> 0:04:31.040
一起成长

109
0:04:31.040 --> 0:04:33.080
第三种就是self distillation

110
0:04:33.080 --> 0:04:35.280
就是学生自己学习

111
0:04:35.280 --> 0:04:36.400
自己成长

112
0:04:39.520 --> 0:04:41.360
下面呢我们以一个最经典的算法

113
0:04:41.360 --> 0:04:44.440
应该是16年到17年的时候

114
0:04:44.440 --> 0:04:47.720
Hinton第一次提出知识增留这个概念

115
0:04:47.760 --> 0:04:49.000
的这篇文章

116
0:04:49.000 --> 0:04:50.080
那下面这篇文章呢

117
0:04:50.080 --> 0:04:51.360
比较粗暴

118
0:04:51.360 --> 0:04:52.520
名字呢叫做

119
0:04:52.520 --> 0:04:55.920
Distilling the Knowledge in a Nature Network

120
0:04:57.680 --> 0:04:59.680
在正式了解这篇文章之前呢

121
0:04:59.680 --> 0:05:02.200
我们要提前去看看两个概念

122
0:05:02.200 --> 0:05:03.680
一个叫做hard target

123
0:05:03.680 --> 0:05:05.960
一个叫做soft target

124
0:05:05.960 --> 0:05:08.480
在传统神经网络模型当中的训练

125
0:05:08.480 --> 0:05:10.680
其实我们首先定一个损失函数

126
0:05:10.680 --> 0:05:12.240
然后定一个优化器

127
0:05:12.240 --> 0:05:15.040
优化器在不断地去优化我们的损失函数

128
0:05:15.040 --> 0:05:16.800
目的是使得我们的预示值呢

129
0:05:16.840 --> 0:05:19.120
尽可能地接近于我们的真实值

130
0:05:19.120 --> 0:05:20.720
就是Y等于Y label

131
0:05:20.720 --> 0:05:22.560
那这个就是我们的目标

132
0:05:23.480 --> 0:05:24.920
而为了产生这个目标呢

133
0:05:24.920 --> 0:05:26.960
损失函数就是使我们神经网络的

134
0:05:26.960 --> 0:05:28.400
损失值和真实值呢

135
0:05:28.400 --> 0:05:30.400
之间尽可能地少

136
0:05:30.400 --> 0:05:32.720
我们看看下面左边的这个图

137
0:05:32.720 --> 0:05:34.480
假设我现在有四个数字

138
0:05:34.480 --> 0:05:36.320
0 1 3 4 5 6 7 8 9 10

139
0:05:36.880 --> 0:05:39.240
我输进去一张图片是2

140
0:05:39.240 --> 0:05:42.440
我们希望预测是2的概率越高越好

141
0:05:42.960 --> 0:05:43.640
这种方式呢

142
0:05:43.640 --> 0:05:45.120
在数学或者统计方面呢

143
0:05:45.160 --> 0:05:47.480
就是对我们的GNU真实的数据

144
0:05:47.480 --> 0:05:49.360
起了极大的施压值

145
0:05:49.360 --> 0:05:51.640
我们看一下右边的这个图

146
0:05:52.280 --> 0:05:53.520
在知识增充里面呢

147
0:05:53.520 --> 0:05:55.440
我们就像右边的这个图所示

148
0:05:55.440 --> 0:05:57.320
希望能够学习到更多的

149
0:05:57.320 --> 0:05:59.240
其他额外相关的知识

150
0:05:59.240 --> 0:06:01.360
就是我假设输进去的一个数字

151
0:06:01.360 --> 0:06:04.040
手写数字可能长得像3

152
0:06:04.040 --> 0:06:04.560
这个时候呢

153
0:06:04.560 --> 0:06:05.800
我们希望神经网络呢

154
0:06:05.800 --> 0:06:07.960
学到更多的勇于的信息

155
0:06:07.960 --> 0:06:09.720
当然了他告诉我这个肯定是2

156
0:06:09.720 --> 0:06:10.760
那肯定是最好的

157
0:06:10.760 --> 0:06:13.320
把手写数字的字体长得有点像3

158
0:06:13.360 --> 0:06:15.880
这个勇于的信息也告诉出来

159
0:06:15.880 --> 0:06:17.360
那这个肯定是最好的

160
0:06:17.360 --> 0:06:19.120
因此呢我们看一下左边的这个图

161
0:06:19.120 --> 0:06:20.560
跟右边的这个图所示

162
0:06:20.560 --> 0:06:22.520
左边的这个呢我们叫做Hard Target

163
0:06:22.520 --> 0:06:25.120
右边的这个呢我们叫做Soft Target

164
0:06:25.120 --> 0:06:27.720
带有一些其他勇于的信息

165
0:06:28.240 --> 0:06:30.120
下面我们再了解另外一个概念

166
0:06:30.120 --> 0:06:33.040
叫做Soft Maxed with Temperature

167
0:06:33.600 --> 0:06:35.120
在Soft Maxed函数里面呢

168
0:06:35.120 --> 0:06:37.400
增加了一个温度系数

169
0:06:38.280 --> 0:06:39.840
下面我们看一下这条公式的

170
0:06:39.840 --> 0:06:41.560
几个数字的含义

171
0:06:41.560 --> 0:06:44.640
Q1呢就是指第i个类别的输出的概率

172
0:06:44.640 --> 0:06:48.640
而Zi呢就是指第i个类别输出的Logist

173
0:06:49.280 --> 0:06:52.440
下面我们需要对每个类别输出的Logist

174
0:06:52.440 --> 0:06:54.560
进行一个指数的求和

175
0:06:54.560 --> 0:06:57.120
那就得到了我们Soft Maxed的函数了

176
0:06:57.760 --> 0:07:00.520
下面呢我们进行了一个修改

177
0:07:00.520 --> 0:07:02.280
把刚才的Soft Target

178
0:07:02.280 --> 0:07:04.040
就是Soft Label的信息

179
0:07:04.280 --> 0:07:06.080
给到我们的Soft Maxed函数

180
0:07:06.080 --> 0:07:09.480
这里面呢就增加了一个温度的系数T

181
0:07:09.480 --> 0:07:10.560
Zi除以T

182
0:07:10.960 --> 0:07:12.280
Zj除以T

183
0:07:12.800 --> 0:07:14.800
当温度等于1的时候

184
0:07:14.800 --> 0:07:15.960
其实大家看到没有

185
0:07:15.960 --> 0:07:18.400
其实等于我们标准的Soft Maxed的函数

186
0:07:18.760 --> 0:07:19.840
T的数字越高呢

187
0:07:19.840 --> 0:07:22.480
Soft Maxed输出的概率的分布呢

188
0:07:22.480 --> 0:07:23.520
就越平滑

189
0:07:23.840 --> 0:07:25.640
分布的信息桑呢也就越大

190
0:07:25.640 --> 0:07:27.360
所以副标签所携带的

191
0:07:27.360 --> 0:07:29.120
一些额外的冗余的信息呢

192
0:07:29.120 --> 0:07:30.640
也会相对的放大

193
0:07:31.160 --> 0:07:33.120
这个时候呢我们网络模型的训练呢

194
0:07:33.120 --> 0:07:34.680
就更关注于我们一些

195
0:07:34.680 --> 0:07:36.360
副标签的冗余的信息

196
0:07:36.360 --> 0:07:38.080
就是我们刚才讲到的这个图

197
0:07:38.400 --> 0:07:40.240
Soft Target里面的一些

198
0:07:40.240 --> 0:07:41.960
冗余的信息额外的信息

199
0:07:41.960 --> 0:07:43.320
也把它记录下来

200
0:07:43.320 --> 0:07:45.360
就是通过简单的设置一个

201
0:07:45.360 --> 0:07:47.560
温度系数来控制

202
0:07:49.560 --> 0:07:52.400
那下面我们再看一个比较明确的图

203
0:07:53.520 --> 0:07:54.800
随着T的增加呢

204
0:07:54.800 --> 0:07:56.280
T从小到大

205
0:07:56.280 --> 0:07:58.520
我们可以看到Soft Maxed输出的分布呢

206
0:07:58.520 --> 0:07:59.560
就会越平滑

207
0:07:59.760 --> 0:08:01.400
信息桑呢也就会越大

208
0:08:01.400 --> 0:08:03.240
信息的差异呢也就会越少

209
0:08:03.640 --> 0:08:05.800
当然了怎幺找到一个合理的T

210
0:08:05.800 --> 0:08:07.840
得到我们中间这种图呢

211
0:08:08.080 --> 0:08:10.320
是很关键的一步

212
0:08:11.080 --> 0:08:12.880
下面我们就来探讨一下

213
0:08:12.880 --> 0:08:15.120
如何选择这个T

214
0:08:17.120 --> 0:08:19.160
实际上呢选择温度T呢

215
0:08:19.160 --> 0:08:20.920
主要是下面一种情况

216
0:08:21.280 --> 0:08:23.040
假设想从副标签里面呢

217
0:08:23.040 --> 0:08:24.920
学习到更多的有用的知识

218
0:08:24.920 --> 0:08:25.640
有用的信息

219
0:08:25.640 --> 0:08:26.920
或者一些额外的参数

220
0:08:26.920 --> 0:08:28.520
我们的温度T呢

221
0:08:28.520 --> 0:08:31.400
就是适当的去调高一点点

222
0:08:31.920 --> 0:08:34.040
但是呢当我们想减少副标签

223
0:08:34.040 --> 0:08:35.440
对我们整个神经网络

224
0:08:35.440 --> 0:08:37.280
或者对我们的预测值的干扰的时候呢

225
0:08:37.280 --> 0:08:38.400
我们的温度T呢

226
0:08:38.400 --> 0:08:41.600
就适当的往低去调整就好了

227
0:08:42.480 --> 0:08:44.760
当然了T的大小应该是指为多少

228
0:08:44.760 --> 0:08:46.760
我们需要根据我们实际的情况

229
0:08:46.760 --> 0:08:49.080
实际的任务进行设定的

230
0:08:49.320 --> 0:08:50.800
在分类任务和检测任务

231
0:08:50.800 --> 0:08:53.000
我们的T的选择也是不同的

232
0:08:56.080 --> 0:08:57.560
接下来呢就正式的回到

233
0:08:57.560 --> 0:08:59.160
知识增留这个算法里面

234
0:09:00.000 --> 0:09:00.960
首先去了解一下

235
0:09:00.960 --> 0:09:02.640
知识增留算法的训练流程呢

236
0:09:02.640 --> 0:09:04.080
跟传统的训练流程的

237
0:09:04.080 --> 0:09:06.000
一个不一样的区别

238
0:09:07.400 --> 0:09:09.760
第一个呢就是传统的训练流程

239
0:09:09.760 --> 0:09:11.600
传统训练流程我们刚才讲到了

240
0:09:11.600 --> 0:09:13.320
就是我们最大的目标呢

241
0:09:13.320 --> 0:09:15.280
就是训练我们的hard target

242
0:09:15.880 --> 0:09:17.520
对光truth真实的样本呢

243
0:09:17.520 --> 0:09:20.120
求极大的释然softmax的值

244
0:09:20.480 --> 0:09:23.520
但是呢在知识增留的训练过程当中呢

245
0:09:23.520 --> 0:09:25.720
我们更多的是希望学习到

246
0:09:25.720 --> 0:09:27.480
很多soft target

247
0:09:28.040 --> 0:09:30.640
利用教师模型的分类的概率呢

248
0:09:30.640 --> 0:09:31.840
作为soft target

249
0:09:32.280 --> 0:09:33.760
就像周米给大家去汇报

250
0:09:33.760 --> 0:09:35.480
AI系统的这个相关的知识呢

251
0:09:35.520 --> 0:09:37.600
我一般来说都不会照着字来念

252
0:09:37.960 --> 0:09:39.720
而是插入了很多我自己的理解

253
0:09:39.720 --> 0:09:41.560
或者额外的知识一样

254
0:09:45.400 --> 0:09:48.040
毫不意外的就是这篇文章的知识增留呢

255
0:09:48.040 --> 0:09:50.800
采用了一个offline的离线的增留方式

256
0:09:50.800 --> 0:09:52.800
然后呢结构上面呢就采用了

257
0:09:52.800 --> 0:09:55.680
经典的师生的网络模型

258
0:09:55.920 --> 0:09:57.600
teacher呢就是知识的输出子

259
0:09:57.600 --> 0:10:00.080
student呢就是知识的接受指握

260
0:10:01.960 --> 0:10:04.640
整个知识增留呢分为两个阶段

261
0:10:04.760 --> 0:10:06.040
注意是两个

262
0:10:06.040 --> 0:10:09.120
第一个就是训练我们的教师模型

263
0:10:09.800 --> 0:10:13.120
第二个就是学生模型进行增留

264
0:10:13.120 --> 0:10:14.040
就是学习

265
0:10:14.840 --> 0:10:19.200
下面呢我就分开两个给大家进行一个汇报

266
0:10:21.760 --> 0:10:25.960
现在呢更多的是一个字面和概念的意义的了解

267
0:10:25.960 --> 0:10:27.320
后面我们会展开一个图

268
0:10:27.320 --> 0:10:28.600
让大家看得更清楚

269
0:10:28.840 --> 0:10:30.520
首先我们训练teacher model的时候呢

270
0:10:30.520 --> 0:10:32.120
teacher model我们叫做NetT

271
0:10:32.400 --> 0:10:33.720
特点就是这个网络模型呢

272
0:10:33.720 --> 0:10:35.200
相对来说比较复杂

273
0:10:35.520 --> 0:10:37.200
像transformer之类的大模型呢

274
0:10:37.200 --> 0:10:39.520
确实更加适合教师模型

275
0:10:39.520 --> 0:10:42.600
那唯一的要求就是对于输入的x呢

276
0:10:42.600 --> 0:10:44.440
它都能输出一个y

277
0:10:44.440 --> 0:10:46.760
那这个y呢经过softmax的映射呢

278
0:10:46.760 --> 0:10:49.880
能够输出对应概率的一个预测的

279
0:10:49.880 --> 0:10:51.000
概率的类别值

280
0:10:51.600 --> 0:10:54.880
接着第二步就是学生模型进行增留

281
0:10:54.880 --> 0:10:56.760
那学生模型进行增留了说白了

282
0:10:56.760 --> 0:10:59.080
就是我们需要训练一个student model

283
0:10:59.080 --> 0:11:00.720
我们叫做NetX

284
0:11:01.040 --> 0:11:02.800
它的特点就是参数量呢

285
0:11:02.800 --> 0:11:06.080
相对来说比我们的teacher model要少

286
0:11:06.080 --> 0:11:08.880
我们的模型结构呢也相对来说简单

287
0:11:08.880 --> 0:11:12.040
同样的有个要求就是对于输入的x呢

288
0:11:12.040 --> 0:11:13.520
我们都能够输出y

289
0:11:13.520 --> 0:11:16.440
而y呢经过softmax的映射后呢

290
0:11:16.440 --> 0:11:19.600
能够与NetT分别对应起来

291
0:11:19.600 --> 0:11:20.880
用大白话来说呢

292
0:11:20.880 --> 0:11:23.840
就是teacher model我要预测1000个分类

293
0:11:23.840 --> 0:11:26.760
我的student model也需要预测1000个分类

294
0:11:26.760 --> 0:11:28.440
而不是变成500个分类

295
0:11:28.440 --> 0:11:30.200
那这是没办法做映射了

296
0:11:32.920 --> 0:11:33.920
在预训练阶段呢

297
0:11:33.920 --> 0:11:36.560
会训练一个性能比较好的teacher model

298
0:11:36.560 --> 0:11:38.520
所以呢我们会把teacher model的信息呢

299
0:11:38.520 --> 0:11:41.080
给到我们的student model去学习

300
0:11:41.080 --> 0:11:43.880
下面我们来看一下真正的一个算法流程

301
0:11:43.880 --> 0:11:45.960
首先第一步我需要训练一个teacher model

302
0:11:45.960 --> 0:11:47.400
就上面的这个teacher model

303
0:11:47.400 --> 0:11:49.120
我先把它训练出来

304
0:11:49.960 --> 0:11:52.480
接着呢我利用一个高温的t呢

305
0:11:52.480 --> 0:11:54.960
就是这个t的值呢适得比较大

306
0:11:54.960 --> 0:11:56.560
产生一个soft target

307
0:11:56.560 --> 0:11:59.520
把很多勇于的信息呢保留起来

308
0:12:00.320 --> 0:12:01.880
接着呢就是第二步了

309
0:12:01.880 --> 0:12:05.640
第二步就是我们的student model的学习和征留的过程

310
0:12:05.640 --> 0:12:08.360
那有两个点特别是需要注意的

311
0:12:08.360 --> 0:12:10.120
就是在我们的第三步

312
0:12:10.120 --> 0:12:11.240
第三步的时候呢

313
0:12:11.240 --> 0:12:12.120
这里面呢说白了

314
0:12:12.120 --> 0:12:13.400
就使用一个soft target

315
0:12:13.400 --> 0:12:14.520
还有hard target

316
0:12:14.520 --> 0:12:17.720
同时训练student model

317
0:12:17.720 --> 0:12:18.800
那可以看到呢

318
0:12:18.800 --> 0:12:20.520
我们上面有一部分

319
0:12:20.520 --> 0:12:21.400
就这里面呢

320
0:12:21.400 --> 0:12:24.200
有两个损失函数拼在一起

321
0:12:24.200 --> 0:12:26.160
作为一个总的损失函数

322
0:12:26.160 --> 0:12:27.120
这个损失函数呢

323
0:12:27.120 --> 0:12:29.320
就是我们的t呢会比较高

324
0:12:29.320 --> 0:12:30.800
跟上面的可以保持一致

325
0:12:30.840 --> 0:12:32.800
然后呢训练一个soft target

326
0:12:32.800 --> 0:12:36.040
通过distillation loss呢去进行一个学习

327
0:12:36.800 --> 0:12:39.440
那第二个呢就是我们的hard target

328
0:12:39.440 --> 0:12:42.360
通过一个通用的或者普通的一个损失函数

329
0:12:42.360 --> 0:12:44.480
去训练学生网络模型

330
0:12:44.480 --> 0:12:46.720
最后一步就是推理了

331
0:12:46.720 --> 0:12:47.400
推理的时候呢

332
0:12:47.400 --> 0:12:49.320
我们把t视之为1

333
0:12:49.320 --> 0:12:52.000
进行一个学生模型的在线推理

334
0:12:52.000 --> 0:12:54.240
所以student model的训练或者征留的过程呢

335
0:12:54.240 --> 0:12:55.720
会相对来说复杂一点

336
0:12:55.720 --> 0:12:56.960
它有两个损失

337
0:12:56.960 --> 0:12:58.320
一个是distillation loss

338
0:12:58.320 --> 0:13:00.560
一个是student loss

339
0:13:00.560 --> 0:13:04.560
下面呢我们来看一下具体的一个loss的情况

340
0:13:06.080 --> 0:13:08.880
这个l呢就是对应的总的损失函数

341
0:13:08.880 --> 0:13:11.160
这里面刚才讲到了有两个损失函数

342
0:13:11.160 --> 0:13:12.040
一个损失函数呢

343
0:13:12.040 --> 0:13:14.200
就是针对一个soft label的损失函数

344
0:13:14.200 --> 0:13:15.040
一个损失函数呢

345
0:13:15.040 --> 0:13:17.840
就是对应hard label的一个损失函数

346
0:13:17.840 --> 0:13:19.400
而soft label的损失函数呢

347
0:13:19.400 --> 0:13:21.000
就是来自于我们的teacher model

348
0:13:21.000 --> 0:13:21.600
hard label呢

349
0:13:21.600 --> 0:13:24.320
就是来自于我们真实的数据标签

350
0:13:24.320 --> 0:13:25.520
通过两种方式

351
0:13:25.520 --> 0:13:27.440
或者通过两个损失函数

352
0:13:27.440 --> 0:13:28.880
把它合在一起

353
0:13:28.920 --> 0:13:30.640
变成一个总的损失函数

354
0:13:30.640 --> 0:13:31.880
来去学习

355
0:13:32.600 --> 0:13:36.240
所以来说我们只需要看懂了这个图的流程

356
0:13:36.240 --> 0:13:39.560
基本上你就明白这个算法是怎幺去实现了

357
0:13:40.760 --> 0:13:42.800
好了今天的内容呢就到此为止

358
0:13:42.800 --> 0:13:43.920
如果大家有兴趣的话

359
0:13:43.920 --> 0:13:47.160
也可以看一下相关的文献和内容

360
0:13:47.160 --> 0:13:47.840
谢谢各位

361
0:13:47.840 --> 0:13:49.000
拜了个拜

362
0:13:49.000 --> 0:13:50.680
卷的不行了卷的不行了

363
0:13:50.680 --> 0:13:52.520
记得一键三连加关注哦

364
0:13:52.520 --> 0:13:55.600
所有的内容都会开源在下面这条链接里面

365
0:13:56.120 --> 0:13:56.920
拜了个拜

