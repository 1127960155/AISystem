0
0:00:00.000 --> 0:00:07.300


1
0:00:07.300 --> 0:00:12.100
现在看看时间已经到了凌晨三十五分就晚上十二点半了

2
0:00:13.500 --> 0:00:17.700
我终于知道为什么大家叫做这种晚上更新视频的阿普或者人呢

3
0:00:17.700 --> 0:00:22.900
叫做甘地啊原来确实很像甘不是说你很能干

4
0:00:23.600 --> 0:00:25.800
嘿哩真朝气

5
0:00:27.000 --> 0:00:29.400
那录完这个视频呢我就要去休息了

6
0:00:29.400 --> 0:00:36.800
那今天我给大家去汇报的一个内容呢就是推理引擎的模型小型化一个新的内容啊模型小型化哦

7
0:00:36.800 --> 0:00:46.400
然后呢我们在进入正式的一些算法之前呢我想给大家去介绍一下推理的一个具体的参数或者相关的参数

8
0:00:46.400 --> 0:00:58.600
那在模型小型化我们会分开三个内容去介绍的第一个就是基础的参数的概念了解完基础的参数我们才知道我们的模型小型化到底什么样才是有效的

9
0:00:58.600 --> 0:01:04.000
我们应该用什么参数或者什么指标去衡量我们的小型化

10
0:01:04.000 --> 0:01:14.400
那接着呢我们去看看CN小型化最后我们再看看圈缩码小型化的一些内容

11
0:01:14.400 --> 0:01:20.280
其实呢随着我们的AI业务的发展呢我们的模型啊应该相对来说是越来越大

12
0:01:20.280 --> 0:01:28.440
那这个圈圈呢就代表我们的模型的参数量模型的参数量越大我们的精度呢是越高不管是哪种方式也好

13
0:01:28.440 --> 0:01:42.120
走上面这条也好啊确实越大呢精度是越高的那这一点呢是无庸置疑的只是我们大到什么程度高到什么程度中间呢可能会有一个权衡

14
0:01:42.120 --> 0:01:58.040
那往右边一看呢现在的大模型越来越多确实已经变成大模型了既然叫大模型了这个红色这条线呢就是拉锯掉了就大规模地使得到了我们的模型的参数量进一步的增加这个时候呢

15
0:01:58.040 --> 0:02:06.880
我们的计算量要求也是非常的高那基于这一点呢我们来看看具体的参数量怎么去评价的

16
0:02:09.680 --> 0:02:19.080
那现在呢我们有几个指标第一个呢就是flops f l o p s指的是我们的浮点运算的次数floating point operation

17
0:02:19.080 --> 0:02:25.440
那这个时候呢我们一般呢会以flops作为我们的计算量来去衡量算法模型的时间的复杂度

18
0:02:25.440 --> 0:02:40.560
那接着呢我们看一个概念它也叫flops但是那个s呢就变成大写了那这种情况下呢我们叫做每秒所执行的浮点的运算的次数floating point operation per second

19
0:02:40.560 --> 0:02:54.600
per second这个s呢就变成了一个缩写每秒所执行的浮点运算次数呢我们叫做运算的或者叫做充足的理解计算的数据去衡量我们硬件的一个指标还有模型速度的一个指标

20
0:02:54.600 --> 0:03:06.160
作为芯片的一个算力指标接下来呢我们看一下第三个概念就是m a c c s乘加了操作次数multiple accumulator operations

21
0:03:06.160 --> 0:03:23.160
通常来说呢乘加了操作次数就m a c c s呢是第一个点浮点运算次数flops的一半而举个例子就是我们现在呢有很多矩阵的乡城呢w零乘以x零呢我们把它视为简单的一个乘法的操作

22
0:03:23.160 --> 0:03:31.320
那大部分时候呢我们都会做非常大量的乘法的运算或者乘加了运算在我们的推理芯片或者AI加速芯片里面

23
0:03:31.320 --> 0:03:46.800
那这也是其中一个指标那第四个指标呢就是我们的parameter这个呢是我们去衡量刚才的那些图里面非常有力的一个指标数而就我们的模型的大小说白了就是模型的大小数

24
0:03:46.800 --> 0:03:50.720
那这个时候呢会直接影响到我们对内存的占用量

25
0:03:50.720 --> 0:04:00.760
但为了通常为m就是k b m b这个m那这个m呢就主要是指m b而我们的参数量呢一般用flow三十二去表示

26
0:04:00.760 --> 0:04:08.440
因为我们一般存储或者训练的时候呢都是用fp三十二去训练的那这个时候呢模型的大小呢是参数量的四倍

27
0:04:09.880 --> 0:04:17.440
下面我们来再看另外两个指标另外两个指标呢叫做m a c跟m a c c是不一样的大家要注意一下

28
0:04:17.440 --> 0:04:24.160
m a c呢这个指标我们经常去用到就是我们的内存访问的代价memory access cost

29
0:04:25.440 --> 0:04:44.760
m a c呢主要是指我们输一个简单的样本那我们以图像为例子我输入对我们的系统的输一个图片那我们完成一个整体的前向传播或者一个简单的卷迹之后呢摸索对内存的一个交换的总量就模型的空间复杂度但为了我们用败者来去做一个统计

30
0:04:44.760 --> 0:05:13.840
那最后一个呢就是内存的带宽内存的带宽这一个参数量是非常重要的就我觉得里面比较重要的几个参数量吧或者几个指标就是内存的带宽m a c flow模型的参数这四个其实是比较重要的内存的带宽呢主要决定了我们将数据呢从内存里面移到我们的all或者我们的科诺的核心或者探测阿梯里面去做计算的数据就是搬运内存的一个数据

31
0:05:14.760 --> 0:05:31.240
那内存带宽的值呢这个值呢决定于我们内存和计算核心之间的数据传输的速率这个值是越高越好但肯定了因为我们的硬件的设计的问题或者我们的功耗的问题还有那个价格的问题呢这个内存带宽呢会有一定的峰值的

32
0:05:31.240 --> 0:06:00.480
那我们现在来看看几个嗯比较典型的一个计算那我们在标准的卷积常就积那这个时候呢我们的参数量呢就等于我们的科诺的和科诺的外乘以科诺的in和科诺的奥我们的参数量呢大部分是这么去计算的为啥都是科诺呢为啥都是科诺跟数的数据呢是因为我们大部分的参数量啊都是从我们的科诺或者从我们的channel信息奥的一些参数量

33
0:06:01.240 --> 0:06:31.160
那在算测试浮点预算精度的时候呢就会再乘一个h和w就是图像的长和宽那下面呢我们还有好几个就是全连接了全连接比较简单基本都是心思要去计算然后也没有其他了另外的话我们卷积呢还有固卷积所以说固卷积呢可能里面呢就会做成一个固然后做测试的时候呢会对w除一个固当然还有对外卷积对外卷积呢就会除一个c

34
0:06:31.200 --> 0:06:45.440
印然后呢这个测试呢也是相同的所以说我们要了解算法为啥要了解算法要了解科诺呢就是因为我们有很多不同的计算的方式都会影响我们整个的系统的效率

35
0:06:50.080 --> 0:07:00.440
那下面呢我们以英伟达的梯次呢去了解一下这些具体的参数指标那这个就是英伟达梯次的一个GPU双链六的一个具体的推理的性能

36
0:07:00.440 --> 0:07:05.840
还有训练的性能可以看到啊梯次大部分都是做推理的所以训练我们可以不看

37
0:07:05.840 --> 0:07:09.400
那推理的性能可以看到确实它有非常对比起

38
0:07:09.400 --> 0:07:22.120
CPU呢有非常大大的或者非常高的一个性能的提升而这些性能的提升呢我们看看它具体的规格里面的一个探测的核心数还有库打的核心数

39
0:07:22.120 --> 0:07:30.400
库打的核心数呢就意味着我们对于外盘的计算或者现成数呢可以做得非常的多而探测的技术核心数呢就我们对一些稠密的局限

40
0:07:30.400 --> 0:07:39.200
的运算接着我们可以看一下其实很多不管是单精度浮点精度还是英特巴英英特四呢我们都会有一个提浮

41
0:07:39.200 --> 0:07:51.800
那这个S呢是大小每秒处理的数据量为啥英特巴英特四少了个浮呢因为浮的是指浮停浮点运算所以里面呢就少了个F

42
0:07:51.800 --> 0:08:00.080
接着我们可以看看比较留意的参数就GPU的显存三百GBS那这个呢就是我们显存的一个传输的数据

43
0:08:00.080 --> 0:08:18.080
也是非常的重要的参数另外的话还有一个互联的带宽就我们的PCIE桥会传输多高的数据那这个呢就是被外的传输的数据了而是被内的传输的数据呢就三百GBS这个呢也是非常重要的对应到我们刚才聊到的内存的带宽

44
0:08:20.880 --> 0:08:29.800
好了今天内容呢就到这里为止我们今天呢主要是了解了一些基础的参数的概念然后以英伟达梯四作为例子再看了一些具体的这些参数

45
0:08:29.800 --> 0:08:44.240
对我们怎么去看芯片对我们的模型小型化推引擎有什么作用

