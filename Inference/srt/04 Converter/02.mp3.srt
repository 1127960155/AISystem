0
0:00:00.000 --> 0:00:01.960
Buddy

1
0:00:05.320 --> 0:00:07.520
哈喽大家好我是宗米

2
0:00:07.560 --> 0:00:12.120
那这里面呢宗米两个英文单词呢都是大写

3
0:00:12.200 --> 0:00:15.280
因为它是我宗门名字的一个缩写

4
0:00:15.400 --> 0:00:20.680
今天我要给大家汇报的还是模型转换和优化这个类型里面

5
0:00:21.240 --> 0:00:26.120
在模型转换技术这个类型里面呢后面的更新频率应该会越来越慢

6
0:00:26.120 --> 0:00:27.600
因为很多知识啊

7
0:00:27.600 --> 0:00:32.320
其实在网上很难搜得到更多的是工程化的一些经验的总结

8
0:00:33.720 --> 0:00:36.880
这里面呢应该会分开两个视频给大家介绍的

9
0:00:36.880 --> 0:00:39.840
让我们可以看一下主要呢有很多内容

10
0:00:40.440 --> 0:00:44.880
首先在第一个视频呢我们更多的是聚焦于一些工程理念和知识概念

11
0:00:44.880 --> 0:00:49.000
例如模型转换的挑战还有整体的架构应该长什么样子

12
0:00:49.000 --> 0:00:54.680
接着呢我们去看一看模型的序列化和反序列化的这个操作

13
0:00:54.680 --> 0:01:00.520
序列化的工作就是把其他AI框架的网络模型呢转换成为我们推定引擎的模型

14
0:01:01.200 --> 0:01:07.960
反序列化呢就是把已经保存下来的网络模型加载到我们的内存当中给推定引擎去执行的

15
0:01:07.960 --> 0:01:13.560
接着我们会去介绍序列化和反序列化当中用的很多的两种格式

16
0:01:13.560 --> 0:01:17.240
一种呢是proto buffer一种是flat buffer

17
0:01:17.240 --> 0:01:24.440
讲完这两个内容之后呢我们将会在下个内容里面来到一些比较核心的技术或者核心的内容

18
0:01:24.440 --> 0:01:27.120
就是自定义计算图的按压

19
0:01:27.120 --> 0:01:31.360
针对推定引擎的计算图的按压应该怎么定义

20
0:01:31.360 --> 0:01:37.120
然后呢第二个内容也是很重要的一块转换的流程和技术的细节

21
0:01:37.120 --> 0:01:41.720
那流程和细节这个呢就是指导我们怎么去开发怎么去写代码的

22
0:01:43.520 --> 0:01:48.240
下面呢我们来到第一个正式的内容转换模块的挑战和架构

23
0:01:48.240 --> 0:01:53.440
那其实挑战和架构我们在上一节里面已经详细地去给大家去汇报过

24
0:01:53.440 --> 0:01:55.720
今天呢我们简单地去罗列一下

25
0:01:56.840 --> 0:02:05.840
converter这个模块呢其实有非常多的挑战第一个呢就是AI框架或者AI本身呢有非常多的模型而且有非常多的框架

26
0:02:05.840 --> 0:02:11.000
不同的框架有不同的知识格式而且我们需要支持非常多主流的网络模型

27
0:02:11.000 --> 0:02:18.760
AI发展的越来越多很多模型都是千奇百怪之后就是需要支持很多AI特有的一些特性

28
0:02:19.760 --> 0:02:29.760
为了应对上面的这些挑战呢所以我们设计了一个转换模块的整体的架构主要是由graph converter还有graph optimizer两个模块来去组成

29
0:02:29.760 --> 0:02:46.880
那今天我们主要是围绕着graph converter就是我们的图转换的这个模块下面我们可以看一下主要就是聚焦于上面的这坨内容每一个AI框架都会有自己的一个converter最终呢都会汇聚成我们自己推力引擎的挨压

30
0:02:46.880 --> 0:02:58.840
既然挨压很重要我们看一下整个转换模块的工作流程当中可以看到左边的很多的不同的框架最后都会汇聚成自己的一个独立的挨压

31
0:02:59.280 --> 0:03:20.320
转换模块的阶段呢我们统一了整个计算图的挨压于是呢在优化模块的时候我们就可以通过统一的自定义的挨压完成很多不同的计算图的优化的模式或者优化图的parts这个就是为什么我们需要自定义的挨压为什么需要深入地去给大家讲解转换模块的这个作用

32
0:03:20.320 --> 0:03:26.480
下面我们来看一下第二个比较重要的内容就是模型的序列化和反序列化

33
0:03:26.480 --> 0:03:44.160
首先我们来了解一下模型的序列化的工作其实序列化呢很简单哦就是我们把模型呢在部署的时候怎么去把已经训练好的模型AI框架训练出来的模型把它存储起来给后续我们需要发计论或者推理的时候使用的

34
0:03:44.160 --> 0:03:54.200
而反序列化呢就是把我们刚才保存下来的网络模型的结构还有权重呢反序列到内存当中那内存呢就变成一个具体的对象

35
0:03:54.200 --> 0:03:58.000
我们看一下下面的这个图

36
0:03:58.000 --> 0:04:24.000
在AI框架执行阶段呢我们写的很多网络模型的代码还有一些权重参数啊其实都变成我们内存的一个对象我们需要保存下来把我们的权重和把我们的代码固化下来变成我们硬盘的一些具体的地址最后要加载的时候呢就变成我们需要反序列化回去我们的内存对象那这个呢就是一般的AI框架里面所使用的一个流程

37
0:04:24.000 --> 0:04:35.120
而在推理引擎呢也是相同的左边呢就是AI框架训练的一个网络模型我们把它序列化需要用推理引擎的序列化的API把它固化下来成为我们硬盘的数据

38
0:04:35.120 --> 0:04:45.800
在真正推理引擎执行的时候呢我们需要把一些数据反序列化成为内存的对象最后再去执行这个就是整体的流程

39
0:04:45.800 --> 0:04:49.320
下面我们来看一下序列化的分类

40
0:04:49.320 --> 0:04:53.880
实际上序列化的格式有很多种有XML呢追审呢还有普通buff

41
0:04:53.880 --> 0:05:05.200
和快速buff而在AI框架或者AI的这个领域里面呢普通buff是用的最为广泛的我们可以看到下面这个图谷歌呢是普通buff的一个发起者

42
0:05:05.200 --> 0:05:13.040
最后我们现在经常用的only是Facebook和微软呢组成一个联盟一起去支持这种开放性的格式

43
0:05:13.040 --> 0:05:23.840
而另外方面呢我们平时用的苹果很多AI功能包括思维呢用的就是coreML的格式而coreML呢也是集成于普通buff进行自己一个磨改或者自己的一个修改定义的

44
0:05:24.840 --> 0:05:29.920
下面呢我们以一个简单的例子去看一下拍套许的序列化的方式

45
0:05:29.920 --> 0:05:34.560
拍套许的内部格式呢只是存储已经熏好的网络模型的状态

46
0:05:34.560 --> 0:05:46.200
那所谓的这些状态呢主要是包括之我们的权重了偏移了优化器的更新的参数呢更多的是对网络模型的权重参数信息进行加载和保存的

47
0:05:46.200 --> 0:05:50.720
那其他参数呢其实也有非常的多我们只是不一一列举了

48
0:05:50.720 --> 0:06:00.840
另外的话像拍套许的内部格式呢非常类似于派森里面的序列化的方式直接用披口来去做的这个就是拍套许原生的方式

49
0:06:00.840 --> 0:06:09.440
那在代码里面呢就直接套许点赛然后把我们的网络模型告诉API我们要存在哪个地址就可以了

50
0:06:09.440 --> 0:06:14.360
下次加载的时候呢直接model点楼队地址然后就可以进行一个推理

51
0:06:14.360 --> 0:06:17.080
所以用起来呢是比较简单的

52
0:06:17.080 --> 0:06:19.880
但是呢这种方式呢实在是太难易服了

53
0:06:19.880 --> 0:06:21.680
就是非常的原始

54
0:06:21.680 --> 0:06:31.240
它只是保存了网络模型的对应的参数网络模型的结构网络模型的信息计算图这些信息它都没有保存而是通过代码来去承载

55
0:06:31.240 --> 0:06:37.760
那下面我们来看一下另外一个方面就是拍套许另外一个序列化的方式onlix

56
0:06:39.400 --> 0:06:48.320
欧恩恩X大家都知道拍套许要导到一些推定进去计算的时候呢一般呢我们都会把它转成一个onlix的格式

57
0:06:48.320 --> 0:07:16.640
那拍套许恩可那拍套许内部呢只是支持onlix的export的包括我们现在在生堂去对接到拍套许的框架也是通过onlix的一个接口去实现的下面呢确实看到代码很简单我们前面的都是一些加载网络模型最重要的就是这条套许onlix export这条语句呢就告诉我们需要把拍套许的一个网络模型呢保存为AlexNet点onlix

58
0:07:16.800 --> 0:07:32.680
这里面的保存的信息呢就会比拍套许原生要多很多除了网络模型的权重偏移还有化学参数它还会保存网络模型的结构每一层所使用的蒜子tensor的shape还有很多很多的额外的信息那这些呢就是拍套许计划的一个过程

59
0:07:32.680 --> 0:08:02.680
在最后一个内容里面也是比较长的一个内容我们来看一下目标文件的格式这里面用的更多的在AI领域更多的是Proto Buffer和Fact Buffer那现在呢我们来看一下Proto Buffer其实Proto Buffer他AKA叫Proto Buffer嘛实际上呢他叫做Proto Co Buffer看一下它的logo五颜六色的就知道大部分都是像谷歌的风格也是谷歌发起的一个开源性的

60
0:08:02.680 --> 0:08:32.680
项目因为它确实有很多特殊的优点比XML还有追寻要好所以现在很多AI框架tensorflowmodelsport拍套许都是使用Proto Buffer作为它一个主要的导出的格式现在我们看一下Proto Buffer的一个文件的语法那基本的语法的规则呢下面就是一段message然后呢就告诉我这段message属于哪个域然后在这个域里面呢加了个话或号那中间的这两行呢就是

61
0:08:32.680 --> 0:09:02.680
具体的字段的规则或内容具体的中间两行呢就是具体的内容了我们看一下每一行代表什么意思首先呢我们有一个字段的规则告诉他这个字段呢是属于哪个范围然后有个数据类型有个名称等于然后就有一个域值了等于什么那这个呢就是Proto Buffer的一个文件的最主要的语法规则下面呢就是咖啡这个AI框架用Proto Buffer去表示的那这里面呢有一个data layer

62
0:09:02.680 --> 0:09:32.680
去声明data layer是怎么组成的那这种呢也是Proto Buffer的写的格式那右边的就是卷积层通过这种方式呢去表示我们的卷积层下面我们看一下两个AI框架什么区别像咖啡这种早期的AI框架呢是使用Proto Buffer的格式呢去写我们的网络模型的定义的而后来呢探测复确实觉得大家去写这种网络模型的定义啊去写底层的这些Proto Buffer很容易出错那还不如通过拍照

63
0:09:32.680 --> 0:10:02.680
去封装好然后给到TF TensorFlow去封装好的API给用户去调然后呢通过简单地去调一些API就可以把这个Proto Buffer给调起来去写我们的网络模型所以说当时候TensorFlow出来呢确实大家觉得哇原来AI框架开发AI程序还能这么玩在一七一半年的时候呢确实它已经是个很大的一个创新不过后来又有了派套讯这也是另外一个故事不在我们今天的主线

64
0:10:03.680 --> 0:10:08.560
现在呢我们稍微深入地去看一下Proto Buffer的一个编码的模式

65
0:10:09.340 --> 0:10:10.880
简单地去理解一下哦

66
0:10:11.640 --> 0:10:12.920
我们的计算机哦

67
0:10:13.180 --> 0:10:19.320
一般来说它是通过二进制进行编码那么就是零一零一零一这种方式

68
0:10:20.080 --> 0:10:25.720
它的技术是二规则就是逢二进一像Int这种类型呢是由三十二位去组成

69
0:10:25.980 --> 0:10:32.640
每位的数值呢就是二的恩次方恩的就是零的三十一这个范围大家可以去翻一翻计算机原理

70
0:10:33.400 --> 0:10:41.340
去了解一下那这里面呢就不详细地展开而Proto Buffer这种呢采用的是TRV的编码模式那TRV说白了你可能听不懂

71
0:10:41.600 --> 0:10:45.940
我一开始听不懂但是呢我们把它的详写打印出来它其实就是Tech

72
0:10:46.460 --> 0:10:49.520
Length还有Value的模式进行编码

73
0:10:50.040 --> 0:10:58.480
像Tech跟Value呢它其实是一对的对应起来的一个呢类似于我们经常字典里面的一个key一个呢类似于Value

74
0:10:58.740 --> 0:11:02.320
而Length呢就代表我们整个Value的长度我们写Value的时候呢

75
0:11:02.480 --> 0:11:10.480
有一个长度告诉我们的计算机我要保存多长方便我们的弟子索引嘛那这个时候呢我们整个Proto Buffer的对外的对象呢

76
0:11:10.720 --> 0:11:20.080
就用一个message来去描述这整一个数据结构或者我们整个的对象结构那通过这种方式呢就比较好的进行一个编码

77
0:11:20.320 --> 0:11:29.880
我们看一下它Proto Buffer的编码模式我们这里面呢就不详细地去给大家介绍了因为它会有一个编码的过程也会有一个解码的过程

78
0:11:30.780 --> 0:11:39.840
通过TLV的编码方式呢就把我们内存的对象和内存的数据结构变成我们硬盘的数据啦那第二个我们看一下Flat Buffer

79
0:11:40.080 --> 0:11:59.240
可能很多人听过Proto Buffer但是嗯至少呢在中米开发推力引擎的时候呢我是真没接触过Flat Buffer确实用得也比较小像Proto Buffer用得会更多那我们看一下Flat Buffer呢它对比Proto Buffer有一些的主要的优点之后我们会在推力引擎里面呢

80
0:11:59.440 --> 0:12:03.600
大量地去用到Flat Buffer我们后面会去讲讲有哪些用到

81
0:12:05.080 --> 0:12:21.400
像Flat Buffer呢它有自己主要的特点哦一个就是数据的访问不需要解析那这点很重要不需要解析那我们证明的内存肯定会更高效速度会更快生成的代码量也会相对来说比较少所以说这是它的一个很重要的优点

82
0:12:22.280 --> 0:12:34.560
那很多人就会问那既然Flat Buffer那么好为什么你不直接用Flat Buffer去代替掉Proto Buffer呢那这个就是它们之间的一个对比我就在这里面的不详细的展开

83
0:12:36.320 --> 0:12:50.960
其实Proto Buffer知识的格式和类型呢会更加多而且它的接口呢也会更加多非常方便我们做一些常用的一些工作除了在AI框架里面用Proto Buffer去表示神经网络模型的meta数据还有它的权中数据

84
0:12:50.960 --> 0:12:56.960
它其实还有很多作用特别是在一些游戏的协议的传输啊还有网络资料的传输里面

85
0:12:56.960 --> 0:13:02.560
Proto Buffer还是做的非常好的而且它经过编辑嘛有利于数据的加解密

86
0:13:04.080 --> 0:13:16.880
那下面呢我们看一下Flat Buffer我们刚才说到Flat Buffer其实也是谷歌去发起的后来呢很多AI推理的框架呢确实把Flat Buffer用起来那最主要的两个呢有MMM

87
0:13:16.920 --> 0:13:44.360
MMM呢就是阿里推出的一个推理引擎这个推理引擎呢在阿里非常多的APP里面已经用到了官网宣称有十八个APP已经用了包括我们经常刷的淘宝里面的很多AI功能就是用了MMM做一个推理的那像华为的MineSport Lite里面的Screamer或者里面的阿亚呢也是用Flat Buffer去定义的好了今天的内容就到这里为止我们简单地总结一下

88
0:13:45.360 --> 0:13:54.000
因为转换模块会遇到很多的挑战于是呢我们设计了一个转换模块的架构去承载这些挑战或者去应对这些挑战的

89
0:13:55.240 --> 0:14:12.480
在推理引擎里面的转换模块很重要的一个工作呢就是把不同AI框架训练出来的网络模型呢序列化成推理引擎能够识别的网络模型那在推理引擎真正去执行的时候呢就会把这个网络模型反序列化为我们的内存的对象

90
0:14:12.480 --> 0:14:17.720
然后给温泰去执行这个就是模型序列化和反序列化最重要的工作

91
0:14:17.720 --> 0:14:23.200
那序列化和反序列化里面用到什么数据的格式或者文件的格式或者标准呢

92
0:14:24.400 --> 0:14:30.520
于是我们最后呢就介绍了Portable Buffer和Flat Buffer两种文件格式的内容

93
0:14:30.520 --> 0:14:33.960
而在推理引擎里面呢用的更多的是Flat Buffer

94
0:14:33.960 --> 0:14:40.120
因为它在反序列化的过程当中不需要解析反序列化序列化的过程呢会更加的快

95
0:14:40.840 --> 0:14:45.640
我们在推理引擎里面呢更多的会用到Flat Buffer而不是Portable Buffer

96
0:14:45.640 --> 0:14:57.520
我们将会在下一节内容里面呢去跟大家看看如何自定义图的按按还有转换的流程和具体的技术细节后面的这节课更吸引哦谢谢各位摆了个掰

97
0:14:57.520 --> 0:15:06.120
卷得不行了卷得不行了记得一键三连加关注哦所有的内容都会开源在下面这条链接里面摆了个掰

