1
00:00:00,000 --> 00:00:07,560
Hello,大家好,我是宗米

2
00:00:07,560 --> 00:00:12,080
这里面宗米两个英文单词都是大写

3
00:00:12,080 --> 00:00:15,240
因为它是我中文名字的一个缩写

4
00:00:15,240 --> 00:00:20,600
今天我要给大家汇报的还是模型转换和优化这个内容里面

5
00:00:20,600 --> 00:00:23,480
在模型转换技术这个内容里面

6
00:00:23,480 --> 00:00:26,200
后面的更新频率应该会越来越慢

7
00:00:26,200 --> 00:00:27,200
因为很多知识

8
00:00:27,680 --> 00:00:32,320
其实在网上很难搜得到更多的是工程化的一些经验的总结

9
00:00:33,720 --> 00:00:36,880
这里面应该会分开两个视频给大家介绍的

10
00:00:36,880 --> 00:00:39,840
我们可以看一下主要有很多内容

11
00:00:40,400 --> 00:00:44,880
首先在第一个视频我们更多的是聚焦于一些工程理念和知识概念

12
00:00:44,880 --> 00:00:46,480
例如模型转换的挑战

13
00:00:46,480 --> 00:00:49,000
还有整体的架构应该长什幺样子

14
00:00:49,000 --> 00:00:54,640
接着我们去看一看模型的串行化和反串行化的操作

15
00:00:54,800 --> 00:00:58,120
串行化的工作就是把其他AI框架的网络模型

16
00:00:58,120 --> 00:01:00,480
转换成为我们推进行的模型

17
00:01:01,240 --> 00:01:04,520
反串行化就是把已经保存下来的网络模型

18
00:01:04,520 --> 00:01:08,000
加载到我们的内存当中给推进行去执行的

19
00:01:08,000 --> 00:01:11,360
接着我们会去介绍串行化和反串行化当中

20
00:01:11,360 --> 00:01:13,600
用的很多的两种格式

21
00:01:13,600 --> 00:01:15,440
一种是Portal Buffer

22
00:01:15,440 --> 00:01:17,280
一种是Flat Buffer

23
00:01:17,280 --> 00:01:18,600
讲完这两个内容之后

24
00:01:18,840 --> 00:01:20,800
我们将会在下个内容里面

25
00:01:20,800 --> 00:01:24,480
来到一些比较内核的技术或者内核的内容

26
00:01:24,520 --> 00:01:27,000
就是自定义计算图的IR

27
00:01:27,000 --> 00:01:30,840
针对推力引擎的计算图的IR应该怎幺定义

28
00:01:31,360 --> 00:01:34,040
然后第二个内容也是很重要的一块

29
00:01:34,040 --> 00:01:37,000
转换的流程和技术的细节

30
00:01:37,000 --> 00:01:40,440
流程和细节这个就是指导我们怎幺去开发

31
00:01:40,440 --> 00:01:41,680
怎幺去写代码的

32
00:01:43,520 --> 00:01:45,720
下面我们来到第一个正式的内容

33
00:01:45,720 --> 00:01:48,160
转换模块的挑战和架构

34
00:01:48,160 --> 00:01:49,440
其实挑战和架构

35
00:01:49,440 --> 00:01:53,360
我们在上一节里面已经详细的去给大家去汇报过

36
00:01:53,400 --> 00:01:55,640
今天我们简单的去罗列一下

37
00:01:56,800 --> 00:01:59,720
Converter这个模块其实有非常多的挑战

38
00:01:59,720 --> 00:02:03,640
第一个就是AI框架或者AI本身有非常多的模型

39
00:02:03,640 --> 00:02:05,720
而且有非常多的框架

40
00:02:05,720 --> 00:02:07,880
不同的框架有不同的知识格式

41
00:02:07,880 --> 00:02:10,920
而且我们需要支持非常多主流的网络模型

42
00:02:10,920 --> 00:02:12,560
AI发展的越来越多

43
00:02:12,560 --> 00:02:15,080
很多模型都是千奇百怪

44
00:02:15,080 --> 00:02:18,720
最后就是需要支持很多AI特有的一些特性

45
00:02:19,840 --> 00:02:21,560
为了应对上面的这些挑战

46
00:02:21,720 --> 00:02:24,720
所以我们设计了一个转换模块的整体的架构

47
00:02:24,720 --> 00:02:26,640
主要是由Graph Converter

48
00:02:26,640 --> 00:02:29,760
还有Graph Optimizer两个模块来去组成

49
00:02:29,760 --> 00:02:32,360
今天我们主要是围绕着Graph Converter

50
00:02:32,360 --> 00:02:35,240
就是我们的图转换的模块

51
00:02:35,240 --> 00:02:36,640
下面我们可以看一下

52
00:02:36,640 --> 00:02:40,040
主要就是聚焦于上面的这坨内容

53
00:02:40,040 --> 00:02:42,760
每一个AI框架都会有自己的一个Converter

54
00:02:42,760 --> 00:02:46,960
最终都会汇聚成我们自己推理引擎的IR

55
00:02:48,040 --> 00:02:49,720
既然IR很重要

56
00:02:49,720 --> 00:02:52,640
我们看一下整个转换模块的工作流程当中

57
00:02:52,640 --> 00:02:55,640
可以看到左边的很多的不同的框架

58
00:02:55,640 --> 00:02:58,720
最后都会汇聚成自己的一个独立的IR

59
00:02:59,160 --> 00:03:00,680
转换模块的阶段

60
00:03:00,920 --> 00:03:03,680
我们统一了整个计算图的IR

61
00:03:03,880 --> 00:03:05,560
于是在优化模块的时候

62
00:03:05,560 --> 00:03:08,120
我们就可以通过统一的自定义的IR

63
00:03:08,120 --> 00:03:11,080
完成很多不同的计算图的优化的模式

64
00:03:11,080 --> 00:03:12,280
或者优化图的Path

65
00:03:12,280 --> 00:03:15,000
这个就是为什幺我们需要自定义的IR

66
00:03:15,000 --> 00:03:17,560
为什幺需要深入的去给大家讲解

67
00:03:17,560 --> 00:03:19,520
转换模块的作用

68
00:03:20,320 --> 00:03:22,760
下面我们来看一下第二个比较重要的内容

69
00:03:22,760 --> 00:03:26,200
就是模型的串行化和反串行化

70
00:03:26,440 --> 00:03:29,360
首先我们来了解一下模型的串行化的工作

71
00:03:29,600 --> 00:03:31,480
其实串行化很简单

72
00:03:32,240 --> 00:03:34,360
我们把模型在部署的时候

73
00:03:34,360 --> 00:03:36,320
怎幺去把已经训练好的模型

74
00:03:36,320 --> 00:03:38,400
AI框架训练出来的模型

75
00:03:38,400 --> 00:03:40,480
把它存储起来

76
00:03:40,480 --> 00:03:42,280
给后续我们需要File Tuning

77
00:03:42,280 --> 00:03:44,000
或者推理的时候使用的

78
00:03:44,000 --> 00:03:47,240
而反串行化就是把我们刚才保存下来的

79
00:03:47,240 --> 00:03:49,320
网络模型的结构还有权重

80
00:03:49,800 --> 00:03:51,800
反串行到内存当中

81
00:03:51,800 --> 00:03:54,080
内存就变成一个具体的对象

82
00:03:54,080 --> 00:03:56,880
我们看一下下面的图

83
00:03:57,880 --> 00:03:59,280
在AI框架执行阶段

84
00:03:59,400 --> 00:04:01,480
我们写的很多网络模型的代码

85
00:04:01,480 --> 00:04:02,920
还有一些权重参数

86
00:04:03,040 --> 00:04:06,120
其实都变成我们内存的一个对象

87
00:04:06,120 --> 00:04:07,360
我们需要保存下来

88
00:04:07,360 --> 00:04:08,160
把我们的权重

89
00:04:08,160 --> 00:04:09,600
把我们的代码固化下来

90
00:04:09,600 --> 00:04:12,520
变成我们硬盘的一些具体的地址

91
00:04:12,880 --> 00:04:14,000
最后要加载的时候

92
00:04:14,160 --> 00:04:16,080
就变成我们需要反串行化

93
00:04:16,080 --> 00:04:17,640
回去我们的内存对象

94
00:04:17,880 --> 00:04:19,800
这个就是一般的AI框架里面

95
00:04:19,800 --> 00:04:22,080
所使用的一个流程

96
00:04:23,960 --> 00:04:25,920
而在推理引擎也是相同的

97
00:04:25,920 --> 00:04:28,640
左边就是AI框架训练的一个网络模型

98
00:04:28,640 --> 00:04:29,880
我们把它串行化

99
00:04:29,880 --> 00:04:32,000
需要用推理引擎的串行化的API

100
00:04:32,000 --> 00:04:32,960
把它固化下来

101
00:04:32,960 --> 00:04:34,760
成为我们硬盘的数据

102
00:04:35,040 --> 00:04:36,680
在真正推理引擎执行的时候

103
00:04:36,800 --> 00:04:38,080
我们需要把一些数据

104
00:04:38,080 --> 00:04:39,880
反串行化成为内存的对象

105
00:04:40,080 --> 00:04:41,280
最后再去执行

106
00:04:41,280 --> 00:04:42,880
这个就是整体的流程

107
00:04:43,440 --> 00:04:45,680
下面我们来看一下串行化的分类

108
00:04:47,080 --> 00:04:49,240
实际上串行化的格式有很多种

109
00:04:49,240 --> 00:04:49,840
有XML

110
00:04:50,040 --> 00:04:50,360
JSON

111
00:04:50,560 --> 00:04:52,560
还有Portal Buffer和Fat Buffer

112
00:04:52,560 --> 00:04:55,560
而在AI框架或者AI的领域里面

113
00:04:55,560 --> 00:04:58,200
Portal Buffer是用的最为广泛的

114
00:04:58,200 --> 00:04:59,680
我们可以看到下面这个图

115
00:04:59,680 --> 00:05:02,320
谷歌是Portal Buffer的一个发起者

116
00:05:02,320 --> 00:05:04,640
最后我们现在经常用的onix

117
00:05:04,640 --> 00:05:07,160
是Facebook和微软组成一个联盟

118
00:05:07,160 --> 00:05:09,280
一起去支持这种开放性的格式

119
00:05:09,280 --> 00:05:10,000
而另外一方面

120
00:05:10,000 --> 00:05:11,880
我们平时用的苹果很多AI功能

121
00:05:11,880 --> 00:05:14,280
包括Siri用的就是CoreML的格式

122
00:05:14,280 --> 00:05:16,400
而CoreML也是继承于Portal Buffer

123
00:05:16,400 --> 00:05:17,920
进行自己一个魔改

124
00:05:17,920 --> 00:05:19,880
或者自己的一个修改定义的

125
00:05:21,440 --> 00:05:23,200
下面我们以一个简单的例子

126
00:05:23,200 --> 00:05:25,800
去看一下Pytorch的串行化的方式

127
00:05:26,320 --> 00:05:27,440
Pytorch的内部格式

128
00:05:27,640 --> 00:05:30,440
只是存储已经训好的网络模型的状态

129
00:05:30,440 --> 00:05:31,680
所谓的这些状态

130
00:05:31,680 --> 00:05:33,960
主要是包括我们的权重了

131
00:05:33,960 --> 00:05:34,760
偏移了

132
00:05:34,760 --> 00:05:35,960
用了很多的数据

133
00:05:35,960 --> 00:05:37,120
然后我们可以看到

134
00:05:37,120 --> 00:05:38,240
我们的权重了

135
00:05:38,240 --> 00:05:39,080
偏移了

136
00:05:39,080 --> 00:05:40,760
优化器的更新的参数

137
00:05:41,080 --> 00:05:44,440
更多的是对网络模型的权重参数信息

138
00:05:44,440 --> 00:05:46,160
进行加载和保存的

139
00:05:46,440 --> 00:05:49,040
其他参数其实也有非常的多

140
00:05:49,040 --> 00:05:50,680
我们只是不一一列举了

141
00:05:50,680 --> 00:05:51,360
另外的话

142
00:05:51,360 --> 00:05:52,720
像Pytorch的内部格式

143
00:05:52,920 --> 00:05:54,800
非常类似于Python里面的

144
00:05:54,800 --> 00:05:55,800
串行化的方式

145
00:05:55,800 --> 00:05:57,840
直接用Pico来去做的

146
00:05:57,840 --> 00:06:00,800
这个就是Pytorch原生的方式

147
00:06:01,000 --> 00:06:03,360
在代码里面就直接touch.save

148
00:06:03,360 --> 00:06:05,400
然后把我们的网络模型

149
00:06:05,800 --> 00:06:06,480
告诉API

150
00:06:06,480 --> 00:06:08,720
我们要存在哪个地址就可以了

151
00:06:09,400 --> 00:06:10,480
下次加载的时候

152
00:06:10,600 --> 00:06:12,400
直接model.loadstatedist

153
00:06:12,400 --> 00:06:14,280
然后就可以进行一个推理

154
00:06:14,280 --> 00:06:16,480
所以用起来是比较简单的

155
00:06:17,000 --> 00:06:19,800
但是这种方式实在是太naive了

156
00:06:19,800 --> 00:06:21,320
就是非常的原始

157
00:06:21,600 --> 00:06:24,480
它只是保存了网络模型的对应的参数

158
00:06:24,480 --> 00:06:25,680
网络模型的结构

159
00:06:25,680 --> 00:06:27,560
网络模型的信息计算图

160
00:06:27,560 --> 00:06:29,160
这些信息它都没有保存

161
00:06:29,160 --> 00:06:31,080
而是通过代码来去承载

162
00:06:31,080 --> 00:06:32,360
那下面我们来看一下

163
00:06:32,360 --> 00:06:33,440
另外一个方面

164
00:06:33,560 --> 00:06:34,720
就是Pytorch

165
00:06:34,720 --> 00:06:36,720
另外一个串行化的方式

166
00:06:36,720 --> 00:06:37,720
onlix

167
00:06:39,400 --> 00:06:40,800
onlix

168
00:06:40,800 --> 00:06:43,520
大家都知道Pytorch要导到一些推理

169
00:06:43,520 --> 00:06:44,480
情绪计算的时候

170
00:06:44,880 --> 00:06:48,200
一般我们都会把它转成一个onlix的格式

171
00:06:48,200 --> 00:06:49,520
那Pytorch

172
00:06:49,520 --> 00:06:51,000
那Pytorch内部

173
00:06:51,200 --> 00:06:53,520
其实是支持onlix的export的

174
00:06:53,520 --> 00:06:55,120
包括我们现在在升腾

175
00:06:55,120 --> 00:06:57,040
去对接到Pytorch的框架

176
00:06:57,040 --> 00:07:00,360
也是通过onlix的一个接口去实现的

177
00:07:00,360 --> 00:07:03,040
下面确实看到代码很简单

178
00:07:03,040 --> 00:07:05,920
我们前面的都是一些加载网络模型

179
00:07:05,920 --> 00:07:08,760
最重要的就是这条torch-onlix-export

180
00:07:08,760 --> 00:07:10,920
这条语句就告诉我们

181
00:07:11,120 --> 00:07:13,600
需要把Pytorch的一个网络模型

182
00:07:13,880 --> 00:07:16,560
保存为AlexNet.onlix

183
00:07:16,720 --> 00:07:17,920
这里面的保存的信息

184
00:07:18,040 --> 00:07:20,240
就会比Pytorch原生要多很多

185
00:07:20,240 --> 00:07:22,240
除了网络模型的权重偏移

186
00:07:22,240 --> 00:07:23,520
还有优化器的参数

187
00:07:23,520 --> 00:07:25,680
它还会保存网络模型的结构

188
00:07:25,680 --> 00:07:27,360
每一层所使用的算子

189
00:07:27,360 --> 00:07:28,120
tensor的shape

190
00:07:28,120 --> 00:07:29,960
还有很多的额外的信息

191
00:07:29,960 --> 00:07:32,720
那这些就是Pytorch串行化的一个过程

192
00:07:33,040 --> 00:07:38,360
在最后一个内容里面

193
00:07:38,360 --> 00:07:39,800
也是比较长的一个内容

194
00:07:39,800 --> 00:07:42,800
我们来看一下目标文档的格式

195
00:07:42,800 --> 00:07:44,000
这里面用的更多的

196
00:07:44,000 --> 00:07:44,840
在AI领域

197
00:07:44,920 --> 00:07:47,240
更多的是Portal Buffer和Fact Buffer

198
00:07:47,600 --> 00:07:49,880
现在我们来看一下Portal Buffer

199
00:07:49,880 --> 00:07:52,080
其实Portal Buffer它aka叫Portal Buffer

200
00:07:52,480 --> 00:07:55,080
实际上它叫做Portoco Buffer

201
00:07:55,080 --> 00:07:56,280
看一下它的logo

202
00:07:56,280 --> 00:07:57,720
五颜六色的就知道

203
00:07:57,720 --> 00:08:00,040
大部分都是像谷歌的风格

204
00:08:00,320 --> 00:08:03,400
也是谷歌发起的一个开源性的项目

205
00:08:03,400 --> 00:08:06,120
因为它确实有很多特殊的优点

206
00:08:06,120 --> 00:08:07,960
比XML还有JSON要好

207
00:08:07,960 --> 00:08:10,000
所以现在很多AI框架

208
00:08:10,000 --> 00:08:10,680
Tensorflow

209
00:08:10,680 --> 00:08:11,480
MindSpore

210
00:08:11,480 --> 00:08:13,760
Pytorch都是使用Portal Buffer

211
00:08:13,760 --> 00:08:16,480
作为它一个主要的导出的格式

212
00:08:18,480 --> 00:08:19,320
现在我们看一下

213
00:08:19,320 --> 00:08:21,640
Portal Buffer的一个文档的语法

214
00:08:21,640 --> 00:08:23,040
那基本的语法的规则

215
00:08:23,240 --> 00:08:24,960
下面就是一段message

216
00:08:24,960 --> 00:08:26,160
然后就告诉我

217
00:08:26,160 --> 00:08:28,240
这段message属于哪个域

218
00:08:28,280 --> 00:08:30,840
然后在这个域里面加了个花和号

219
00:08:30,840 --> 00:08:32,120
那中间的这两行

220
00:08:32,280 --> 00:08:35,080
就是具体的字段的规则或者内容

221
00:08:35,080 --> 00:08:36,400
具体的中间两行

222
00:08:36,560 --> 00:08:37,840
就是具体的内容了

223
00:08:37,840 --> 00:08:39,840
我们看一下每一行代表什幺意思

224
00:08:40,040 --> 00:08:42,320
首先我们有一个字段的规则

225
00:08:42,320 --> 00:08:44,560
告诉它这个字段是属于哪个范围

226
00:08:44,560 --> 00:08:46,000
然后有个数据类型

227
00:08:46,000 --> 00:08:47,200
有个名称

228
00:08:47,200 --> 00:08:48,040
等于

229
00:08:48,040 --> 00:08:49,400
然后就有一个域值了

230
00:08:49,400 --> 00:08:50,360
等于什幺

231
00:08:50,560 --> 00:08:53,400
这个就是Portal Buffer的一个文档的

232
00:08:53,400 --> 00:08:54,920
最主要的语法规则

233
00:08:55,880 --> 00:08:57,160
下面就是cafe

234
00:08:57,160 --> 00:09:00,040
这个AI框架用Portal Buffer去表示的

235
00:09:00,040 --> 00:09:02,520
那这里面有一个data layer

236
00:09:02,520 --> 00:09:04,760
去声明data layer是怎幺组成的

237
00:09:04,920 --> 00:09:07,560
这种也是Portal Buffer的写的格式

238
00:09:07,560 --> 00:09:10,000
那右边就是卷积层

239
00:09:10,520 --> 00:09:14,080
通过这种方式去表示我们的卷积层

240
00:09:15,640 --> 00:09:17,920
下面我们看一下两个AI框架有什幺区别

241
00:09:18,600 --> 00:09:20,520
像cafe这种早期的AI框架

242
00:09:20,640 --> 00:09:22,000
是使用Portal Buffer的格式

243
00:09:22,120 --> 00:09:24,320
去写我们的网络模型的定义的

244
00:09:24,320 --> 00:09:26,440
而后来TensorFlow确实觉得

245
00:09:26,440 --> 00:09:28,280
大家去写这种网络模型的定义

246
00:09:28,600 --> 00:09:30,920
去写底层的这些Portal Buffer很容易出错

247
00:09:30,920 --> 00:09:33,600
那还不如通过python去封装好

248
00:09:33,600 --> 00:09:36,360
然后给到TFTensorFlow去封装好的API

249
00:09:36,360 --> 00:09:37,520
给用户去调

250
00:09:37,520 --> 00:09:40,000
然后通过简单的去调一些API

251
00:09:40,000 --> 00:09:42,360
就可以把Portal Buffer给调起来

252
00:09:42,360 --> 00:09:43,880
去写我们的网络模型

253
00:09:43,880 --> 00:09:46,160
所以说当时候TensorFlow出来

254
00:09:46,320 --> 00:09:47,720
确实大家觉得

255
00:09:48,120 --> 00:09:51,600
原来AI框架开发AI进程还能这幺玩

256
00:09:51,600 --> 00:09:52,920
在1718年的时候

257
00:09:53,080 --> 00:09:55,960
确实它已经是一个很大的一个创新

258
00:09:56,080 --> 00:09:57,880
不过后来又有了PyTorch

259
00:09:57,880 --> 00:09:59,400
这也是另外一个故事

260
00:09:59,400 --> 00:10:00,920
不在我们今天的主线

261
00:10:03,600 --> 00:10:06,080
现在我们稍微深入的去看一下

262
00:10:06,080 --> 00:10:08,560
Portal Buffer的一个编码的模式

263
00:10:09,280 --> 00:10:10,480
简单的去理解一下

264
00:10:11,720 --> 00:10:12,600
我们的计算机

265
00:10:13,160 --> 00:10:15,920
一般来说它是通过二进制进行编码

266
00:10:15,920 --> 00:10:19,360
那幺就是010101这种方式

267
00:10:20,040 --> 00:10:21,320
它的基数是2

268
00:10:21,320 --> 00:10:23,040
规则就是逢二进一

269
00:10:23,040 --> 00:10:25,680
像int这种类型是由32位去组成

270
00:10:25,800 --> 00:10:27,600
每位的数值就是2的n

271
00:10:27,600 --> 00:10:30,480
次方n就是0的31这个范围

272
00:10:30,480 --> 00:10:31,680
大家可以去翻一翻

273
00:10:31,680 --> 00:10:33,760
计算机原理去了解一下

274
00:10:33,920 --> 00:10:35,760
这里面就不详细的展开

275
00:10:35,760 --> 00:10:37,040
而Portal Buffer这种

276
00:10:37,160 --> 00:10:39,240
采用的是TLV的编码模式

277
00:10:39,440 --> 00:10:40,400
TLV说白了

278
00:10:40,400 --> 00:10:41,400
你可能听不懂

279
00:10:41,400 --> 00:10:42,440
我一开始也听不懂

280
00:10:42,440 --> 00:10:45,040
但是我们把它的详细打印出来

281
00:10:45,040 --> 00:10:46,040
它其实就是Tag

282
00:10:46,560 --> 00:10:47,040
Length

283
00:10:47,280 --> 00:10:49,560
还有Value的模式进行编码

284
00:10:50,120 --> 00:10:53,200
像Tag跟Value它其实是一对的

285
00:10:53,200 --> 00:10:54,040
对应起来的

286
00:10:54,040 --> 00:10:57,040
一个类似于我们经常字典里面的key

287
00:10:57,040 --> 00:10:58,480
一个类似于Value

288
00:10:58,480 --> 00:11:01,200
而Length就代表我们整个Value的长度

289
00:11:01,200 --> 00:11:02,120
我们写Value的时候

290
00:11:02,400 --> 00:11:04,320
有一个长度告诉我们的计算机

291
00:11:04,320 --> 00:11:05,520
我要保存多长

292
00:11:05,520 --> 00:11:07,040
方便我们的地址索引

293
00:11:07,520 --> 00:11:09,520
这个时候我们整个Portal Buffer的

294
00:11:09,520 --> 00:11:10,280
对外的对象

295
00:11:10,600 --> 00:11:12,920
就用一个Message来去描述

296
00:11:12,920 --> 00:11:14,760
这整一个数据结构

297
00:11:14,760 --> 00:11:16,840
或者我们整个的对象结构

298
00:11:17,040 --> 00:11:17,880
通过这种方式

299
00:11:18,040 --> 00:11:20,200
就比较好的进行一个编码

300
00:11:20,200 --> 00:11:22,200
我们看一下它Portal Buffer的编码模式

301
00:11:22,200 --> 00:11:26,120
我们字里面就不详细的去给大家介绍了

302
00:11:26,120 --> 00:11:28,040
因为它会有一个编码的过程

303
00:11:28,040 --> 00:11:29,960
也会有一个解码的过程

304
00:11:30,800 --> 00:11:32,320
通过TLV的编码方式

305
00:11:32,440 --> 00:11:34,840
就把我们内存的对象和内存的数据结构

306
00:11:35,200 --> 00:11:37,080
变成我们硬盘的数据

307
00:11:37,760 --> 00:11:39,880
第二个我们看一下Flat Buffer

308
00:11:39,880 --> 00:11:41,960
可能很多人听过Portal Buffer

309
00:11:41,960 --> 00:11:46,000
但是至少在ZOMI开发Twin引擎的时候

310
00:11:46,120 --> 00:11:48,120
我是真没接触过Flat Buffer

311
00:11:48,120 --> 00:11:49,640
确实用的也比较小

312
00:11:49,640 --> 00:11:52,120
像Portal Buffer用的会更多

313
00:11:52,320 --> 00:11:54,040
我们看一下Flat Buffer

314
00:11:54,040 --> 00:11:57,200
它对比Portal Buffer有一些的主要的优点

315
00:11:57,200 --> 00:11:59,280
所以我们会在Twin引擎里面

316
00:11:59,280 --> 00:12:01,280
大量的去用到Flat Buffer

317
00:12:01,280 --> 00:12:03,600
我们后面会去讲讲有哪些用到

318
00:12:05,080 --> 00:12:07,600
像Flat Buffer它有自己主要的特点

319
00:12:07,600 --> 00:12:10,520
一个就是数据的访问不需要解析

320
00:12:10,520 --> 00:12:11,520
这点很重要

321
00:12:11,520 --> 00:12:12,400
不需要解析

322
00:12:12,400 --> 00:12:14,680
我们证明了内存肯定会更高效

323
00:12:14,680 --> 00:12:15,800
速度会更快

324
00:12:15,800 --> 00:12:18,880
生成的代码量也会相对来说比较少

325
00:12:18,880 --> 00:12:21,320
所以说这是它的一个很重要的优点

326
00:12:22,240 --> 00:12:23,720
很多人就会问

327
00:12:23,720 --> 00:12:25,520
既然Flat Buffer那幺好

328
00:12:25,520 --> 00:12:28,480
为什幺你不直接用Flat Buffer去代替掉

329
00:12:28,480 --> 00:12:29,720
Portal Buffer呢

330
00:12:29,720 --> 00:12:32,280
这个就是它们之间的一个对比

331
00:12:32,280 --> 00:12:34,640
我就在这里面不详细的展开

332
00:12:36,240 --> 00:12:39,240
其实Portal Buffer支持的格式和类型会更加多

333
00:12:39,240 --> 00:12:41,720
而且它的接口也会更加多

334
00:12:41,720 --> 00:12:44,400
非常方便我们做一些常用的工作

335
00:12:44,760 --> 00:12:47,960
除了在AI框架里面用Portal Buffer去表示

336
00:12:47,960 --> 00:12:49,680
神经网络模型的Meta数据

337
00:12:49,680 --> 00:12:50,920
还有它的权重数据

338
00:12:50,960 --> 00:12:52,560
它其实还有很多作用

339
00:12:52,560 --> 00:12:54,680
特别是在一些游戏的协议的传输

340
00:12:54,920 --> 00:12:56,920
还有网络自动的传输里面

341
00:12:56,920 --> 00:12:59,080
Portal Buffer还是做得非常好的

342
00:12:59,080 --> 00:13:02,520
而且它经过编辑有利于数据的加减密

343
00:13:04,200 --> 00:13:06,280
下面我们看一下Flat Buffer

344
00:13:06,280 --> 00:13:10,120
我们刚才说到Flat Buffer其实也是谷歌去发起的

345
00:13:10,120 --> 00:13:12,320
后来很多AI推理的框架

346
00:13:12,440 --> 00:13:14,320
确实把Flat Buffer用起来

347
00:13:14,600 --> 00:13:16,920
最主要的两个有MMM

348
00:13:16,920 --> 00:13:20,320
MMM就是阿里推出的一个推理引擎

349
00:13:20,520 --> 00:13:23,680
推理引擎在ID非常多的APP里面已经用到了

350
00:13:23,680 --> 00:13:26,400
官网宣传有18个APP已经用了

351
00:13:26,400 --> 00:13:28,680
包括我们经常刷的淘宝

352
00:13:28,680 --> 00:13:32,480
里面的很多AI功能就是用了MMM做一个推理的

353
00:13:32,800 --> 00:13:35,960
像华为的Mouseboard Lite里面的Screema

354
00:13:35,960 --> 00:13:39,480
或者里面的AR也是用Flat Buffer去定义的

355
00:13:39,920 --> 00:13:42,240
好了今天的内容就到这里为止

356
00:13:42,240 --> 00:13:44,360
我们简单的总结一下

357
00:13:45,480 --> 00:13:48,080
因为转换模块会遇到很多的挑战

358
00:13:48,080 --> 00:13:51,000
于是我们设计了一个转换模块的架构

359
00:13:51,000 --> 00:13:54,080
去承载这些挑战或者去应对这些挑战的

360
00:13:55,200 --> 00:13:58,320
在推理引擎里面的转换模块很重要的一个工作

361
00:13:58,720 --> 00:14:01,720
就是把不同AI框架训练出来的网络模型

362
00:14:02,120 --> 00:14:06,080
串行化成推理引擎能够识别的网络模型

363
00:14:06,280 --> 00:14:08,240
在推理引擎真正去执行的时候

364
00:14:08,400 --> 00:14:12,520
就会把网络模型反串行化为我们的内存的对象

365
00:14:12,520 --> 00:14:14,240
然后给OneTime去执行

366
00:14:14,240 --> 00:14:17,720
这个就是模型串行化和反串行化最重要的工作

367
00:14:17,800 --> 00:14:21,000
串行化和反串行化里面用到什幺数据的格式

368
00:14:21,000 --> 00:14:23,120
或者文档的格式或者标准呢

369
00:14:24,440 --> 00:14:26,360
于是我们最后就介绍了

370
00:14:26,360 --> 00:14:30,480
Portal Buffer和Thread Buffer两种文档格式的内容

371
00:14:30,480 --> 00:14:33,800
而在推理引擎里面用的更多的是Thread Buffer

372
00:14:34,200 --> 00:14:36,080
因为它在反串行化的过程当中

373
00:14:36,080 --> 00:14:40,040
不需要解析反串行化串行化的过程会更加的快

374
00:14:40,880 --> 00:14:44,280
我们在推理引擎里面更多的会用到Thread Buffer

375
00:14:44,280 --> 00:14:45,440
而不是Portal Buffer

376
00:14:45,600 --> 00:14:47,360
我们将会在下一节内容里面

377
00:14:47,360 --> 00:14:50,360
去跟大家看看如何自定义图的IR

378
00:14:50,360 --> 00:14:53,560
还有转换的流程和具体的技术细节

379
00:14:53,560 --> 00:14:55,640
后面的这节课更吸引哦

380
00:14:55,640 --> 00:14:56,440
谢谢各位

381
00:14:56,440 --> 00:14:57,400
拜了个拜

382
00:14:58,080 --> 00:14:58,840
卷的不行了

383
00:14:58,840 --> 00:14:59,720
卷的不行了

384
00:14:59,720 --> 00:15:01,520
记得一键三连加关注哦

385
00:15:01,520 --> 00:15:04,720
所有的内容都会开源在下面这条链接里面

386
00:15:05,160 --> 00:15:06,040
拜拜

