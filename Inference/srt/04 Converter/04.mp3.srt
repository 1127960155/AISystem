0
0:00:00.960 --> 0:00:04.360
啦啦啦啦啦啦啦啦啦啦啦啦啦

1
0:00:05.420 --> 0:00:08.660
哈喽大家好我是宗明冷热事发抖的宗明

2
0:00:08.660 --> 0:00:12.240
大家不要只关注不点赞也不要只点赞不关注啊

3
0:00:13.000 --> 0:00:17.500
现在呢我们还是在推定其模型转换和优化的这个内容

4
0:00:17.560 --> 0:00:21.160
因为在转换模块确实之前的内容呢有点多

5
0:00:21.160 --> 0:00:23.160
所以最终呢还是分成三级内容

6
0:00:23.440 --> 0:00:28.000
今天主要去给大家汇报一下的就是模型转换的整体的流程

7
0:00:28.000 --> 0:00:32.400
我们看一下之前讲到的一些内容先来简单地回顾一下

8
0:00:32.400 --> 0:00:35.800
之前呢我们去看了一下最基础的挑战和架构

9
0:00:35.800 --> 0:00:39.000
然后看了一下网络模型怎么去反序列化和序列化

10
0:00:39.000 --> 0:00:43.600
接着呢进入了一个自定义的计算图自定完计算图之后呢

11
0:00:43.800 --> 0:00:49.400
现在来看看整体的转换模块的流程还有相关的一些技术的细节

12
0:00:51.200 --> 0:00:57.200
下面我们来到转换模块的最后一个内容啊就是模型转换的流程和技术细节

13
0:00:57.200 --> 0:01:01.600
那说实话这里面的更多的技术细节我们在分散才没结了

14
0:01:01.600 --> 0:01:07.000
我们来看看转换模块总有两个思路啊第一个呢就是直接转换

15
0:01:07.000 --> 0:01:15.000
那第二个呢就是规范式的一种转换直接转换呢我们看刚才我们的一个转换的架构图可以看到

16
0:01:15.000 --> 0:01:21.400
例如我们现在以麦思波为例呢我们把麦思波通过一个converter转成推力引擎的IR

17
0:01:22.200 --> 0:01:27.000
这种方式呢就是直接把AI框架的格式呢转换成为推力引擎的格式

18
0:01:27.800 --> 0:01:32.000
第二种规范性的转换主要是指使用开放竞的文件格式

19
0:01:32.000 --> 0:01:36.200
然后呢让更多的主流的AI框架都对应到这个格式范围

20
0:01:36.200 --> 0:01:44.800
那说白了就是像我们的这个图我们的架构图又出现了例如派特许它不是直接转派特许而是把派特许转成onix

21
0:01:44.800 --> 0:01:47.400
或者我们可以把麦思波转成onix

22
0:01:47.400 --> 0:01:51.800
然后呢通过onix converter这个模块转成推力引擎的IR

23
0:01:51.800 --> 0:01:54.400
那这种呢就是第二种规范性的转换

24
0:01:54.400 --> 0:01:58.400
其实在我们现在呀至少在中美了解过的很多的AI框架

25
0:01:58.400 --> 0:02:03.000
基本上两种的转换的方式和转换的技术呢都是同时支持的

26
0:02:04.200 --> 0:02:07.400
像直接转换的它整个算法呢还是比较清晰的

27
0:02:07.400 --> 0:02:10.400
我们看一下就是第一个呢就是内容的读取

28
0:02:10.400 --> 0:02:16.200
把从不同AI框架生成的一个网络模型呢通过识别几个内容非常重要

29
0:02:16.200 --> 0:02:21.600
网络模型的张量的数据的类型和格式还有算子的类型和参数

30
0:02:21.600 --> 0:02:27.600
另外还有计算图的结构和命名规范和它们之间的相关的信息进行读取

31
0:02:27.600 --> 0:02:36.000
那这几个呢也是对应于我们自定义计算图里面的张量算子还有图三个内容进行一个识别

32
0:02:36.000 --> 0:02:38.600
接着呢第二步就是格式的转换

33
0:02:38.600 --> 0:02:42.600
那格式的转换呢就是把我们刚才识别到的一些内容了

34
0:02:42.600 --> 0:02:48.800
其实在识别完之后呢就变成了内存的一个对象或者代码具体指向的一个地址

35
0:02:48.800 --> 0:02:55.200
那这个时候呢我们就可以真正的做一些格式的转换通过converter来进行转换

36
0:02:55.200 --> 0:03:02.800
转换之后呢就是对模型进行保存的保存的可能还会用回那个PD或者FB的这种文件的格式

37
0:03:02.800 --> 0:03:07.800
然后用于我们下一次推进引擎真正one time的时候去调用的

38
0:03:09.200 --> 0:03:16.200
像第二种呢规范式的转换呢就是ONIX的确是ONIX是个非常典型的代表

39
0:03:16.200 --> 0:03:19.800
现在呢我们看一下ONIX官网的一个AI的定义

40
0:03:20.800 --> 0:03:28.800
下面这个就是ONIX的AI的定义确实大家也可以去看一看ONIX的AI跟普通buffer或者我们刚才定义的有什么不一样

41
0:03:28.800 --> 0:03:35.400
对于它的网络模型呢它的定义有什么不同对于模型的一些可选的参数还有op opset

42
0:03:35.400 --> 0:03:43.600
那还有当然还有很多那个function的功能还有graph的功能确实它的定义呢比我们刚才讲的要多很多

43
0:03:43.600 --> 0:03:46.600
那这里面呢我就不跟大家一一去介绍了

44
0:03:48.200 --> 0:03:54.400
回到我们模型转换的一个通用的流程那下面这个图呢就是整个模型转换的通用流程

45
0:03:54.400 --> 0:04:01.600
不管是直接转换还是像ONIX的这种规范化的一个格式转换呢其实流程还是这一套流程

46
0:04:01.600 --> 0:04:10.400
首先呢我们有AI框架就AI训练好的框架生成一个计算图那这个生成计算图的功能呢主要是AI框架去实现的

47
0:04:10.400 --> 0:04:18.600
我们在推定引擎实际上呢是不感知或者没怎么去接触的接着呢真正的在推定引擎里面的converter呢主要是三个模块

48
0:04:18.600 --> 0:04:30.600
第一个是做一个算子的对接我们需要把计算图里面的按压的算子或者计算图里面的一些primitive的算子对接到我们刚才自定义的一些算子

49
0:04:30.600 --> 0:04:38.200
接着呢会进行一个具体的格式的转换就真正的一些工程化的转换把不同的计算图的按压转成自己的一个按压

50
0:04:38.200 --> 0:04:56.600
最后呢就是模型的保存与导出主要是这三部而这里面的代码量确实基本上都是一一对应你要做很多大量的工程这里面呢就是大家各位兄弟们业以即日去开发的一些工作了好了今天的内容呢就到这里为止我们简单的回顾一下

51
0:04:58.100 --> 0:05:07.000
今天呢主要是给大家汇报了一下整个转换模块最核心的计算图的一个概念那计算图更重要的主要三个模块

52
0:05:07.000 --> 0:05:14.680
计算图的两个基本组成张量和算子另外呢还有图相关信息就完成了我们整个计算图的定义

53
0:05:14.680 --> 0:05:29.960
我们中间还穿超了AI框架的计算图跟推定引擎的计算图的区别接着呢我们去看了一下转换模块的一个整体的流程还有它的技术的细节和算法的流程那讲完这个之后呢整个转换模块基本上就结束了

54
0:05:29.960 --> 0:05:52.200
我们将会在下一个内容里面呢去给大家汇报一下图优化的相关的功能这些功能呢也是在我们爱冰心里面比较像的所以后面呢应该会过得稍微快一点点谢谢各位摆了个掰卷得不行了卷得不行了记得一键三连加关注哦所有的内容都会开源在下面这条链接里面摆了个掰

