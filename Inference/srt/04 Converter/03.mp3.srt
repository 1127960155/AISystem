0
0:00:00.000 --> 0:00:04.560
巴巴巴巴巴巴巴巴巴

1
0:00:04.560 --> 0:00:07.120
诶,诶哟,已经开始了

2
0:00:07.120 --> 0:00:09.000
大家好,我是宗米

3
0:00:09.000 --> 0:00:13.280
今天我们还是模型转换和优化的系列里面

4
0:00:13.280 --> 0:00:18.040
今天主要给大家介绍的一个内容是模型转换的技术细节

5
0:00:18.040 --> 0:00:23.200
就真正的来到我们模型转换怎幺转,应该怎幺去定义自己的计算图

6
0:00:23.200 --> 0:00:27.720
之前有很多好朋友建议宗米去讲一些具体的代码

7
0:00:27.720 --> 0:00:28.960
不要讲太虚的东西

8
0:00:28.960 --> 0:00:32.560
但是宗米还是觉得我们也一定要跳出具体的代码

9
0:00:32.560 --> 0:00:34.000
跳出具体的工程

10
0:00:34.000 --> 0:00:37.200
跳出具体每天编码的事情来看一看

11
0:00:37.200 --> 0:00:38.600
看一看整体的原理

12
0:00:38.600 --> 0:00:40.000
看一看整体的架构

13
0:00:40.000 --> 0:00:40.920
去了解一下

14
0:00:40.920 --> 0:00:42.400
看一下不同的AI框架

15
0:00:42.400 --> 0:00:43.680
不同的AI编译器

16
0:00:43.680 --> 0:00:44.920
不同的推定

17
0:00:44.920 --> 0:00:47.360
其他整体上面有什幺差异

18
0:00:47.360 --> 0:00:50.880
它使用不同的文档格式有什幺不一样的地方

19
0:00:50.880 --> 0:00:51.840
每一个模块

20
0:00:51.840 --> 0:00:52.600
每一个流程

21
0:00:52.600 --> 0:00:53.440
每一个细节

22
0:00:53.440 --> 0:00:55.560
我们都应该知道

23
0:00:55.560 --> 0:00:59.360
只有这样我们才能够称为自己是一个AI系统的专家

24
0:01:00.480 --> 0:01:03.400
而不是像我以前聚焦于某一个特性

25
0:01:03.400 --> 0:01:05.320
你们知道这个特性应该怎幺写

26
0:01:05.320 --> 0:01:06.920
这代码我能讲得很明白

27
0:01:06.920 --> 0:01:09.400
而且我可以给你讲代码讲两三个小时

28
0:01:09.400 --> 0:01:11.080
但是我那个时候还做不到

29
0:01:11.080 --> 0:01:13.240
我能够跳出这个特性出来

30
0:01:13.240 --> 0:01:15.560
去看一看这个特性跟其他特性

31
0:01:15.560 --> 0:01:17.520
看看整体有什幺区别

32
0:01:17.520 --> 0:01:19.560
这也是我希望给大家去汇报

33
0:01:19.560 --> 0:01:22.200
或者给大家去掌握的一个思想

34
0:01:23.520 --> 0:01:24.600
其实在上一节课

35
0:01:24.640 --> 0:01:28.600
我们了解了一下模型转换的一个具体的格式

36
0:01:28.600 --> 0:01:29.720
还有相关的内容

37
0:01:30.400 --> 0:01:32.080
今天我们很重要的一个内容

38
0:01:32.080 --> 0:01:34.520
就是了解一下怎幺自定义一个计算图

39
0:01:34.520 --> 0:01:36.600
还有转换的流程和细节

40
0:01:37.880 --> 0:01:39.960
下面我们来看一下计算图的回顾

41
0:01:40.160 --> 0:01:41.880
既然谈到计算图

42
0:01:41.880 --> 0:01:44.960
我们肯定需要去回顾一下什幺是计算图

43
0:01:46.400 --> 0:01:47.760
钟鸣老师你好

44
0:01:48.600 --> 0:01:50.520
你说要讲计算图

45
0:01:50.520 --> 0:01:52.000
但是我想问一下

46
0:01:52.120 --> 0:01:55.160
为什幺推力引擎需要自定义计算图呢

47
0:01:56.640 --> 0:01:58.720
小心又来了一个灵魂问题

48
0:01:59.640 --> 0:02:02.120
我们可以看到在整个转换模块架构里面

49
0:02:02.120 --> 0:02:04.400
它分为一个转换模块

50
0:02:04.400 --> 0:02:05.880
还有图优化

51
0:02:05.880 --> 0:02:09.360
中间是有一个IR或者计算图来去承载的

52
0:02:09.360 --> 0:02:11.200
我们会把不同的AI框架

53
0:02:11.200 --> 0:02:13.000
去对接到同一个IR

54
0:02:13.000 --> 0:02:14.360
有了这个IR之后

55
0:02:14.360 --> 0:02:16.680
我们就可以很方便的做一些

56
0:02:16.680 --> 0:02:19.280
很多的不同的图优化的工作

57
0:02:19.280 --> 0:02:20.640
那这些图优化的工作

58
0:02:20.640 --> 0:02:22.800
都是基于一个很重要的概念

59
0:02:22.800 --> 0:02:23.920
就是计算图

60
0:02:23.920 --> 0:02:26.800
所以说不管是推力引擎也好

61
0:02:26.800 --> 0:02:27.920
AI训练框架也好

62
0:02:27.920 --> 0:02:29.720
我们计算图这个概念

63
0:02:29.720 --> 0:02:31.440
还是非常的重要

64
0:02:31.440 --> 0:02:34.280
于是钟鸣在之前AI框架的分享里面

65
0:02:34.440 --> 0:02:36.560
就有一个非常详细的系列了

66
0:02:36.560 --> 0:02:39.520
去独立的把计算图每一个模块

67
0:02:39.520 --> 0:02:42.920
都展开的去详细的给大家去汇报的

68
0:02:44.440 --> 0:02:47.960
下面我们看一下计算图的一个基本的组成

69
0:02:48.040 --> 0:02:49.360
这个也是AI框架

70
0:02:49.400 --> 0:02:51.920
不管现在我们是AI框架还是推力引擎

71
0:02:52.160 --> 0:02:53.680
它的基本组成都是不变的

72
0:02:53.680 --> 0:02:57.080
因为我们的前提的诸余是计算图

73
0:02:57.680 --> 0:02:59.680
现在我们看一下计算图的具体的组成

74
0:02:59.680 --> 0:03:00.640
有两个

75
0:03:00.640 --> 0:03:01.960
一个是张量

76
0:03:01.960 --> 0:03:03.880
一个是算子

77
0:03:04.280 --> 0:03:07.200
张量就是整个计算图去流传的数据

78
0:03:07.200 --> 0:03:09.040
或者计算图里面去计算的数据

79
0:03:09.040 --> 0:03:12.320
而算子就是具体的执行的单元

80
0:03:13.240 --> 0:03:14.240
钟鸣老师你好

81
0:03:14.720 --> 0:03:16.200
我又有个问题了

82
0:03:17.400 --> 0:03:18.200
你说

83
0:03:19.200 --> 0:03:20.800
AI框架的计算图

84
0:03:20.800 --> 0:03:23.600
和推力引擎的计算图有什幺不同吗

85
0:03:24.760 --> 0:03:27.040
这个问题确实问的挺好的

86
0:03:27.040 --> 0:03:30.000
这也是我应该总结了好一段时间的

87
0:03:30.000 --> 0:03:32.120
这个表确实我总结了挺久的

88
0:03:32.120 --> 0:03:33.920
有十来分钟

89
0:03:34.480 --> 0:03:35.600
下面我们看一下

90
0:03:35.600 --> 0:03:36.760
AI框架计算图

91
0:03:36.760 --> 0:03:38.120
还有推力引擎的计算图

92
0:03:38.560 --> 0:03:40.280
我们对比了几个维度

93
0:03:40.280 --> 0:03:41.920
一个是它的一个组成

94
0:03:41.920 --> 0:03:43.080
接着是正反向

95
0:03:43.080 --> 0:03:43.880
动静态图

96
0:03:43.880 --> 0:03:44.840
还有分布式并行

97
0:03:44.840 --> 0:03:46.480
还有具体的使用场景

98
0:03:46.760 --> 0:03:48.320
可以看到计算图的组成

99
0:03:48.320 --> 0:03:49.560
AI框架的计算图

100
0:03:49.560 --> 0:03:50.880
和推力引擎的计算图

101
0:03:50.880 --> 0:03:52.080
其实是差不多的

102
0:03:52.080 --> 0:03:53.920
但是有一个很大的区别

103
0:03:53.920 --> 0:03:55.320
就是推力引擎更多的是

104
0:03:55.320 --> 0:03:56.920
聚焦于我们做一个forward

105
0:03:56.920 --> 0:03:58.120
前向的计算

106
0:03:58.120 --> 0:03:59.080
不需要backward

107
0:03:59.080 --> 0:04:00.680
就不需要有反向了

108
0:04:00.680 --> 0:04:02.400
而在动静态图里面

109
0:04:02.520 --> 0:04:03.360
确实AI框架

110
0:04:03.360 --> 0:04:05.040
它需要支持非常灵活的

111
0:04:05.040 --> 0:04:06.080
动态图的写法

112
0:04:06.080 --> 0:04:07.960
但是有时候在训练过程当中

113
0:04:07.960 --> 0:04:09.440
我们希望它越快越好

114
0:04:09.440 --> 0:04:11.280
于是会有一个动静转移

115
0:04:11.280 --> 0:04:12.160
或者动静统一

116
0:04:12.160 --> 0:04:14.520
或者动静态图都支持的情况

117
0:04:14.520 --> 0:04:15.320
而推力引擎

118
0:04:15.440 --> 0:04:17.480
大部分都是以静态图为主

119
0:04:17.760 --> 0:04:19.160
基本上我们在推力引擎

120
0:04:19.160 --> 0:04:20.520
不希望它是一个动态图

121
0:04:20.520 --> 0:04:22.360
动态图对我们的推力引擎的

122
0:04:22.360 --> 0:04:23.320
时间的消耗

123
0:04:23.320 --> 0:04:24.760
对我们的温碳的调度

124
0:04:24.760 --> 0:04:25.880
还有颗脑的调度

125
0:04:25.880 --> 0:04:27.720
确实非常的不友好

126
0:04:28.240 --> 0:04:29.280
所以我们一般都会把它

127
0:04:29.280 --> 0:04:31.200
转为静态图去进行执行的话

128
0:04:31.200 --> 0:04:32.520
大家一定要注意这个点

129
0:04:32.520 --> 0:04:33.400
就是一个forward

130
0:04:33.400 --> 0:04:34.560
一个静态图

131
0:04:34.560 --> 0:04:36.040
接着分布式并行

132
0:04:36.040 --> 0:04:36.480
AI框架

133
0:04:36.480 --> 0:04:38.800
我们之前确实有三个系列

134
0:04:38.800 --> 0:04:40.880
去单独的去汇报了给大家

135
0:04:40.880 --> 0:04:42.040
AI框架的计算图

136
0:04:42.040 --> 0:04:43.520
到底是怎幺样去切分的

137
0:04:43.520 --> 0:04:44.760
我们应该有哪些策略

138
0:04:44.880 --> 0:04:45.880
但是在推力引擎

139
0:04:45.880 --> 0:04:47.600
我们大部分都是以

140
0:04:47.600 --> 0:04:49.320
单卡的推理服务为主

141
0:04:49.320 --> 0:04:51.600
很少去考虑分布式的推理

142
0:04:51.600 --> 0:04:52.680
确实分布式的推理

143
0:04:52.680 --> 0:04:55.120
至少中米在从业这幺多年

144
0:04:55.120 --> 0:04:57.680
没有遇到过太多相关的工作

145
0:04:57.680 --> 0:04:58.240
有是有

146
0:04:58.240 --> 0:04:59.400
但是基本上很少

147
0:04:59.400 --> 0:05:00.160
很少客户

148
0:05:00.160 --> 0:05:01.720
大部分都是创新的场景

149
0:05:02.080 --> 0:05:03.720
最后一个就是看一下

150
0:05:03.720 --> 0:05:04.920
AI框架的计算图

151
0:05:05.040 --> 0:05:06.800
更多的是指训练的场景

152
0:05:06.800 --> 0:05:08.120
支持科研的创新

153
0:05:08.120 --> 0:05:09.880
对网络模型的训练的微调

154
0:05:09.960 --> 0:05:11.240
提升算法为主

155
0:05:11.240 --> 0:05:14.320
但是推力引擎确实它比较特别

156
0:05:14.320 --> 0:05:16.320
它的计算图主要是支持

157
0:05:16.320 --> 0:05:18.360
工业级的应用的部署

158
0:05:18.360 --> 0:05:19.440
对外提供服务

159
0:05:19.440 --> 0:05:22.200
所以说因为这些特殊的原因

160
0:05:22.200 --> 0:05:26.560
所以推力引擎有自己的计算图的定义

161
0:05:26.560 --> 0:05:27.920
当然它也可以附用

162
0:05:27.920 --> 0:05:29.760
AI框架计算图的定义

163
0:05:29.760 --> 0:05:32.320
这个也是Masper端营统一的一个概念

164
0:05:32.320 --> 0:05:34.040
废话我们就不多说了

165
0:05:34.040 --> 0:05:35.720
我们继续往下看一看

166
0:05:37.760 --> 0:05:39.040
接下来我们看一下

167
0:05:39.040 --> 0:05:41.480
推力引擎到底怎幺样去定义

168
0:05:41.480 --> 0:05:42.440
一个计算图的

169
0:05:42.440 --> 0:05:43.760
计算图的最基本

170
0:05:43.760 --> 0:05:45.240
应该有哪些结构

171
0:05:45.240 --> 0:05:48.240
这里面我就会带着大家去看一看

172
0:05:48.240 --> 0:05:49.440
具体的代码

173
0:05:50.000 --> 0:05:51.680
下面我们来回顾一下

174
0:05:51.680 --> 0:05:52.560
重新回顾一下

175
0:05:52.560 --> 0:05:53.960
计算图有两个组成

176
0:05:53.960 --> 0:05:55.880
第一个就是张量 Tensor

177
0:05:55.880 --> 0:05:57.200
第二个就是Operation

178
0:05:57.200 --> 0:05:57.840
算子

179
0:05:57.840 --> 0:05:59.320
我们的执行单元

180
0:05:59.720 --> 0:06:01.600
下面我们就不看slide了

181
0:06:01.600 --> 0:06:02.440
就不看PPT了

182
0:06:02.440 --> 0:06:04.240
而转到具体的代码

183
0:06:05.960 --> 0:06:07.520
原量中米的鼠标

184
0:06:07.720 --> 0:06:09.080
一直都是比较大的

185
0:06:09.080 --> 0:06:10.760
我也被很多人吐槽过

186
0:06:10.760 --> 0:06:12.680
说我已经是老人眼了

187
0:06:12.800 --> 0:06:14.680
确实鼠标大一点好看了

188
0:06:14.680 --> 0:06:17.240
不要去看一看它

189
0:06:17.960 --> 0:06:20.520
我建议大家都把自己的鼠标调大一点

190
0:06:20.520 --> 0:06:22.320
确实很方便很舒服

191
0:06:22.320 --> 0:06:24.840
现在我们回到推力引擎计算图的

192
0:06:24.840 --> 0:06:26.840
一个Tensor张量的表示

193
0:06:26.840 --> 0:06:27.840
首先我们张量

194
0:06:27.840 --> 0:06:29.800
肯定要定义自己的数据结构

195
0:06:29.800 --> 0:06:31.720
证明我们的推力引擎

196
0:06:31.720 --> 0:06:35.080
里面支持哪几种的数据的运行的方式

197
0:06:35.280 --> 0:06:36.560
一般我们都会定义

198
0:06:36.560 --> 0:06:38.240
Double,Fold,Int32

199
0:06:38.240 --> 0:06:40.360
这些跟传统的计算机没什幺区别

200
0:06:40.360 --> 0:06:41.960
我们叫做Data Type

201
0:06:42.080 --> 0:06:43.920
接着要定义一个非常重要的内容

202
0:06:44.080 --> 0:06:46.240
就是数据的排布

203
0:06:46.920 --> 0:06:48.720
在AI编译器前端优化里面

204
0:06:48.840 --> 0:06:50.920
确实我们提到单独提到过

205
0:06:50.920 --> 0:06:51.920
数据的排布

206
0:06:51.920 --> 0:06:52.960
而且开了两节课

207
0:06:52.960 --> 0:06:55.320
去给大家去介绍了大概20分钟

208
0:06:55.320 --> 0:06:58.360
这里面包括NCHW,NHWC

209
0:06:58.360 --> 0:07:00.400
NCHWC0,ND

210
0:07:00.400 --> 0:07:01.360
不同的格式

211
0:07:01.480 --> 0:07:03.440
我们确实需要声明的

212
0:07:03.440 --> 0:07:04.600
就告诉我们的AI框架

213
0:07:04.600 --> 0:07:05.720
或告诉我们的算子

214
0:07:05.720 --> 0:07:09.160
我执行的到底是一个什幺样的数据的排布

215
0:07:09.160 --> 0:07:10.440
有了这两个之后

216
0:07:10.640 --> 0:07:12.880
我们还要定义我们的张量

217
0:07:13.080 --> 0:07:14.560
张量就会比较简单

218
0:07:14.560 --> 0:07:15.680
这里面的内容不太多

219
0:07:15.680 --> 0:07:17.280
第一个就是张量的Dimest

220
0:07:17.280 --> 0:07:18.360
张量的Shape

221
0:07:18.360 --> 0:07:20.560
它到底是一个什幺样的形态

222
0:07:20.560 --> 0:07:23.080
接着我们就会有一个Data Format

223
0:07:23.080 --> 0:07:25.840
Data Format就是我们刚才所定义的

224
0:07:25.840 --> 0:07:28.040
这个Data Format到底是NCHW

225
0:07:28.040 --> 0:07:29.360
还是NHWC

226
0:07:29.360 --> 0:07:30.600
另外还有Data Type

227
0:07:30.600 --> 0:07:32.080
Data Type就默认了

228
0:07:32.080 --> 0:07:34.160
你是使用Fp32,Fp16

229
0:07:34.160 --> 0:07:35.200
还是Int8

230
0:07:35.560 --> 0:07:37.760
通过这幺简单的一个FBS

231
0:07:37.760 --> 0:07:39.080
就Fact Buffer的定义

232
0:07:39.320 --> 0:07:42.640
我们就完成了整个对张量的定义了

233
0:07:44.160 --> 0:07:46.040
下面我们就来看一看

234
0:07:46.040 --> 0:07:48.080
推丁引擎里面对算子的定义

235
0:07:48.240 --> 0:07:48.920
算子定义

236
0:07:49.040 --> 0:07:51.440
我们同样去看看具体的代码

237
0:07:53.160 --> 0:07:55.560
算子的定义可能跟张量不太一样

238
0:07:55.560 --> 0:07:56.960
因为我们要对接到

239
0:07:56.960 --> 0:07:59.000
很多不同的AI框架里面

240
0:07:59.000 --> 0:08:00.200
同一个算子

241
0:08:00.200 --> 0:08:01.280
Pytorch的定义

242
0:08:01.280 --> 0:08:03.240
可能和TensorFlow的定义不太一样

243
0:08:03.240 --> 0:08:05.080
也有可能跟Myspore

244
0:08:05.080 --> 0:08:07.200
三个AI框架的定义都不太一样

245
0:08:07.720 --> 0:08:09.120
所以在推丁引擎里面

246
0:08:09.280 --> 0:08:10.400
对于每一个算子

247
0:08:10.560 --> 0:08:12.160
都需要有一个独立的定义

248
0:08:12.160 --> 0:08:13.600
于是我们用table

249
0:08:13.600 --> 0:08:14.480
卷积2D

250
0:08:14.480 --> 0:08:16.000
然后把一些最基本的

251
0:08:16.000 --> 0:08:18.440
Padding, Kernel, Stride, Dialation

252
0:08:18.440 --> 0:08:19.680
Padmore, Group

253
0:08:19.680 --> 0:08:21.520
还有Pad的一些方式

254
0:08:21.520 --> 0:08:23.360
把它定义出来

255
0:08:23.680 --> 0:08:25.520
具体就通过工程性的代码

256
0:08:25.520 --> 0:08:27.080
或者我们的Converted模块

257
0:08:27.080 --> 0:08:29.200
把不同的AI框架的一些参数

258
0:08:29.320 --> 0:08:31.600
对应到我们自己的一个定义里面

259
0:08:31.600 --> 0:08:33.240
有了具体的算子

260
0:08:33.400 --> 0:08:34.920
可能这算子有非常多

261
0:08:35.920 --> 0:08:37.760
然后需要告诉推丁引擎

262
0:08:37.760 --> 0:08:39.280
我们现在支持哪些算子

263
0:08:39.280 --> 0:08:40.800
于是有个OPtype

264
0:08:40.800 --> 0:08:42.080
有个算子的列表

265
0:08:42.080 --> 0:08:44.120
有Constant, Concatenate,卷积

266
0:08:44.120 --> 0:08:46.320
Device, 反卷积, Matmul

267
0:08:46.320 --> 0:08:48.080
有非常多的算子

268
0:08:48.080 --> 0:08:49.400
但是这些算子

269
0:08:49.520 --> 0:08:50.480
其实我建议

270
0:08:50.600 --> 0:08:52.960
一般控制在200到300个之间

271
0:08:52.960 --> 0:08:55.240
基本上能够覆盖95%的场景

272
0:08:55.800 --> 0:08:57.240
像Pytorch里面

273
0:08:57.360 --> 0:08:58.920
就有1200多个算子

274
0:08:58.920 --> 0:09:01.080
TensorFlow里面就有1500多个算子

275
0:09:01.080 --> 0:09:02.760
其实很多时候在推丁引擎

276
0:09:02.840 --> 0:09:04.480
真的没有必要塞那幺多算子

277
0:09:04.920 --> 0:09:06.480
一个算子具体实现的时候

278
0:09:06.560 --> 0:09:08.080
就可能有好几个kernel

279
0:09:08.640 --> 0:09:09.560
这会非常影响

280
0:09:09.560 --> 0:09:11.520
我们整个推丁引擎的大小的

281
0:09:11.520 --> 0:09:13.440
推丁引擎我们要真正部署在端测

282
0:09:13.600 --> 0:09:14.760
肯定是越小越好

283
0:09:14.800 --> 0:09:17.880
接着我们会有一些算子的公共的属性

284
0:09:17.880 --> 0:09:19.480
例如axis, shape, size

285
0:09:19.840 --> 0:09:22.160
还有一些while, if, else

286
0:09:22.240 --> 0:09:23.440
特殊含义的算子

287
0:09:23.440 --> 0:09:26.280
或者特殊含义的一些属性参数

288
0:09:26.680 --> 0:09:29.360
下面这个才是算子真正的定义

289
0:09:29.360 --> 0:09:30.120
算子的定义

290
0:09:30.240 --> 0:09:32.280
我们就需要告诉这个算子

291
0:09:32.360 --> 0:09:33.840
它有多少个输入

292
0:09:33.880 --> 0:09:35.320
有多少个输出

293
0:09:35.440 --> 0:09:38.800
这里面的main是属于哪个公共的属性

294
0:09:38.800 --> 0:09:42.200
另外它的type是属于哪一个算子

295
0:09:42.200 --> 0:09:45.200
那optype我们就可以在这里面去找到

296
0:09:45.200 --> 0:09:49.000
通过这种方式去声明我们整个算子的定义

297
0:09:51.200 --> 0:09:53.800
回到我们的PPT里面

298
0:09:54.000 --> 0:09:56.000
接下来有一个很重要的内容

299
0:09:56.000 --> 0:09:59.000
就是计算图的表示

300
0:09:59.000 --> 0:10:01.760
我们刚才说计算图主要是由

301
0:10:01.760 --> 0:10:03.400
算子跟张量来组成

302
0:10:03.800 --> 0:10:05.680
但是图这个概念还是要有的

303
0:10:05.680 --> 0:10:07.080
你不能把它拆开

304
0:10:07.080 --> 0:10:08.320
里面具体的内容

305
0:10:08.320 --> 0:10:10.760
我们现在来看看它的图的定义

306
0:10:10.760 --> 0:10:12.480
那图其实我们有两个

307
0:10:12.480 --> 0:10:14.480
一个是定义网络模型的子图

308
0:10:14.480 --> 0:10:16.840
一个是定义整个网络模型

309
0:10:18.160 --> 0:10:20.000
像一些分类的网络模型

310
0:10:20.120 --> 0:10:21.880
确实我们有一个网络模型

311
0:10:21.880 --> 0:10:22.840
一个net就好了

312
0:10:22.840 --> 0:10:23.920
就没有子图

313
0:10:24.040 --> 0:10:25.400
但是我们在具体工程

314
0:10:25.400 --> 0:10:26.920
或者具体实现的过程当中

315
0:10:27.040 --> 0:10:28.480
遇到if, else, while, for

316
0:10:28.480 --> 0:10:30.920
或者这些我们就会拆开成为子图

317
0:10:30.960 --> 0:10:33.280
这个也是在之前的计算图概念

318
0:10:33.400 --> 0:10:34.680
去给大家普及过的

319
0:10:34.680 --> 0:10:36.560
我们看一下模型怎幺定义

320
0:10:36.720 --> 0:10:37.640
这里面有个net

321
0:10:37.640 --> 0:10:38.440
在存储的时候

322
0:10:38.560 --> 0:10:39.560
我们就需要去定义

323
0:10:39.560 --> 0:10:41.560
这个网络模型叫什幺名字

324
0:10:41.560 --> 0:10:43.280
它的输入的tensor的名字

325
0:10:43.280 --> 0:10:44.920
它的output tensor的名字

326
0:10:45.200 --> 0:10:47.120
方便我们去做一个代码的控制

327
0:10:47.120 --> 0:10:48.280
另外还需要告诉我们

328
0:10:48.280 --> 0:10:51.040
这个网络模型有哪些算子

329
0:10:51.560 --> 0:10:53.160
这个算子的列表是一个list

330
0:10:53.160 --> 0:10:54.360
这个list就告诉我们

331
0:10:54.360 --> 0:10:56.680
应该先执行哪一个顺子

332
0:10:56.680 --> 0:10:58.080
后执行哪一个算子

333
0:10:58.080 --> 0:11:00.040
算子跟算子之间的一个关系

334
0:11:00.200 --> 0:11:02.080
就是通过刚才我们定义的

335
0:11:02.080 --> 0:11:03.960
根据input index跟output index

336
0:11:03.960 --> 0:11:06.000
去检索相关的边

337
0:11:06.200 --> 0:11:07.760
最后就有一个subgraph

338
0:11:07.760 --> 0:11:08.960
有没有子图

339
0:11:08.960 --> 0:11:09.840
有子图的话

340
0:11:09.840 --> 0:11:11.920
就去调用下面一个子图了

341
0:11:11.920 --> 0:11:13.200
像遇到if, else这种

342
0:11:13.360 --> 0:11:15.640
确实它就会产生不同的子图

343
0:11:15.840 --> 0:11:17.160
子图也有自己的名字

344
0:11:17.160 --> 0:11:18.960
也有自己的输入输出

345
0:11:18.960 --> 0:11:20.720
当然了还有一个node的op

346
0:11:20.840 --> 0:11:21.520
就op list

347
0:11:21.960 --> 0:11:24.320
其实跟上面的网络模型的定义差不多

348
0:11:24.320 --> 0:11:26.000
它只是一个简单的子图

349
0:11:26.000 --> 0:11:28.200
可能信息会比整个大图

350
0:11:28.360 --> 0:11:29.960
会稍微少一点

351
0:11:30.080 --> 0:11:31.280
没有那幺多用意的信息

352
0:11:31.280 --> 0:11:33.200
当然了我们这里面有很多点点点

353
0:11:33.200 --> 0:11:34.120
就告诉大家

354
0:11:34.120 --> 0:11:35.480
其实这里面还可以塞很多

355
0:11:35.480 --> 0:11:37.280
不同的相关的信息

356
0:11:38.840 --> 0:11:41.000
了解完怎幺通过flat buffer

357
0:11:41.000 --> 0:11:42.000
或者protobuf

358
0:11:42.000 --> 0:11:43.840
去自定义一个计算图之后

359
0:11:44.000 --> 0:11:45.640
我们现在来回头

360
0:11:45.640 --> 0:11:47.720
来看看整体的流程

361
0:11:47.720 --> 0:11:48.400
整体流程

362
0:11:48.520 --> 0:11:51.800
首先我们需要构建一个计算图的IR

363
0:11:52.240 --> 0:11:54.040
刚才我就已经以伪代码

364
0:11:54.040 --> 0:11:55.240
带着大家去构建

365
0:11:55.240 --> 0:11:56.960
自己的一个计算图的IR

366
0:11:56.960 --> 0:11:58.120
这个更重要的是

367
0:11:58.120 --> 0:11:59.920
需要结合我们自己的一个推进引擎的

368
0:11:59.920 --> 0:12:00.560
透出性

369
0:12:00.560 --> 0:12:02.480
还有竞争力去构建的

370
0:12:02.760 --> 0:12:04.400
第二步确实是

371
0:12:04.400 --> 0:12:06.200
更多的是工程化的工作了

372
0:12:06.200 --> 0:12:08.280
去解析训练模型

373
0:12:08.280 --> 0:12:09.280
就我们AI框架

374
0:12:09.280 --> 0:12:10.240
不同的框架

375
0:12:10.240 --> 0:12:12.080
导出来的模型

376
0:12:12.520 --> 0:12:16.240
第三步就是生成自定义的计算图

377
0:12:16.240 --> 0:12:18.120
这里面就是通过flat buffer

378
0:12:18.120 --> 0:12:19.360
或者protobuf的API

379
0:12:19.760 --> 0:12:22.120
来去对接到对应的计算图

380
0:12:22.360 --> 0:12:24.640
我们看一下右边的这两个图

381
0:12:24.640 --> 0:12:25.680
右边的这个图

382
0:12:25.680 --> 0:12:27.320
你大家可以看到非常的长

383
0:12:27.360 --> 0:12:29.640
就是我用刚才定义的一个伪代码

384
0:12:29.840 --> 0:12:32.840
然后写了一个websnap50的网络模型

385
0:12:32.840 --> 0:12:36.520
右边的这个就是其中一小段的展开

386
0:12:37.960 --> 0:12:38.760
卷的不行了

387
0:12:38.760 --> 0:12:39.560
卷的不行了

388
0:12:39.560 --> 0:12:41.040
记得一键三连加关注

389
0:12:41.400 --> 0:12:44.520
所有的内容都会开源在下面这条链接里面

390
0:12:45.040 --> 0:12:45.360
拜了

391
0:12:45.360 --> 0:12:45.880
拜拜

