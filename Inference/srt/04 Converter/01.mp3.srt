0
0:00:00.000 --> 0:00:10.000
eller大家好我是曾敏今天我们来到一个新的内容

1
0:00:10.000 --> 0:00:27.180
虽然这个内容还是在推理引擎下面但是呢我们来到模型转换和优化这个内容里面本来呢我在这个内容只是讲讲模型转换优化接下来我们要讲哪些内容后来梳理着梳理着就变成了模型转换优化的一个整体的架构和它的流程

2
0:00:27.180 --> 0:00:35.060
在接下来在正式进入模型转化与优化的这个内容里面呢我想跟大家一起去回顾一下之前讲的一个内容

3
0:00:35.060 --> 0:00:41.580
之前讲的推理系统的介绍的时候呢其实更关注的是推理系统的架构还有推理引擎的架构

4
0:00:41.580 --> 0:00:49.260
接着呢我们了解了整个大的概念之后呢就开始来到了模型的小型化或者叫做模型轻量化

5
0:00:49.260 --> 0:00:54.380
主要是针对CNN和全数目两个结构进行一个小型化或者轻量化的工作

6
0:00:54.380 --> 0:01:06.100
然后呢我们在离线转化模块的时候呢去讲了很多离线的优化压缩特别是低比德克量化模型减值支持增流这些常见的模型压缩的功能

7
0:01:06.100 --> 0:01:12.660
在第四和第五节的内容呢更多的是聚焦于推理引擎的真正里面的一些核心的模块

8
0:01:12.660 --> 0:01:22.900
那模型转化呢也是作为其中一个很重要的模块这里面我们将会分开三个内容来给大家介绍第一个就是模型转化和优化的整体的架构和流程

9
0:01:22.900 --> 0:01:28.500
接着呢我们去看一下模型格式的转化再我们看一下模型离线的优化

10
0:01:28.500 --> 0:01:35.140
经过了格式转化还有离线优化之后呢我们真正的就会进入到第五节温态和在线的优化

11
0:01:35.140 --> 0:01:41.460
而第四个和第五个内容呢也是推理引擎一个非常非常重要的组成部分

12
0:01:41.460 --> 0:01:47.460
回到推理引擎架构里面我们今天的更多是聚焦于模型转换工具

13
0:01:47.460 --> 0:01:53.740
而这一块呢非常非常的重要没有这一块没有办法去衔接我们后面的温态和科诺

14
0:01:53.740 --> 0:02:09.020
这个模块呢最重要有两个功能一个功能就是模型的格式转化第二个呢就是计算图的优化这里面呢我用了一条虚线去代表上面的就是模型转换下面的就是图优化

15
0:02:09.020 --> 0:02:16.340
在接下来的内容里面总比想跟大家一起去探讨一下转换模块的挑战和相关的目标

16
0:02:16.340 --> 0:02:29.100
首先我们看一下转换模块呀converter它其实有非常大的挑战我们这里面呢总结了四条地条就是AI模型本身呢其实有非常非常多的算子的

17
0:02:29.100 --> 0:02:43.500
那推理引擎呢需要用有限的算子来实现不同AI框架所需要的算子因为推理引擎它需要对接很多种不同AI框架训练出来的网络模型不同的AI框架呢它的算子呢有自己的定义

18
0:02:43.500 --> 0:03:13.140
接着呢第二点就是有非常多的框架不同的框架有自己的一个模型的文件格式第三点就是推理引擎需要支持很多主流的网络模型的结构包括cygn还有transformer最后一点就是相关的DSL的一些特性domain specific就是我们的一个深度学习专用领域的一些特性需要支持动态讯的任意维度的输出还有带空自流的模型

19
0:03:13.140 --> 0:03:43.140
下面呢我们逐个地去展开看一看AI模型本身包含非常多的算子那我们可以看一下下面这个图呢就是总结的一个图虽然咖啡现在用的很少但是我们看一下tensorflow和pytorch这两个框架实际上这两个框架self呢就是它自身本来具有非常非常多的算子不同的AI框架算子的充分度非常的高但是呢这些算子确实定义也不太一样例如pytorch的padding跟tensorflow的padding它们虽然都叫padding但是它们pad的一个方式

20
0:03:43.140 --> 0:04:13.140
和方向也是不同的第二个点就是推定引擎啊虽然我们接下来要实现的推定引擎不可能把每一个框架这么多算子都实现一遍所以我们用有限的算子去对接或者实现不同AI框架训练出来的网络模型网球看看一下其实我们历经了非常多的不同的框架包括tensorflow呢有一点零跟二点零pytorch呢有之前的一点多版本到现在的二点多版本所以说不同的AI框架

21
0:04:13.140 --> 0:04:43.140
训练出来的网络模型还有算子它之间是有差异的而且不同版本之间它又会增加不同的算子不同的AI框架它的模型转换格式呢也是不一样的所以说我们会遇到非常多的工程性的问题针对上面二三四个问题其实推定引擎都要逐一的去解决包括我们在思考整个架构的时候面对这些问题我们应该怎么去设计好我们的架构才能够让我们整个模块或让我们整个推定引擎

22
0:04:44.140 --> 0:04:51.140
做得更好第一个点呢是因为我们的算子非常的多不同的AI框架有不同的算子的格式的定义

23
0:04:51.140 --> 0:05:03.140
于是呢这里面就要求推定引擎需要有自己的算子的定义还有对应的格式有了这个之后呢就可以去对接到不同的AI框架的算子层了

24
0:05:03.140 --> 0:05:10.140
那针对第二个问题呢我们需要支持非常多不同的AI框架那每个AI框架呢都有自己的文件格式定义

25
0:05:10.140 --> 0:05:20.140
于是呢这里面就要求我们的一个推定引擎需要有自己自定义的计算图的AI去对接到不同的AI框架里面的计算图

26
0:05:20.140 --> 0:05:30.140
第三点呢要支持先安捐刷码等主流的网络模型结构那这个时候呢对我们的推定引擎就要求我们有丰富的demo还有benchmark

27
0:05:30.140 --> 0:05:39.140
有了benchmark呢就可以提供主流模型的性能和功能的基准来保证来去看护我们的整个推定引擎的可用性

28
0:05:40.140 --> 0:05:48.140
最后一步是因为深度学习有它的特殊性需要支持动态的设备呢支持音域维度的输出呢支持空字流

29
0:05:48.140 --> 0:05:56.140
于是呢我们要求推定引擎要支持非常好的可扩展性还有AI的比较重要的一些相关的特性例如动态设备呢

30
0:05:56.140 --> 0:06:06.140
针对不同的任务在CV里面呢例如检测分割分类在MLP里面的MLMARK这些我们需要做大量的集成测试和验证

31
0:06:06.140 --> 0:06:22.140
保证呢我们确实能够处理很多不同类型的网络模型特别是像动态设备呢可能在分类里面是没有的但是呢当我们遇到一些但是当我们遇到一些分割的场景可能会用到很多的动态设备

32
0:06:22.140 --> 0:06:33.140
把其他AI框架的网络模型呢转换成为自己推定引擎的一个网络模型呢接着呢我们就需要对这个网络模型或者计算图呢进行优化

33
0:06:33.140 --> 0:06:42.140
而在优化之前呢我们需要分析一下到底我们需要优化哪些内容在计算图里面到底有哪些勇于才能更好地执行我们的一个优化

34
0:06:42.140 --> 0:06:47.140
所以我们首先来分析一下或者总结一下到底有哪些优化的挑战

35
0:06:47.140 --> 0:06:59.140
这里面呢周米总结了四条第一条是结构的勇于第二条是精度的勇于第三条是算法的勇于第四条是读写的勇于我们下面逐条地来去看一看

36
0:06:59.140 --> 0:07:29.140
首先是结构的勇于那结构的勇于其实我们在AI编辑期里面呢大量地去给大家普及过了这里面的确实有很多跟AI编辑器相关的一些内容我们的深度学习网络模型里面呢有非常大量的没有效果或者没有用的计算节点还有很多重复计算的字图还有相同的结构我们都可以在保留相同计算图语义的情况下去去掉这些勇于的结构说白了就是

37
0:07:29.140 --> 0:07:37.140
我怎么改这个图多好我保证这个计算图的语义它的执行的方式跟用户的期望是相同的

38
0:07:38.140 --> 0:07:50.140
所以就引出了我们在计算图优化的过程当中需要执行一些擅自融合的擅自的替换的常量的字节等常用的优化的功能去对我们的结构勇于进行优化

39
0:07:51.140 --> 0:07:58.140
第二个点呢就是精度勇于实际上呢在我们推定型啊大部分存的数据都是张量

40
0:07:58.140 --> 0:08:19.140
那一般呢我们以FP三色浮点数来去一个存储的但是呢在某些情况下特别是分类啊我们确实可以压到白皮石另外英特巴甚至更低比特那数据中呢可能存在大量的零或者重复的数据这个时候呢针对精度勇于呢确实我们可以做很多模型压缩相关的工作

41
0:08:20.140 --> 0:08:27.140
这个功能其实我们在上一个内容里面给大家详细的介绍过做一些低比特的量化要减字和征流

42
0:08:28.140 --> 0:08:49.140
第三个呢就是算法的勇于算法的勇于呢听上去有点虚就是算子或者科诺层面实现的算法本身呢就存在着计算的勇于什么叫计算勇于啊这里面的棕米就举了一个比较明确的例子我们做一个君子模糊的滑窗还有拉普拉斯的一个滑窗的时候

43
0:08:49.140 --> 0:08:57.140
实际上呢这里面都是通过一个卷迹的方式去实现的只是这个卷迹盒呢比较特殊君子卷迹呢可能它的卷迹盒是通过

44
0:08:58.140 --> 0:09:08.140
高斯定理来去实现的拉普拉斯的滑窗呢就是通过拉普拉斯定理来去实现的他们的计算原理都是一样的这个时候呢就存在着计算的勇于了

45
0:09:08.140 --> 0:09:25.140
因为存在计算的勇于于是呢就要求我们的推力引擎呢需要统一算子还有计算图的表达统一的算子计算图的表达中我们就可以针对发现的计算勇于进行一个统一然后整体去提升我们科诺的繁华性

46
0:09:25.140 --> 0:09:41.140
第四点呢就是读写的勇于在我们的计算场景当中啊确实会有大量存在大量的内存访问的问题那内存是不是连续的要不要进行大量的内存访问都会是一个很严重的挑战

47
0:09:41.140 --> 0:09:54.140
针对读写勇于这个问题呢预示在我们的优化模块里面呢就需要进行一些数据的排布的优化还有内存分配的优化了解完转化模块优化模块遇到的一些问题和挑战

48
0:09:54.140 --> 0:10:03.140
这些疑问或者带着这些目标呢我们就需要去设计好推理引擎整个理性模块的架构还有它的工作流程一些挑战

49
0:10:03.140 --> 0:10:33.140
现在呢我们看一下转换模块的整个架构直接看下面这个图转换模块我们分为一个图的转换还有图的优化两大个内容图的转换首先呢我们会遇到非常多不同的AI框架预示呢针对每个AI框架确实它有自己的API所以不可能通过一个converter能够把它所有的AI框架都转换过来预示呢就会针对脉搏这个AI框架可能有脉搏单独的converter

50
0:10:33.140 --> 0:10:41.340
那针对ONIX呢我们有自己独立的converter通过不同的converter都统一转换成为自己推理引擎的按压中间表达

51
0:10:41.340 --> 0:10:51.140
有了这个中间表达呢后面我们在做图优化的时候都是基于这个按压都是基于自己定义的计算图进行一个改写或者修改的

52
0:10:52.140 --> 0:10:59.340
按压上面的就是我们的模型转换或者格式转换按压下面的就是我们的图优化的模块

53
0:10:59.340 --> 0:11:07.540
在图这个模块呢我们要做很多的算子融合算子替换内存重排数据重排还有内存分配

54
0:11:07.540 --> 0:11:18.940
计算图优化的这个功能呢其实不是说非常的新如果大家看过了解过AI编译器这个系列呢可以发现这里面有很多功能都类似于AI编译器的前端优化

55
0:11:18.940 --> 0:11:29.140
对这里面其实有很多功能可以附现的而我们现在公司其实有一部分专家呢就觉得计算图优化这个功能呢应该通过编译器来去做

56
0:11:29.140 --> 0:11:45.940
所以希望另一个编译器的项目但是呢终于觉得其实没有必要做的这么的重很多时候在推定型啊其实没有必要去做一个编译器更多的基于那个拍腾去优化更多的基于我们的规则进行优化就好了没有必要做那么重

57
0:11:45.940 --> 0:11:57.540
另外一个离线模块呀可能它不需要太大简单的很小的几个M可以了因为我们推定型的哎呀尽可能的设计的比较简单跟我们训练的框架是不一样的

58
0:11:57.540 --> 0:12:27.540
训练的框架呢我们要考虑的问题非常多例如有三个特别重要的特性第一个呢就是自动微分第二个就是分布式的并行第三个点呢就是静态图和动态图的问题那像现在这些大部分的问题呢在推定型呢我们没有必要考虑的太多所以没有必要搞一个编译器出来更多的去做一些拍腾的修改就好了嗯废话就不多说我们回到整个整块模块的工作流程里面去看一下刚才的架构图呢针对我们的工作流程

59
0:12:27.540 --> 0:12:57.540
有什么不一样左边的这个呢是转换模块我们用的蓝色底来去给大家划分右边的这个呢就是优化的模块用的黄色底去进行划分我们可以看到确实有很多个converter有非常多的转换器通过不同的转换器把不同的AI框架训练出来的一个网络模型呢转换成为我们推定型的AI有了推定型的AI之后呢我们现在就变成一个统一的表达了于是呢在做后面的优化呢

60
0:12:57.540 --> 0:13:27.540
三段一段呢叫做preoptimize一段呢叫做正式的optimize最后一段呢叫postoptimize三个阶段有三个不同的内容这个呢也是综米开的很多推定型的项目代码所总结出来的首先会对整块模块传过来的一个计算图做一些公共表达式的消除死代码的消除还有代数简化常用的代数简报消除的功能自行一些公共的功能之后呢就正式的

61
0:13:27.540 --> 0:13:57.540
对我们的计算图对我们的神经网络的一些知识涌进来了那第一点呢就有算子融合算子替换还有常量折叠这个呢就是最常用的一些方式也是我们作为中间优化层来到了postoptimize这个阶段呢其实代表我们的计算图基本上能换的就换了更多的是对数据的格式转换的n4hw到nhwc这种还有内存的布局计算另外会把一些重复的算子把它和平掉到这个阶段呢已经没有

62
0:13:57.540 --> 0:14:27.540
太多了更多的在前面这两个阶段已经把它干完了在最后一个阶段呢主要是对我们的数据对我们的内存进行一些管理和预管理的工作好了今天的内容就这么多我们回顾一下这里面呢跟大家一起汇报了一下模型转换的遇到的一些挑战和目标接着我们看了一下计算图优化的一些挑战和目标带着这些挑战和目标呢我们就去设计了推力引擎的整体的架构然后呢把架构图变成

63
0:14:27.540 --> 0:14:31.100
我们的工作流程图把每一个模块呢都梳理清楚

64
0:14:32.540 --> 0:14:40.460
卷得不行了卷得不行了记得一键三连加关注哦所有的内容都会开源在下面这条链接里面摆了个掰

