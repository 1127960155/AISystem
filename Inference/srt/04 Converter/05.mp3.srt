1
00:00:00,000 --> 00:00:07,080
Hello大家好,我是宗美

2
00:00:07,080 --> 00:00:11,280
今天我们还是在推进引擎模型转换和优化这个内容里面

3
00:00:11,280 --> 00:00:13,960
今天我要给大家带来的一个新的内容

4
00:00:13,960 --> 00:00:17,360
就是模型转换的另外一个模块计算图优化

5
00:00:17,360 --> 00:00:19,320
最后的一个内容

6
00:00:19,320 --> 00:00:21,400
今天刚下班回来有点累

7
00:00:21,400 --> 00:00:23,400
我先去找家店按个摩洗个澡

8
00:00:23,400 --> 00:00:24,400
然后再回来

9
00:00:24,400 --> 00:00:27,200
不好意思啊,我这脚可能有点臭

10
00:00:27,600 --> 00:00:29,880
你看大哥你说这话

11
00:00:29,880 --> 00:00:32,360
咱这是专业的足疗

12
00:00:36,240 --> 00:00:37,160
我又回来了

13
00:00:37,160 --> 00:00:40,080
今天我们来到了计算图优化这个系列

14
00:00:40,080 --> 00:00:42,520
这个系列其实应该是这个内容

15
00:00:42,520 --> 00:00:45,360
我们会分开两大节去给大家介绍

16
00:00:45,360 --> 00:00:50,640
第一大节就是去看一看计算图优化里面的挑战和整体的架构

17
00:00:50,640 --> 00:00:54,360
然后看一下计算图优化是怎幺样一个分类

18
00:00:54,400 --> 00:00:57,880
然后我们以一个ONIX OneTime的一个计算图优化的一个执行

19
00:00:57,880 --> 00:01:00,960
来去了解一下具体的一些优化是怎幺做的

20
00:01:00,960 --> 00:01:07,200
在第二个内容就会对计算图优化这一大个内容来进行详细的展开

21
00:01:07,200 --> 00:01:09,680
所以它叫做详解也是Details

22
00:01:09,680 --> 00:01:11,680
把所有很多细节展开起来

23
00:01:11,680 --> 00:01:13,680
但这一个也是最内核的内容

24
00:01:13,680 --> 00:01:16,280
我们留在后面给大家慢慢的汇报

25
00:01:17,280 --> 00:01:20,760
现在我们来到推力引擎转换模块里面的图优化

26
00:01:20,800 --> 00:01:23,640
图优化我们会做很多对计算图做算子融合

27
00:01:23,640 --> 00:01:25,640
布局转换、算子替换、内存优化

28
00:01:25,640 --> 00:01:28,120
非常多不同的类型的优化的parts

29
00:01:28,120 --> 00:01:31,720
现在我们看一看整体的一个挑战和架构

30
00:01:31,720 --> 00:01:35,760
在最开始第一节内容的时候其实已经跟大家详细的普及过

31
00:01:35,760 --> 00:01:38,240
这里面我们简单的去重复一下

32
00:01:38,240 --> 00:01:41,880
首先第一个就是优化模块的挑战

33
00:01:41,880 --> 00:01:45,080
优化模块其实我们遇到很多各种各样的冗余

34
00:01:45,080 --> 00:01:48,600
有结构的冗余、有精度的冗余、有算法的冗余

35
00:01:48,600 --> 00:01:50,160
还有读写的冗余

36
00:01:50,480 --> 00:01:55,600
针对每一种冗余其实我们在离线优化模块里面是有对应的去处理的

37
00:01:55,600 --> 00:01:59,520
例如针对结构冗余我们会对计算图进行优化

38
00:01:59,520 --> 00:02:02,400
算子融合、算子替换、还有常量折叠

39
00:02:02,400 --> 00:02:05,040
这些常用的计算图的优化的方式

40
00:02:05,040 --> 00:02:08,440
我们就会去去除结构上的冗余

41
00:02:08,440 --> 00:02:13,240
第二种针对算法上面的冗余就是具体到某个算法了

42
00:02:13,240 --> 00:02:16,160
我们除了统一算子还有计算图的表达

43
00:02:16,160 --> 00:02:18,560
就是统一我们自己的自定义按压之外

44
00:02:18,560 --> 00:02:21,520
还会对科农提升它的一个范化性

45
00:02:21,520 --> 00:02:26,000
把相类似的科农把它提炼成为相同的一些科农的操作

46
00:02:26,720 --> 00:02:28,960
最后就是针对读写的冗余

47
00:02:28,960 --> 00:02:31,960
读写的冗余我们会做一些数据排布的优化

48
00:02:31,960 --> 00:02:33,840
还有内存分配的优化

49
00:02:34,280 --> 00:02:37,440
上面四个就是我们遇到的一些挑战

50
00:02:38,200 --> 00:02:42,280
针对这些挑战我们设计了整个转换模块的架构图

51
00:02:42,280 --> 00:02:44,640
可以看到转换模块分为两层

52
00:02:44,640 --> 00:02:46,760
第一层就是图的转换

53
00:02:47,280 --> 00:02:50,120
把从不同AI框架训练得到的计算图

54
00:02:50,120 --> 00:02:52,880
转换成为我们推进引擎的计算图

55
00:02:52,880 --> 00:02:54,680
或者推进引擎自己的IR

56
00:02:55,360 --> 00:02:57,280
第二层就是图的优化

57
00:02:57,280 --> 00:03:01,400
图的优化也就是我们现在红色框所标示的这一个模块

58
00:03:01,400 --> 00:03:04,000
整体我们会做很多OPFusion的算子

59
00:03:04,000 --> 00:03:07,160
就和算子这些块布局的转换内存的分配

60
00:03:07,160 --> 00:03:10,160
很多不同的计算图的优化的内容

61
00:03:11,040 --> 00:03:15,760
下面我们再来整体的看一看转换模块的工作流程

62
00:03:15,760 --> 00:03:19,480
左边转换模块其实我们在上一节里面已经详细的介绍了

63
00:03:19,480 --> 00:03:21,080
特别是自定义的IR

64
00:03:21,080 --> 00:03:23,240
这个IR怎幺用、怎幺做、怎幺定义

65
00:03:23,240 --> 00:03:24,720
我们已经详细介绍过了

66
00:03:24,720 --> 00:03:27,400
在优化模块其实它分开三个

67
00:03:27,400 --> 00:03:29,440
第一个就是Pre-Optimizer

68
00:03:29,440 --> 00:03:32,400
在预优化阶段大部分都是会把常用的代数优化

69
00:03:32,400 --> 00:03:34,280
变成我们计算图的一种优化

70
00:03:34,280 --> 00:03:36,440
在真正的我们中间优化阶段

71
00:03:36,560 --> 00:03:39,360
就会做很多跟算子相关的一些优化

72
00:03:39,360 --> 00:03:41,960
也会把神级网络相关的知识融合进来

73
00:03:42,680 --> 00:03:45,400
Post-Optimizer就是最后的一个优化阶段

74
00:03:45,440 --> 00:03:48,000
我们就会对数据的格式转换、类似的布局

75
00:03:48,320 --> 00:03:50,600
还有重复算子进行一些合并

76
00:03:50,880 --> 00:03:52,280
这个也是最后的优化

77
00:03:52,280 --> 00:03:54,680
一般我们在推进引擎里面的优化顺序

78
00:03:54,680 --> 00:03:56,040
就是长这个样子的

79
00:03:56,960 --> 00:04:00,000
我们往下看一看下一个比较内核的内容

80
00:04:00,760 --> 00:04:03,920
就是离线优化模块的计算图优化

81
00:04:03,920 --> 00:04:08,120
真正的来到计算图优化这个内容

82
00:04:08,600 --> 00:04:11,400
其实我们在AI编译器的前端优化

83
00:04:11,400 --> 00:04:13,680
它也是针对计算图进行优化的

84
00:04:13,840 --> 00:04:16,760
我们在这里面就讲了很多相关的内容

85
00:04:17,040 --> 00:04:19,280
有Graph的IR就是我们的图的IR

86
00:04:19,400 --> 00:04:21,080
有算子融合、布局转换

87
00:04:21,080 --> 00:04:22,280
类似的分配常量折叠

88
00:04:22,280 --> 00:04:24,720
还有公共质地表达式的消除

89
00:04:24,720 --> 00:04:26,280
有非常多的优化的parts

90
00:04:26,760 --> 00:04:28,840
这些是基于AI框架去做的

91
00:04:28,840 --> 00:04:31,040
也就是在我们训练场景会非常的多

92
00:04:31,040 --> 00:04:33,640
而训练场景其实在在线训练的过程当中

93
00:04:33,800 --> 00:04:36,200
对时间实验的要求没有那幺苛刻

94
00:04:36,440 --> 00:04:38,880
所以我们可以在里面可以做很多GIT的编译

95
00:04:38,880 --> 00:04:40,000
或者其他的编译

96
00:04:40,320 --> 00:04:43,400
但是在推进引擎计算图的优化

97
00:04:43,800 --> 00:04:45,640
更多的是采用预先写好的模板

98
00:04:45,720 --> 00:04:47,640
而不是通过AI编译区去实现的

99
00:04:47,640 --> 00:04:49,840
如果真的需要通过AI编译区实现

100
00:04:49,840 --> 00:04:53,000
其实个人来说或者我看到很多项目

101
00:04:53,000 --> 00:04:54,760
基本上很少除了TVM之外

102
00:04:55,400 --> 00:04:56,640
但是像TVM这种项目

103
00:04:56,760 --> 00:04:58,680
它也不是专门针对推进引擎的

104
00:04:58,680 --> 00:05:01,520
所以现在大部分大家能看到的推进引擎

105
00:05:01,520 --> 00:05:03,320
包括TensorIR、ONLIX OneTime

106
00:05:03,600 --> 00:05:06,160
还有MMN、MCNN这些推进引擎

107
00:05:06,160 --> 00:05:08,120
大部分都是已经预先写好的模板

108
00:05:08,400 --> 00:05:09,560
进行转换的

109
00:05:10,160 --> 00:05:13,440
转换的目的就是减少我们计算图中的

110
00:05:13,440 --> 00:05:14,800
用于的计算

111
00:05:15,200 --> 00:05:17,120
于是就会衍生很多各种各样的

112
00:05:17,120 --> 00:05:18,280
图优化的技术

113
00:05:18,640 --> 00:05:21,160
在特定场景确实图优化

114
00:05:21,400 --> 00:05:25,000
能够给我们带来相当大的计算的收益

115
00:05:25,720 --> 00:05:27,640
但是基于这种模板的方式

116
00:05:27,760 --> 00:05:30,560
有个缺点就是需要根据鲜艳的知识

117
00:05:30,800 --> 00:05:32,320
去做一个优化的

118
00:05:32,640 --> 00:05:34,280
相对比于我们AI网络模型

119
00:05:34,440 --> 00:05:38,040
确实它有非常多的各种的创新

120
00:05:38,040 --> 00:05:40,800
所以我们没有办法完完全全的去掉用于

121
00:05:41,800 --> 00:05:44,400
下面我们来到图优化的具体的方式

122
00:05:44,640 --> 00:05:47,440
可以看到左边我有三个圈圈

123
00:05:47,440 --> 00:05:48,200
1、2、3

124
00:05:48,200 --> 00:05:51,480
三个圈圈代表三种不同的图优化的方式

125
00:05:51,480 --> 00:05:54,800
这里面我们ZOMI就做了一个简单的总结

126
00:05:54,800 --> 00:05:57,520
首先第一种就是basic基础的优化

127
00:05:57,520 --> 00:06:00,080
基础优化主要是涵盖很多

128
00:06:00,320 --> 00:06:02,040
保留计算图语义的一些修改

129
00:06:02,040 --> 00:06:04,120
就是不改变原来计算图的语义

130
00:06:04,120 --> 00:06:05,880
做一些真正的修改

131
00:06:06,240 --> 00:06:07,320
例如有常量折叠

132
00:06:07,560 --> 00:06:08,520
用于节点的消除

133
00:06:08,640 --> 00:06:10,320
还有有限数量的算子融合

134
00:06:10,640 --> 00:06:13,360
这些都是属于最基础的优化

135
00:06:13,360 --> 00:06:16,200
接着还有extend就是扩展性的优化

136
00:06:16,200 --> 00:06:19,280
扩展性的优化会根据具体的后端

137
00:06:19,280 --> 00:06:20,720
例如CPU GPU

138
00:06:20,720 --> 00:06:23,280
还有NPU等具体的后端

139
00:06:23,280 --> 00:06:26,000
针对具体或者比较复杂的一些kernel

140
00:06:26,000 --> 00:06:28,200
进行融合优化的策略

141
00:06:28,200 --> 00:06:31,760
最后一个就是layout和memory的优化

142
00:06:31,760 --> 00:06:33,760
例如布局转换优化

143
00:06:33,760 --> 00:06:35,360
还有内存排布的优化

144
00:06:35,360 --> 00:06:37,520
这个就是最后的一种

145
00:06:38,160 --> 00:06:39,320
ZOMI老师你好

146
00:06:39,920 --> 00:06:41,120
我想问一下

147
00:06:42,680 --> 00:06:43,680
你说你说

148
00:06:44,120 --> 00:06:45,920
你这里面三种优化方式

149
00:06:45,920 --> 00:06:48,640
跟架构图好像没有一一对应

150
00:06:49,360 --> 00:06:49,800
是的

151
00:06:49,800 --> 00:06:50,800
这里面的优化方式

152
00:06:50,800 --> 00:06:53,480
确实没有跟架构图一一对应起来

153
00:06:53,480 --> 00:06:56,920
我们看一下下面的一个工作的流程图

154
00:06:56,920 --> 00:06:59,240
可以看到像第一个pre-optimized

155
00:06:59,360 --> 00:07:01,320
就是我们最开始的basic

156
00:07:01,320 --> 00:07:03,880
一些最基础的优化的方式

157
00:07:03,880 --> 00:07:06,640
而中间的这个就有可能会涉及到

158
00:07:06,640 --> 00:07:07,760
最基础的优化方式

159
00:07:07,760 --> 00:07:09,240
还有extend的优化方式

160
00:07:09,320 --> 00:07:10,960
最后的post-optimized

161
00:07:11,120 --> 00:07:13,360
会涉及到我们的extend的优化方式

162
00:07:13,360 --> 00:07:16,160
还有最后的layout和memory的优化方式

163
00:07:17,120 --> 00:07:18,000
接下来的内容

164
00:07:18,160 --> 00:07:20,560
我们更多的是通过图优化的方式

165
00:07:20,560 --> 00:07:21,760
做一个简单的分类

166
00:07:21,760 --> 00:07:25,160
更好的去让大家去学习和了解

167
00:07:25,520 --> 00:07:28,040
当然了这里面的优化的模块的顺序

168
00:07:28,040 --> 00:07:28,840
不是固定的

169
00:07:28,840 --> 00:07:30,360
大家也可以按照自己的理解

170
00:07:30,360 --> 00:07:32,200
还有自己推理引擎的一些特性

171
00:07:32,200 --> 00:07:34,600
来对这些parts进行排序

172
00:07:35,360 --> 00:07:37,080
下面我们看一下

173
00:07:37,120 --> 00:07:39,520
onlix one time的一个图优化具体

174
00:07:39,520 --> 00:07:40,920
是怎幺去使用

175
00:07:40,920 --> 00:07:42,560
这里面简单的去讲一讲

176
00:07:42,560 --> 00:07:44,600
具体的使用usage

177
00:07:45,120 --> 00:07:46,080
在onlix里面

178
00:07:46,320 --> 00:07:48,760
这有graph optimizer level

179
00:07:48,760 --> 00:07:51,120
去选择我们具体对哪一层level

180
00:07:51,120 --> 00:07:52,080
进行优化

181
00:07:52,280 --> 00:07:53,880
有basic我们刚才讲到的

182
00:07:53,880 --> 00:07:54,640
还有extend

183
00:07:54,640 --> 00:07:55,480
还有所有

184
00:07:55,480 --> 00:07:57,480
当然了我所有优化都不自行

185
00:07:57,480 --> 00:07:58,800
这也是可以的

186
00:07:58,800 --> 00:08:02,120
这就是onlix的一个使用的方式

187
00:08:02,440 --> 00:08:03,320
下面我们来看一下

188
00:08:03,320 --> 00:08:06,640
具体的代码是怎幺去usage使用

189
00:08:06,840 --> 00:08:09,600
这里面启动了一个section的对象

190
00:08:09,600 --> 00:08:12,600
然后去设置我们的需要优化的level

191
00:08:12,600 --> 00:08:13,680
这里面就是说

192
00:08:13,680 --> 00:08:17,040
我需要开通一个extend的优化的方式

193
00:08:17,040 --> 00:08:19,080
然后就指定优化模型的地址

194
00:08:19,080 --> 00:08:20,720
最后就导出我们的网络模型

195
00:08:20,720 --> 00:08:22,600
执行具体的模型的优化

196
00:08:22,600 --> 00:08:24,320
就是这种方式去执行的

197
00:08:25,960 --> 00:08:26,600
回顾一下

198
00:08:26,600 --> 00:08:29,480
今天我们在离线计算图优化模块

199
00:08:29,480 --> 00:08:32,400
这里面去讲了它遇到的一些挑战

200
00:08:32,400 --> 00:08:35,200
还有最后设计的一个架构和流程图

201
00:08:35,600 --> 00:08:37,200
接着我们去了解了一下

202
00:08:37,200 --> 00:08:39,200
计算图的优化其实分为三种

203
00:08:39,200 --> 00:08:40,560
一种是basic extend

204
00:08:40,560 --> 00:08:42,920
还有layout and memory的优化的方式

205
00:08:42,920 --> 00:08:44,040
最后我们看了一下

206
00:08:44,040 --> 00:08:46,640
onlix one time图优化具体是怎幺使用的

207
00:08:46,640 --> 00:08:49,360
接下来的内容可能会很复杂

208
00:08:49,360 --> 00:08:51,360
我们将会分开三个小视频

209
00:08:51,360 --> 00:08:53,160
给大家分别的去介绍

210
00:08:53,160 --> 00:08:55,080
第二个内容里面的basic extend

211
00:08:55,080 --> 00:08:57,880
layout and memory三种的优化的方式

212
00:08:58,080 --> 00:09:00,600
虽然推理引擎模型转换的计算图优化

213
00:09:00,720 --> 00:09:02,240
跟A编译器的前端优化

214
00:09:02,560 --> 00:09:04,760
在实现上面有着本质的区别

215
00:09:04,800 --> 00:09:07,400
但是它们的原理是非常的相似

216
00:09:07,400 --> 00:09:09,040
所以也鼓励大家去看一下

217
00:09:09,040 --> 00:09:12,240
A编译器的前端优化的一些相关的原理和概念

218
00:09:12,240 --> 00:09:14,440
当然我在后面也会详细的去展开

219
00:09:14,440 --> 00:09:16,080
后面详细的展开更多是

220
00:09:16,080 --> 00:09:17,080
工程性的一些

221
00:09:17,080 --> 00:09:18,960
展开工程性的一些优化的parts

222
00:09:18,960 --> 00:09:21,080
好了今天的内容就到这里为止

223
00:09:21,080 --> 00:09:22,080
谢谢各位

224
00:09:22,080 --> 00:09:23,080
拜了个拜

225
00:09:23,960 --> 00:09:25,600
卷的不行了卷的不行了

226
00:09:25,600 --> 00:09:27,400
记得一键三连加关注哦

227
00:09:27,400 --> 00:09:30,560
所有的内容都会开源在下面这条链接里面

228
00:09:31,040 --> 00:09:31,840
拜了个拜

