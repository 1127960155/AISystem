0
0:00:00.000 --> 0:00:07.080
Hello大家好,我是宗美

1
0:00:07.080 --> 0:00:11.280
今天我们还是在推进引擎模型转换和优化这个内容里面

2
0:00:11.280 --> 0:00:13.960
今天我要给大家带来的一个新的内容

3
0:00:13.960 --> 0:00:17.360
就是模型转换的另外一个模块计算图优化

4
0:00:17.360 --> 0:00:19.320
最后的一个内容

5
0:00:19.320 --> 0:00:21.400
今天刚下班回来有点累

6
0:00:21.400 --> 0:00:23.400
我先去找家店按个摩洗个澡

7
0:00:23.400 --> 0:00:24.400
然后再回来

8
0:00:24.400 --> 0:00:27.200
不好意思啊,我这脚可能有点臭

9
0:00:27.600 --> 0:00:29.880
你看大哥你说这话

10
0:00:29.880 --> 0:00:32.360
咱这是专业的足疗

11
0:00:36.240 --> 0:00:37.160
我又回来了

12
0:00:37.160 --> 0:00:40.080
今天我们来到了计算图优化这个系列

13
0:00:40.080 --> 0:00:42.520
这个系列其实应该是这个内容

14
0:00:42.520 --> 0:00:45.360
我们会分开两大节去给大家介绍

15
0:00:45.360 --> 0:00:50.640
第一大节就是去看一看计算图优化里面的挑战和整体的架构

16
0:00:50.640 --> 0:00:54.360
然后看一下计算图优化是怎幺样一个分类

17
0:00:54.400 --> 0:00:57.880
然后我们以一个ONIX OneTime的一个计算图优化的一个执行

18
0:00:57.880 --> 0:01:00.960
来去了解一下具体的一些优化是怎幺做的

19
0:01:00.960 --> 0:01:07.200
在第二个内容就会对计算图优化这一大个内容来进行详细的展开

20
0:01:07.200 --> 0:01:09.680
所以它叫做详解也是Details

21
0:01:09.680 --> 0:01:11.680
把所有很多细节展开起来

22
0:01:11.680 --> 0:01:13.680
但这一个也是最内核的内容

23
0:01:13.680 --> 0:01:16.280
我们留在后面给大家慢慢的汇报

24
0:01:17.280 --> 0:01:20.760
现在我们来到推力引擎转换模块里面的图优化

25
0:01:20.800 --> 0:01:23.640
图优化我们会做很多对计算图做算子融合

26
0:01:23.640 --> 0:01:25.640
布局转换、算子替换、内存优化

27
0:01:25.640 --> 0:01:28.120
非常多不同的类型的优化的parts

28
0:01:28.120 --> 0:01:31.720
现在我们看一看整体的一个挑战和架构

29
0:01:31.720 --> 0:01:35.760
在最开始第一节内容的时候其实已经跟大家详细的普及过

30
0:01:35.760 --> 0:01:38.240
这里面我们简单的去重复一下

31
0:01:38.240 --> 0:01:41.880
首先第一个就是优化模块的挑战

32
0:01:41.880 --> 0:01:45.080
优化模块其实我们遇到很多各种各样的冗余

33
0:01:45.080 --> 0:01:48.600
有结构的冗余、有精度的冗余、有算法的冗余

34
0:01:48.600 --> 0:01:50.160
还有读写的冗余

35
0:01:50.480 --> 0:01:55.600
针对每一种冗余其实我们在离线优化模块里面是有对应的去处理的

36
0:01:55.600 --> 0:01:59.520
例如针对结构冗余我们会对计算图进行优化

37
0:01:59.520 --> 0:02:02.400
算子融合、算子替换、还有常量折叠

38
0:02:02.400 --> 0:02:05.040
这些常用的计算图的优化的方式

39
0:02:05.040 --> 0:02:08.440
我们就会去去除结构上的冗余

40
0:02:08.440 --> 0:02:13.240
第二种针对算法上面的冗余就是具体到某个算法了

41
0:02:13.240 --> 0:02:16.160
我们除了统一算子还有计算图的表达

42
0:02:16.160 --> 0:02:18.560
就是统一我们自己的自定义按压之外

43
0:02:18.560 --> 0:02:21.520
还会对科农提升它的一个范化性

44
0:02:21.520 --> 0:02:26.000
把相类似的科农把它提炼成为相同的一些科农的操作

45
0:02:26.720 --> 0:02:28.960
最后就是针对读写的冗余

46
0:02:28.960 --> 0:02:31.960
读写的冗余我们会做一些数据排布的优化

47
0:02:31.960 --> 0:02:33.840
还有内存分配的优化

48
0:02:34.280 --> 0:02:37.440
上面四个就是我们遇到的一些挑战

49
0:02:38.200 --> 0:02:42.280
针对这些挑战我们设计了整个转换模块的架构图

50
0:02:42.280 --> 0:02:44.640
可以看到转换模块分为两层

51
0:02:44.640 --> 0:02:46.760
第一层就是图的转换

52
0:02:47.280 --> 0:02:50.120
把从不同AI框架训练得到的计算图

53
0:02:50.120 --> 0:02:52.880
转换成为我们推进引擎的计算图

54
0:02:52.880 --> 0:02:54.680
或者推进引擎自己的IR

55
0:02:55.360 --> 0:02:57.280
第二层就是图的优化

56
0:02:57.280 --> 0:03:01.400
图的优化也就是我们现在红色框所标示的这一个模块

57
0:03:01.400 --> 0:03:04.000
整体我们会做很多OPFusion的算子

58
0:03:04.000 --> 0:03:07.160
就和算子这些块布局的转换内存的分配

59
0:03:07.160 --> 0:03:10.160
很多不同的计算图的优化的内容

60
0:03:11.040 --> 0:03:15.760
下面我们再来整体的看一看转换模块的工作流程

61
0:03:15.760 --> 0:03:19.480
左边转换模块其实我们在上一节里面已经详细的介绍了

62
0:03:19.480 --> 0:03:21.080
特别是自定义的IR

63
0:03:21.080 --> 0:03:23.240
这个IR怎幺用、怎幺做、怎幺定义

64
0:03:23.240 --> 0:03:24.720
我们已经详细介绍过了

65
0:03:24.720 --> 0:03:27.400
在优化模块其实它分开三个

66
0:03:27.400 --> 0:03:29.440
第一个就是Pre-Optimizer

67
0:03:29.440 --> 0:03:32.400
在预优化阶段大部分都是会把常用的代数优化

68
0:03:32.400 --> 0:03:34.280
变成我们计算图的一种优化

69
0:03:34.280 --> 0:03:36.440
在真正的我们中间优化阶段

70
0:03:36.560 --> 0:03:39.360
就会做很多跟算子相关的一些优化

71
0:03:39.360 --> 0:03:41.960
也会把神级网络相关的知识融合进来

72
0:03:42.680 --> 0:03:45.400
Post-Optimizer就是最后的一个优化阶段

73
0:03:45.440 --> 0:03:48.000
我们就会对数据的格式转换、类似的布局

74
0:03:48.320 --> 0:03:50.600
还有重复算子进行一些合并

75
0:03:50.880 --> 0:03:52.280
这个也是最后的优化

76
0:03:52.280 --> 0:03:54.680
一般我们在推进引擎里面的优化顺序

77
0:03:54.680 --> 0:03:56.040
就是长这个样子的

78
0:03:56.960 --> 0:04:00.000
我们往下看一看下一个比较内核的内容

79
0:04:00.760 --> 0:04:03.920
就是离线优化模块的计算图优化

80
0:04:03.920 --> 0:04:08.120
真正的来到计算图优化这个内容

81
0:04:08.600 --> 0:04:11.400
其实我们在AI编译器的前端优化

82
0:04:11.400 --> 0:04:13.680
它也是针对计算图进行优化的

83
0:04:13.840 --> 0:04:16.760
我们在这里面就讲了很多相关的内容

84
0:04:17.040 --> 0:04:19.280
有Graph的IR就是我们的图的IR

85
0:04:19.400 --> 0:04:21.080
有算子融合、布局转换

86
0:04:21.080 --> 0:04:22.280
类似的分配常量折叠

87
0:04:22.280 --> 0:04:24.720
还有公共质地表达式的消除

88
0:04:24.720 --> 0:04:26.280
有非常多的优化的parts

89
0:04:26.760 --> 0:04:28.840
这些是基于AI框架去做的

90
0:04:28.840 --> 0:04:31.040
也就是在我们训练场景会非常的多

91
0:04:31.040 --> 0:04:33.640
而训练场景其实在在线训练的过程当中

92
0:04:33.800 --> 0:04:36.200
对时间实验的要求没有那幺苛刻

93
0:04:36.440 --> 0:04:38.880
所以我们可以在里面可以做很多GIT的编译

94
0:04:38.880 --> 0:04:40.000
或者其他的编译

95
0:04:40.320 --> 0:04:43.400
但是在推进引擎计算图的优化

96
0:04:43.800 --> 0:04:45.640
更多的是采用预先写好的模板

97
0:04:45.720 --> 0:04:47.640
而不是通过AI编译区去实现的

98
0:04:47.640 --> 0:04:49.840
如果真的需要通过AI编译区实现

99
0:04:49.840 --> 0:04:53.000
其实个人来说或者我看到很多项目

100
0:04:53.000 --> 0:04:54.760
基本上很少除了TVM之外

101
0:04:55.400 --> 0:04:56.640
但是像TVM这种项目

102
0:04:56.760 --> 0:04:58.680
它也不是专门针对推进引擎的

103
0:04:58.680 --> 0:05:01.520
所以现在大部分大家能看到的推进引擎

104
0:05:01.520 --> 0:05:03.320
包括TensorIR、ONLIX OneTime

105
0:05:03.600 --> 0:05:06.160
还有MMN、MCNN这些推进引擎

106
0:05:06.160 --> 0:05:08.120
大部分都是已经预先写好的模板

107
0:05:08.400 --> 0:05:09.560
进行转换的

108
0:05:10.160 --> 0:05:13.440
转换的目的就是减少我们计算图中的

109
0:05:13.440 --> 0:05:14.800
用于的计算

110
0:05:15.200 --> 0:05:17.120
于是就会衍生很多各种各样的

111
0:05:17.120 --> 0:05:18.280
图优化的技术

112
0:05:18.640 --> 0:05:21.160
在特定场景确实图优化

113
0:05:21.400 --> 0:05:25.000
能够给我们带来相当大的计算的收益

114
0:05:25.720 --> 0:05:27.640
但是基于这种模板的方式

115
0:05:27.760 --> 0:05:30.560
有个缺点就是需要根据鲜艳的知识

116
0:05:30.800 --> 0:05:32.320
去做一个优化的

117
0:05:32.640 --> 0:05:34.280
相对比于我们AI网络模型

118
0:05:34.440 --> 0:05:38.040
确实它有非常多的各种的创新

119
0:05:38.040 --> 0:05:40.800
所以我们没有办法完完全全的去掉用于

120
0:05:41.800 --> 0:05:44.400
下面我们来到图优化的具体的方式

121
0:05:44.640 --> 0:05:47.440
可以看到左边我有三个圈圈

122
0:05:47.440 --> 0:05:48.200
1、2、3

123
0:05:48.200 --> 0:05:51.480
三个圈圈代表三种不同的图优化的方式

124
0:05:51.480 --> 0:05:54.800
这里面我们ZOMI就做了一个简单的总结

125
0:05:54.800 --> 0:05:57.520
首先第一种就是basic基础的优化

126
0:05:57.520 --> 0:06:00.080
基础优化主要是涵盖很多

127
0:06:00.320 --> 0:06:02.040
保留计算图语义的一些修改

128
0:06:02.040 --> 0:06:04.120
就是不改变原来计算图的语义

129
0:06:04.120 --> 0:06:05.880
做一些真正的修改

130
0:06:06.240 --> 0:06:07.320
例如有常量折叠

131
0:06:07.560 --> 0:06:08.520
用于节点的消除

132
0:06:08.640 --> 0:06:10.320
还有有限数量的算子融合

133
0:06:10.640 --> 0:06:13.360
这些都是属于最基础的优化

134
0:06:13.360 --> 0:06:16.200
接着还有extend就是扩展性的优化

135
0:06:16.200 --> 0:06:19.280
扩展性的优化会根据具体的后端

136
0:06:19.280 --> 0:06:20.720
例如CPU GPU

137
0:06:20.720 --> 0:06:23.280
还有NPU等具体的后端

138
0:06:23.280 --> 0:06:26.000
针对具体或者比较复杂的一些kernel

139
0:06:26.000 --> 0:06:28.200
进行融合优化的策略

140
0:06:28.200 --> 0:06:31.760
最后一个就是layout和memory的优化

141
0:06:31.760 --> 0:06:33.760
例如布局转换优化

142
0:06:33.760 --> 0:06:35.360
还有内存排布的优化

143
0:06:35.360 --> 0:06:37.520
这个就是最后的一种

144
0:06:38.160 --> 0:06:39.320
ZOMI老师你好

145
0:06:39.920 --> 0:06:41.120
我想问一下

146
0:06:42.680 --> 0:06:43.680
你说你说

147
0:06:44.120 --> 0:06:45.920
你这里面三种优化方式

148
0:06:45.920 --> 0:06:48.640
跟架构图好像没有一一对应

149
0:06:49.360 --> 0:06:49.800
是的

150
0:06:49.800 --> 0:06:50.800
这里面的优化方式

151
0:06:50.800 --> 0:06:53.480
确实没有跟架构图一一对应起来

152
0:06:53.480 --> 0:06:56.920
我们看一下下面的一个工作的流程图

153
0:06:56.920 --> 0:06:59.240
可以看到像第一个pre-optimized

154
0:06:59.360 --> 0:07:01.320
就是我们最开始的basic

155
0:07:01.320 --> 0:07:03.880
一些最基础的优化的方式

156
0:07:03.880 --> 0:07:06.640
而中间的这个就有可能会涉及到

157
0:07:06.640 --> 0:07:07.760
最基础的优化方式

158
0:07:07.760 --> 0:07:09.240
还有extend的优化方式

159
0:07:09.320 --> 0:07:10.960
最后的post-optimized

160
0:07:11.120 --> 0:07:13.360
会涉及到我们的extend的优化方式

161
0:07:13.360 --> 0:07:16.160
还有最后的layout和memory的优化方式

162
0:07:17.120 --> 0:07:18.000
接下来的内容

163
0:07:18.160 --> 0:07:20.560
我们更多的是通过图优化的方式

164
0:07:20.560 --> 0:07:21.760
做一个简单的分类

165
0:07:21.760 --> 0:07:25.160
更好的去让大家去学习和了解

166
0:07:25.520 --> 0:07:28.040
当然了这里面的优化的模块的顺序

167
0:07:28.040 --> 0:07:28.840
不是固定的

168
0:07:28.840 --> 0:07:30.360
大家也可以按照自己的理解

169
0:07:30.360 --> 0:07:32.200
还有自己推理引擎的一些特性

170
0:07:32.200 --> 0:07:34.600
来对这些parts进行排序

171
0:07:35.360 --> 0:07:37.080
下面我们看一下

172
0:07:37.120 --> 0:07:39.520
onlix one time的一个图优化具体

173
0:07:39.520 --> 0:07:40.920
是怎幺去使用

174
0:07:40.920 --> 0:07:42.560
这里面简单的去讲一讲

175
0:07:42.560 --> 0:07:44.600
具体的使用usage

176
0:07:45.120 --> 0:07:46.080
在onlix里面

177
0:07:46.320 --> 0:07:48.760
这有graph optimizer level

178
0:07:48.760 --> 0:07:51.120
去选择我们具体对哪一层level

179
0:07:51.120 --> 0:07:52.080
进行优化

180
0:07:52.280 --> 0:07:53.880
有basic我们刚才讲到的

181
0:07:53.880 --> 0:07:54.640
还有extend

182
0:07:54.640 --> 0:07:55.480
还有所有

183
0:07:55.480 --> 0:07:57.480
当然了我所有优化都不自行

184
0:07:57.480 --> 0:07:58.800
这也是可以的

185
0:07:58.800 --> 0:08:02.120
这就是onlix的一个使用的方式

186
0:08:02.440 --> 0:08:03.320
下面我们来看一下

187
0:08:03.320 --> 0:08:06.640
具体的代码是怎幺去usage使用

188
0:08:06.840 --> 0:08:09.600
这里面启动了一个section的对象

189
0:08:09.600 --> 0:08:12.600
然后去设置我们的需要优化的level

190
0:08:12.600 --> 0:08:13.680
这里面就是说

191
0:08:13.680 --> 0:08:17.040
我需要开通一个extend的优化的方式

192
0:08:17.040 --> 0:08:19.080
然后就指定优化模型的地址

193
0:08:19.080 --> 0:08:20.720
最后就导出我们的网络模型

194
0:08:20.720 --> 0:08:22.600
执行具体的模型的优化

195
0:08:22.600 --> 0:08:24.320
就是这种方式去执行的

196
0:08:25.960 --> 0:08:26.600
回顾一下

197
0:08:26.600 --> 0:08:29.480
今天我们在离线计算图优化模块

198
0:08:29.480 --> 0:08:32.400
这里面去讲了它遇到的一些挑战

199
0:08:32.400 --> 0:08:35.200
还有最后设计的一个架构和流程图

200
0:08:35.600 --> 0:08:37.200
接着我们去了解了一下

201
0:08:37.200 --> 0:08:39.200
计算图的优化其实分为三种

202
0:08:39.200 --> 0:08:40.560
一种是basic extend

203
0:08:40.560 --> 0:08:42.920
还有layout and memory的优化的方式

204
0:08:42.920 --> 0:08:44.040
最后我们看了一下

205
0:08:44.040 --> 0:08:46.640
onlix one time图优化具体是怎幺使用的

206
0:08:46.640 --> 0:08:49.360
接下来的内容可能会很复杂

207
0:08:49.360 --> 0:08:51.360
我们将会分开三个小视频

208
0:08:51.360 --> 0:08:53.160
给大家分别的去介绍

209
0:08:53.160 --> 0:08:55.080
第二个内容里面的basic extend

210
0:08:55.080 --> 0:08:57.880
layout and memory三种的优化的方式

211
0:08:58.080 --> 0:09:00.600
虽然推理引擎模型转换的计算图优化

212
0:09:00.720 --> 0:09:02.240
跟A编译器的前端优化

213
0:09:02.560 --> 0:09:04.760
在实现上面有着本质的区别

214
0:09:04.800 --> 0:09:07.400
但是它们的原理是非常的相似

215
0:09:07.400 --> 0:09:09.040
所以也鼓励大家去看一下

216
0:09:09.040 --> 0:09:12.240
A编译器的前端优化的一些相关的原理和概念

217
0:09:12.240 --> 0:09:14.440
当然我在后面也会详细的去展开

218
0:09:14.440 --> 0:09:16.080
后面详细的展开更多是

219
0:09:16.080 --> 0:09:17.080
工程性的一些

220
0:09:17.080 --> 0:09:18.960
展开工程性的一些优化的parts

221
0:09:18.960 --> 0:09:21.080
好了今天的内容就到这里为止

222
0:09:21.080 --> 0:09:22.080
谢谢各位

223
0:09:22.080 --> 0:09:23.080
拜了个拜

224
0:09:23.960 --> 0:09:25.600
卷的不行了卷的不行了

225
0:09:25.600 --> 0:09:27.400
记得一键三连加关注哦

226
0:09:27.400 --> 0:09:30.560
所有的内容都会开源在下面这条链接里面

227
0:09:31.040 --> 0:09:31.840
拜了个拜

