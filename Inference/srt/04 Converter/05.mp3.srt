0
0:00:00.000 --> 0:00:05.600
爸爸爸爸爸爸爸爸爸

1
0:00:05.600 --> 0:00:07.040
哈喽大家好我是邹妹

2
0:00:07.040 --> 0:00:11.320
今天我们还是在推进引擎模型转换和优化这个内容里面

3
0:00:11.320 --> 0:00:13.920
今天我要给大家带来的一个新的内容

4
0:00:13.920 --> 0:00:19.400
就是模型转换的另外一个模块计算图优化最后的一个内容

5
0:00:19.400 --> 0:00:21.400
今天刚下班回来有点累

6
0:00:21.400 --> 0:00:24.640
我先去早家店按个摩洗个澡然后再回来

7
0:00:25.000 --> 0:00:27.560
啥意思啊我的脚可能有点臭吧

8
0:00:27.560 --> 0:00:30.200
哈哈哈你看大哥你说这话啊

9
0:00:30.800 --> 0:00:32.500
咱这是专业的足疗

10
0:00:36.240 --> 0:00:37.200
哦又回来了

11
0:00:37.200 --> 0:00:40.060
今天呢我们来到了计算图优化这个系列

12
0:00:40.060 --> 0:00:42.640
那这个系列其实应该是这个内容呢

13
0:00:42.640 --> 0:00:45.360
我们会分开两大节去给大家介绍

14
0:00:45.400 --> 0:00:47.500
那第一大节呢就是去看一看

15
0:00:47.740 --> 0:00:50.700
计算图优化里面的挑战和整体的架构

16
0:00:50.700 --> 0:00:54.440
然后看一下计算图优化是怎么样一个分类

17
0:00:54.440 --> 0:00:55.340
然后呢我们以一个

18
0:00:55.340 --> 0:00:57.880
only one time的一个计算图优化的一个执行

19
0:00:57.940 --> 0:01:00.980
来去了解一下具体例行优化是怎么做的

20
0:01:01.680 --> 0:01:05.340
在第二个内容呢就会对计算图优化这一大个内容

21
0:01:05.340 --> 0:01:07.180
来进行详细的展开

22
0:01:07.180 --> 0:01:08.720
所以它叫做详解

23
0:01:08.720 --> 0:01:11.640
也是detail是把所有很多细节展开起来

24
0:01:11.640 --> 0:01:13.680
那这个呢也是最核心的内容

25
0:01:13.680 --> 0:01:16.280
我们留在留在后面给大家慢慢的汇报

26
0:01:17.340 --> 0:01:20.720
现在呢我们来到推定型转换模块里面的图优化

27
0:01:20.820 --> 0:01:22.940
那图优化我们会做很多对计算图做二

28
0:01:22.940 --> 0:01:25.720
算子融合布局转换的算子替换内存优化

29
0:01:25.840 --> 0:01:28.280
非常多不同的类型的优化的parts

30
0:01:28.680 --> 0:01:31.840
现在呢我们看一看整体的一个挑战和架构

31
0:01:31.940 --> 0:01:33.480
在最开始第一节内容的时候

32
0:01:33.480 --> 0:01:35.840
其实已经跟大家详细的普及过

33
0:01:35.840 --> 0:01:38.320
这里面呢我们简单的去重复一下

34
0:01:38.720 --> 0:01:41.920
首先第一个呢就是优化模块的挑战

35
0:01:41.920 --> 0:01:45.180
那优化模块其实我们遇到很多各种各样的勇于

36
0:01:45.280 --> 0:01:47.680
有结构的勇于呢有精度的勇于呢

37
0:01:47.680 --> 0:01:50.240
有算法的勇于还有读写的勇于

38
0:01:50.580 --> 0:01:51.840
针对每一种勇于呢

39
0:01:51.840 --> 0:01:55.680
其实我们在离线优化模块里面是有对应的去处理的

40
0:01:55.780 --> 0:01:59.540
例如针对结构勇于呢我们会对计算图进行优化

41
0:02:00.080 --> 0:02:02.540
算子融合算子替换还有常量折叠

42
0:02:02.620 --> 0:02:05.220
这些常用的计算图的优化的方式

43
0:02:05.220 --> 0:02:08.580
我们就会去去除结构上的勇于

44
0:02:08.680 --> 0:02:11.480
那第二种呢针对算法上面的勇于

45
0:02:11.480 --> 0:02:13.340
就是具体到某个算法了

46
0:02:13.420 --> 0:02:16.280
我们除了统一算子还有计算图的表达

47
0:02:16.280 --> 0:02:18.720
就是统一我们自己的自定义按压之外呢

48
0:02:18.720 --> 0:02:21.620
还会对科诺提升它的一个范化性

49
0:02:21.620 --> 0:02:26.060
把相类似的科诺呢把它提炼成为相同的一些科诺的操作

50
0:02:26.800 --> 0:02:29.820
最后就是针对读写的勇于读写的勇于呢

51
0:02:29.820 --> 0:02:33.900
我们会做一些数据排布的优化还有内存分配的优化

52
0:02:34.420 --> 0:02:37.500
上面四个呢就是我们遇到的一些挑战

53
0:02:38.320 --> 0:02:42.400
针对这些挑战呢我们设计了整个转换模块的架构图

54
0:02:42.400 --> 0:02:46.760
可以看到转换模块分为两层第一层就是图的转换

55
0:02:47.320 --> 0:02:50.860
把从不同AI框架训练得到的计算图呢转换成为

56
0:02:50.860 --> 0:02:54.700
我们推定型的计算图或者推定型自己的按压

57
0:02:55.360 --> 0:03:01.360
第二层呢就是图的优化图的优化也就是我们现在红色框所标识的这一个模块

58
0:03:01.360 --> 0:03:07.160
整体我们会做很多OPFusion的算子量和算子地块布局的转换内存的分配

59
0:03:07.160 --> 0:03:10.200
很多不同的计算图的优化的内容

60
0:03:11.000 --> 0:03:15.700
下面呢我们再来整体的看看转换模块的工作流程

61
0:03:15.700 --> 0:03:20.200
左边这个转换模块呢其实我们在上一集里面已经详细的介绍了特别是

62
0:03:20.200 --> 0:03:24.700
自定义的按压这个按压怎么用怎么做怎么定义我们已经详细介绍过了

63
0:03:24.700 --> 0:03:29.500
在优化模块其实它分开三个第一个呢就是preoptimizer

64
0:03:29.500 --> 0:03:34.300
在预优化阶段呢大部分都是会把常用的代数优化类变成我们计算图的一种优化

65
0:03:34.300 --> 0:03:39.400
那在真正的我们中间优化阶段呢就会做很多跟算子相关的一些优化

66
0:03:39.400 --> 0:03:42.000
也会把神经网络相关的知识融合进来

67
0:03:42.700 --> 0:03:48.400
postoptimizer呢就是最后的一个优化阶段呢我们就会对数据的格式转换内存的布局啊

68
0:03:48.500 --> 0:03:56.100
还有重复算子进行一些合并那这个呢也是最后的优化一般呢我们在推定型里面的优化顺序就是长这个样子的

69
0:03:57.000 --> 0:04:04.100
让我们往下看一看下一个比较核心的内容就是离线优化模块的计算图优化

70
0:04:04.100 --> 0:04:13.900
真正的来到计算图优化这个内容其实呢我们在AI编译器的前端优化它也是针对计算图进行优化的

71
0:04:13.900 --> 0:04:26.400
我们在这里面呢就讲了很多相关的内容有graph的啊呀啦就是我们的图的啊呀啦有算子融合布局转换内存的分配常量则点还有公众知识表达式的消除有非常多的优化的parts

72
0:04:26.800 --> 0:04:36.400
这些呢是基于AI框架去做的也就在我们训练场景会非常的多而训练场景呢其实在在线训练的过程当中呢对时间时间的要求呢没有那么苛刻

73
0:04:36.500 --> 0:04:43.500
所以我们可以在里面呢可以做很多具IT的编译或其他的编译但是呢在推定引擎啊计算图的优化

74
0:04:43.900 --> 0:04:47.800
更多的是采用预先写好的模板而不是通过AI编译器去实现的

75
0:04:47.900 --> 0:04:55.000
如果真的需要通过AI编译器实现其实嗯个人来说呀或者我看到很多项目基本上很少除了TVM之外

76
0:04:55.400 --> 0:05:09.800
但是像TVM这种项目呢它也不是专门针对推定引擎的所以现在呢大部分大家能看到的推定引擎包括探测按压呢onlyswan time呢还有MMN呢MCN这些推定引擎大部分都是已经预先写好的模板进行转换的

77
0:05:09.800 --> 0:05:10.000
转换的目的呢就是减少我们计算图中的勇于的计算于是呢就会衍生很多各种各样的图优化的技术那在特定场景的确实图优化能够给我们带来相当大的计算的收益但是呢基于这种模板的方式呢有个缺点就是需要根据鲜艳的知识去做一个优化的相对比于我们AI网络模型呢确实它有非常非常多的各种的创新所以呢我们没有办法完全

78
0:05:39.800 --> 0:06:09.800
地去掉勇于下面我们来到图优化的具体的方式呢可以看到左边呢我有三个圈圈一二三三个圈圈代表三种不同的图优化的方式这里面呢我呢宗敏就做了一个简单的总结首先第一种就是basic基础的优化基础优化呢主要是涵盖很多保留计算图语义的一些修改就是不改变原来计算图的语义做一些真正的修改例如有常量折叠了勇于节点的消除了还有有限数量的

79
0:06:09.800 --> 0:06:39.800
端子融合呢这些都是属于最基础的优化接着呢还有extend就是扩展性的优化扩展性的优化呢会根据具体的后端例如CPU啊GPU啊还有MPU等具体的后端针对具体或者比较复杂的一些可能进行融合优化的策略最后一个呢就是layout和memory的优化例如呢布局转换优化还有内存排布的优化那这个呢就是最后的一种

80
0:06:39.800 --> 0:06:41.720
我想问一下

81
0:06:41.720 --> 0:06:44.040
嗯你说你说

82
0:06:44.040 --> 0:06:49.360
你这里面三种优化方式跟架构图好像没有一一对应诶

83
0:06:49.360 --> 0:06:53.680
是的这里面的优化方式确实没有跟架构图一一对应起来

84
0:06:53.680 --> 0:06:57.720
我们看一下下面的一个工作的流程图可以看到

85
0:06:57.720 --> 0:07:04.000
像第一个pre-optimized呢就是我们最开始的basic一些最基础的优化的方式

86
0:07:04.000 --> 0:07:09.400
而中间的这个呢就有可能会涉及到最基础的优化方式还有extend的优化方式

87
0:07:09.400 --> 0:07:17.200
最后的这个post-optimized呢会涉及到我们的extend的优化方式还有最后的layout和memory的优化方式

88
0:07:17.200 --> 0:07:25.640
接下来的内容呢我们更多的是通过图优化的方式做一个简单的分类更好的去让大家去学习和了解

89
0:07:25.640 --> 0:07:35.440
当然了这里面的优化的模块的顺序不是固定的大家也可以按照自己的理解还有自己推进引擎的一些特性来对这些parts呢进行排序

90
0:07:35.440 --> 0:07:40.920
下面呢我们看一下ONLYX的one time的一个图优化具体是怎么去使用

91
0:07:40.920 --> 0:07:45.120
这里面呢简单的去讲讲啊具体的使用优势

92
0:07:45.120 --> 0:07:52.280
在ONLYX里面呢这有啊graph optimizer level去选择我们具体对哪一层level进行优化

93
0:07:52.280 --> 0:08:02.520
有basic呢我们刚才讲到的还有extend还有所有当然了我所有优化都不执行这也是可以的这就是ONLYX的一个使用的方式

94
0:08:02.520 --> 0:08:24.360
下面我们来看一下具体的代码是怎么去优势使用这里面呢启动了一个section的对象然后去设置我们的需要优化的level这里面呢就说我需要开通一个extend的优化的方式然后呢就指定优化模型的地址最后呢就导出我们的网络模型执行具体的模型的优化就是这种方式去执行的

95
0:08:25.360 --> 0:08:35.360
回顾一下今天的我们在离线计算图优化模块之里面呢去讲了它遇到的一些挑战还有最后设计的一个架构和流程图

96
0:08:35.360 --> 0:08:54.320
接着呢我们去了解了一下计算图的优化其实分为三种一种是basicextend还有layoutandmemory的优化的方式最后呢我们看了一下ONLYX温泰图优化具体是怎么使用的接下来的内容呢可能会很复杂我们将会分开三个小视频给大家分别的去介绍第二个内容里面的basicextend

97
0:08:54.320 --> 0:09:24.320
layoutandmemory三种的优化的方式虽然推理引擎模型转换的计算图优化呢跟AI兵器的前端优化呢在实现上面呢有着本质的区别但是它们的原理呢是非常的相似所以鼓励大家去看一下AI兵器的前端优化的一些相关的原理和概念当然我在后面呢也会详细的去展开后面详细的展开更多是工程性的一些展开工程性的一些优化的parts好了今天的内容呢就到这里为止谢谢各位摆了个掰

98
0:09:24.320 --> 0:09:32.000
不行了卷的不行了记得一键三连加关注哦所有的内容都会开源在下面这条链接里面摆了个掰

