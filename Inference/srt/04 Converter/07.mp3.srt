0
0:00:00.000 --> 0:00:08.700
Hello大家好,我还是那个ZOMIE

1
0:00:08.700 --> 0:00:14.000
现在我们还是在推理引擎的模型脱机优化里面的计算图优化这个内容

2
0:00:14.000 --> 0:00:20.800
我们在上一集里面呢讲了很多常量值得的一些具体的PASS还有具体的规则

3
0:00:20.800 --> 0:00:24.400
下面呢我们其实又讲了很多勇于节点的消除

4
0:00:24.400 --> 0:00:26.900
其实勇于节点的消除特别特别的多

5
0:00:27.100 --> 0:00:30.200
总结起来都有20多条了,常量值得有十几条了

6
0:00:30.600 --> 0:00:32.500
那接下来的内容呢我们快速的过一下

7
0:00:32.500 --> 0:00:36.600
算子融合、算子替换还有算子迁移

8
0:00:37.100 --> 0:00:39.500
所以说在基础的图优化里面

9
0:00:40.200 --> 0:00:44.100
ZOMIE看到了有些开源项目里面的计算图优化

10
0:00:44.500 --> 0:00:47.500
就有50多甚至上百个PASS

11
0:00:47.500 --> 0:00:49.000
这里面就有非常多的PASS

12
0:00:49.000 --> 0:00:51.200
而这里面的只是一个Basic第一

13
0:00:51.600 --> 0:00:55.400
我们还有三还有非常多的不同的优化的PASS

14
0:00:55.800 --> 0:00:57.400
那现在呢我们马上开始

15
0:00:57.700 --> 0:00:59.400
算子融合这个内容

16
0:01:01.800 --> 0:01:04.800
算子融合这个概念呢其实我觉得大家都知道了

17
0:01:04.800 --> 0:01:09.600
像卷积ADD、卷积MOD、卷积BN、还有VLOOKIP、还有VSHIP

18
0:01:09.600 --> 0:01:12.100
这些基本上都可以做很多融合的方式

19
0:01:12.400 --> 0:01:14.700
这里面呢确实融合的规则呢也有很多

20
0:01:15.000 --> 0:01:18.000
只是OP的一些线性的融合

21
0:01:18.000 --> 0:01:22.700
线性融合呢就是说相邻的OP存在线性上可融合的关系

22
0:01:22.800 --> 0:01:25.000
线性上呢我们可以从数学层面呢

23
0:01:25.300 --> 0:01:27.200
去把它们通过线性的变换

24
0:01:27.200 --> 0:01:28.500
或者数学的线性组合

25
0:01:28.800 --> 0:01:30.900
把它们变成一个相同的算子

26
0:01:30.900 --> 0:01:32.000
或者变成一个大算子

27
0:01:32.500 --> 0:01:35.000
那像这种呢我们叫做OP的线性融合

28
0:01:35.300 --> 0:01:37.000
那从卷积来看呢

29
0:01:37.000 --> 0:01:39.300
卷积BN ADD就卷积BN激活

30
0:01:39.700 --> 0:01:40.900
卷积BN ADD啦

31
0:01:41.400 --> 0:01:42.600
卷积SCALE ADD啦

32
0:01:42.900 --> 0:01:44.300
卷积MOD ADD啦

33
0:01:44.300 --> 0:01:45.800
这种就卷积架很多

34
0:01:45.800 --> 0:01:47.900
其实都可以做很多非常的融合

35
0:01:48.300 --> 0:01:51.700
那假设像BN呢就可以把BN的那些Gamma、Beta

36
0:01:51.900 --> 0:01:54.700
其实融合到我们的卷积参数里面

37
0:01:54.900 --> 0:01:56.200
那卷积参数呢就有两个

38
0:01:56.200 --> 0:01:58.200
一个是Weight一个是Bias

39
0:01:58.600 --> 0:02:00.700
所以说一般呢都可以把很多的数呢

40
0:02:00.700 --> 0:02:04.400
提前算到我们的Weight和Bias里面两个方式

41
0:02:04.600 --> 0:02:06.200
下面我们看一下具体的图啊

42
0:02:07.700 --> 0:02:09.100
我做这一期的时候呢

43
0:02:09.100 --> 0:02:12.400
画图就花了我基本上三四天的时间了

44
0:02:12.400 --> 0:02:13.600
三四天业余的时间

45
0:02:13.800 --> 0:02:14.400
所以还是

46
0:02:15.400 --> 0:02:16.300
图还是很难的

47
0:02:16.300 --> 0:02:18.500
所以欢迎大家去取悦或者拿来用

48
0:02:18.900 --> 0:02:20.300
那声明来源就好了

49
0:02:20.600 --> 0:02:22.900
像我们可以看到卷积BN ADD呢

50
0:02:22.900 --> 0:02:24.100
卷积BN的公式呢

51
0:02:24.100 --> 0:02:25.600
我们可以看到在训练的时候呢

52
0:02:25.600 --> 0:02:27.600
我们就已经训练好Bias跟Mean了嘛

53
0:02:28.200 --> 0:02:29.400
像我们的权重的B呢

54
0:02:29.400 --> 0:02:32.200
就可以通过这种方式呢去重新的计算

55
0:02:32.400 --> 0:02:33.800
那最后呢就变成一个具体的

56
0:02:33.800 --> 0:02:34.700
只有一个卷积了

57
0:02:34.700 --> 0:02:36.400
像激活呢基本上都可以融进去

58
0:02:36.800 --> 0:02:38.900
那好像里面的一个ADD的Const

59
0:02:39.200 --> 0:02:40.900
就可以融合到我们的Bias里面

60
0:02:41.200 --> 0:02:42.600
像SCALE里面的SCALE呢

61
0:02:42.600 --> 0:02:43.600
还有Bias呢

62
0:02:43.600 --> 0:02:44.800
就可以融合到我们的Bias

63
0:02:44.800 --> 0:02:46.000
还有我们的Weight里面

64
0:02:46.300 --> 0:02:47.600
同样的方式卷积呢

65
0:02:47.600 --> 0:02:49.400
可以做非常多的融合

66
0:02:50.100 --> 0:02:52.900
下面我们还是在图算融合里面的

67
0:02:52.900 --> 0:02:55.100
OPS的一种线性的融合

68
0:02:55.300 --> 0:02:56.400
线性融合有非常多

69
0:02:56.400 --> 0:02:58.200
刚才只是举了一些卷积啊

70
0:02:58.200 --> 0:02:59.600
我们可以看到线性融合有

71
0:02:59.600 --> 0:03:00.800
MATMUL加ADD呢

72
0:03:00.800 --> 0:03:02.000
MATMUL加SCALE呢

73
0:03:02.000 --> 0:03:02.900
MEAN加ADD呢

74
0:03:02.900 --> 0:03:04.000
BATCHROM加SCALE呢

75
0:03:04.300 --> 0:03:05.600
MATMUL加BATCHROM呢

76
0:03:05.600 --> 0:03:06.600
MATMUL加ADD

77
0:03:06.600 --> 0:03:09.300
大家觉得可以自己创新很多的Path

78
0:03:09.300 --> 0:03:10.800
或者自己能想到很多的Path

79
0:03:11.000 --> 0:03:12.000
但除了自己想到

80
0:03:12.000 --> 0:03:14.800
更多的是一些实际场景来去驱动的

81
0:03:14.800 --> 0:03:17.400
因为MEAN确实后面可以加很多不同的算子

82
0:03:17.500 --> 0:03:19.600
也做很多的新的创新

83
0:03:19.600 --> 0:03:22.000
那我们可以看到像MATMUL加ADD

84
0:03:22.000 --> 0:03:24.200
可以把ADD这个参数变成GMM

85
0:03:24.200 --> 0:03:25.600
这种相乘

86
0:03:26.500 --> 0:03:28.500
在MATMUL前面有个SCALE或者DIV

87
0:03:28.500 --> 0:03:30.700
确实也可以把它融合进来

88
0:03:30.900 --> 0:03:32.200
像MEAN跟ADD呢

89
0:03:32.200 --> 0:03:33.600
我们就可以把它变成一个

90
0:03:33.600 --> 0:03:36.300
Layer-long的方式做一个简单的融合

91
0:03:36.600 --> 0:03:39.500
所以说算子融合的方式特别特别的多

92
0:03:40.000 --> 0:03:42.300
这里面也是一节是讲不完的

93
0:03:42.300 --> 0:03:43.500
我们只是简单的串一串

94
0:03:43.500 --> 0:03:45.500
给大家知道一下有这么一个事情

95
0:03:45.800 --> 0:03:46.100
就好了

96
0:03:46.100 --> 0:03:47.200
大家听听就完了

97
0:03:47.500 --> 0:03:48.300
当个开心

98
0:03:49.700 --> 0:03:52.300
后面还有OP的一些激活的融合

99
0:03:52.300 --> 0:03:53.500
就卷机加Widlow

100
0:03:53.500 --> 0:03:54.500
卷机加Widlow6

101
0:03:54.600 --> 0:03:56.500
还有卷机加其他的ACK

102
0:03:56.500 --> 0:03:58.000
基本上都可以做融合

103
0:03:58.000 --> 0:03:59.000
这是很重要

104
0:03:59.000 --> 0:03:59.800
为什么要这么做

105
0:03:59.900 --> 0:04:03.000
确实它可以减少我们的第二次仿存

106
0:04:03.800 --> 0:04:06.400
卷机的时候我可能仿存有两三次

107
0:04:06.400 --> 0:04:08.700
第一次去取里面的输入的数据

108
0:04:08.700 --> 0:04:10.400
然后去取我们的Wid

109
0:04:10.400 --> 0:04:11.700
还有去取我们的Bias

110
0:04:11.700 --> 0:04:13.200
相比Wid我们输出之后

111
0:04:13.300 --> 0:04:14.700
又要取我们的输入

112
0:04:14.700 --> 0:04:16.300
这个时候把它融合在一起

113
0:04:16.400 --> 0:04:19.300
确实能够减少我们的仿存的次数

114
0:04:19.300 --> 0:04:21.100
还可以加快我们的计算的时间

115
0:04:21.100 --> 0:04:24.300
不用换出HBM解答的减少了

116
0:04:25.400 --> 0:04:26.600
接着我们可以看一下

117
0:04:26.600 --> 0:04:27.700
看完算子融合之后

118
0:04:27.700 --> 0:04:29.800
我们看看算子的替换

119
0:04:29.800 --> 0:04:31.800
那算子的替换就真的很简单

120
0:04:31.800 --> 0:04:33.000
就一Paste一个Node

121
0:04:33.000 --> 0:04:34.100
或者一Paste一个OD

122
0:04:34.100 --> 0:04:35.300
变成另外一个OD

123
0:04:35.700 --> 0:04:36.900
这里面有几种方式

124
0:04:36.900 --> 0:04:38.100
一种是1 to 1

125
0:04:38.100 --> 0:04:40.100
就一个算子换一个算子

126
0:04:40.100 --> 0:04:42.700
像MacMount就直接换成卷机

127
0:04:43.000 --> 0:04:44.700
这种也是很好的一个优化

128
0:04:45.600 --> 0:04:48.500
像Liner全连接方式变成我们的卷机

129
0:04:48.500 --> 0:04:49.900
就变成一个1x1的卷机

130
0:04:49.900 --> 0:04:51.100
不是通用的卷机

131
0:04:51.300 --> 0:04:53.700
像BN的原理是等价于Scale的

132
0:04:53.700 --> 0:04:56.700
这个时候我们其实也可以通过Scale来去换算

133
0:04:56.700 --> 0:04:59.200
那Scale的计算方式其实更少

134
0:04:59.200 --> 0:05:00.100
像PickWidLoo

135
0:05:00.100 --> 0:05:02.000
我们其实可以在真正推理的时候

136
0:05:02.000 --> 0:05:03.400
换成NickWidLoo

137
0:05:03.400 --> 0:05:05.300
其实真的是不影响我们的精度的

138
0:05:05.300 --> 0:05:07.500
而且有可能精度还有提升

139
0:05:07.500 --> 0:05:11.300
所以说基本上我们的1 to 1的算子替换有非常多

140
0:05:11.300 --> 0:05:13.800
值得注意的就是像MacMount

141
0:05:13.900 --> 0:05:15.500
虽然是1 to 1的替换

142
0:05:15.500 --> 0:05:16.500
替换成卷机

143
0:05:16.500 --> 0:05:17.400
但注意的时候

144
0:05:17.400 --> 0:05:22.200
MacMount的数是一个二维的数据的一个相乘

145
0:05:22.200 --> 0:05:23.200
A乘以B

146
0:05:23.200 --> 0:05:24.700
然后乘以B乘以A

147
0:05:24.700 --> 0:05:26.000
这两个矩阵相乘

148
0:05:26.000 --> 0:05:28.400
就得到了一个A乘以A的矩阵

149
0:05:28.400 --> 0:05:31.200
那这个时候我们卷机数的数据维度

150
0:05:31.200 --> 0:05:33.100
一般都是四维的

151
0:05:33.100 --> 0:05:34.200
NCHW

152
0:05:34.200 --> 0:05:36.500
所以这个时候我们需要对两维的数据

153
0:05:36.500 --> 0:05:37.900
进行一个Wishap

154
0:05:38.200 --> 0:05:40.200
对我们的Input第二个数据

155
0:05:40.200 --> 0:05:41.600
进行一个Transpose

156
0:05:41.700 --> 0:05:43.800
然后再给它进行一个运算的

157
0:05:43.800 --> 0:05:44.700
所以大家注意

158
0:05:44.700 --> 0:05:47.800
像这里面一个全连接变成一个卷机1乘1的

159
0:05:47.800 --> 0:05:49.800
也是需要进行一个Wishap

160
0:05:49.800 --> 0:05:52.300
输出也是进行一个Wishap就好了

161
0:05:52.300 --> 0:05:54.600
简单的改改它的一个内存排布

162
0:05:54.600 --> 0:05:57.700
还有BN我们确实可以把它变成一个Scale的方式

163
0:05:57.700 --> 0:05:59.200
这也是具体的计算

164
0:05:59.200 --> 0:06:01.900
那像PW就变成一个NickWidLoo

165
0:06:01.900 --> 0:06:04.500
看图说话总是这么的简单

166
0:06:04.500 --> 0:06:07.600
我们接下来再看看一些移换多

167
0:06:07.600 --> 0:06:10.200
就是一个算子换成多个算子

168
0:06:10.200 --> 0:06:11.600
能够减少我们推进引擎

169
0:06:11.600 --> 0:06:13.800
要实现很多很多不同的算子

170
0:06:13.800 --> 0:06:16.400
就是一个大颗粒换成一个小的

171
0:06:17.600 --> 0:06:19.400
为什么会出现移换多

172
0:06:19.400 --> 0:06:21.100
有一个算子换成多个算子

173
0:06:21.100 --> 0:06:23.400
是因为我们在推进引擎里面假设

174
0:06:23.400 --> 0:06:24.600
我没有支持这个算子

175
0:06:24.600 --> 0:06:28.700
但这个算子可以通过很多小算子进行拼接的

176
0:06:28.700 --> 0:06:31.100
那这个时候我们的脱机总和优化模块

177
0:06:31.100 --> 0:06:33.400
就可以做一些移换多的方式

178
0:06:34.300 --> 0:06:36.800
像ShuffleNet里面就有ShuffleChannel

179
0:06:36.800 --> 0:06:40.000
ShuffleChannel可能有一些推进引擎没有实现

180
0:06:40.100 --> 0:06:42.200
于是就可以通过Vshape加Premute

181
0:06:42.200 --> 0:06:43.500
这种方式进行组合

182
0:06:43.500 --> 0:06:46.900
像Pet确实有些AI框架会有Pet2

183
0:06:46.900 --> 0:06:48.900
或者其他的方式我们也可以转换

184
0:06:48.900 --> 0:06:52.200
像ShapeN是TensorFlow里面特有的一种算子

185
0:06:52.200 --> 0:06:55.100
我们也可以通过多个Shape的算子进行转换

186
0:06:55.100 --> 0:06:57.500
像Group卷机也可以通过

187
0:06:57.500 --> 0:07:01.100
Slist加Group进行一个替换

188
0:07:01.100 --> 0:07:03.300
所以说里面的方式特别特别的多

189
0:07:03.300 --> 0:07:04.900
我们举简单一个例子

190
0:07:04.900 --> 0:07:06.600
像ShuffleChannel确实可以通过

191
0:07:06.600 --> 0:07:09.700
Vshape加Premute这种方式去进行一个转换

192
0:07:09.800 --> 0:07:11.500
具体的为什么可以这么转

193
0:07:11.500 --> 0:07:13.000
大家也可以推理一下

194
0:07:13.000 --> 0:07:16.300
像这里面的卷机是Group不等于1

195
0:07:16.300 --> 0:07:20.800
我们可以把它Slist成Group跟Number的一个卷机的参数

196
0:07:21.500 --> 0:07:22.200
有Group个

197
0:07:22.200 --> 0:07:24.100
这里面的卷机Group就等于0

198
0:07:24.100 --> 0:07:25.400
就把它Concate到一起

199
0:07:25.400 --> 0:07:26.800
那这种就替换掉了

200
0:07:27.400 --> 0:07:30.000
这样就可以去实现推理引擎里面

201
0:07:30.000 --> 0:07:31.000
本来没有这些算子

202
0:07:31.000 --> 0:07:34.200
但是我们可以通过一些算子的组合进行一个替换

203
0:07:36.500 --> 0:07:38.800
在计算图优化里面的一个Basic

204
0:07:38.900 --> 0:07:40.900
最基础的我们还有最后一个内容

205
0:07:40.900 --> 0:07:42.700
就是算子的前移

206
0:07:42.700 --> 0:07:43.900
算子的前移有比较多

207
0:07:43.900 --> 0:07:45.100
像是Slist跟Modular

208
0:07:45.100 --> 0:07:46.600
还有BitShift跟Reduce

209
0:07:46.600 --> 0:07:49.500
上面这些都可以把它替换掉位置

210
0:07:49.500 --> 0:07:51.300
把它往前挪

211
0:07:52.800 --> 0:07:53.700
而算子前移

212
0:07:53.700 --> 0:07:56.500
其实我觉得大家其实不要觉得

213
0:07:56.500 --> 0:07:58.300
你要去发现规律

214
0:07:58.300 --> 0:07:59.000
更多的时候

215
0:07:59.000 --> 0:08:01.900
我们可以利用算数的一个交换率

216
0:08:01.900 --> 0:08:03.200
去考虑这个问题

217
0:08:03.200 --> 0:08:04.900
我们可不可以这么去操作

218
0:08:04.900 --> 0:08:07.700
就是我们的算数的计算的过程当中

219
0:08:07.700 --> 0:08:09.000
能不能通过交换率

220
0:08:09.000 --> 0:08:10.600
减少我们的数据的传输

221
0:08:10.600 --> 0:08:12.200
还有仿存的次数

222
0:08:12.200 --> 0:08:13.000
这一点很重要

223
0:08:13.000 --> 0:08:16.400
就大家要去真正的站在问题的本质去看问题

224
0:08:16.400 --> 0:08:18.000
而不是为了发现Path

225
0:08:18.000 --> 0:08:19.600
发现创造不同的规律

226
0:08:19.600 --> 0:08:20.800
创造规律

227
0:08:20.800 --> 0:08:24.200
更多的要结合我们的真正的场景和数学的研拟

228
0:08:24.200 --> 0:08:26.100
那下面我们可以看到像这种

229
0:08:26.100 --> 0:08:28.500
就是算子前移的一个很经典的案例

230
0:08:28.500 --> 0:08:29.300
我一个Modular

231
0:08:29.300 --> 0:08:30.000
然后在Slist

232
0:08:30.000 --> 0:08:31.600
我确实可以把它直接Slist掉

233
0:08:31.600 --> 0:08:33.600
然后直接再做一个Modular

234
0:08:33.600 --> 0:08:34.800
那像一个BitShift

235
0:08:34.800 --> 0:08:35.600
还有Reduce

236
0:08:35.700 --> 0:08:37.900
确实可以把它换回来

237
0:08:37.900 --> 0:08:40.300
可以减少我们的通信的次数

238
0:08:42.000 --> 0:08:42.600
好了

239
0:08:42.600 --> 0:08:44.100
今天的内容就到这里为止

240
0:08:44.200 --> 0:08:45.300
我们回顾一下

241
0:08:47.200 --> 0:08:50.800
在计算图的基础图优化的这个模块

242
0:08:50.900 --> 0:08:53.000
我们讲了常量的折叠

243
0:08:53.000 --> 0:08:56.400
把一些不用的常量的就把它合并在一起

244
0:08:56.400 --> 0:08:58.900
其实它有点类似于勇于节点的消除

245
0:08:58.900 --> 0:09:00.600
就把一些常量把它干掉

246
0:09:00.600 --> 0:09:02.900
那接着我们又讲了一些勇于节点的消除

247
0:09:02.900 --> 0:09:05.200
勇于节点的消除有非常多

248
0:09:05.300 --> 0:09:07.300
我列出来的就已经快接近20个了

249
0:09:07.300 --> 0:09:09.300
然后有些算子的融合

250
0:09:09.300 --> 0:09:13.500
把很多零散的算子变成一个大的算子

251
0:09:13.500 --> 0:09:15.000
还有算子的替换

252
0:09:15.000 --> 0:09:16.400
有1对1的替换

253
0:09:16.400 --> 0:09:17.800
也有1对多的替换

254
0:09:17.800 --> 0:09:18.900
那1对多的替换

255
0:09:18.900 --> 0:09:22.000
就有点算子融合的一个逆过程

256
0:09:22.000 --> 0:09:24.300
最后我们还有一些算子的前移

257
0:09:24.300 --> 0:09:27.500
前移的工作确实为了减少我们的仿存的次数

258
0:09:27.500 --> 0:09:28.900
让我们训练的更快

259
0:09:28.900 --> 0:09:30.500
以这个目的作为驱动

260
0:09:30.500 --> 0:09:31.100
好了

261
0:09:31.100 --> 0:09:33.000
今天的内容就到这里为止

262
0:09:33.000 --> 0:09:33.600
谢谢各位

263
0:09:33.600 --> 0:09:34.800
拜拜

264
0:09:35.000 --> 0:09:35.800
卷的不行啦

265
0:09:35.800 --> 0:09:36.600
卷的不行啦

266
0:09:36.600 --> 0:09:38.400
记得一键三连加关注哦

267
0:09:38.400 --> 0:09:41.600
所有的内容都会开源在下面这条链接里面

268
0:09:41.600 --> 0:09:42.900
摆了个掰

