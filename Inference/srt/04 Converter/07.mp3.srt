1
00:00:00,000 --> 00:00:08,700
Hello大家好,我还是那个ZOMIE

2
00:00:08,700 --> 00:00:14,000
现在我们还是在推理引擎的模型脱机优化里面的计算图优化这个内容

3
00:00:14,000 --> 00:00:20,800
我们在上一集里面呢讲了很多常量值得的一些具体的PASS还有具体的规则

4
00:00:20,800 --> 00:00:24,400
下面呢我们其实又讲了很多勇于节点的消除

5
00:00:24,400 --> 00:00:26,900
其实勇于节点的消除特别特别的多

6
00:00:27,100 --> 00:00:30,200
总结起来都有20多条了,常量值得有十几条了

7
00:00:30,600 --> 00:00:32,500
那接下来的内容呢我们快速的过一下

8
00:00:32,500 --> 00:00:36,600
算子融合、算子替换还有算子迁移

9
00:00:37,100 --> 00:00:39,500
所以说在基础的图优化里面

10
00:00:40,200 --> 00:00:44,100
ZOMIE看到了有些开源项目里面的计算图优化

11
00:00:44,500 --> 00:00:47,500
就有50多甚至上百个PASS

12
00:00:47,500 --> 00:00:49,000
这里面就有非常多的PASS

13
00:00:49,000 --> 00:00:51,200
而这里面的只是一个Basic第一

14
00:00:51,600 --> 00:00:55,400
我们还有三还有非常多的不同的优化的PASS

15
00:00:55,800 --> 00:00:57,400
那现在呢我们马上开始

16
00:00:57,700 --> 00:00:59,400
算子融合这个内容

17
00:01:01,800 --> 00:01:04,800
算子融合这个概念呢其实我觉得大家都知道了

18
00:01:04,800 --> 00:01:09,600
像卷积ADD、卷积MOD、卷积BN、还有VLOOKIP、还有VSHIP

19
00:01:09,600 --> 00:01:12,100
这些基本上都可以做很多融合的方式

20
00:01:12,400 --> 00:01:14,700
这里面呢确实融合的规则呢也有很多

21
00:01:15,000 --> 00:01:18,000
只是OP的一些线性的融合

22
00:01:18,000 --> 00:01:22,700
线性融合呢就是说相邻的OP存在线性上可融合的关系

23
00:01:22,800 --> 00:01:25,000
线性上呢我们可以从数学层面呢

24
00:01:25,300 --> 00:01:27,200
去把它们通过线性的变换

25
00:01:27,200 --> 00:01:28,500
或者数学的线性组合

26
00:01:28,800 --> 00:01:30,900
把它们变成一个相同的算子

27
00:01:30,900 --> 00:01:32,000
或者变成一个大算子

28
00:01:32,500 --> 00:01:35,000
那像这种呢我们叫做OP的线性融合

29
00:01:35,300 --> 00:01:37,000
那从卷积来看呢

30
00:01:37,000 --> 00:01:39,300
卷积BN ADD就卷积BN激活

31
00:01:39,700 --> 00:01:40,900
卷积BN ADD啦

32
00:01:41,400 --> 00:01:42,600
卷积SCALE ADD啦

33
00:01:42,900 --> 00:01:44,300
卷积MOD ADD啦

34
00:01:44,300 --> 00:01:45,800
这种就卷积架很多

35
00:01:45,800 --> 00:01:47,900
其实都可以做很多非常的融合

36
00:01:48,300 --> 00:01:51,700
那假设像BN呢就可以把BN的那些Gamma、Beta

37
00:01:51,900 --> 00:01:54,700
其实融合到我们的卷积参数里面

38
00:01:54,900 --> 00:01:56,200
那卷积参数呢就有两个

39
00:01:56,200 --> 00:01:58,200
一个是Weight一个是Bias

40
00:01:58,600 --> 00:02:00,700
所以说一般呢都可以把很多的数呢

41
00:02:00,700 --> 00:02:04,400
提前算到我们的Weight和Bias里面两个方式

42
00:02:04,600 --> 00:02:06,200
下面我们看一下具体的图啊

43
00:02:07,700 --> 00:02:09,100
我做这一期的时候呢

44
00:02:09,100 --> 00:02:12,400
画图就花了我基本上三四天的时间了

45
00:02:12,400 --> 00:02:13,600
三四天业余的时间

46
00:02:13,800 --> 00:02:14,400
所以还是

47
00:02:15,400 --> 00:02:16,300
图还是很难的

48
00:02:16,300 --> 00:02:18,500
所以欢迎大家去取悦或者拿来用

49
00:02:18,900 --> 00:02:20,300
那声明来源就好了

50
00:02:20,600 --> 00:02:22,900
像我们可以看到卷积BN ADD呢

51
00:02:22,900 --> 00:02:24,100
卷积BN的公式呢

52
00:02:24,100 --> 00:02:25,600
我们可以看到在训练的时候呢

53
00:02:25,600 --> 00:02:27,600
我们就已经训练好Bias跟Mean了嘛

54
00:02:28,200 --> 00:02:29,400
像我们的权重的B呢

55
00:02:29,400 --> 00:02:32,200
就可以通过这种方式呢去重新的计算

56
00:02:32,400 --> 00:02:33,800
那最后呢就变成一个具体的

57
00:02:33,800 --> 00:02:34,700
只有一个卷积了

58
00:02:34,700 --> 00:02:36,400
像激活呢基本上都可以融进去

59
00:02:36,800 --> 00:02:38,900
那好像里面的一个ADD的Const

60
00:02:39,200 --> 00:02:40,900
就可以融合到我们的Bias里面

61
00:02:41,200 --> 00:02:42,600
像SCALE里面的SCALE呢

62
00:02:42,600 --> 00:02:43,600
还有Bias呢

63
00:02:43,600 --> 00:02:44,800
就可以融合到我们的Bias

64
00:02:44,800 --> 00:02:46,000
还有我们的Weight里面

65
00:02:46,300 --> 00:02:47,600
同样的方式卷积呢

66
00:02:47,600 --> 00:02:49,400
可以做非常多的融合

67
00:02:50,100 --> 00:02:52,900
下面我们还是在图算融合里面的

68
00:02:52,900 --> 00:02:55,100
OPS的一种线性的融合

69
00:02:55,300 --> 00:02:56,400
线性融合有非常多

70
00:02:56,400 --> 00:02:58,200
刚才只是举了一些卷积啊

71
00:02:58,200 --> 00:02:59,600
我们可以看到线性融合有

72
00:02:59,600 --> 00:03:00,800
MATMUL加ADD呢

73
00:03:00,800 --> 00:03:02,000
MATMUL加SCALE呢

74
00:03:02,000 --> 00:03:02,900
MEAN加ADD呢

75
00:03:02,900 --> 00:03:04,000
BATCHROM加SCALE呢

76
00:03:04,300 --> 00:03:05,600
MATMUL加BATCHROM呢

77
00:03:05,600 --> 00:03:06,600
MATMUL加ADD

78
00:03:06,600 --> 00:03:09,300
大家觉得可以自己创新很多的Path

79
00:03:09,300 --> 00:03:10,800
或者自己能想到很多的Path

80
00:03:11,000 --> 00:03:12,000
但除了自己想到

81
00:03:12,000 --> 00:03:14,800
更多的是一些实际场景来去驱动的

82
00:03:14,800 --> 00:03:17,400
因为MEAN确实后面可以加很多不同的算子

83
00:03:17,500 --> 00:03:19,600
也做很多的新的创新

84
00:03:19,600 --> 00:03:22,000
那我们可以看到像MATMUL加ADD

85
00:03:22,000 --> 00:03:24,200
可以把ADD这个参数变成GMM

86
00:03:24,200 --> 00:03:25,600
这种相乘

87
00:03:26,500 --> 00:03:28,500
在MATMUL前面有个SCALE或者DIV

88
00:03:28,500 --> 00:03:30,700
确实也可以把它融合进来

89
00:03:30,900 --> 00:03:32,200
像MEAN跟ADD呢

90
00:03:32,200 --> 00:03:33,600
我们就可以把它变成一个

91
00:03:33,600 --> 00:03:36,300
Layer-long的方式做一个简单的融合

92
00:03:36,600 --> 00:03:39,500
所以说算子融合的方式特别特别的多

93
00:03:40,000 --> 00:03:42,300
这里面也是一节是讲不完的

94
00:03:42,300 --> 00:03:43,500
我们只是简单的串一串

95
00:03:43,500 --> 00:03:45,500
给大家知道一下有这么一个事情

96
00:03:45,800 --> 00:03:46,100
就好了

97
00:03:46,100 --> 00:03:47,200
大家听听就完了

98
00:03:47,500 --> 00:03:48,300
当个开心

99
00:03:49,700 --> 00:03:52,300
后面还有OP的一些激活的融合

100
00:03:52,300 --> 00:03:53,500
就卷机加Widlow

101
00:03:53,500 --> 00:03:54,500
卷机加Widlow6

102
00:03:54,600 --> 00:03:56,500
还有卷机加其他的ACK

103
00:03:56,500 --> 00:03:58,000
基本上都可以做融合

104
00:03:58,000 --> 00:03:59,000
这是很重要

105
00:03:59,000 --> 00:03:59,800
为什么要这么做

106
00:03:59,900 --> 00:04:03,000
确实它可以减少我们的第二次仿存

107
00:04:03,800 --> 00:04:06,400
卷机的时候我可能仿存有两三次

108
00:04:06,400 --> 00:04:08,700
第一次去取里面的输入的数据

109
00:04:08,700 --> 00:04:10,400
然后去取我们的Wid

110
00:04:10,400 --> 00:04:11,700
还有去取我们的Bias

111
00:04:11,700 --> 00:04:13,200
相比Wid我们输出之后

112
00:04:13,300 --> 00:04:14,700
又要取我们的输入

113
00:04:14,700 --> 00:04:16,300
这个时候把它融合在一起

114
00:04:16,400 --> 00:04:19,300
确实能够减少我们的仿存的次数

115
00:04:19,300 --> 00:04:21,100
还可以加快我们的计算的时间

116
00:04:21,100 --> 00:04:24,300
不用换出HBM解答的减少了

117
00:04:25,400 --> 00:04:26,600
接着我们可以看一下

118
00:04:26,600 --> 00:04:27,700
看完算子融合之后

119
00:04:27,700 --> 00:04:29,800
我们看看算子的替换

120
00:04:29,800 --> 00:04:31,800
那算子的替换就真的很简单

121
00:04:31,800 --> 00:04:33,000
就一Paste一个Node

122
00:04:33,000 --> 00:04:34,100
或者一Paste一个OD

123
00:04:34,100 --> 00:04:35,300
变成另外一个OD

124
00:04:35,700 --> 00:04:36,900
这里面有几种方式

125
00:04:36,900 --> 00:04:38,100
一种是1 to 1

126
00:04:38,100 --> 00:04:40,100
就一个算子换一个算子

127
00:04:40,100 --> 00:04:42,700
像MacMount就直接换成卷机

128
00:04:43,000 --> 00:04:44,700
这种也是很好的一个优化

129
00:04:45,600 --> 00:04:48,500
像Liner全连接方式变成我们的卷机

130
00:04:48,500 --> 00:04:49,900
就变成一个1x1的卷机

131
00:04:49,900 --> 00:04:51,100
不是通用的卷机

132
00:04:51,300 --> 00:04:53,700
像BN的原理是等价于Scale的

133
00:04:53,700 --> 00:04:56,700
这个时候我们其实也可以通过Scale来去换算

134
00:04:56,700 --> 00:04:59,200
那Scale的计算方式其实更少

135
00:04:59,200 --> 00:05:00,100
像PickWidLoo

136
00:05:00,100 --> 00:05:02,000
我们其实可以在真正推理的时候

137
00:05:02,000 --> 00:05:03,400
换成NickWidLoo

138
00:05:03,400 --> 00:05:05,300
其实真的是不影响我们的精度的

139
00:05:05,300 --> 00:05:07,500
而且有可能精度还有提升

140
00:05:07,500 --> 00:05:11,300
所以说基本上我们的1 to 1的算子替换有非常多

141
00:05:11,300 --> 00:05:13,800
值得注意的就是像MacMount

142
00:05:13,900 --> 00:05:15,500
虽然是1 to 1的替换

143
00:05:15,500 --> 00:05:16,500
替换成卷机

144
00:05:16,500 --> 00:05:17,400
但注意的时候

145
00:05:17,400 --> 00:05:22,200
MacMount的数是一个二维的数据的一个相乘

146
00:05:22,200 --> 00:05:23,200
A乘以B

147
00:05:23,200 --> 00:05:24,700
然后乘以B乘以A

148
00:05:24,700 --> 00:05:26,000
这两个矩阵相乘

149
00:05:26,000 --> 00:05:28,400
就得到了一个A乘以A的矩阵

150
00:05:28,400 --> 00:05:31,200
那这个时候我们卷机数的数据维度

151
00:05:31,200 --> 00:05:33,100
一般都是四维的

152
00:05:33,100 --> 00:05:34,200
NCHW

153
00:05:34,200 --> 00:05:36,500
所以这个时候我们需要对两维的数据

154
00:05:36,500 --> 00:05:37,900
进行一个Wishap

155
00:05:38,200 --> 00:05:40,200
对我们的Input第二个数据

156
00:05:40,200 --> 00:05:41,600
进行一个Transpose

157
00:05:41,700 --> 00:05:43,800
然后再给它进行一个运算的

158
00:05:43,800 --> 00:05:44,700
所以大家注意

159
00:05:44,700 --> 00:05:47,800
像这里面一个全连接变成一个卷机1乘1的

160
00:05:47,800 --> 00:05:49,800
也是需要进行一个Wishap

161
00:05:49,800 --> 00:05:52,300
输出也是进行一个Wishap就好了

162
00:05:52,300 --> 00:05:54,600
简单的改改它的一个内存排布

163
00:05:54,600 --> 00:05:57,700
还有BN我们确实可以把它变成一个Scale的方式

164
00:05:57,700 --> 00:05:59,200
这也是具体的计算

165
00:05:59,200 --> 00:06:01,900
那像PW就变成一个NickWidLoo

166
00:06:01,900 --> 00:06:04,500
看图说话总是这么的简单

167
00:06:04,500 --> 00:06:07,600
我们接下来再看看一些移换多

168
00:06:07,600 --> 00:06:10,200
就是一个算子换成多个算子

169
00:06:10,200 --> 00:06:11,600
能够减少我们推进引擎

170
00:06:11,600 --> 00:06:13,800
要实现很多很多不同的算子

171
00:06:13,800 --> 00:06:16,400
就是一个大颗粒换成一个小的

172
00:06:17,600 --> 00:06:19,400
为什么会出现移换多

173
00:06:19,400 --> 00:06:21,100
有一个算子换成多个算子

174
00:06:21,100 --> 00:06:23,400
是因为我们在推进引擎里面假设

175
00:06:23,400 --> 00:06:24,600
我没有支持这个算子

176
00:06:24,600 --> 00:06:28,700
但这个算子可以通过很多小算子进行拼接的

177
00:06:28,700 --> 00:06:31,100
那这个时候我们的脱机总和优化模块

178
00:06:31,100 --> 00:06:33,400
就可以做一些移换多的方式

179
00:06:34,300 --> 00:06:36,800
像ShuffleNet里面就有ShuffleChannel

180
00:06:36,800 --> 00:06:40,000
ShuffleChannel可能有一些推进引擎没有实现

181
00:06:40,100 --> 00:06:42,200
于是就可以通过Vshape加Premute

182
00:06:42,200 --> 00:06:43,500
这种方式进行组合

183
00:06:43,500 --> 00:06:46,900
像Pet确实有些AI框架会有Pet2

184
00:06:46,900 --> 00:06:48,900
或者其他的方式我们也可以转换

185
00:06:48,900 --> 00:06:52,200
像ShapeN是TensorFlow里面特有的一种算子

186
00:06:52,200 --> 00:06:55,100
我们也可以通过多个Shape的算子进行转换

187
00:06:55,100 --> 00:06:57,500
像Group卷机也可以通过

188
00:06:57,500 --> 00:07:01,100
Slist加Group进行一个替换

189
00:07:01,100 --> 00:07:03,300
所以说里面的方式特别特别的多

190
00:07:03,300 --> 00:07:04,900
我们举简单一个例子

191
00:07:04,900 --> 00:07:06,600
像ShuffleChannel确实可以通过

192
00:07:06,600 --> 00:07:09,700
Vshape加Premute这种方式去进行一个转换

193
00:07:09,800 --> 00:07:11,500
具体的为什么可以这么转

194
00:07:11,500 --> 00:07:13,000
大家也可以推理一下

195
00:07:13,000 --> 00:07:16,300
像这里面的卷机是Group不等于1

196
00:07:16,300 --> 00:07:20,800
我们可以把它Slist成Group跟Number的一个卷机的参数

197
00:07:21,500 --> 00:07:22,200
有Group个

198
00:07:22,200 --> 00:07:24,100
这里面的卷机Group就等于0

199
00:07:24,100 --> 00:07:25,400
就把它Concate到一起

200
00:07:25,400 --> 00:07:26,800
那这种就替换掉了

201
00:07:27,400 --> 00:07:30,000
这样就可以去实现推理引擎里面

202
00:07:30,000 --> 00:07:31,000
本来没有这些算子

203
00:07:31,000 --> 00:07:34,200
但是我们可以通过一些算子的组合进行一个替换

204
00:07:36,500 --> 00:07:38,800
在计算图优化里面的一个Basic

205
00:07:38,900 --> 00:07:40,900
最基础的我们还有最后一个内容

206
00:07:40,900 --> 00:07:42,700
就是算子的前移

207
00:07:42,700 --> 00:07:43,900
算子的前移有比较多

208
00:07:43,900 --> 00:07:45,100
像是Slist跟Modular

209
00:07:45,100 --> 00:07:46,600
还有BitShift跟Reduce

210
00:07:46,600 --> 00:07:49,500
上面这些都可以把它替换掉位置

211
00:07:49,500 --> 00:07:51,300
把它往前挪

212
00:07:52,800 --> 00:07:53,700
而算子前移

213
00:07:53,700 --> 00:07:56,500
其实我觉得大家其实不要觉得

214
00:07:56,500 --> 00:07:58,300
你要去发现规律

215
00:07:58,300 --> 00:07:59,000
更多的时候

216
00:07:59,000 --> 00:08:01,900
我们可以利用算数的一个交换率

217
00:08:01,900 --> 00:08:03,200
去考虑这个问题

218
00:08:03,200 --> 00:08:04,900
我们可不可以这么去操作

219
00:08:04,900 --> 00:08:07,700
就是我们的算数的计算的过程当中

220
00:08:07,700 --> 00:08:09,000
能不能通过交换率

221
00:08:09,000 --> 00:08:10,600
减少我们的数据的传输

222
00:08:10,600 --> 00:08:12,200
还有仿存的次数

223
00:08:12,200 --> 00:08:13,000
这一点很重要

224
00:08:13,000 --> 00:08:16,400
就大家要去真正的站在问题的本质去看问题

225
00:08:16,400 --> 00:08:18,000
而不是为了发现Path

226
00:08:18,000 --> 00:08:19,600
发现创造不同的规律

227
00:08:19,600 --> 00:08:20,800
创造规律

228
00:08:20,800 --> 00:08:24,200
更多的要结合我们的真正的场景和数学的研拟

229
00:08:24,200 --> 00:08:26,100
那下面我们可以看到像这种

230
00:08:26,100 --> 00:08:28,500
就是算子前移的一个很经典的案例

231
00:08:28,500 --> 00:08:29,300
我一个Modular

232
00:08:29,300 --> 00:08:30,000
然后在Slist

233
00:08:30,000 --> 00:08:31,600
我确实可以把它直接Slist掉

234
00:08:31,600 --> 00:08:33,600
然后直接再做一个Modular

235
00:08:33,600 --> 00:08:34,800
那像一个BitShift

236
00:08:34,800 --> 00:08:35,600
还有Reduce

237
00:08:35,700 --> 00:08:37,900
确实可以把它换回来

238
00:08:37,900 --> 00:08:40,300
可以减少我们的通信的次数

239
00:08:42,000 --> 00:08:42,600
好了

240
00:08:42,600 --> 00:08:44,100
今天的内容就到这里为止

241
00:08:44,200 --> 00:08:45,300
我们回顾一下

242
00:08:47,200 --> 00:08:50,800
在计算图的基础图优化的这个模块

243
00:08:50,900 --> 00:08:53,000
我们讲了常量的折叠

244
00:08:53,000 --> 00:08:56,400
把一些不用的常量的就把它合并在一起

245
00:08:56,400 --> 00:08:58,900
其实它有点类似于勇于节点的消除

246
00:08:58,900 --> 00:09:00,600
就把一些常量把它干掉

247
00:09:00,600 --> 00:09:02,900
那接着我们又讲了一些勇于节点的消除

248
00:09:02,900 --> 00:09:05,200
勇于节点的消除有非常多

249
00:09:05,300 --> 00:09:07,300
我列出来的就已经快接近20个了

250
00:09:07,300 --> 00:09:09,300
然后有些算子的融合

251
00:09:09,300 --> 00:09:13,500
把很多零散的算子变成一个大的算子

252
00:09:13,500 --> 00:09:15,000
还有算子的替换

253
00:09:15,000 --> 00:09:16,400
有1对1的替换

254
00:09:16,400 --> 00:09:17,800
也有1对多的替换

255
00:09:17,800 --> 00:09:18,900
那1对多的替换

256
00:09:18,900 --> 00:09:22,000
就有点算子融合的一个逆过程

257
00:09:22,000 --> 00:09:24,300
最后我们还有一些算子的前移

258
00:09:24,300 --> 00:09:27,500
前移的工作确实为了减少我们的仿存的次数

259
00:09:27,500 --> 00:09:28,900
让我们训练的更快

260
00:09:28,900 --> 00:09:30,500
以这个目的作为驱动

261
00:09:30,500 --> 00:09:31,100
好了

262
00:09:31,100 --> 00:09:33,000
今天的内容就到这里为止

263
00:09:33,000 --> 00:09:33,600
谢谢各位

264
00:09:33,600 --> 00:09:34,800
拜拜

265
00:09:35,000 --> 00:09:35,800
卷的不行啦

266
00:09:35,800 --> 00:09:36,600
卷的不行啦

267
00:09:36,600 --> 00:09:38,400
记得一键三连加关注哦

268
00:09:38,400 --> 00:09:41,600
所有的内容都会开源在下面这条链接里面

269
00:09:41,600 --> 00:09:42,900
摆了个掰

